# rerank_inplace_by_config.py  (progress-logging ê°•í™”íŒ)
import re
import os
import json
import argparse
import time
from typing import List, Tuple

import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer


# --------------------------
# Config & Columns
# --------------------------
def log(msg: str):
    print(msg, flush=True)


def load_config(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def find_article_cols(
    df: pd.DataFrame, pattern=r"^prediction_retrieved_article_name_(\d+)$"
) -> List[str]:
    rx = re.compile(pattern)
    cols = [c for c in df.columns if rx.match(c)]
    if not cols:
        raise ValueError(
            "prediction_retrieved_article_name_{n} í˜•íƒœì˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        )
    cols = sorted(cols, key=lambda c: int(rx.match(c).group(1)))
    return cols


# --------------------------
# Parsing & Embedding Text
# --------------------------
TITLE_RX = re.compile(r"^\s*Title\s*:\s*(.+?)\s*$", re.IGNORECASE | re.MULTILINE)
ABSTRACT_RX = re.compile(
    r"^\s*Abstract\s*:\s*(.+?)(?=^\s*[A-Za-z][A-Za-z0-9_\- ]{0,20}\s*:|\Z)",
    re.IGNORECASE | re.MULTILINE | re.DOTALL,
)


def extract_title_abstract(text: str) -> Tuple[str, str]:
    if not isinstance(text, str):
        return "", ""
    title_match = TITLE_RX.search(text)
    abstract_match = ABSTRACT_RX.search(text)
    title = title_match.group(1).strip() if title_match else ""
    abstract = abstract_match.group(1).strip() if abstract_match else ""
    return title, abstract


def build_embedding_text(
    candidate_text: str, embedding_mode: str, fallback_fields: List[str] = None
) -> str:
    """
    embedding_mode ì˜ˆ: '3*title+abstract'
    - Title/Abstract íŒŒì‹± ì‹¤íŒ¨ ì‹œ: fallback_fields ë¼ë²¨ ë¸”ë¡ì„ ìˆœì„œëŒ€ë¡œ ë¶™ì„.
    - ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ ì›ë¬¸ ì „ì²´ ì‚¬ìš©.
    """
    title, abstract = extract_title_abstract(candidate_text)

    if embedding_mode.lower() == "3*title+abstract":
        if title or abstract:
            return f"{title} {title} {title} {abstract}".strip()

    if fallback_fields:
        parts = []
        for label in fallback_fields:
            rx = re.compile(
                rf"^\s*{re.escape(label)}\s*:\s*(.+?)(?=^\s*[A-Za-z].*?:|\Z)",
                re.IGNORECASE | re.MULTILINE | re.DOTALL,
            )
            m = rx.search(candidate_text or "")
            if m:
                parts.append(m.group(1).strip())
        if parts:
            return " ".join(parts)

    return candidate_text or ""


# --------------------------
# Embedding & Similarity
# --------------------------
def encode_texts(
    model: SentenceTransformer, texts: List[str], batch_size: int = 64, desc: str = ""
) -> np.ndarray:
    if desc:
        log(f"ğŸ§® Encoding {len(texts)} items [{desc}] (batch={batch_size})â€¦")
    return model.encode(
        texts,
        convert_to_numpy=True,
        batch_size=batch_size,
        show_progress_bar=True,  # ì§„í–‰ë°” ON
        normalize_embeddings=True,  # ì •ê·œí™” â†’ dot == cosine
    )


def cosine_sim_vector_to_matrix(vec: np.ndarray, mat: np.ndarray) -> np.ndarray:
    # vec: (d,), mat: (N, d)  -> (N,)
    return mat @ vec  # ì´ë¯¸ ì •ê·œí™”ë¨


# --------------------------
# Main Rerank
# --------------------------
def rerank_inplace(
    df: pd.DataFrame,
    question_col: str,
    article_cols: List[str],
    model_name: str,
    embedding_mode: str,
    batch_size: int = 64,
    text_fields_from_config: List[str] = None,
) -> pd.DataFrame:
    start = time.time()

    if question_col not in df.columns:
        raise ValueError(f"'{question_col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ëª¨ë¸ ë¡œë“œ
    log(f"ğŸ§  Loading model: {model_name}")
    model = SentenceTransformer(model_name, trust_remote_code=True)

    # ì§ˆë¬¸ ì„ë² ë”©
    questions = df[question_col].fillna("").astype(str).tolist()
    q_start = time.time()
    q_embs = encode_texts(
        model, questions, batch_size=batch_size, desc="questions"
    )  # (R, d)
    log(f"âœ… Questions encoded in {time.time() - q_start:.2f}s")

    # ê° í–‰ë§ˆë‹¤ í›„ë³´ 50ê°œ íŒŒì‹± â†’ ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„±
    log("ğŸ§µ Building candidate embedding texts per row (parsing Title/Abstract)â€¦")
    build_start = time.time()
    cand_texts_per_row: List[List[str]] = []
    for r_i, (_, row) in enumerate(df.iterrows(), 1):
        row_texts = []
        for c in article_cols:
            raw_text = row.get(c, "")
            emb_text = build_embedding_text(
                str(raw_text),
                embedding_mode=embedding_mode,
                fallback_fields=(text_fields_from_config or []),
            )
            row_texts.append(emb_text)
        cand_texts_per_row.append(row_texts)
        if r_i % 200 == 0 or r_i == len(df):
            log(f"  â€¢ parsed {r_i}/{len(df)} rows")
    log(f"âœ… Candidate texts built in {time.time() - build_start:.2f}s")

    # í›„ë³´ ì„ë² ë”© + ì¬ì •ë ¬
    log("ğŸ” Reranking within row (placing best at _1 â€¦ worst at _50)â€¦")
    R = len(df)
    for i in range(R):
        # í›„ë³´ ì„ë² ë”© (í–‰ ë‹¨ìœ„)
        c_start = time.time()
        cand_texts = cand_texts_per_row[i]
        cand_embs = encode_texts(
            model, cand_texts, batch_size=batch_size, desc=f"row {i + 1}/{R}"
        )  # (C, d)

        # ìœ ì‚¬ë„ ê³„ì‚° â†’ ë‚´ë¦¼ì°¨ìˆœ ì¸ë±ìŠ¤
        sims = cosine_sim_vector_to_matrix(q_embs[i], cand_embs)  # (C,)
        order = np.argsort(-sims)

        # ê°™ì€ í–‰ ë‚´ë¶€ì—ì„œ article_cols ìˆœì„œë§Œ ë°”ê¿” ë¼ìš°ê¸°
        original_values = [df.at[df.index[i], c] for c in article_cols]
        reordered_values = [original_values[idx] for idx in order]
        for j, col in enumerate(article_cols):
            df.at[df.index[i], col] = reordered_values[j]

        # ì§„í–‰ ë¡œê·¸
        took = time.time() - c_start
        if (i + 1) % 50 == 0 or (i + 1) == R:
            log(f"  â€¢ processed {i + 1}/{R} rows (last row took {took:.2f}s)")

    log(f"âœ… Reranking done in {time.time() - start:.2f}s total")
    return df


def main():
    parser = argparse.ArgumentParser(
        description="config ê¸°ë°˜ ì„ë² ë”© ë°©ì‹ìœ¼ë¡œ í–‰ ë‚´ë¶€ í›„ë³´(1~50) ì¬ì •ë ¬(in-place)"
    )
    parser.add_argument("--input", required=True, help="ì…ë ¥ íŒŒì¼ ê²½ë¡œ (CSV)")
    parser.add_argument(
        "--output",
        default=None,
        help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì§€ì • ì—†ìœ¼ë©´ _reranked_inplace.csv)",
    )
    parser.add_argument(
        "--config",
        default="/workspace/configs/query_encoder/config_gte-multilingual-base.json",
        help="ì„ë² ë”© ì„¤ì • JSON ê²½ë¡œ",
    )
    parser.add_argument("--question_col", default="Question", help="ì§ˆë¬¸ ì»¬ëŸ¼ëª…")
    parser.add_argument(
        "--pattern",
        default=r"^prediction_retrieved_article_name_(\d+)$",
        help="í›„ë³´ ì»¬ëŸ¼ ì •ê·œì‹",
    )
    parser.add_argument("--batch_size", type=int, default=64, help="ì„ë² ë”© ë°°ì¹˜ ì‚¬ì´ì¦ˆ")
    args = parser.parse_args()

    # ë¡œë“œ
    log(f"ğŸ“‚ Loading CSV: {args.input}")
    df = pd.read_csv(args.input)
    log(f"ğŸ“ Rows: {len(df)}, Columns: {len(df.columns)}")

    cfg = load_config(args.config)
    model_name = cfg.get("model_name", "Alibaba-NLP/gte-multilingual-base")
    embedding_mode = cfg.get("embedding_mode", "3*title+abstract")
    text_fields = cfg.get("text_fields", ["context"])

    article_cols = find_article_cols(df, args.pattern)
    log(
        f"ğŸ” Candidate columns: {len(article_cols)} ({article_cols[0]}..{article_cols[-1]})"
    )
    log(f"âš™ï¸ Embedding mode: {embedding_mode}")

    # ì¬ì •ë ¬
    df_out = rerank_inplace(
        df=df,
        question_col=args.question_col,
        article_cols=article_cols,
        model_name=model_name,
        embedding_mode=embedding_mode,
        batch_size=args.batch_size,
        text_fields_from_config=text_fields,
    )

    # ì €ì¥
    if args.output:
        out_path = args.output
    else:
        stem, ext = os.path.splitext(args.input)
        out_path = f"{stem}_reranked_inplace.csv"
    df_out.to_csv(out_path, index=False, encoding="utf-8-sig")
    log(f"âœ… Saved: {out_path}")
    log(f"â€¢ Model: {model_name}")
    log(
        f"â€¢ Reordered columns: {len(article_cols)} ({article_cols[0]}..{article_cols[-1]})"
    )


if __name__ == "__main__":
    main()
