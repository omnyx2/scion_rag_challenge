{
  "id": "row_000015",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-10T23:48:40.747949+09:00",
  "trial_id": "407e777d",
  "queries": [
    {
      "query": "What are the key findings of the socio-technical evaluation on Big Data developmental processes and the factors influencing user adoption?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6095267534255981,
          "doc_id": "NART117776930",
          "title": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk",
          "abstract": "<P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "source": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk <P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "author": "Shakeri Hossein Abad, Zahra;Butler, Gregory P;Thompson, Wendy;Lee, Joon;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 2,
          "score": 0.6017051339149475,
          "doc_id": "NPAP12463036",
          "title": "Exploring Crowd Consistency in a Mechanical Turk Survey",
          "abstract": "<P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "source": "Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey <P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "author": "Sun, Peng;Stolee, Kathryn T.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 3,
          "score": 0.5929315090179443,
          "doc_id": "JAKO202116057056093",
          "title": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로",
          "abstract": "본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "source": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "author": "차현주;권상희;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 4,
          "score": 0.5832434892654419,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "author": "Pavlick, Ellie;Post, Matt;Irvine, Ann;Kachaev, Dmitry;Callison-Burch, Chris;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 5,
          "score": 0.5832293629646301,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "author": "De Lurgio II, Stephen A.;Young, Amber;Steelman, Zachary R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 6,
          "score": 0.5809273719787598,
          "doc_id": "NART121336460",
          "title": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples",
          "abstract": "<P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "source": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples <P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "author": "Weigold, Arne;Weigold, Ingrid K.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 7,
          "score": 0.5793218612670898,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "author": "Bohannon, John",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 8,
          "score": 0.572426438331604,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;Ipeirotis, Panagiotis G.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 9,
          "score": 0.5701112747192383,
          "doc_id": "NART87817032",
          "title": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative",
          "abstract": "<P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "source": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative <P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "author": "Tosti-Kharas, Jennifer;Conley, Caryn;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 10,
          "score": 0.5665075778961182,
          "doc_id": "NART77189173",
          "title": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks",
          "abstract": "<P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "source": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks <P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "author": "Gomez, Steven R.;Jianu, Radu;Cabeen, Ryan;Guo, Hua;Laidlaw, David H.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 11,
          "score": 0.5608202815055847,
          "doc_id": "JAKO202433335467568",
          "title": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석",
          "abstract": "This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "source": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "author": "민준홍;김미량;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 12,
          "score": 0.5582288503646851,
          "doc_id": "NART109637313",
          "title": "Annotator Rationales for Labeling Tasks in Crowdsourcing",
          "abstract": "<P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "source": "Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing <P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "author": "Kutlu, Mucahid;McDonnell, Tyler;Lease, Matthew;Elsayed, Tamer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 13,
          "score": 0.5541390180587769,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "author": "Schnoebelen, Tyler;Kuperman, Victor;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 14,
          "score": 0.5481353998184204,
          "doc_id": "NPAP13430839",
          "title": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion",
          "abstract": "<P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "source": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion <P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "author": "Wu, Yu Hsuan;Wu, Eric Hsiaokuang;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 15,
          "score": 0.5454936027526855,
          "doc_id": "NART74131061",
          "title": "Lessons Learned from Crowdsourcing Complex Engineering Tasks",
          "abstract": "<P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "source": "Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks <P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "author": "Staffelbach, Matthew;Sempolinski, Peter;Kijewski-Correa, Tracy;Thain, Douglas;Wei, Daniel;Kareem, Ahsan;Madey, Gregory;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 16,
          "score": 0.5449417233467102,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "author": "Shapiro, Danielle N.;Chandler, Jesse;Mueller, Pam A.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 17,
          "score": 0.5420547127723694,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "author": "Rouse, S.V.",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 18,
          "score": 0.5419468879699707,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "author": "Dai, P.;Lin, C.H.;Mausam;Weld, D.S.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 19,
          "score": 0.5417848229408264,
          "doc_id": "NART69743055",
          "title": "Crowdsourcing content analysis for managerial research",
          "abstract": "<P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "source": "Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research <P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "author": "Conley, Caryn;Tosti-Kharas, Jennifer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 20,
          "score": 0.5356940031051636,
          "doc_id": "DIKO0016959108",
          "title": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구",
          "abstract": "본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "source": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "author": "이승현",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 21,
          "score": 0.5334810018539429,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "author": "Lewis, Andrew R.;Djupe, Paul A.;Mockabee, Stephen T.;Su&#8208;Ya Wu, Joshua;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 22,
          "score": 0.532053530216217,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "author": "Tran, M.;Cabral, L.;Patel, R.;Cusack, R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 23,
          "score": 0.5301628112792969,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 24,
          "score": 0.5281366109848022,
          "doc_id": "NART120020213",
          "title": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces",
          "abstract": "<P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "source": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces <P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "author": "Baba, Yukino;Kashima, Hisashi;Kinoshita, Kei;Yamaguchi, Goushi;Akiyoshi, Yosuke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 25,
          "score": 0.5221172571182251,
          "doc_id": "ATN0036732137",
          "title": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk",
          "abstract": "<jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "source": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk <jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "author": "De Lellis Lorenzo",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 26,
          "score": 0.5183160901069641,
          "doc_id": "NART106764981",
          "title": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data",
          "abstract": "<P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "source": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data <P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "author": "Ortega-Santos, Iv&aacute;n;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 27,
          "score": 0.5175075531005859,
          "doc_id": "ATN0051728156",
          "title": "언어학, 전산언어학, 그리고 디지털 인문학",
          "abstract": "디지털 시대는 인문학에 새로운 가능성을 열어주었으며, 특히 컴퓨터 기술과 융합한 디지털 인문학이 부상하고 있다. 디지털 인문학의 효시는 ‘인문전산학’으로, 로베르토 부사 신부의 중세 라틴어 색인 작업에서 시작되었다. 초기 디지털 인문학은 전산언어학 및 컴퓨터공학과 함께 언어학, 고고학 등의 통계자료 처리에 활용되었으나, 컴퓨터 성능의 한계로 텍스트 색인 및 2차 가공에 머물렀다. 그러나 1980년대 이후 컴퓨터 성능 향상과 전산언어학의 발전으로 디지털 인문학은 대규모 데이터 기반 연구가 가능해졌고, 디지털 자원 구축 및 관리, 텍스트 분석, 데이터 시각화 등의 분석 방법이 발전했다. 2000년대 이후 빅데이터와 생성형 AI의 등장으로 디지털 인문학은 더욱 발전하여 독립된 학문 분야로 나아가고 있다. 언어학은 인문학적이면서도 자연과학적인 특성을 지닌 융복합 학문이며, 특히 전산언어학은 디지털 시대의 인문학에 최적화된 분야이다. 디지털 기술 도입으로 언어학은 코퍼스 기반 연구, 전산 실험 언어학, 디지털 기록 보존 및 분석 등 방법론과 연구 대상을 확장하고 있다. 전산언어학은 텍스트 분석, 의미 분석, 정보 추출 등을 통해 인문학 연구자가 방대한 언어 데이터를 효율적으로 탐색하고 의미 있는 통찰력을 도출하는 데 핵심적인 역할을 수행한다. 디지털 인문학과 전산언어학의 융합은 문학, 역사, 철학, 고고학 등 다양한 인문학 분야에서 새로운 연구 성과를 창출하고 있다. 향후 연구에서는 융합적 접근을 심화하고, 디지털 데이터 활용의 윤리적 문제 등을 고려하며, 디지털 시대의 언어 기술 발전에 따른 사회적 책임을 논의해야 할 것이다. 언어학과 전산언어학은 지속적인 연구와 혁신을 통해 ‘디지털 인문학’ 분야에 중요한 영향을 미칠 것으로 기대된다.",
          "source": "언어학, 전산언어학, 그리고 디지털 인문학 언어학, 전산언어학, 그리고 디지털 인문학 언어학, 전산언어학, 그리고 디지털 인문학 디지털 시대는 인문학에 새로운 가능성을 열어주었으며, 특히 컴퓨터 기술과 융합한 디지털 인문학이 부상하고 있다. 디지털 인문학의 효시는 ‘인문전산학’으로, 로베르토 부사 신부의 중세 라틴어 색인 작업에서 시작되었다. 초기 디지털 인문학은 전산언어학 및 컴퓨터공학과 함께 언어학, 고고학 등의 통계자료 처리에 활용되었으나, 컴퓨터 성능의 한계로 텍스트 색인 및 2차 가공에 머물렀다. 그러나 1980년대 이후 컴퓨터 성능 향상과 전산언어학의 발전으로 디지털 인문학은 대규모 데이터 기반 연구가 가능해졌고, 디지털 자원 구축 및 관리, 텍스트 분석, 데이터 시각화 등의 분석 방법이 발전했다. 2000년대 이후 빅데이터와 생성형 AI의 등장으로 디지털 인문학은 더욱 발전하여 독립된 학문 분야로 나아가고 있다. 언어학은 인문학적이면서도 자연과학적인 특성을 지닌 융복합 학문이며, 특히 전산언어학은 디지털 시대의 인문학에 최적화된 분야이다. 디지털 기술 도입으로 언어학은 코퍼스 기반 연구, 전산 실험 언어학, 디지털 기록 보존 및 분석 등 방법론과 연구 대상을 확장하고 있다. 전산언어학은 텍스트 분석, 의미 분석, 정보 추출 등을 통해 인문학 연구자가 방대한 언어 데이터를 효율적으로 탐색하고 의미 있는 통찰력을 도출하는 데 핵심적인 역할을 수행한다. 디지털 인문학과 전산언어학의 융합은 문학, 역사, 철학, 고고학 등 다양한 인문학 분야에서 새로운 연구 성과를 창출하고 있다. 향후 연구에서는 융합적 접근을 심화하고, 디지털 데이터 활용의 윤리적 문제 등을 고려하며, 디지털 시대의 언어 기술 발전에 따른 사회적 책임을 논의해야 할 것이다. 언어학과 전산언어학은 지속적인 연구와 혁신을 통해 ‘디지털 인문학’ 분야에 중요한 영향을 미칠 것으로 기대된다.",
          "author": "정성훈",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 28,
          "score": 0.517110288143158,
          "doc_id": "NART130522867",
          "title": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective",
          "abstract": "<P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "source": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective <P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "author": "Kwon, Hyeok Jun;Lee, Jong Tak;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 29,
          "score": 0.5166457891464233,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "author": "정수근",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 30,
          "score": 0.5158295035362244,
          "doc_id": "DIKO0013926033",
          "title": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향",
          "abstract": "nan",
          "source": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 ",
          "author": "임재은",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 31,
          "score": 0.5146658420562744,
          "doc_id": "JAKO202317962662812",
          "title": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석",
          "abstract": "이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "source": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "author": "윤지현;허소림;강성주;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 32,
          "score": 0.5144826769828796,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "author": "Arch, Joanna J.;Carr, Alaina L.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 33,
          "score": 0.5124759674072266,
          "doc_id": "NART126358912",
          "title": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining",
          "abstract": "<P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "source": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining <P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "author": "Yang, Hyeji;Kim, Jamee;Lee, Wongyu;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 34,
          "score": 0.5112500190734863,
          "doc_id": "NPAP13833015",
          "title": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk",
          "abstract": "nan",
          "source": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk ",
          "author": "Uzor, Stephen;Jacques, Jason T.;Dudley, John J;Kristensson, Per Ola;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 35,
          "score": 0.5096453428268433,
          "doc_id": "ATN0047358973",
          "title": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구",
          "abstract": "In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "source": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "author": "강아름;이용훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 36,
          "score": 0.5091328620910645,
          "doc_id": "DIKO0016395992",
          "title": "모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당",
          "abstract": "nan",
          "source": "모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 ",
          "author": "이윤열",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 37,
          "score": 0.506883442401886,
          "doc_id": "JAKO202424074483478",
          "title": "수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전",
          "abstract": "인공지능(AI)과 디지털 기술의 도입 등과 같은 디지털 기반 변화의 시대를 맞아, 2025년에는 수학, 영어, 정보 교과에 AI 디지털교과서를 단계적으로 도입하는 교육혁신이 추진되고 있다. 본 연구는 2023년 11월 전국 132명의 초등학교 교사를 대상으로 실시한 설문조사를 통해 교사들의 수학 AI 디지털교과서에 대한 이해도, 핵심 기술의 필요성, 수업 활용에 대한 인식, 그리고 AI 디지털교과서의 학교 현장에의 안착을 위한 요구사항을 조사하였다. 분석 결과, 대다수 교사들은 수학 AI 디지털교과서의 도입과 필요성에 대해 낮은 인식을 보였지만, 일부 교사들은 개인별 맞춤형 학습 및 효과적인 교수&#x00B7;학습 지원 가능성을 인식하고 있었다. 또한, 교사들은 AI 디지털교과서의 학습 진단과 교사 재구성 기능의 필요성을 높게 평가했으며, 수업에서의 유용성을 긍정적으로 평가했지만, AI 디지털교과서의 도입으로 인해 교실에서의 상호작용성은 저하시킬 것이라고 우려했다. 이는 AI 디지털교과서의 성공적 도입 및 활용을 위해 교사연수 및 정보 제공을 통한 인식 변화의 필요성을 시사하며, 구체적이고 실용적인 활용 방안 제공, 디지털 과잉 사용 및 의존에 대한 대안 모색, 핵심 기술의 지속적 개발 등, 이와 관련한 연구의 지속적인 필요성을 제언한다.",
          "source": "수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 인공지능(AI)과 디지털 기술의 도입 등과 같은 디지털 기반 변화의 시대를 맞아, 2025년에는 수학, 영어, 정보 교과에 AI 디지털교과서를 단계적으로 도입하는 교육혁신이 추진되고 있다. 본 연구는 2023년 11월 전국 132명의 초등학교 교사를 대상으로 실시한 설문조사를 통해 교사들의 수학 AI 디지털교과서에 대한 이해도, 핵심 기술의 필요성, 수업 활용에 대한 인식, 그리고 AI 디지털교과서의 학교 현장에의 안착을 위한 요구사항을 조사하였다. 분석 결과, 대다수 교사들은 수학 AI 디지털교과서의 도입과 필요성에 대해 낮은 인식을 보였지만, 일부 교사들은 개인별 맞춤형 학습 및 효과적인 교수&#x00B7;학습 지원 가능성을 인식하고 있었다. 또한, 교사들은 AI 디지털교과서의 학습 진단과 교사 재구성 기능의 필요성을 높게 평가했으며, 수업에서의 유용성을 긍정적으로 평가했지만, AI 디지털교과서의 도입으로 인해 교실에서의 상호작용성은 저하시킬 것이라고 우려했다. 이는 AI 디지털교과서의 성공적 도입 및 활용을 위해 교사연수 및 정보 제공을 통한 인식 변화의 필요성을 시사하며, 구체적이고 실용적인 활용 방안 제공, 디지털 과잉 사용 및 의존에 대한 대안 모색, 핵심 기술의 지속적 개발 등, 이와 관련한 연구의 지속적인 필요성을 제언한다.",
          "author": "김소민;이기마;김희정;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 38,
          "score": 0.5043824911117554,
          "doc_id": "ATN0027086510",
          "title": "인공신경망과 강건설계를 이용한 기계적 RMR 분류",
          "abstract": "Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "source": "인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "author": "장명환;하태욱;최기훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 39,
          "score": 0.501387357711792,
          "doc_id": "NART126363952",
          "title": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses",
          "abstract": "<P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "source": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses <P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "author": "Schleiss, Johannes;Laupichler, Matthias Carl;Raupach, Tobias;Stober, Sebastian;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 40,
          "score": 0.5002925395965576,
          "doc_id": "NART133815556",
          "title": "Developing AI Digital Textbook: Policy Status and Key Issues",
          "abstract": "<P>This study explores the current status and challenges of education policies related to the development of AI Digital Textbook in South Korea. It aims to gather foundational data to support the improvement and innovation of education policies amidst the transition to a digital education system. The research methodology included a scoping review using press releases, explanatory materials from the Ministry of Education, and documents from affiliated research institutions. The findings of the study are as follows. First, setting 2023 as the starting point for digital education innovation, the Ministry of Education has been promoting policies for the development of AI Digital Textbook, aiming to provide customized learning support for students. In the process of implementing these policies, establishing the legal status of AI digital textbooks and building institutional frameworks in collaboration with EdTech companies have been identified as key initiatives. Second, it was revealed that the Ministry of Education has established a T.O.U.C.H Teacher Group to drive innovation in digital-based education. This group is expected to grow members by 2025, with relevant training in a bootcamp format, with a focus on leading the transition to digital education. In addition, the study discusses emerging issues related to teachers and various aspects of AI Digital Textbook in the context of ongoing policy implementation. </P>",
          "source": "Developing AI Digital Textbook: Policy Status and Key Issues Developing AI Digital Textbook: Policy Status and Key Issues Developing AI Digital Textbook: Policy Status and Key Issues <P>This study explores the current status and challenges of education policies related to the development of AI Digital Textbook in South Korea. It aims to gather foundational data to support the improvement and innovation of education policies amidst the transition to a digital education system. The research methodology included a scoping review using press releases, explanatory materials from the Ministry of Education, and documents from affiliated research institutions. The findings of the study are as follows. First, setting 2023 as the starting point for digital education innovation, the Ministry of Education has been promoting policies for the development of AI Digital Textbook, aiming to provide customized learning support for students. In the process of implementing these policies, establishing the legal status of AI digital textbooks and building institutional frameworks in collaboration with EdTech companies have been identified as key initiatives. Second, it was revealed that the Ministry of Education has established a T.O.U.C.H Teacher Group to drive innovation in digital-based education. This group is expected to grow members by 2025, with relevant training in a bootcamp format, with a focus on leading the transition to digital education. In addition, the study discusses emerging issues related to teachers and various aspects of AI Digital Textbook in the context of ongoing policy implementation. </P>",
          "author": "Hwang, Jae Woon",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 41,
          "score": 0.500148594379425,
          "doc_id": "NART73866218",
          "title": "The Southern Dative Presentative Meets Mechanical Turk",
          "abstract": "<P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "source": "The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk <P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "author": "Wood, Jim;Horn, Laurence;Zanuttini, Raffaella;Lindemann, Luke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 42,
          "score": 0.4960651695728302,
          "doc_id": "JAKO201017337344335",
          "title": "인공신경망모델을 이용한 교량의 상태평가",
          "abstract": "대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "source": "인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "author": "오순택;이동준;이재호;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 43,
          "score": 0.49430692195892334,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "author": "Mason, Winter;Suri, Siddharth;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 44,
          "score": 0.4912181496620178,
          "doc_id": "NPAP13663736",
          "title": "모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정",
          "abstract": "최근 모바일 기술이 실생활에 널리 활용하면서 점점 모바일 크라우드소싱 활용이 크게 기대되고 있다. 그래서 배달 인력이 아닌 일반인도 어플리케이션을 모바일 기기에 설치하면 배달 인력이 되어 작업을 수행할 수 있다. 본 연구에서는 일반인도 참여할 수 있는 모바일 크라우드소싱 기반 배달에서 딥러닝을 이용한 작업자 선정 기법을 소개한다. 그리고 실험을 통하여 합성곱 신경망(Convolutional Neural Network)을 적용한 본 기법이 효과적이라는 것을 보인다.",
          "source": "모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 최근 모바일 기술이 실생활에 널리 활용하면서 점점 모바일 크라우드소싱 활용이 크게 기대되고 있다. 그래서 배달 인력이 아닌 일반인도 어플리케이션을 모바일 기기에 설치하면 배달 인력이 되어 작업을 수행할 수 있다. 본 연구에서는 일반인도 참여할 수 있는 모바일 크라우드소싱 기반 배달에서 딥러닝을 이용한 작업자 선정 기법을 소개한다. 그리고 실험을 통하여 합성곱 신경망(Convolutional Neural Network)을 적용한 본 기법이 효과적이라는 것을 보인다.",
          "author": "이윤열;김응모;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 45,
          "score": 0.4905736744403839,
          "doc_id": "JAKO202516139604364",
          "title": "AI 디지털 교과서의 성공적 도입을 위한 방향 탐색",
          "abstract": "AI 디지털 교과서는 학습 개인화와 교육격차 해소를 목표로 기존의 교육 방식을 혁신할 잠재력을 가지고 있다. 학생의 수준과 필요에 맞춘 맞춤형 학습을 통해 학습 효율을 극대화하고, 학습자의 흥미와 몰입을 높이는 다양한 교육 콘텐츠를 제공할 수 있다. 그러나 이러한 가능성을 실현하기 위해서는 여러 문제를 사전에 파악하고, 이를 해결할 수 있는 실질적인 대책 마련이 필요하다. 이 연구의 목적은 인공지능 디지털 교과서의 성공적인 도입을 위한 방향을 탐색하는 것이다. 연구 결과는 다음과 같다. 첫째, 디지털 교과서의 법적 지위와 정의를 명확히 해야 한다. 현행 법규에서 AI 디지털 교과서는 교육자료로 규정될 가능성이 있다. 그러므로 학습의 핵심 매체로서의 정체성을 인정받기 위해서는 교과서로서의 법적 지위 확보가 중요하다. 둘째, 개인정보 보호 및 데이터 윤리를 보장하는 체계적인 법적 기반이 마련되어야 한다. AI 디지털 교과서가 데이터를 활용하여 개인화된 학습을 제공하려면, 데이터 보안 및 개인정보 보호 문제에 대한 해결책이 필수적이다. 이를 통해 학습자의 신뢰를 확보하고, 도입 과정에서 발생할 수 있는 법적 분쟁을 예방할 수 있다.",
          "source": "AI 디지털 교과서의 성공적 도입을 위한 방향 탐색 AI 디지털 교과서의 성공적 도입을 위한 방향 탐색 AI 디지털 교과서의 성공적 도입을 위한 방향 탐색 AI 디지털 교과서는 학습 개인화와 교육격차 해소를 목표로 기존의 교육 방식을 혁신할 잠재력을 가지고 있다. 학생의 수준과 필요에 맞춘 맞춤형 학습을 통해 학습 효율을 극대화하고, 학습자의 흥미와 몰입을 높이는 다양한 교육 콘텐츠를 제공할 수 있다. 그러나 이러한 가능성을 실현하기 위해서는 여러 문제를 사전에 파악하고, 이를 해결할 수 있는 실질적인 대책 마련이 필요하다. 이 연구의 목적은 인공지능 디지털 교과서의 성공적인 도입을 위한 방향을 탐색하는 것이다. 연구 결과는 다음과 같다. 첫째, 디지털 교과서의 법적 지위와 정의를 명확히 해야 한다. 현행 법규에서 AI 디지털 교과서는 교육자료로 규정될 가능성이 있다. 그러므로 학습의 핵심 매체로서의 정체성을 인정받기 위해서는 교과서로서의 법적 지위 확보가 중요하다. 둘째, 개인정보 보호 및 데이터 윤리를 보장하는 체계적인 법적 기반이 마련되어야 한다. AI 디지털 교과서가 데이터를 활용하여 개인화된 학습을 제공하려면, 데이터 보안 및 개인정보 보호 문제에 대한 해결책이 필수적이다. 이를 통해 학습자의 신뢰를 확보하고, 도입 과정에서 발생할 수 있는 법적 분쟁을 예방할 수 있다.",
          "author": "윤옥한",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 46,
          "score": 0.4904286563396454,
          "doc_id": "NART134452383",
          "title": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk",
          "abstract": "<P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "source": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk <P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "author": "Kassem, Sarrah;Wilpert (&Uuml;bersetzung), Chris W.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 47,
          "score": 0.48801130056381226,
          "doc_id": "ATN0043505185",
          "title": "대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제",
          "abstract": "Conversation analysis is a field pioneered by sociologists such as Harvey Sacks in the 1960s and aims to analyze the functions of various social interactions that speakers achieve through conversation and reveal the structural systematicity of social behavior. Recently, conversation analysis has become interested in the field of applied linguistics to solve real-life problems related to language based on interest in daily conversation as a social act. Applied linguistics using conversational analysis is developing in a variety of ways, showing that systematic research between various disciplines and academic systems is possible, including language and social interaction, professional and workplace interaction, language and other problems. Currently, many studies on conversation analysis in applied linguistics is being actively conducted in Europe and Japan beyond the U.S. region where conversation analysis originated. Since 2000, Chinese applied linguistics research using conversation analysis has begun to appear in Korea, but there are no studies examining research trends in this regard.This study summarizes research trends and analyzes major discussions of previous studies on conversation analysis in applied linguistics. This study firstly established a database of related research lists through a complete eunmeration survey of research articles by Korean researchers published in Korean academic journals and books. Based on the database, this study summarized research trends of preceding studies by fields, by topics, by methodologies, and by research subjects. This study also explored the tasks and directions for future research. Conversation analysis as a mode of inquiry is addressed to all forms of talk and other conduct in interaction, and, accordingly, has increasingly contributed to several established fields in applied linguistics. This study indicates past or potential points of contact with applied linguistics.",
          "source": "대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 Conversation analysis is a field pioneered by sociologists such as Harvey Sacks in the 1960s and aims to analyze the functions of various social interactions that speakers achieve through conversation and reveal the structural systematicity of social behavior. Recently, conversation analysis has become interested in the field of applied linguistics to solve real-life problems related to language based on interest in daily conversation as a social act. Applied linguistics using conversational analysis is developing in a variety of ways, showing that systematic research between various disciplines and academic systems is possible, including language and social interaction, professional and workplace interaction, language and other problems. Currently, many studies on conversation analysis in applied linguistics is being actively conducted in Europe and Japan beyond the U.S. region where conversation analysis originated. Since 2000, Chinese applied linguistics research using conversation analysis has begun to appear in Korea, but there are no studies examining research trends in this regard.This study summarizes research trends and analyzes major discussions of previous studies on conversation analysis in applied linguistics. This study firstly established a database of related research lists through a complete eunmeration survey of research articles by Korean researchers published in Korean academic journals and books. Based on the database, this study summarized research trends of preceding studies by fields, by topics, by methodologies, and by research subjects. This study also explored the tasks and directions for future research. Conversation analysis as a mode of inquiry is addressed to all forms of talk and other conduct in interaction, and, accordingly, has increasingly contributed to several established fields in applied linguistics. This study indicates past or potential points of contact with applied linguistics.",
          "author": "이지원",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 48,
          "score": 0.4876963198184967,
          "doc_id": "DIKO0016951486",
          "title": "AI디지털교과서 요구 분석",
          "abstract": "교육부의 “인공지능(AI) 디지털교과서 추진 방안” 정책에 따라 2025년부터 초·중· 고 학교 수업에 ‘AI디지털교과서’가 도입된다. 교육부는 AI디지털교과서 개발 가이드 라인에 AI디지털교과서 활용 모델을 활용 방식(예습형·복습형·수업활용형 등), 적용 과정(정규 교과 / 방과 후 과정) 및 교과 특성 등을 고려하여 ‘교사의 수업 설계와 재량’에 따라 자유롭게 활용하는 것으로 제시하고 있다. 교과서는 교과 교육과정 및 검인정 심사 기준에 따라 편찬되며, 국가 정책에 따라 개발·보급되는 교육 자료이다. AI디지털교과서는 인공지능을 포함한 지능 정보 기술 을 활용하여 다양한 학습 자료 및 학습 지원 기능 등을 탑재한 소프트웨어로 교사의 수업 설계에 따라 자유롭게 활용하는 것으로 제시하고 있지만, 교과서의 지위를 가지는 교육 자료이므로, AI디지털교과서 구성 설계는 교실 수업에서 활용하는 것을 전제로 개발되어야 할 것이다. &amp;#xD; 본 연구에서는 한 교과목의 수업에서 교과서가 2가지 형태 즉, 종이교과서와 AI디지털교과서로 개발·보급되기에 “교사들은 교실 수업에서 종이교과서와 AI디지털교과 서를 어떻게 함께 활용할까?”에 대해 알아보고자 하였고, 새로운 형태의 AI디지털교과서가 수업에서 효과적으로 활용되기 위한 AI디지털교과서 구성에 대해 초등학교 교사 요구 분석을 온라인 설문 조사와 FGI로 진행하였다. &amp;#xD; 요구 조사는 ‘현재의 교과서(종이교과서) 수업 활용에 대한 조사’, ‘향후 종이교과서와 AI디지털교과서 역할과 활용에 대한 조사’, ‘AI디지털교과서 구성 체제에 대한 요구 조사’ 로 구분하여 실시하였으며, 다음 3가지 관점에서 수요자 요구를 분석하였다. &amp;#xD; 첫째, 종이교과서와 AI디지털교과서가 병용 보급되는 환경에서 교수자들은 종이교과서와 AI디지털교과서를 어떻게 활용하고자 하는가? &amp;#xD; 요구 조사 결과, ‘종이교과서를 주로 활용’은 63%, ‘종이교과서와 AI디지털교과서 반반 활용’은 21%, ‘AI디지털교과서를 주로 활용’은 16%였다. 초등 교사들은 AI디지 털교과서 도입 초기에는 AI디지털교과서의 편의성 및 안정성을 담보할 수 없어서 종이교과서의 보조적 역할로 활용할 계획이고, AI디지털교과서를 사용하더라도 종이 교과서와 병용할 계획이라고 하였다. 종이교과서가 교과서 사용의 편리성, 안정성, 적응성, 탐구력, 집중도, 종이 문해 력, 건강 발달 측면에서는 AI디지털교과서보다 우수하여, 종이교과서를 여전히 주된 교육 자료로 사용할 계획임을 밝혔다. 반면, 맞춤형 학습, 학습 분석, 흥미 유발, 디지털 문해력에 있어서는 AI디지털교과서가 도움이 된다고 하였다. 즉, 초등학교 교사들은 운영 안전성과 탐구력, 건강 발달에서는 종이교과서의 활용을 선호하였고, 맞춤형 학습에는 AI디지털교과서가 도움을 줄 것이며, 미래 역량으로 종이 문해력과 디지털 문해력이 모두 필요하여, 종이 교과서와 AI디지털교과서를 상호 보완적으로 사용할 계획임을 밝혔다. 또한, 종이교과서 내용이 담겨 있는 AI디지털교과서를 선정하겠다는 교사가 92%, 종이교과서 내용과 다른 AI디지털교과서를 선정하겠다는 교사가 8%로, 종이교과서 와 AI디지털교과서의 수업의 연속성을 고려하여, 종이교과서 내용이 담겨 있는 AI디 지털교과서를 선정하고 활용할 예정임을 조사를 통해 확인할 수 있었다. &amp;#xD; 둘째, AI디지털교과서는 학습자의 학습에 대한 데이터가 남아 있어야 기대 역할을 할 수 있는데, 과연, 교수자는 학습자로 하여금 AI디지털교과서를 얼마나 자주, 어떤 목적으로 활용하게 할 것인가? &amp;#xD; 설문에 응답한 초등학교 교사 71%가 2~3차시에 한 번 이상은 사용할 수 있다고 하였다. 매 차시 AI디지털교과서를 사용할 수 있다는 답변도 45%로 나타나서, AI디지털교과서를 보조적으로 활용하더라도, AI디지털교과서의 활용 빈도는 높게 나타날 것으로 보인다. &amp;#xD; 활용 용도의 우선 순위를 살펴보면, “사전 지식 개념 학습(23명) = 진단 확인 평가 문제 풀기(23명) &amp;gt; 종이교과서 문제 풀기(19명) &amp;gt; 디지털교구 활용 조작형 탐구 활동(16명)” 으로 나타났다. &amp;#xD; 셋째, 초등학교 교사들의 AI디지털교과서에 대한 긍정적 기대 정도는 어떠하고, 꼭 담겨져야 하는 기능으로는 무엇을 생각하는가? &amp;#xD; AI디지털교과서에 대한 긍정적 기대는 71%, 보통 21%, 부정적 의견은 8%로, 대체 로 AI디지털교과서에 대해 긍정적 기대를 가졌다. AI디지털교과서에 꼭 담겨져야 하 는 기능으로는 ‘학습자’에게는 동기 유발 및 보상, 개인 맞춤형 관리 시스템, 기본 개 념 콘텐츠, 사용의 편의성이 제공되어야 하며, ‘교수자’에게는 맞춤형 수업 자료, 평 가 진단 서비스, 학습 결과 확인 및 분석, 수업 운영 편의성, 저작툴, 공유 기능이 제공되어야 함을 제안하였다. &amp;#xD; 위와 같은 수요자 요구 조사 분석을 바탕으로, 본 연구에서는 활용성 높은 AI디지털교과서 개발을 위한 AI디지털교과서 구성 원리를 7가지로 도출하였다. 수요자 요구 조사를 통해 도출된 AI디지털교과서 7가지 구성 원리는 “종이교과서 수업과 연 속성 원리, 종이교과서 수업과 차별성 원리, 학습자 진단 평가의 원리, 맞춤형 학습 콘텐츠 지원의 원리, 학습자 격려의 원리, 학습 데이터 수집의 원리, 사용 편의성의 원리” 이다. &amp;#xD; 향후 이러한 구성 원리를 반영하여 AI디지털교과서를 개발하면, AI디지털교과서는 종이교과서의 한계를 보완하며 종이교과서와 AI디지털교과서가 상호 보완적으로 사용될 수 있을 것이다. 또한, AI디지털교과서를 통해 모두를 위한 맞춤 교육 실현을 목표로 학생, 교사, 학부모, 정책 입안자 등 교육 주체가 학습에 대한 데이터 기반의 의사 결정을 내릴 수 있도록 사용자, 학교, 국가 차원의 학습 분석이 교육 시스템의 지속적인 개선을 위한 기반이 제공될 수 있기를 기대한다.&amp;#xD;",
          "source": "AI디지털교과서 요구 분석 AI디지털교과서 요구 분석 AI디지털교과서 요구 분석 교육부의 “인공지능(AI) 디지털교과서 추진 방안” 정책에 따라 2025년부터 초·중· 고 학교 수업에 ‘AI디지털교과서’가 도입된다. 교육부는 AI디지털교과서 개발 가이드 라인에 AI디지털교과서 활용 모델을 활용 방식(예습형·복습형·수업활용형 등), 적용 과정(정규 교과 / 방과 후 과정) 및 교과 특성 등을 고려하여 ‘교사의 수업 설계와 재량’에 따라 자유롭게 활용하는 것으로 제시하고 있다. 교과서는 교과 교육과정 및 검인정 심사 기준에 따라 편찬되며, 국가 정책에 따라 개발·보급되는 교육 자료이다. AI디지털교과서는 인공지능을 포함한 지능 정보 기술 을 활용하여 다양한 학습 자료 및 학습 지원 기능 등을 탑재한 소프트웨어로 교사의 수업 설계에 따라 자유롭게 활용하는 것으로 제시하고 있지만, 교과서의 지위를 가지는 교육 자료이므로, AI디지털교과서 구성 설계는 교실 수업에서 활용하는 것을 전제로 개발되어야 할 것이다. &amp;#xD; 본 연구에서는 한 교과목의 수업에서 교과서가 2가지 형태 즉, 종이교과서와 AI디지털교과서로 개발·보급되기에 “교사들은 교실 수업에서 종이교과서와 AI디지털교과 서를 어떻게 함께 활용할까?”에 대해 알아보고자 하였고, 새로운 형태의 AI디지털교과서가 수업에서 효과적으로 활용되기 위한 AI디지털교과서 구성에 대해 초등학교 교사 요구 분석을 온라인 설문 조사와 FGI로 진행하였다. &amp;#xD; 요구 조사는 ‘현재의 교과서(종이교과서) 수업 활용에 대한 조사’, ‘향후 종이교과서와 AI디지털교과서 역할과 활용에 대한 조사’, ‘AI디지털교과서 구성 체제에 대한 요구 조사’ 로 구분하여 실시하였으며, 다음 3가지 관점에서 수요자 요구를 분석하였다. &amp;#xD; 첫째, 종이교과서와 AI디지털교과서가 병용 보급되는 환경에서 교수자들은 종이교과서와 AI디지털교과서를 어떻게 활용하고자 하는가? &amp;#xD; 요구 조사 결과, ‘종이교과서를 주로 활용’은 63%, ‘종이교과서와 AI디지털교과서 반반 활용’은 21%, ‘AI디지털교과서를 주로 활용’은 16%였다. 초등 교사들은 AI디지 털교과서 도입 초기에는 AI디지털교과서의 편의성 및 안정성을 담보할 수 없어서 종이교과서의 보조적 역할로 활용할 계획이고, AI디지털교과서를 사용하더라도 종이 교과서와 병용할 계획이라고 하였다. 종이교과서가 교과서 사용의 편리성, 안정성, 적응성, 탐구력, 집중도, 종이 문해 력, 건강 발달 측면에서는 AI디지털교과서보다 우수하여, 종이교과서를 여전히 주된 교육 자료로 사용할 계획임을 밝혔다. 반면, 맞춤형 학습, 학습 분석, 흥미 유발, 디지털 문해력에 있어서는 AI디지털교과서가 도움이 된다고 하였다. 즉, 초등학교 교사들은 운영 안전성과 탐구력, 건강 발달에서는 종이교과서의 활용을 선호하였고, 맞춤형 학습에는 AI디지털교과서가 도움을 줄 것이며, 미래 역량으로 종이 문해력과 디지털 문해력이 모두 필요하여, 종이 교과서와 AI디지털교과서를 상호 보완적으로 사용할 계획임을 밝혔다. 또한, 종이교과서 내용이 담겨 있는 AI디지털교과서를 선정하겠다는 교사가 92%, 종이교과서 내용과 다른 AI디지털교과서를 선정하겠다는 교사가 8%로, 종이교과서 와 AI디지털교과서의 수업의 연속성을 고려하여, 종이교과서 내용이 담겨 있는 AI디 지털교과서를 선정하고 활용할 예정임을 조사를 통해 확인할 수 있었다. &amp;#xD; 둘째, AI디지털교과서는 학습자의 학습에 대한 데이터가 남아 있어야 기대 역할을 할 수 있는데, 과연, 교수자는 학습자로 하여금 AI디지털교과서를 얼마나 자주, 어떤 목적으로 활용하게 할 것인가? &amp;#xD; 설문에 응답한 초등학교 교사 71%가 2~3차시에 한 번 이상은 사용할 수 있다고 하였다. 매 차시 AI디지털교과서를 사용할 수 있다는 답변도 45%로 나타나서, AI디지털교과서를 보조적으로 활용하더라도, AI디지털교과서의 활용 빈도는 높게 나타날 것으로 보인다. &amp;#xD; 활용 용도의 우선 순위를 살펴보면, “사전 지식 개념 학습(23명) = 진단 확인 평가 문제 풀기(23명) &amp;gt; 종이교과서 문제 풀기(19명) &amp;gt; 디지털교구 활용 조작형 탐구 활동(16명)” 으로 나타났다. &amp;#xD; 셋째, 초등학교 교사들의 AI디지털교과서에 대한 긍정적 기대 정도는 어떠하고, 꼭 담겨져야 하는 기능으로는 무엇을 생각하는가? &amp;#xD; AI디지털교과서에 대한 긍정적 기대는 71%, 보통 21%, 부정적 의견은 8%로, 대체 로 AI디지털교과서에 대해 긍정적 기대를 가졌다. AI디지털교과서에 꼭 담겨져야 하 는 기능으로는 ‘학습자’에게는 동기 유발 및 보상, 개인 맞춤형 관리 시스템, 기본 개 념 콘텐츠, 사용의 편의성이 제공되어야 하며, ‘교수자’에게는 맞춤형 수업 자료, 평 가 진단 서비스, 학습 결과 확인 및 분석, 수업 운영 편의성, 저작툴, 공유 기능이 제공되어야 함을 제안하였다. &amp;#xD; 위와 같은 수요자 요구 조사 분석을 바탕으로, 본 연구에서는 활용성 높은 AI디지털교과서 개발을 위한 AI디지털교과서 구성 원리를 7가지로 도출하였다. 수요자 요구 조사를 통해 도출된 AI디지털교과서 7가지 구성 원리는 “종이교과서 수업과 연 속성 원리, 종이교과서 수업과 차별성 원리, 학습자 진단 평가의 원리, 맞춤형 학습 콘텐츠 지원의 원리, 학습자 격려의 원리, 학습 데이터 수집의 원리, 사용 편의성의 원리” 이다. &amp;#xD; 향후 이러한 구성 원리를 반영하여 AI디지털교과서를 개발하면, AI디지털교과서는 종이교과서의 한계를 보완하며 종이교과서와 AI디지털교과서가 상호 보완적으로 사용될 수 있을 것이다. 또한, AI디지털교과서를 통해 모두를 위한 맞춤 교육 실현을 목표로 학생, 교사, 학부모, 정책 입안자 등 교육 주체가 학습에 대한 데이터 기반의 의사 결정을 내릴 수 있도록 사용자, 학교, 국가 차원의 학습 분석이 교육 시스템의 지속적인 개선을 위한 기반이 제공될 수 있기를 기대한다.&amp;#xD;",
          "author": "허보욱",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 49,
          "score": 0.48435288667678833,
          "doc_id": "JAKO200411922315329",
          "title": "인공신경망을 이용한 BTX 농도 측정에 관한 연구",
          "abstract": "휘발성유기 화합물(Vo1ati1e Organic Compounds : VOCs)은 탄화수소 화합물을 총칭한다. 이는 오존 및 광화학 스모그의 원인물질일 뿐 아니라 인체에는 암을 유발시키는 유해 물질이다. 또한 대기 중 악취 물질로서 환경 및 건강에 영향을 초래하는 유해성 물질이다. 본 논문은 대기 중에 포함된 암을 유발시키는 유해성 물질인 BTX(Benzene, Toluene, Xylene)의 존재 유무와 농도 측정에 대해서 연구하였다. 다종의 가스센서를 어레이하여 BTX 가스를 측정하고 인공신경망(Artificial Neural Network : ANN)의 역전파(Back propagation : BP) 알고리즘으로 시뮬레이션과 실험을 통해 농도를 추론하였다. ANN모듈은 기준 데이터를 시뮬레이션을 통해 학습시키고, 가스를 주입하여 실험 할 때 학습된 델타 모델에 근거하여 추론을 할 수 있는 추론 알고리즘 모듈이다. 이 모듈은 기준데이터를 MATLAB 코드로 시뮬레이션을 하여 생성된 parameter를 가지고 수행했으며, 시뮬레이션 결과를 실험을 통해 비교 테스트하여 검증하였다.",
          "source": "인공신경망을 이용한 BTX 농도 측정에 관한 연구 인공신경망을 이용한 BTX 농도 측정에 관한 연구 인공신경망을 이용한 BTX 농도 측정에 관한 연구 휘발성유기 화합물(Vo1ati1e Organic Compounds : VOCs)은 탄화수소 화합물을 총칭한다. 이는 오존 및 광화학 스모그의 원인물질일 뿐 아니라 인체에는 암을 유발시키는 유해 물질이다. 또한 대기 중 악취 물질로서 환경 및 건강에 영향을 초래하는 유해성 물질이다. 본 논문은 대기 중에 포함된 암을 유발시키는 유해성 물질인 BTX(Benzene, Toluene, Xylene)의 존재 유무와 농도 측정에 대해서 연구하였다. 다종의 가스센서를 어레이하여 BTX 가스를 측정하고 인공신경망(Artificial Neural Network : ANN)의 역전파(Back propagation : BP) 알고리즘으로 시뮬레이션과 실험을 통해 농도를 추론하였다. ANN모듈은 기준 데이터를 시뮬레이션을 통해 학습시키고, 가스를 주입하여 실험 할 때 학습된 델타 모델에 근거하여 추론을 할 수 있는 추론 알고리즘 모듈이다. 이 모듈은 기준데이터를 MATLAB 코드로 시뮬레이션을 하여 생성된 parameter를 가지고 수행했으며, 시뮬레이션 결과를 실험을 통해 비교 테스트하여 검증하였다.",
          "author": "정영창;김동진;홍철호;이장훈;권혁구;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 50,
          "score": 0.48322993516921997,
          "doc_id": "JAKO202332657687316",
          "title": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구",
          "abstract": "본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "source": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "author": "이은철;변영신;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        }
      ]
    },
    {
      "query": "What are the key findings of the socio-technical evaluation regarding Big Data developmental processes?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6403363943099976,
          "doc_id": "NART117776930",
          "title": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk",
          "abstract": "<P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "source": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk <P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "author": "Shakeri Hossein Abad, Zahra;Butler, Gregory P;Thompson, Wendy;Lee, Joon;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 2,
          "score": 0.6017366647720337,
          "doc_id": "NPAP12463036",
          "title": "Exploring Crowd Consistency in a Mechanical Turk Survey",
          "abstract": "<P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "source": "Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey <P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "author": "Sun, Peng;Stolee, Kathryn T.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 3,
          "score": 0.596054196357727,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "author": "Pavlick, Ellie;Post, Matt;Irvine, Ann;Kachaev, Dmitry;Callison-Burch, Chris;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 4,
          "score": 0.5893439054489136,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;Ipeirotis, Panagiotis G.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 5,
          "score": 0.5871260166168213,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "author": "Bohannon, John",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 6,
          "score": 0.5766309499740601,
          "doc_id": "NART74131061",
          "title": "Lessons Learned from Crowdsourcing Complex Engineering Tasks",
          "abstract": "<P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "source": "Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks <P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "author": "Staffelbach, Matthew;Sempolinski, Peter;Kijewski-Correa, Tracy;Thain, Douglas;Wei, Daniel;Kareem, Ahsan;Madey, Gregory;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 7,
          "score": 0.5753034353256226,
          "doc_id": "NART87817032",
          "title": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative",
          "abstract": "<P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "source": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative <P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "author": "Tosti-Kharas, Jennifer;Conley, Caryn;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 8,
          "score": 0.5716599225997925,
          "doc_id": "JAKO202433335467568",
          "title": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석",
          "abstract": "This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "source": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "author": "민준홍;김미량;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 9,
          "score": 0.5704314708709717,
          "doc_id": "JAKO202116057056093",
          "title": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로",
          "abstract": "본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "source": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "author": "차현주;권상희;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 10,
          "score": 0.5684773921966553,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "author": "De Lurgio II, Stephen A.;Young, Amber;Steelman, Zachary R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 11,
          "score": 0.5674195289611816,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "author": "Schnoebelen, Tyler;Kuperman, Victor;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 12,
          "score": 0.5639113187789917,
          "doc_id": "NART121336460",
          "title": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples",
          "abstract": "<P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "source": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples <P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "author": "Weigold, Arne;Weigold, Ingrid K.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 13,
          "score": 0.5600020885467529,
          "doc_id": "NART109637313",
          "title": "Annotator Rationales for Labeling Tasks in Crowdsourcing",
          "abstract": "<P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "source": "Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing <P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "author": "Kutlu, Mucahid;McDonnell, Tyler;Lease, Matthew;Elsayed, Tamer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 14,
          "score": 0.5547574162483215,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "author": "Dai, P.;Lin, C.H.;Mausam;Weld, D.S.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 15,
          "score": 0.5529255867004395,
          "doc_id": "NART69743055",
          "title": "Crowdsourcing content analysis for managerial research",
          "abstract": "<P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "source": "Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research <P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "author": "Conley, Caryn;Tosti-Kharas, Jennifer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 16,
          "score": 0.5516870617866516,
          "doc_id": "NART77189173",
          "title": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks",
          "abstract": "<P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "source": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks <P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "author": "Gomez, Steven R.;Jianu, Radu;Cabeen, Ryan;Guo, Hua;Laidlaw, David H.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 17,
          "score": 0.5448694825172424,
          "doc_id": "NART120020213",
          "title": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces",
          "abstract": "<P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "source": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces <P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "author": "Baba, Yukino;Kashima, Hisashi;Kinoshita, Kei;Yamaguchi, Goushi;Akiyoshi, Yosuke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 18,
          "score": 0.5421091318130493,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "author": "Rouse, S.V.",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 19,
          "score": 0.5419403910636902,
          "doc_id": "NPAP13430839",
          "title": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion",
          "abstract": "<P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "source": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion <P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "author": "Wu, Yu Hsuan;Wu, Eric Hsiaokuang;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 20,
          "score": 0.5404473543167114,
          "doc_id": "DIKO0013926033",
          "title": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향",
          "abstract": "nan",
          "source": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 ",
          "author": "임재은",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 21,
          "score": 0.5357716083526611,
          "doc_id": "ATN0027086510",
          "title": "인공신경망과 강건설계를 이용한 기계적 RMR 분류",
          "abstract": "Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "source": "인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "author": "장명환;하태욱;최기훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 22,
          "score": 0.533832848072052,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "author": "Shapiro, Danielle N.;Chandler, Jesse;Mueller, Pam A.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 23,
          "score": 0.5334393382072449,
          "doc_id": "ATN0036732137",
          "title": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk",
          "abstract": "<jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "source": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk <jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "author": "De Lellis Lorenzo",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 24,
          "score": 0.5330906510353088,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "author": "정수근",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 25,
          "score": 0.5329165458679199,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 26,
          "score": 0.5317521095275879,
          "doc_id": "JAKO201017337344335",
          "title": "인공신경망모델을 이용한 교량의 상태평가",
          "abstract": "대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "source": "인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "author": "오순택;이동준;이재호;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 27,
          "score": 0.5304728150367737,
          "doc_id": "NART126358912",
          "title": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining",
          "abstract": "<P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "source": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining <P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "author": "Yang, Hyeji;Kim, Jamee;Lee, Wongyu;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 28,
          "score": 0.5293274521827698,
          "doc_id": "DIKO0016395992",
          "title": "모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당",
          "abstract": "nan",
          "source": "모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 모바일 크라우드소싱에서 딥러닝 기반 신뢰성 인지 작업 할당 ",
          "author": "이윤열",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 29,
          "score": 0.5282415747642517,
          "doc_id": "NART130522867",
          "title": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective",
          "abstract": "<P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "source": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective <P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "author": "Kwon, Hyeok Jun;Lee, Jong Tak;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 30,
          "score": 0.5275310277938843,
          "doc_id": "JAKO202516136003211",
          "title": "유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성",
          "abstract": "본 연구는 유아들을 위한 인공지능 사고 기반의 창의적 문제해결력 요소를 구성하기 위해서 수행되었다. 이를 위해서 문헌을 분석하기 위해 선행연구를 탐색하였고, 그 결과 국문4편, 영문 5편의 자료를 수집하였다. 수집된 문헌을 분석하여 인공지능적 사고의 구성 요소를 AI 사고(데이터 분석, 알고리즘, 구축, 디버깅), 창의적 문제해결(발산적 사고, 수렴적 사고), AI 이해(AI 이해, AI 활용, AI 윤리)를 도출하였다. 도출된 구성 요소를 기반으로 인공지능적 사고의 구성 요소를 분류하고, 분류된 구성요소의 특성을 종합하여 정의를 '인공지능에 기반한 창의적 문제해결력'으로 규정하였다. 본 연구를 통해서 구성된 요소와 정의의 타당성을 검증하기 위해서 델파이 조사를 수행하였다. 델파이 조사에 참여한 전문가는 인공지능 교육 전문가 3명, 교육공학 전문가 1명, 유아교육 전문가 1명으로 모두 5명이 참여하였다. 1차 델파이 조사에서 수렴도와 합의도가 모두 양호하게 산출되었으며, 이에 2차 델파이 조사를 수행하지 않았다.",
          "source": "유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 본 연구는 유아들을 위한 인공지능 사고 기반의 창의적 문제해결력 요소를 구성하기 위해서 수행되었다. 이를 위해서 문헌을 분석하기 위해 선행연구를 탐색하였고, 그 결과 국문4편, 영문 5편의 자료를 수집하였다. 수집된 문헌을 분석하여 인공지능적 사고의 구성 요소를 AI 사고(데이터 분석, 알고리즘, 구축, 디버깅), 창의적 문제해결(발산적 사고, 수렴적 사고), AI 이해(AI 이해, AI 활용, AI 윤리)를 도출하였다. 도출된 구성 요소를 기반으로 인공지능적 사고의 구성 요소를 분류하고, 분류된 구성요소의 특성을 종합하여 정의를 '인공지능에 기반한 창의적 문제해결력'으로 규정하였다. 본 연구를 통해서 구성된 요소와 정의의 타당성을 검증하기 위해서 델파이 조사를 수행하였다. 델파이 조사에 참여한 전문가는 인공지능 교육 전문가 3명, 교육공학 전문가 1명, 유아교육 전문가 1명으로 모두 5명이 참여하였다. 1차 델파이 조사에서 수렴도와 합의도가 모두 양호하게 산출되었으며, 이에 2차 델파이 조사를 수행하지 않았다.",
          "author": "이은철;변영신;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 31,
          "score": 0.5270107984542847,
          "doc_id": "NPAP13833015",
          "title": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk",
          "abstract": "nan",
          "source": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk ",
          "author": "Uzor, Stephen;Jacques, Jason T.;Dudley, John J;Kristensson, Per Ola;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 32,
          "score": 0.526107132434845,
          "doc_id": "ATN0051728156",
          "title": "언어학, 전산언어학, 그리고 디지털 인문학",
          "abstract": "디지털 시대는 인문학에 새로운 가능성을 열어주었으며, 특히 컴퓨터 기술과 융합한 디지털 인문학이 부상하고 있다. 디지털 인문학의 효시는 ‘인문전산학’으로, 로베르토 부사 신부의 중세 라틴어 색인 작업에서 시작되었다. 초기 디지털 인문학은 전산언어학 및 컴퓨터공학과 함께 언어학, 고고학 등의 통계자료 처리에 활용되었으나, 컴퓨터 성능의 한계로 텍스트 색인 및 2차 가공에 머물렀다. 그러나 1980년대 이후 컴퓨터 성능 향상과 전산언어학의 발전으로 디지털 인문학은 대규모 데이터 기반 연구가 가능해졌고, 디지털 자원 구축 및 관리, 텍스트 분석, 데이터 시각화 등의 분석 방법이 발전했다. 2000년대 이후 빅데이터와 생성형 AI의 등장으로 디지털 인문학은 더욱 발전하여 독립된 학문 분야로 나아가고 있다. 언어학은 인문학적이면서도 자연과학적인 특성을 지닌 융복합 학문이며, 특히 전산언어학은 디지털 시대의 인문학에 최적화된 분야이다. 디지털 기술 도입으로 언어학은 코퍼스 기반 연구, 전산 실험 언어학, 디지털 기록 보존 및 분석 등 방법론과 연구 대상을 확장하고 있다. 전산언어학은 텍스트 분석, 의미 분석, 정보 추출 등을 통해 인문학 연구자가 방대한 언어 데이터를 효율적으로 탐색하고 의미 있는 통찰력을 도출하는 데 핵심적인 역할을 수행한다. 디지털 인문학과 전산언어학의 융합은 문학, 역사, 철학, 고고학 등 다양한 인문학 분야에서 새로운 연구 성과를 창출하고 있다. 향후 연구에서는 융합적 접근을 심화하고, 디지털 데이터 활용의 윤리적 문제 등을 고려하며, 디지털 시대의 언어 기술 발전에 따른 사회적 책임을 논의해야 할 것이다. 언어학과 전산언어학은 지속적인 연구와 혁신을 통해 ‘디지털 인문학’ 분야에 중요한 영향을 미칠 것으로 기대된다.",
          "source": "언어학, 전산언어학, 그리고 디지털 인문학 언어학, 전산언어학, 그리고 디지털 인문학 언어학, 전산언어학, 그리고 디지털 인문학 디지털 시대는 인문학에 새로운 가능성을 열어주었으며, 특히 컴퓨터 기술과 융합한 디지털 인문학이 부상하고 있다. 디지털 인문학의 효시는 ‘인문전산학’으로, 로베르토 부사 신부의 중세 라틴어 색인 작업에서 시작되었다. 초기 디지털 인문학은 전산언어학 및 컴퓨터공학과 함께 언어학, 고고학 등의 통계자료 처리에 활용되었으나, 컴퓨터 성능의 한계로 텍스트 색인 및 2차 가공에 머물렀다. 그러나 1980년대 이후 컴퓨터 성능 향상과 전산언어학의 발전으로 디지털 인문학은 대규모 데이터 기반 연구가 가능해졌고, 디지털 자원 구축 및 관리, 텍스트 분석, 데이터 시각화 등의 분석 방법이 발전했다. 2000년대 이후 빅데이터와 생성형 AI의 등장으로 디지털 인문학은 더욱 발전하여 독립된 학문 분야로 나아가고 있다. 언어학은 인문학적이면서도 자연과학적인 특성을 지닌 융복합 학문이며, 특히 전산언어학은 디지털 시대의 인문학에 최적화된 분야이다. 디지털 기술 도입으로 언어학은 코퍼스 기반 연구, 전산 실험 언어학, 디지털 기록 보존 및 분석 등 방법론과 연구 대상을 확장하고 있다. 전산언어학은 텍스트 분석, 의미 분석, 정보 추출 등을 통해 인문학 연구자가 방대한 언어 데이터를 효율적으로 탐색하고 의미 있는 통찰력을 도출하는 데 핵심적인 역할을 수행한다. 디지털 인문학과 전산언어학의 융합은 문학, 역사, 철학, 고고학 등 다양한 인문학 분야에서 새로운 연구 성과를 창출하고 있다. 향후 연구에서는 융합적 접근을 심화하고, 디지털 데이터 활용의 윤리적 문제 등을 고려하며, 디지털 시대의 언어 기술 발전에 따른 사회적 책임을 논의해야 할 것이다. 언어학과 전산언어학은 지속적인 연구와 혁신을 통해 ‘디지털 인문학’ 분야에 중요한 영향을 미칠 것으로 기대된다.",
          "author": "정성훈",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 33,
          "score": 0.5260823965072632,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "author": "Tran, M.;Cabral, L.;Patel, R.;Cusack, R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 34,
          "score": 0.5259288549423218,
          "doc_id": "NART133815556",
          "title": "Developing AI Digital Textbook: Policy Status and Key Issues",
          "abstract": "<P>This study explores the current status and challenges of education policies related to the development of AI Digital Textbook in South Korea. It aims to gather foundational data to support the improvement and innovation of education policies amidst the transition to a digital education system. The research methodology included a scoping review using press releases, explanatory materials from the Ministry of Education, and documents from affiliated research institutions. The findings of the study are as follows. First, setting 2023 as the starting point for digital education innovation, the Ministry of Education has been promoting policies for the development of AI Digital Textbook, aiming to provide customized learning support for students. In the process of implementing these policies, establishing the legal status of AI digital textbooks and building institutional frameworks in collaboration with EdTech companies have been identified as key initiatives. Second, it was revealed that the Ministry of Education has established a T.O.U.C.H Teacher Group to drive innovation in digital-based education. This group is expected to grow members by 2025, with relevant training in a bootcamp format, with a focus on leading the transition to digital education. In addition, the study discusses emerging issues related to teachers and various aspects of AI Digital Textbook in the context of ongoing policy implementation. </P>",
          "source": "Developing AI Digital Textbook: Policy Status and Key Issues Developing AI Digital Textbook: Policy Status and Key Issues Developing AI Digital Textbook: Policy Status and Key Issues <P>This study explores the current status and challenges of education policies related to the development of AI Digital Textbook in South Korea. It aims to gather foundational data to support the improvement and innovation of education policies amidst the transition to a digital education system. The research methodology included a scoping review using press releases, explanatory materials from the Ministry of Education, and documents from affiliated research institutions. The findings of the study are as follows. First, setting 2023 as the starting point for digital education innovation, the Ministry of Education has been promoting policies for the development of AI Digital Textbook, aiming to provide customized learning support for students. In the process of implementing these policies, establishing the legal status of AI digital textbooks and building institutional frameworks in collaboration with EdTech companies have been identified as key initiatives. Second, it was revealed that the Ministry of Education has established a T.O.U.C.H Teacher Group to drive innovation in digital-based education. This group is expected to grow members by 2025, with relevant training in a bootcamp format, with a focus on leading the transition to digital education. In addition, the study discusses emerging issues related to teachers and various aspects of AI Digital Textbook in the context of ongoing policy implementation. </P>",
          "author": "Hwang, Jae Woon",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 35,
          "score": 0.5243775844573975,
          "doc_id": "NART106764981",
          "title": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data",
          "abstract": "<P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "source": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data <P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "author": "Ortega-Santos, Iv&aacute;n;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 36,
          "score": 0.5235443711280823,
          "doc_id": "DIKO0016959108",
          "title": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구",
          "abstract": "본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "source": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "author": "이승현",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 37,
          "score": 0.522831916809082,
          "doc_id": "JAKO202332657687316",
          "title": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구",
          "abstract": "본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "source": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "author": "이은철;변영신;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 38,
          "score": 0.5215164422988892,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "author": "Lewis, Andrew R.;Djupe, Paul A.;Mockabee, Stephen T.;Su&#8208;Ya Wu, Joshua;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 39,
          "score": 0.5207136273384094,
          "doc_id": "ATN0047358973",
          "title": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구",
          "abstract": "In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "source": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "author": "강아름;이용훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 40,
          "score": 0.5157712697982788,
          "doc_id": "JAKO202317962662812",
          "title": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석",
          "abstract": "이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "source": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "author": "윤지현;허소림;강성주;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 41,
          "score": 0.5111258029937744,
          "doc_id": "NART134452383",
          "title": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk",
          "abstract": "<P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "source": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk <P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "author": "Kassem, Sarrah;Wilpert (&Uuml;bersetzung), Chris W.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 42,
          "score": 0.5101865530014038,
          "doc_id": "JAKO202332657680960",
          "title": "유아 교육을 위한 AI 교육 내용 체계 구성 연구",
          "abstract": "본 연구는 유아 인공지능 교육을 위해 교육 내용 체계를 개발하는 것을 목적으로 수행되었다. 이를 위해서 유아 교육 및 인공지능 전문가 5인을 대상으로 FGI를 수행하였다. 전문가들의 담화는 의미해석 방법을 사용하였다. 의미해석 방법은 담화를 분석하는 전문적인 방법으로서 의미 압축-의미 범주화-의미 구조화의 절차를 사용한다. 본 연구는 전문가들의 담화에서 43개의 의미를 압축하였다. 43개의 의미는 범주화를 통해서 인간의 사고과정, 컴퓨팅 능력, 인공지능의 원리와 역사, 인공지능 기술의 활용, 데이터의 개념, 인공지능의 창의적 표현, 창의 융합적 문제해결을 위한 인공지능 하드웨어 구성, 창의 융합적 문제해결을 위한 인공지능 도구 탐색 및 활용, 창의 융합적 문제해결을 위한 인공지능 생성, 인공지능에 대한 관심, 인공지능과 더불어 살기, 인공지능의 윤리적 사용 및 태도'까지 12개의 내용으로 구성되었다. 마지막으로 12개의 내용은 의미구조화를 통해서 컴퓨팅 사고력, 인공지능과 데이터, 창의 융합적 문제해결, 인공지능 윤리'까지 4개의 범주로 구성되었다. 본 연구의 결과는 유아 교육 영역에서 인공지능 교육을 구성하기 위한 기초가 될 수 있다는 것이 가치를 가진다.",
          "source": "유아 교육을 위한 AI 교육 내용 체계 구성 연구 유아 교육을 위한 AI 교육 내용 체계 구성 연구 유아 교육을 위한 AI 교육 내용 체계 구성 연구 본 연구는 유아 인공지능 교육을 위해 교육 내용 체계를 개발하는 것을 목적으로 수행되었다. 이를 위해서 유아 교육 및 인공지능 전문가 5인을 대상으로 FGI를 수행하였다. 전문가들의 담화는 의미해석 방법을 사용하였다. 의미해석 방법은 담화를 분석하는 전문적인 방법으로서 의미 압축-의미 범주화-의미 구조화의 절차를 사용한다. 본 연구는 전문가들의 담화에서 43개의 의미를 압축하였다. 43개의 의미는 범주화를 통해서 인간의 사고과정, 컴퓨팅 능력, 인공지능의 원리와 역사, 인공지능 기술의 활용, 데이터의 개념, 인공지능의 창의적 표현, 창의 융합적 문제해결을 위한 인공지능 하드웨어 구성, 창의 융합적 문제해결을 위한 인공지능 도구 탐색 및 활용, 창의 융합적 문제해결을 위한 인공지능 생성, 인공지능에 대한 관심, 인공지능과 더불어 살기, 인공지능의 윤리적 사용 및 태도'까지 12개의 내용으로 구성되었다. 마지막으로 12개의 내용은 의미구조화를 통해서 컴퓨팅 사고력, 인공지능과 데이터, 창의 융합적 문제해결, 인공지능 윤리'까지 4개의 범주로 구성되었다. 본 연구의 결과는 유아 교육 영역에서 인공지능 교육을 구성하기 위한 기초가 될 수 있다는 것이 가치를 가진다.",
          "author": "이은철;한정수;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 43,
          "score": 0.5090956687927246,
          "doc_id": "DIKO0015787734",
          "title": "검사 공정 작업자 이미지 반복 처리 작업의 자동화 구현",
          "abstract": "본 논문은 검사 공정 작업자 이미지 반복 처리 작업을 자동화 시스템으로 대체하고자 하는 연구를 진행하였다. 검사 장비의 자동화에 따른 작업 스피드가 향상되었지만, 그 이면에 자동화 적용이 어려워 작업자가 직접 해야 하는 이미지 반복 확인 작업의 과제가 남아 있다. 이를 해결하기 위해 딥러닝을 활용한 이미지 분류 자동화 시스템을 개발하는 것이 본고의 목적이다.&amp;#xD; &amp;#xD; 검사 공정 작업자 이미지 반복 작업의 문제점은 단순 반복 행위로 인한 작업자의 건강상 역기능, 즉 시력 저하와 손목 통증이 대표적이다. 또한 작업자의 개인적인 판단과 오류로 인한 품질적인 측면인 재현성과 반복성도 문제점 중 하나이다. 뿐만 아니라 검사기에 이미지가 증가되면 작업자의 업무 부하로 인한 실시간 처리도 지연된다.&amp;#xD; &amp;#xD; 작업자의 이미지 확인 작업의 주요 이유는 이물성 불량을 양품으로 전환하여 수율을 향상시키는 것과 불량의 세부 Trend를 파악하고자 하기 위함이다. 이런 문제들을 해소하고자 딥러닝에서 CNN(Convolution Neural Network) 합성곱 신경망을 활용하여 이미지의 특징을 추출하고 학습을 진행 후 파라미터를 컴퓨터 신경망이 기억하였다가 분류 이미지가 들어오면 기억된 신경망이 이미지를 14가지 유형으로 자동 분류 예측하는 시스템을 개발하였다. 이미지 분류에는 전처리 과정과 이미지 분류 그리고 후처리 과정을 거치게 된다. 개발된 자동화 시스템에 평가 검증의 비교 대상은 작업자의 결과물과 비교하게 된다. 평가품을 선정 후 작업자가 선 작업을 하고 이 후 원본 이미지를 자동화 시스템이 분류하여 작업자 대비 자동화 시스템의 성능인 정합도를 비교하여 취합하였다. 이런 과정을 반복하면서 Confusion Matrix 오차 행렬을 이용하여 세부적 분석을 통해 정합도 이상 유형을 찾고 추가적인 학습에 파라미터를 수정하여 최적화에 점점 다가가게 된다.&amp;#xD; &amp;#xD; 14가지 항목의 이미지 15,000개를 학습시킨 후 1일 1,900,000개의 이미지를 분류하는 자동화 시스템의 정합도는 작업자 대비 93.26%의 정합도를 확인하였고 유형별 정합도의 최대 100%에서 최소 80.87%의 유형별 정합도를 확인하였다. 치명적 오류 681 ppm 그리고 치명적이지 않은 오류 6.7%에 성능을 확인하였다. 작업자 대비 이미지 처리 속도는 약 10배 이상의 개선 효과를 확인하였으며 이로 인하여 작업자의 건강상의 역기능 부담을 감소시켰고 작업자의 이미지 분류 확인 작업의 일관성을 시스템화하였다.&amp;#xD; &amp;#xD; 또한 이미지 처리 속도 향상으로 실시간 처리에 좀 더 가까워졌다. 현재 자동화 시스템의 정합도 93.26%에 유형별 정합도 100% 가까운 유형의 항목은 자동화 시스템의 이미지 분류 후 후처리 과정에서 분류 결과를 확인하여 강제로 작업자에게 전송시키지 않는 상태이며 이로 인한 작업자는 기존 대비 약 80%의 업무 과중을 줄일 수 있다.&amp;#xD; 업무에 과중을 최소화 함으로써 작업자 인력 소인화에 도달하였다. &amp;#xD; &amp;#xD; 추가적으로 향후 분리 되어 있는 검사기와 자동화 시스템을 검사기 장비 내에 결합하여 불필요한 전송 및 Loss를 최소화 하여 실시간 처리 및 인력 무인화에 도움이 될 것이라 기대된다. 또한 GPU를 추가적으로 멀티로 사용하여 자동화 시스템의 처리 속도 또한 현재보다 더 향상될 것으로 기대된다.",
          "source": "검사 공정 작업자 이미지 반복 처리 작업의 자동화 구현 검사 공정 작업자 이미지 반복 처리 작업의 자동화 구현 검사 공정 작업자 이미지 반복 처리 작업의 자동화 구현 본 논문은 검사 공정 작업자 이미지 반복 처리 작업을 자동화 시스템으로 대체하고자 하는 연구를 진행하였다. 검사 장비의 자동화에 따른 작업 스피드가 향상되었지만, 그 이면에 자동화 적용이 어려워 작업자가 직접 해야 하는 이미지 반복 확인 작업의 과제가 남아 있다. 이를 해결하기 위해 딥러닝을 활용한 이미지 분류 자동화 시스템을 개발하는 것이 본고의 목적이다.&amp;#xD; &amp;#xD; 검사 공정 작업자 이미지 반복 작업의 문제점은 단순 반복 행위로 인한 작업자의 건강상 역기능, 즉 시력 저하와 손목 통증이 대표적이다. 또한 작업자의 개인적인 판단과 오류로 인한 품질적인 측면인 재현성과 반복성도 문제점 중 하나이다. 뿐만 아니라 검사기에 이미지가 증가되면 작업자의 업무 부하로 인한 실시간 처리도 지연된다.&amp;#xD; &amp;#xD; 작업자의 이미지 확인 작업의 주요 이유는 이물성 불량을 양품으로 전환하여 수율을 향상시키는 것과 불량의 세부 Trend를 파악하고자 하기 위함이다. 이런 문제들을 해소하고자 딥러닝에서 CNN(Convolution Neural Network) 합성곱 신경망을 활용하여 이미지의 특징을 추출하고 학습을 진행 후 파라미터를 컴퓨터 신경망이 기억하였다가 분류 이미지가 들어오면 기억된 신경망이 이미지를 14가지 유형으로 자동 분류 예측하는 시스템을 개발하였다. 이미지 분류에는 전처리 과정과 이미지 분류 그리고 후처리 과정을 거치게 된다. 개발된 자동화 시스템에 평가 검증의 비교 대상은 작업자의 결과물과 비교하게 된다. 평가품을 선정 후 작업자가 선 작업을 하고 이 후 원본 이미지를 자동화 시스템이 분류하여 작업자 대비 자동화 시스템의 성능인 정합도를 비교하여 취합하였다. 이런 과정을 반복하면서 Confusion Matrix 오차 행렬을 이용하여 세부적 분석을 통해 정합도 이상 유형을 찾고 추가적인 학습에 파라미터를 수정하여 최적화에 점점 다가가게 된다.&amp;#xD; &amp;#xD; 14가지 항목의 이미지 15,000개를 학습시킨 후 1일 1,900,000개의 이미지를 분류하는 자동화 시스템의 정합도는 작업자 대비 93.26%의 정합도를 확인하였고 유형별 정합도의 최대 100%에서 최소 80.87%의 유형별 정합도를 확인하였다. 치명적 오류 681 ppm 그리고 치명적이지 않은 오류 6.7%에 성능을 확인하였다. 작업자 대비 이미지 처리 속도는 약 10배 이상의 개선 효과를 확인하였으며 이로 인하여 작업자의 건강상의 역기능 부담을 감소시켰고 작업자의 이미지 분류 확인 작업의 일관성을 시스템화하였다.&amp;#xD; &amp;#xD; 또한 이미지 처리 속도 향상으로 실시간 처리에 좀 더 가까워졌다. 현재 자동화 시스템의 정합도 93.26%에 유형별 정합도 100% 가까운 유형의 항목은 자동화 시스템의 이미지 분류 후 후처리 과정에서 분류 결과를 확인하여 강제로 작업자에게 전송시키지 않는 상태이며 이로 인한 작업자는 기존 대비 약 80%의 업무 과중을 줄일 수 있다.&amp;#xD; 업무에 과중을 최소화 함으로써 작업자 인력 소인화에 도달하였다. &amp;#xD; &amp;#xD; 추가적으로 향후 분리 되어 있는 검사기와 자동화 시스템을 검사기 장비 내에 결합하여 불필요한 전송 및 Loss를 최소화 하여 실시간 처리 및 인력 무인화에 도움이 될 것이라 기대된다. 또한 GPU를 추가적으로 멀티로 사용하여 자동화 시스템의 처리 속도 또한 현재보다 더 향상될 것으로 기대된다.",
          "author": "김영규",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 44,
          "score": 0.5073234438896179,
          "doc_id": "NART73866218",
          "title": "The Southern Dative Presentative Meets Mechanical Turk",
          "abstract": "<P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "source": "The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk <P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "author": "Wood, Jim;Horn, Laurence;Zanuttini, Raffaella;Lindemann, Luke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 45,
          "score": 0.5070512294769287,
          "doc_id": "JAKO201416760764337",
          "title": "인공신경망 기반의 TBM 터널 세그먼트 라이닝 부재력 평가",
          "abstract": "본 논문에서는 TBM 터널의 세그먼트 라이닝 설계 자동화 기술 개발의 일환으로 인공신경망기법을 이용한 세그먼트 라이닝 부재력 산정기법 개발에 관한 내용을 다루었다. 부재력 평가가 가능한 인공신경망을 개발하기 위해 먼저 다양한 설계조건을 도출하고 이에 대해 2-Ring Beam 모델을 이용한 유한요소해석을 수행하여 인공신경망 학습에 필요한 설계조건별 부재력에 관한 DB를 구축하였다. 구축된 DB를 활용하여 인공신경망의 최적화 과정을 통해 최대 부재력 및 분포도를 예측할 수 있는 인공신경망을 구축하였다. 검토 결과 구축된 인공신경망은 유한요소해석과 동일한 정밀도의 부재력 산정 기능을 확보하는 것으로 검토되었으며 따라서 TBM 세그먼트 라이닝 설계시 필요한 부재력 평가를 위한 효율적인 수단으로 활용될 수 있는 것으로 판단된다.",
          "source": "인공신경망 기반의 TBM 터널 세그먼트 라이닝 부재력 평가 인공신경망 기반의 TBM 터널 세그먼트 라이닝 부재력 평가 인공신경망 기반의 TBM 터널 세그먼트 라이닝 부재력 평가 본 논문에서는 TBM 터널의 세그먼트 라이닝 설계 자동화 기술 개발의 일환으로 인공신경망기법을 이용한 세그먼트 라이닝 부재력 산정기법 개발에 관한 내용을 다루었다. 부재력 평가가 가능한 인공신경망을 개발하기 위해 먼저 다양한 설계조건을 도출하고 이에 대해 2-Ring Beam 모델을 이용한 유한요소해석을 수행하여 인공신경망 학습에 필요한 설계조건별 부재력에 관한 DB를 구축하였다. 구축된 DB를 활용하여 인공신경망의 최적화 과정을 통해 최대 부재력 및 분포도를 예측할 수 있는 인공신경망을 구축하였다. 검토 결과 구축된 인공신경망은 유한요소해석과 동일한 정밀도의 부재력 산정 기능을 확보하는 것으로 검토되었으며 따라서 TBM 세그먼트 라이닝 설계시 필요한 부재력 평가를 위한 효율적인 수단으로 활용될 수 있는 것으로 판단된다.",
          "author": "유충식;최정혁;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 46,
          "score": 0.5063290596008301,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "author": "Mason, Winter;Suri, Siddharth;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 47,
          "score": 0.5061911344528198,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "author": "Arch, Joanna J.;Carr, Alaina L.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 48,
          "score": 0.5059177875518799,
          "doc_id": "DIKO0010672988",
          "title": "인공신경망을 이용한 문서 분류 : Text Categorization based on Artificial Neural Networks (ANN)",
          "abstract": "Abstract Li Chenghua Department of Information and Communication Chebuk National University Text categorization is an important application of machine learning to the field of document information retrieval. This thesis described two kinds of neural networks for text categorization, multi-output perceptron learning (MOPL) and back propagation neural network (BPNN). BPNN has been widely used in classification and pattern recognition. However it has some generally acknowledged defects, usually these defects evolve from some morbidity neurons In this thesis I proposed a novel adaptive learning approach for text categorization using improved back propagation neural network. This algorithm can overcome some shortcomings in traditional back propagation neural network such as slow training speed and easy to get into local minimum. We compared the training time and performance and test the three methods on the standard Reuter-21578. The results show that the proposed algorithm is able to achieve high categorization effectiveness as measured by precision, recall and F-measure. 요약 문서분류는 정보검색에서 기계학습을 응용하는 중요한 분야이다. 본 논문에서는 다중출력 퍼셉트론 학습(Multi-Output Perceptron Learning:MOPL)과 백 프로퍼게이션 신경망(Back Propagation Neural Network:BPNN) 두 가지의 신경망 이론을 문서분류에 적용하였다. BPNN은 분류와 패턴인식에 많이 사용되고 있지만, 치명적인 신경을 포함하는 몇 가지 결점이 있다. 본 논문에서는 향상된 백 프로퍼게이션 신경망이론을 사용한 새로운 학습법을 제안할 것이다. 이 알고리즘은 기존의 백 프로퍼게이션 신경망의 느린 학습 속도와 쉽게 국소적인 제한치로 빠지는 문제를 개선할 수 있다. 로이터 자료(Reuter-21578)을 이용하여 세 가지 방법을 테스트하고, 학습시간과 성능을 비교하였다. 정확율, 재현율, 그리고 F-mesure를 통하여 본 논문에서 제안한 문서분류 알고리즘의 높은 성능을 확인할 수 있다.",
          "source": "인공신경망을 이용한 문서 분류 : Text Categorization based on Artificial Neural Networks (ANN) 인공신경망을 이용한 문서 분류 : Text Categorization based on Artificial Neural Networks (ANN) 인공신경망을 이용한 문서 분류 : Text Categorization based on Artificial Neural Networks (ANN) Abstract Li Chenghua Department of Information and Communication Chebuk National University Text categorization is an important application of machine learning to the field of document information retrieval. This thesis described two kinds of neural networks for text categorization, multi-output perceptron learning (MOPL) and back propagation neural network (BPNN). BPNN has been widely used in classification and pattern recognition. However it has some generally acknowledged defects, usually these defects evolve from some morbidity neurons In this thesis I proposed a novel adaptive learning approach for text categorization using improved back propagation neural network. This algorithm can overcome some shortcomings in traditional back propagation neural network such as slow training speed and easy to get into local minimum. We compared the training time and performance and test the three methods on the standard Reuter-21578. The results show that the proposed algorithm is able to achieve high categorization effectiveness as measured by precision, recall and F-measure. 요약 문서분류는 정보검색에서 기계학습을 응용하는 중요한 분야이다. 본 논문에서는 다중출력 퍼셉트론 학습(Multi-Output Perceptron Learning:MOPL)과 백 프로퍼게이션 신경망(Back Propagation Neural Network:BPNN) 두 가지의 신경망 이론을 문서분류에 적용하였다. BPNN은 분류와 패턴인식에 많이 사용되고 있지만, 치명적인 신경을 포함하는 몇 가지 결점이 있다. 본 논문에서는 향상된 백 프로퍼게이션 신경망이론을 사용한 새로운 학습법을 제안할 것이다. 이 알고리즘은 기존의 백 프로퍼게이션 신경망의 느린 학습 속도와 쉽게 국소적인 제한치로 빠지는 문제를 개선할 수 있다. 로이터 자료(Reuter-21578)을 이용하여 세 가지 방법을 테스트하고, 학습시간과 성능을 비교하였다. 정확율, 재현율, 그리고 F-mesure를 통하여 본 논문에서 제안한 문서분류 알고리즘의 높은 성능을 확인할 수 있다.",
          "author": "리청화",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 49,
          "score": 0.5039064884185791,
          "doc_id": "ATN0037485880",
          "title": "한국수어 응용언어학 연구 동향 분석",
          "abstract": "The purpose of this study is to analyze the research trends of Korean Sign Language(KSL) applied linguistics from 2005 to 2020 and identify the implications and characteristics of existing studies, and suggest directions for future research. As a result of analyzing a total of 211 research papers, research topics were revealed by 11 research fields, and KSL applied linguistics has been the most researched in engineering with 116 papers(54.98%). Developmental researches were the most with 123 papers(58.29%).  The year in which research papers were published the most was 2019, with the largest number of 32 papers(15.16%). Of the total, 117 papers(55.45%) were published in the journal, followed by ‘Excellent registered’for 3 papers(2.56%), ‘Registered’for 91 papers(77.78%), ‘Registered candidate’for 23 papers(19.66%). KSL applied linguistics research was published the most in ‘The Journal of Special Education’with 15 papers(7.11%), two authors were the most with 60 papers(28.44%), the most frequently used key word was ‘Sign Language’with 25 papers(22.94%).",
          "source": "한국수어 응용언어학 연구 동향 분석 한국수어 응용언어학 연구 동향 분석 한국수어 응용언어학 연구 동향 분석 The purpose of this study is to analyze the research trends of Korean Sign Language(KSL) applied linguistics from 2005 to 2020 and identify the implications and characteristics of existing studies, and suggest directions for future research. As a result of analyzing a total of 211 research papers, research topics were revealed by 11 research fields, and KSL applied linguistics has been the most researched in engineering with 116 papers(54.98%). Developmental researches were the most with 123 papers(58.29%).  The year in which research papers were published the most was 2019, with the largest number of 32 papers(15.16%). Of the total, 117 papers(55.45%) were published in the journal, followed by ‘Excellent registered’for 3 papers(2.56%), ‘Registered’for 91 papers(77.78%), ‘Registered candidate’for 23 papers(19.66%). KSL applied linguistics research was published the most in ‘The Journal of Special Education’with 15 papers(7.11%), two authors were the most with 60 papers(28.44%), the most frequently used key word was ‘Sign Language’with 25 papers(22.94%).",
          "author": "고인경;윤병천;이보경;이지민;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 50,
          "score": 0.5034880638122559,
          "doc_id": "NART126363952",
          "title": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses",
          "abstract": "<P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "source": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses <P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "author": "Schleiss, Johannes;Laupichler, Matthias Carl;Raupach, Tobias;Stober, Sebastian;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        }
      ]
    },
    {
      "query": "What are the key findings of the socio-technical evaluation regarding factors influencing user adoption?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6539841294288635,
          "doc_id": "NPAP12463036",
          "title": "Exploring Crowd Consistency in a Mechanical Turk Survey",
          "abstract": "<P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "source": "Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey Exploring Crowd Consistency in a Mechanical Turk Survey <P>Crowdsourcing can provide a platform for evaluating software engineering research. In this paper, we aim to explore characteristics of the worker population on Amazon's Mechanical Turk, a popular micro task crowdsourcing environment, and measure the percentage of workers who are potentially qualified to perform software- or computer science- related tasks. Through a baseline survey and two replications, we measure workers' answer consistency as well as the consistency of sample characteristics. In the end, we deployed 1,200 total surveys that were completed by 1,064 unique workers. Our results show that 24% of the study participants have a computer science or IT background and most people are payment driven when choosing tasks. The sample characteristics can vary significantly, even on large samples with 300 participants. Additionally, we often observed inconsistency in workers' answers for those who completed two surveys; approximately 30% answered at least one question inconsistently between the two survey submissions. This implies a need for replication and quality controls in crowdsourced experiments.</P>",
          "author": "Sun, Peng;Stolee, Kathryn T.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 2,
          "score": 0.6479091644287109,
          "doc_id": "NART121336460",
          "title": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples",
          "abstract": "<P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "source": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples <P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "author": "Weigold, Arne;Weigold, Ingrid K.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 3,
          "score": 0.6467693448066711,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "author": "De Lurgio II, Stephen A.;Young, Amber;Steelman, Zachary R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 4,
          "score": 0.6301431655883789,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;Ipeirotis, Panagiotis G.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 5,
          "score": 0.6291248798370361,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "author": "Bohannon, John",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 6,
          "score": 0.6275292038917542,
          "doc_id": "NART77189173",
          "title": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks",
          "abstract": "<P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "source": "Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks Fauxvea: Crowdsourcing Gaze Location Estimates for Visualization Analysis Tasks <P>We present the design and evaluation of a method for estimating gaze locations during the analysis of static visualizations using crowdsourcing. Understanding gaze patterns is helpful for evaluating visualizations and user behaviors, but traditional eye-tracking studies require specialized hardware and local users. To avoid these constraints, we developed a method called Fauxvea, which crowdsources visualization tasks on the Web and estimates gaze fixations through cursor interactions without eye-tracking hardware. We ran experiments to evaluate how gaze estimates from our method compare with eye-tracking data. First, we evaluated crowdsourced estimates for three common types of information visualizations and basic visualization tasks using Amazon Mechanical Turk (MTurk). In another, we reproduced findings from a previous eye-tracking study on tree layouts using our method on MTurk. Results from these experiments show that fixation estimates using Fauxvea are qualitatively and quantitatively similar to eye tracking on the same stimulus-task pairs. These findings suggest that crowdsourcing visual analysis tasks with static information visualizations could be a viable alternative to traditional eye-tracking studies for visualization research and design.</P>",
          "author": "Gomez, Steven R.;Jianu, Radu;Cabeen, Ryan;Guo, Hua;Laidlaw, David H.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 7,
          "score": 0.6265528798103333,
          "doc_id": "NART117776930",
          "title": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk",
          "abstract": "<P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "source": "Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk Crowdsourcing for Machine Learning in Public Health Surveillance: Lessons Learned From Amazon Mechanical Turk <P><B>Background</B></P><P>Crowdsourcing services, such as Amazon Mechanical Turk (AMT), allow researchers to use the collective intelligence of a wide range of web users for labor-intensive tasks. As the manual verification of the quality of the collected results is difficult because of the large volume of data and the quick turnaround time of the process, many questions remain to be explored regarding the reliability of these resources for developing digital public health systems.</P><P><B>Objective</B></P><P>This study aims to explore and evaluate the application of crowdsourcing, generally, and AMT, specifically, for developing digital public health surveillance systems.</P><P><B>Methods</B></P><P>We collected 296,166 crowd-generated labels for 98,722 tweets, labeled by 610 AMT workers, to develop machine learning (ML) models for detecting behaviors related to physical activity, sedentary behavior, and sleep quality among Twitter users. To infer the ground truth labels and explore the quality of these labels, we studied 4 statistical consensus methods that are agnostic of task features and only focus on worker labeling behavior. Moreover, to model the meta-information associated with each labeling task and leverage the potential of context-sensitive data in the truth inference process, we developed 7 ML models, including traditional classifiers (offline and active), a deep learning&#x2013;based classification model, and a hybrid convolutional neural network model.</P><P><B>Results</B></P><P>Although most crowdsourcing-based studies in public health have often equated majority vote with quality, the results of our study using a truth set of 9000 manually labeled tweets showed that consensus-based inference models mask underlying uncertainty in data and overlook the importance of task meta-information. Our evaluations across 3 physical activity, sedentary behavior, and sleep quality data sets showed that truth inference is a context-sensitive process, and none of the methods studied in this paper were consistently superior to others in predicting the truth label. We also found that the performance of the ML models trained on crowd-labeled data was sensitive to the quality of these labels, and poor-quality labels led to incorrect assessment of these models. Finally, we have provided a set of practical recommendations to improve the quality and reliability of crowdsourced data.</P><P><B>Conclusions</B></P><P>Our findings indicate the importance of the quality of crowd-generated labels in developing ML models designed for decision-making purposes, such as public health surveillance decisions. A combination of inference models outlined and analyzed in this study could be used to quantitatively measure and improve the quality of crowd-generated labels for training ML models.</P>",
          "author": "Shakeri Hossein Abad, Zahra;Butler, Gregory P;Thompson, Wendy;Lee, Joon;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 8,
          "score": 0.6258745193481445,
          "doc_id": "JAKO202116057056093",
          "title": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로",
          "abstract": "본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "source": "인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 인공지능(AI) 스피커에 대한 사회구성 차원의 발달과정 연구: 제품과 시기별 공진화 과정을 중심으로 본 연구는 전통뉴스 보도에 나타난 인공지능(AI)스피커 뉴스 텍스트 분석을 통해 인공지능(AI) 스피커 발달과정을 분류하고 시기별 제품별 특성을 파악하였다. 또한 AI 스피커 사업자 제품별 뉴스 보도와 시기별 뉴스 보도간의 상관관계를 분석하였다. 분석에 사용된 이론적 배경은 뉴스의 프레임과 토픽프레임이다. 분석방법으로는 LDA 방식을 활용한 토픽모델링(Topic Modeling)과 의미연결망분석이 사용되었으며, 추가로 'UCINET'중 QAP분석을 적용하였다. 연구방법은 내용분석 방법으로 2014년부터 2019년까지 AI 스피커 관련 2,710건의 뉴스를 1차로 수집하였고, 2차적으로 Nodexl 알고리즘을 이용하여 토픽프레임을 분석하였다. 분석 결과 첫째, AI 스피커 사업자 유형별 토픽 프레임의 경향은 4개 사업자(통신사업자, 온라인 플랫폼, OS 사업자, IT디바이스 생산업자) 특성에 따라 다르게 나타났다. 구체적으로, 온라인 플랫폼 사업자(구글, 네이버, 아마존, 카카오)와 관련한 프레임은 AI 스피커를 '검색 또는 입력 디바이스'로 사용하는 프레임의 비중이 높았다. 반면 통신 사업자(SKT, KT)는 모회사의 주력 사업인 IPTV, 통신 사업의 '보조 디바이스' 관련한 프레임이 두드러지게 나타났다. 나아가 OS 사업자(MS, 애플)는 '제품의 의인화 및 음성 서비스' 프레임이 두드러지게 보였으며, IT 디바이스 생산업자(삼성)는 '사물인터넷(IoT) 종합지능시스템'과 관련한 프레임이 두드러지게 나타났다. 둘째, AI 스피커 시기별(연도별) 토픽 프레임의 경향은 1기(2014-2016년)에는 AI 기술 중심으로 발달하는 경향을 보였고, 2기(2017-2018년)에는 AI 기술과 이용자 간의 사회적 상호 작용과 관련되어 있었으며, 3기(2019년)에는 AI 기술 중심에서 이용자 중심으로 전환되는 경향을 나타냈다. QAP 분석 결과, AI 스피커 발달에서 사업자별과 시기별 뉴스 프레임이 미디어 담론의 결정요인에 의해 사회적으로 구성되는 것을 알 수 있었다. 본연구의 함의는 AI 스피커 진화는 사업자별, 발달시기별로 모회사 기업의 특성과 이용자 간의 상호작용으로 인한 공진화 과정이 나타냄을 발견할 수 있었다. 따라서 본 연구는 AI 스피커의 향후 전망을 예측하고 그에 따른 방향성을 제시하는 데 중요한 시사점을 제공한다.",
          "author": "차현주;권상희;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 9,
          "score": 0.6192003488540649,
          "doc_id": "NART109637313",
          "title": "Annotator Rationales for Labeling Tasks in Crowdsourcing",
          "abstract": "<P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "source": "Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing Annotator Rationales for Labeling Tasks in Crowdsourcing <P>When collecting item ratings from human judges, it can be difficult to measure and enforce data quality due to task subjectivity and lack of transparency into how judges make each rating decision. To address this, we investigate asking judges to provide a specific form of rationale supporting each rating decision. We evaluate this approach on an information retrieval task in which human judges rate the relevance of Web pages for different search topics. Cost-benefit analysis over 10,000 judgments collected on Amazon&rsquo;s Mechanical Turk suggests a win-win. Firstly, rationales yield a multitude of benefits: more reliable judgments, greater transparency for evaluating both human raters and their judgments, reduced need for expert gold, the opportunity for dual-supervision from ratings and rationales, and added value from the rationales themselves. Secondly, once experienced in the task, crowd workers provide rationales with almost no increase in task completion time. Consequently, we can realize the above benefits with minimal additional cost.</P>",
          "author": "Kutlu, Mucahid;McDonnell, Tyler;Lease, Matthew;Elsayed, Tamer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 10,
          "score": 0.6181523203849792,
          "doc_id": "NART87817032",
          "title": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative",
          "abstract": "<P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "source": "Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative Coding Psychological Constructs in Text Using Mechanical Turk: A Reliable, Accurate, and Efficient Alternative <P>In this paper we evaluate how to effectively use the crowdsourcing service, Amazon's Mechanical Turk (MTurk), to content analyze textual data for use in psychological research. MTurk is a marketplace for discrete tasks completed by workers, typically for small amounts of money. MTurk has been used to aid psychological research in general, and content analysis in particular. In the current study, MTurk workers content analyzed personally-written textual data using coding categories previously developed and validated in psychological research. These codes were evaluated for reliability, accuracy, completion time, and cost. Results indicate that MTurk workers categorized textual data with comparable reliability and accuracy to both previously published studies and expert raters. Further, the coding tasks were performed quickly and cheaply. These data suggest that crowdsourced content analysis can help advance psychological research.</P>",
          "author": "Tosti-Kharas, Jennifer;Conley, Caryn;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 11,
          "score": 0.617058277130127,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "author": "Schnoebelen, Tyler;Kuperman, Victor;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 12,
          "score": 0.6133634448051453,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "author": "Shapiro, Danielle N.;Chandler, Jesse;Mueller, Pam A.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 13,
          "score": 0.6039255857467651,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "author": "Rouse, S.V.",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 14,
          "score": 0.6035667061805725,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "author": "Lewis, Andrew R.;Djupe, Paul A.;Mockabee, Stephen T.;Su&#8208;Ya Wu, Joshua;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 15,
          "score": 0.5997825264930725,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "author": "Tran, M.;Cabral, L.;Patel, R.;Cusack, R.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 16,
          "score": 0.596435010433197,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "author": "Pavlick, Ellie;Post, Matt;Irvine, Ann;Kachaev, Dmitry;Callison-Burch, Chris;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 17,
          "score": 0.5861618518829346,
          "doc_id": "NART69743055",
          "title": "Crowdsourcing content analysis for managerial research",
          "abstract": "<P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "source": "Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research Crowdsourcing content analysis for managerial research <P><B>Purpose</B></P> <P> &ndash; The purpose of this paper is to evaluate the effectiveness of a novel method for performing content analysis in managerial research &ndash; crowdsourcing, a system where geographically distributed workers complete small, discrete tasks via the internet for a small amount of money. </P> <P><B>Design/methodology/approach</B></P> <P> &ndash; The authors examined whether workers from one popular crowdsourcing marketplace, Amazon's Mechanical Turk, could perform subjective content analytic tasks involving the application of inductively generated codes to unstructured, personally written textual passages. </P> <P><B>Findings</B></P> <P> &ndash; The findings suggest that anonymous, self-selected, non-expert crowdsourced workers were applied content codes efficiently and at low cost, and that their reliability and accuracy compared to that of trained researchers. </P> <P><B>Research limitations/implications</B></P> <P> &ndash; The authors provide recommendations for management researchers interested in using crowdsourcing most effectively for content analysis, including a discussion of the limitations and ethical issues involved in using this method. Future research could extend the findings by considering alternative data sources and coding schemes of interest to management researchers. </P> <P><B>Originality/value</B></P> <P> &ndash; Scholars have begun to explore whether crowdsourcing can assist in academic research; however, this is the first study to examine how crowdsourcing might facilitate content analysis. Crowdsourcing offers several advantages over existing content analytic approaches by combining the efficiency of computer-aided text analysis with the interpretive ability of traditional human coding.</P>",
          "author": "Conley, Caryn;Tosti-Kharas, Jennifer;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 18,
          "score": 0.5798627138137817,
          "doc_id": "JAKO202433335467568",
          "title": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석",
          "abstract": "This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "source": "텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 텍스트 마이닝을 활용한 AI 디지털교과서 키워드 분석 This study aims to explore the potential issues and challenges associated with the development, introduction, utilization, and stabilization of AI digital textbook, as well as to identify tasks necessary to address these challenges. We collected and analyzed data from domestic news articles and previous research literature related to 'AI digital textbook' to derive key keywords using a comprehensive text analysis approach with Bigkinds and Textom. Through Bigkinds, we conducted keyword trend analysis, associated word analysis, and relationship analysis. Using Textom, we performed keyword frequency analysis, N-gram analysis, TF-IDF(Term Frequency-Inverse Document Frequency) analysis, and network analysis. This approach allowed us to identify the main issues related to the development, implementation, utilization of AI digital textbook and explore the necessary tasks to address these challenges.",
          "author": "민준홍;김미량;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 19,
          "score": 0.5789716243743896,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "author": "Paolacci, Gabriele;Chandler, Jesse;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 20,
          "score": 0.5765239000320435,
          "doc_id": "DIKO0016959108",
          "title": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구",
          "abstract": "본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "source": "AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 AI 디지털교과서 개발 방향 설정에 대한 초등 교사 인식 연구 본 연구는 교육부의 AI 디지털교과서 개발 방향 설정에 대한 초등 교사의 인식을 알아보기 위한 목적으로 실시되었다. 이를 위해 교육부의 AI 디지털교과서 개발 정책과 한국교육학술정보원의 AI 디지털교과서 개발 가이드라인을 바탕으로 약 40개의 문항이 담긴 설문지를 제작하여 배포하였다. 회수된 초등 교사 106명의 응답을 대응표본 t-검정, Borich 요구도, The Locus for Focus 모델을 통해 통계 처리하였으며 분석을 통해 얻은 결과는 다음과 같다.&amp;#xD; 첫째, 현재 서비스 되고 있는 디지털교과서와 발행사별 교수학습지원사이트의 이용 경험은 발행사별 교수학습지원사이트 이용 경험에 비해 굉장히 낮았으며 그 원인으로는 교수학습지원사이트에 비해 멀티미디어 콘텐츠의 부족, 사용법의 어려움과 기능의 불편함, 필요한 기능의 부재 등을 꼽았다.&amp;#xD; 둘째, AI 디지털교과서의 기본 기능인 통합 인증 기능, 통합 대시보드, 디지털교과서 책장, 학습데이터 허브 기능의 필요성을 묻는 질문에 대해 약 80% 이상의 교사가 필요하다고 응답하였다.&amp;#xD; 셋째, AI 기반 맞춤형 학습 지원 기능인 학습 진단 기능, 맞춤형 콘텐츠 제공 기능, 대시보드 기능, AI 튜터 기능, AI 보조교사 기능, 교사 재구성 기능의 필요성을 묻는 질문에 대한 응답을 전체 집단과 최종 학력 기준 집단으로 분석을 실시하였다. 대응표본 t-검정 결과는 모든 집단의 응답 결과에 대해 통계적으로 유의미한 차이(&amp;amp;lt; .001)가 있는 것으로 나타났다. Borich 요구도 및 The Locus for Focus 모델에 의한 분석 결과는 전체 집단의 경우 AI 보조교사 AI 튜터 기능에 대한 요구 수준이 가장 높았으며 The Locus for Focus 모델을 통한 분석 결과도 위의 두 기능 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력을 기준으로 집단을 나누어 분석한 결과는 최종 학력이 학사인 경우와 컴퓨터 관련 석사 과정 재학 중 또는 석사 학위 소지인 경우 AI 보조교사 기능과 AI 튜터 기능에 대한 요구도가 가장 높았으며 The Locus for Focus 모델 분석 결과 또한 두 기능이 모두 1사분면(HH)에 위치하여 우선순위가 가장 높은 것으로 나타났다. 최종 학력이 그 외 석사 과정 재학 중 또는 석사 학위 소지인 경우 위의 두 집단과 마찬가지로 AI 튜터 기능과 AI 보조교사 기능이 요구도가 가장 높았으나 The Locus for Focus 모델 분석 결과의 경우 1사분면에 위치한 기능이 존재하지 않아 개발 우선 순위에 대한 논의가 필요한 것으로 나타났다.&amp;#xD; 넷째, 여섯 가지 AI 기반 맞춤형 학습 지원 기능에 대한 추가 수요 분석 결과를 실시하였다. 학습 진단 기능에 대한 추가 수요는 학생 참여 정도 진단 서비스, 협업 정도 진단 서비스, 정서 분석 서비스 등으로 나타났다. 맞춤형 콘텐츠 제공 기능에 대한 추가 수요는 이전 학년 과정 추천 기능, 맞춤형 콘텐츠 교사 제시 기능, 문항 난이도 조절 기능, 학습 경로 설정 기능 등으로 나타났다. 대시보드 기능에 대한 추가 수요는 오답 노트 작성 기능, 학습전략 추천 기능, 토론 및 채팅 기능 등으로 나타났다. AI 튜터 기능에 대한 추가 수요는 추가 학습 자료 제공 기능, 힌트 제공 기능 등으로 나타났다. AI 보조교사 기능에 대한 추가 수요는 문항 자동 채점 기능 및 결과 제공 기능, 교과학습발달상황 및 행동발상황 작성 지원 기능, 학생 수준별 문항 자동 구성 및 출제 기능, 수행평가 결과 NEIS 전송 기능 등으로 나타났다. 교사 재구성 기능에 대한 추가 수요는 프로젝트 학습을 위한 교과서 간 내용 통합 및 순서 조정 기능, 발행사별 교과서 내용 비교 및 끌어오기 기능 등으로 나타났다. 그 밖의 기능에 대한 수요는 에듀테크 사이트 연결 기능, 게임을 통한 성취도 확인 기능, 과제에 따른 보상 기능, 학교 간 학습 내용 공유 기능, 자료 저장소 기능, 출결 확인 기능, 커뮤니티 기능 등으로 나타났다. &amp;#xD; 본 연구는 AI 디지털교과서 개발과 관련한 교육부 정책의 방향을 확인하고 한국교육학술정보원이 발간한 AI 디지털교과서 개발 가이드라인의 의미를 해석하는 데 활용될 수 있다. 또한 AI 디지털교과서 개발 방향 설정에 대한 교사의 인식 및 수요를 확인하는 자료로 사용될 수 있으며 이를 바탕으로 AI 디지털교과서 개발 관련자들이 교수학습지원시스템으로서의 AI 디지털교과서를 개발하는 데 도움이 될 것으로 기대한다.",
          "author": "이승현",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 21,
          "score": 0.5751478672027588,
          "doc_id": "NPAP13833015",
          "title": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk",
          "abstract": "nan",
          "source": "Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk Investigating the Accessibility of Crowdwork Tasks on Mechanical Turk ",
          "author": "Uzor, Stephen;Jacques, Jason T.;Dudley, John J;Kristensson, Per Ola;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 22,
          "score": 0.5721697211265564,
          "doc_id": "JAKO200315875829102",
          "title": "수작업의 반복성 평가 방법 조사",
          "abstract": "Evaluation of repetitiveness for hand-intensive tasks is essential to determine the level of risk for upper-extremity musculoskeletal disorders at the workplace. Many measures and methods have been introduced for repetitiveness assessment: however, our understanding of the differences among these measures and methods is lacking. The present study compared the repetitiveness measures and measurement/analysis methods to help practitioners apply the proper repetitiveness assessment methodology in the workplace. By reviewing 51 studies of repetitiveness assessment, measures and corresponding measurement/analysis methods were surveyed. Of the repetitiveness measures, two types of dimensions (frequency and time) and corresponding types of analysis scopes were identified. According to the dimensional and analysis-scope types. the repetitiveness measures were categorized and then the surveyed studies were counted for each measure. It is identified that frequency measures have used 2.7 times higher than time measures and the frequency of wrist motions has been most frequently used in repetitiveness assessment. Furthermore, the measurement methods were categorized into objective and subjective methods, and the analysis methods into statistical and spectral methods. Lastly, eight factors (accuracy, reliability. sensitivity. efficiency. ease of use. applicability. interference. and robustness) were listed to be considered in selecting the appropriate assessment methodology.",
          "source": "수작업의 반복성 평가 방법 조사 수작업의 반복성 평가 방법 조사 수작업의 반복성 평가 방법 조사 Evaluation of repetitiveness for hand-intensive tasks is essential to determine the level of risk for upper-extremity musculoskeletal disorders at the workplace. Many measures and methods have been introduced for repetitiveness assessment: however, our understanding of the differences among these measures and methods is lacking. The present study compared the repetitiveness measures and measurement/analysis methods to help practitioners apply the proper repetitiveness assessment methodology in the workplace. By reviewing 51 studies of repetitiveness assessment, measures and corresponding measurement/analysis methods were surveyed. Of the repetitiveness measures, two types of dimensions (frequency and time) and corresponding types of analysis scopes were identified. According to the dimensional and analysis-scope types. the repetitiveness measures were categorized and then the surveyed studies were counted for each measure. It is identified that frequency measures have used 2.7 times higher than time measures and the frequency of wrist motions has been most frequently used in repetitiveness assessment. Furthermore, the measurement methods were categorized into objective and subjective methods, and the analysis methods into statistical and spectral methods. Lastly, eight factors (accuracy, reliability. sensitivity. efficiency. ease of use. applicability. interference. and robustness) were listed to be considered in selecting the appropriate assessment methodology.",
          "author": "권오채;유희천;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 23,
          "score": 0.5708683729171753,
          "doc_id": "NART74131061",
          "title": "Lessons Learned from Crowdsourcing Complex Engineering Tasks",
          "abstract": "<P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "source": "Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks Lessons Learned from Crowdsourcing Complex Engineering Tasks <P><B>Crowdsourcing</B></P><P>Crowdsourcing is the practice of obtaining needed ideas, services, or content by requesting contributions from a large group of people. Amazon Mechanical Turk is a web marketplace for crowdsourcing microtasks, such as answering surveys and image tagging. We explored the limits of crowdsourcing by using Mechanical Turk for a more complicated task: analysis and creation of wind simulations.</P><P><B>Harnessing Crowdworkers for Engineering</B></P><P>Our investigation examined the feasibility of using crowdsourcing for complex, highly technical tasks. This was done to determine if the benefits of crowdsourcing could be harnessed to accurately and effectively contribute to solving complex real world engineering problems. Of course, untrained crowds cannot be used as a mere substitute for trained expertise. Rather, we sought to understand how crowd workers can be used as a large pool of labor for a preliminary analysis of complex data.</P><P><B>Virtual Wind Tunnel</B></P><P>We compared the skill of the anonymous crowd workers from Amazon Mechanical Turk with that of civil engineering graduate students, making a first pass at analyzing wind simulation data. For the first phase, we posted analysis questions to Amazon crowd workers and to two groups of civil engineering graduate students. A second phase of our experiment instructed crowd workers and students to create simulations on our Virtual Wind Tunnel website to solve a more complex task.</P><P><B>Conclusions</B></P><P>With a sufficiently comprehensive tutorial and compensation similar to typical crowd-sourcing wages, we were able to enlist crowd workers to effectively complete longer, more complex tasks with competence comparable to that of graduate students with more comprehensive, expert-level knowledge. Furthermore, more complex tasks require increased communication with the workers. As tasks become more complex, the employment relationship begins to become more akin to outsourcing than crowdsourcing. Through this investigation, we were able to stretch and explore the limits of crowdsourcing as a tool for solving complex problems.</P>",
          "author": "Staffelbach, Matthew;Sempolinski, Peter;Kijewski-Correa, Tracy;Thain, Douglas;Wei, Daniel;Kareem, Ahsan;Madey, Gregory;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 24,
          "score": 0.5702561140060425,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "author": "Arch, Joanna J.;Carr, Alaina L.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 25,
          "score": 0.5672237277030945,
          "doc_id": "NART120020213",
          "title": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces",
          "abstract": "<P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "source": "Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces Leveraging Crowdsourcing to Detect Improper Tasks in Crowdsourcing Marketplaces <P>Controlling the quality of tasks is a major challenge in crowdsourcing marketplaces. Most of the existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in the marketplaces have to monitor the tasks continuously to find such improper tasks; however, it is too expensive to manually investigate each task. In this paper, we present the reports of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We perform experiments using real task data from a commercial crowdsourcing marketplace and show that the classifier trained by the operator judgments achieves high accuracy in detecting improper tasks. In addition, to reduce the annotation costs of the operator and improve the classification accuracy, we consider the use of crowdsourcing for task annotation. We hire a group of crowdsourcing (non-expert) workers to monitor posted tasks, and incorporate their judgments into the training data of the classifier. By applying quality control techniques to handle the variability in worker reliability, our results show that the use of non-expert judgments by crowdsourcing workers in combination with expert judgments improves the accuracy of detecting improper crowdsourcing tasks.</P>",
          "author": "Baba, Yukino;Kashima, Hisashi;Kinoshita, Kei;Yamaguchi, Goushi;Akiyoshi, Yosuke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 26,
          "score": 0.5646579265594482,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "author": "Dai, P.;Lin, C.H.;Mausam;Weld, D.S.;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 27,
          "score": 0.5631174445152283,
          "doc_id": "DIKO0013926033",
          "title": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향",
          "abstract": "nan",
          "source": "피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 피드백과 목표가 크라우드소싱 결과물의 질에 미치는 영향 ",
          "author": "임재은",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 28,
          "score": 0.5628286600112915,
          "doc_id": "NART106764981",
          "title": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data",
          "abstract": "<P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "source": "Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data Crowdsourcing for Hispanic Linguistics: Amazon’s Mechanical Turk as a source of Spanish data <P>Within the field of Linguistics, Amazon&rsquo;s Mechanical Turk, a crowdsourcing marketplace specializes in computer-based Human Intelligence Tasks, has been praised as a cost efficient source of data for English and other major languages. Spanish is a good candidate due to its presence within the US and beyond. Still, detailed information concerning the linguistic and demographic profile of Spanish-speaking &lsquo;Turkers&rsquo; is missing, thus making it difficult for researchers to evaluate whether the Mechanical Turk provides the right environment for their tasks. This paper addresses this gap in our knowledge by developing the first detailed study of the presence of Spanish-speaking workers, focusing on factors relevant for research planning, namely, (socio)linguistically relevant variables and information concerning work habits. The results show that this platform provides access to a fairly active participant pool of both L1 and L2Spanish speakers as well as bilinguals. A brief introduction to how Amazon&rsquo;s Mechanical Turk works and overview of Hispanic Linguistics projects that have so far used the Mechanical Turk successfully is included.</P>",
          "author": "Ortega-Santos, Iv&aacute;n;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 29,
          "score": 0.5591803789138794,
          "doc_id": "JAKO199925458940212",
          "title": "반복적인 손목 및 손가락 작업에서의 수작업 부하 평가",
          "abstract": "The purpose of this study was to evaluate the manual workload in repetitive wrist and finger motion. To evaluate manual workload, angular displacement of the joint, EMG of the muscle and subjective rating were studied. Both wrist motion and finger motion were studied. A screw-driving task was used for the wrist motion experiment. A keyboard typing task was used for the finger motion experiment. All finger joint angles and wrist angles were measured by an angle-measuring glove(<TEX>$CyberGlove^{TM}$</TEX>, Virtual Technologies, Inc.). Surface EMG was recorded from FCU muscle and FDS muscle simultaneously with the angle measurement. Subjective ratings of exertion were also recorded using the modified Borg's CR-10 scale. Repetition rates of 0.5, 1, 2 motions per second were used with each task. As a result, manual workload increased with increasing repetitiveness. Peak spectral magnitude and frequency components corresponded closely with joint angular displacement amplitudes and repetition rates. Results of the correlation analysis showed that there were significant correlation among EMG, frequency-weighted motion and subjective measurement. Both EMG and frequency-weighted filtering showed consistent workload estimation with increasing task frequency. Subjective ratings showed slight over-estimation of the workload as the task frequency is increased.",
          "source": "반복적인 손목 및 손가락 작업에서의 수작업 부하 평가 반복적인 손목 및 손가락 작업에서의 수작업 부하 평가 반복적인 손목 및 손가락 작업에서의 수작업 부하 평가 The purpose of this study was to evaluate the manual workload in repetitive wrist and finger motion. To evaluate manual workload, angular displacement of the joint, EMG of the muscle and subjective rating were studied. Both wrist motion and finger motion were studied. A screw-driving task was used for the wrist motion experiment. A keyboard typing task was used for the finger motion experiment. All finger joint angles and wrist angles were measured by an angle-measuring glove(<TEX>$CyberGlove^{TM}$</TEX>, Virtual Technologies, Inc.). Surface EMG was recorded from FCU muscle and FDS muscle simultaneously with the angle measurement. Subjective ratings of exertion were also recorded using the modified Borg's CR-10 scale. Repetition rates of 0.5, 1, 2 motions per second were used with each task. As a result, manual workload increased with increasing repetitiveness. Peak spectral magnitude and frequency components corresponded closely with joint angular displacement amplitudes and repetition rates. Results of the correlation analysis showed that there were significant correlation among EMG, frequency-weighted motion and subjective measurement. Both EMG and frequency-weighted filtering showed consistent workload estimation with increasing task frequency. Subjective ratings showed slight over-estimation of the workload as the task frequency is increased.",
          "author": "권오채;윤명환;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 30,
          "score": 0.5579217672348022,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "author": "정수근",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 31,
          "score": 0.5551060438156128,
          "doc_id": "NPAP13430839",
          "title": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion",
          "abstract": "<P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "source": "AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion AI-based College Course Selection Recommendation System: Performance Prediction and Curriculum Suggestion <P>Recent advances of AI applications in various of industries have led to remarkable performance and efficiency. Driven by the great success of datasets and experience sharing, people are exploring more precious datasets with diverse features and longer time range. The promising reasoning information of well-curated student grade datasets is expected to assist young students to find the best of themselves and then improve their learning outcome and study experience. Through data and experience sharing, young students can have a better understanding of their learning condition and possible learning outcomes. Existing course selection systems in Taiwan which offer limited basic enrolling functions fail to provide performance prediction and course arrangement guidance based on their own learning condition. Students now selecting courses with unawareness of their expecting performance. A personalized guide for students on course selection is crucial for how they structure professional knowledge and arrange study schedule. In this paper, we first analyzed what factors can be used on defining learning curve, and discovered the difference between students with different properties and background. Second, we developed a recommendation system based on great amount of grade datasets of past students, and the system can give students suggestions on how to assign their credits based on their own learning curve and students that had similar learning curve. The result of our research demonstrates the feasibility of a new approach on applying big data and AI technology on learning analysis and course selection.</P>",
          "author": "Wu, Yu Hsuan;Wu, Eric Hsiaokuang;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 32,
          "score": 0.5534473061561584,
          "doc_id": "JAKO202317962662812",
          "title": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석",
          "abstract": "이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "source": "AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 AI 활용 역량 강화 교육 프로그램이 중등 과학 예비교사들의 AI 이해, AI 효능감 및 AI 활용에 대한 인식 개선에 미친 효과 분석 이 연구에서는 중등 과학 예비교사들의 AI 활용 역량 강화를 위하여, 구글의 티쳐블머신을 활용하여 예비교사들이 'AI 기반 분자구조 맞춤형 학습 지원 도구'를 직접 생성해 보는 프로젝트 활동을 개발 및 적용하였다. 이를 위하여, 충청북도 소재 H 대학교 화학교육과에 재학 중인 3학년 예비교사 26명을 대상으로 비교과 활동 시간에 개발된 프로그램을 14차시 동안 적용하였고, 'AI의 작동 원리 이해', '과학 수업에서 AI 활용에 대한 효능감', '과학 수업에서 AI 활용 방안'에 대한 인식을 살펴보았다. 연구 결과, 본 연구에서 개발한 프로그램은 예비교사들에게 머신러닝에 대한 AI 기술의 작동 원리를 기초적 수준에서 이해시키고, 그 사용법을 익히는 데 효과가 있는 것으로 나타났다. 또한 본 연구에서 개발한 프로그램은 과학 수업에서 AI 활용에 대한 예비교사들의 효능감을 높이는 데에도 효과가 있는 것으로 나타났다. 그리고 예비교사들은 학생들의 과학 개념 이해를 도울 수 있는 새로운 교수학습 전략이자 도구로서 AI 기술의 활용 방안 측면을 인식한 것으로 나타났다. 이에 본 연구에서 개발한 프로그램은 기초적 수준에서 예비교사들의 AI 활용 역량 강화 및 인식 개선 등에 긍정적 영향을 미쳤음을 알 수 있었다. 이에 대한 시사점에 대해 논의하였다.",
          "author": "윤지현;허소림;강성주;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 33,
          "score": 0.5525489449501038,
          "doc_id": "NART73866218",
          "title": "The Southern Dative Presentative Meets Mechanical Turk",
          "abstract": "<P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "source": "The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk The Southern Dative Presentative Meets Mechanical Turk <P>This article introduces the southern dative presentative, an understudied construction that varies across speakers of American English. The authors discuss similarities and differences between this construction and the better-studied personal dative construction and compare the Southern dative presentative with similar constructions cross-linguistically. They then present the results of a nationwide acceptability judgment survey administered on Amazon Mechanical Turk. The results show that Southern dative presentatives are alive and well in Southern dialects of American English. In the process, they also illustrate the usefulness of Amazon Mechanical Turk (and similar crowdsourcing platforms) for the study of dialect variation in the domain of syntax.</P>",
          "author": "Wood, Jim;Horn, Laurence;Zanuttini, Raffaella;Lindemann, Luke;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 34,
          "score": 0.5509188175201416,
          "doc_id": "ATN0047358973",
          "title": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구",
          "abstract": "In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "source": "딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 딥러닝 언어 모델과 인공신경망 기계 번역을 활용한 담화 조응 현상과 한정 명사구 연구 In this preliminary study, we investigate the phenomena of discourse anaphora and definite descriptions within the framework of the so-called “donkey sentence.” Unlike English, Korean allows for the expression of donkey anaphora using either the pronoun kukes ‘it’ or definite noun phrases (bare NP or ku+NP). Employing neural machine translations and deep learning models, we examine the appropriateness of these two types of donkey sentences in Korean through the following procedure: Firstly, utilizing ChatGPT, we generate 60 sentences with donkey structures containing both pronouns and definite noun phrases. Secondly, we employ Google Translation and Papago to translate these sentences. Thirdly, we use KR-BERT to evaluate the acceptability of the translations. Finally, we conduct a statistical analysis based on the obtained acceptability scores. The results reveal that definite noun phrases are a more natural expression than pronouns in Korean donkey sentences. This novel finding suggests that the E-type approach would provide a better theoretical account than DRT (Discourse Representation Theory).",
          "author": "강아름;이용훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 35,
          "score": 0.5491160750389099,
          "doc_id": "ATN0043505185",
          "title": "대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제",
          "abstract": "Conversation analysis is a field pioneered by sociologists such as Harvey Sacks in the 1960s and aims to analyze the functions of various social interactions that speakers achieve through conversation and reveal the structural systematicity of social behavior. Recently, conversation analysis has become interested in the field of applied linguistics to solve real-life problems related to language based on interest in daily conversation as a social act. Applied linguistics using conversational analysis is developing in a variety of ways, showing that systematic research between various disciplines and academic systems is possible, including language and social interaction, professional and workplace interaction, language and other problems. Currently, many studies on conversation analysis in applied linguistics is being actively conducted in Europe and Japan beyond the U.S. region where conversation analysis originated. Since 2000, Chinese applied linguistics research using conversation analysis has begun to appear in Korea, but there are no studies examining research trends in this regard.This study summarizes research trends and analyzes major discussions of previous studies on conversation analysis in applied linguistics. This study firstly established a database of related research lists through a complete eunmeration survey of research articles by Korean researchers published in Korean academic journals and books. Based on the database, this study summarized research trends of preceding studies by fields, by topics, by methodologies, and by research subjects. This study also explored the tasks and directions for future research. Conversation analysis as a mode of inquiry is addressed to all forms of talk and other conduct in interaction, and, accordingly, has increasingly contributed to several established fields in applied linguistics. This study indicates past or potential points of contact with applied linguistics.",
          "source": "대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 대화분석을 활용한 국내 중국어 응용언어학 연구 현황과 과제 Conversation analysis is a field pioneered by sociologists such as Harvey Sacks in the 1960s and aims to analyze the functions of various social interactions that speakers achieve through conversation and reveal the structural systematicity of social behavior. Recently, conversation analysis has become interested in the field of applied linguistics to solve real-life problems related to language based on interest in daily conversation as a social act. Applied linguistics using conversational analysis is developing in a variety of ways, showing that systematic research between various disciplines and academic systems is possible, including language and social interaction, professional and workplace interaction, language and other problems. Currently, many studies on conversation analysis in applied linguistics is being actively conducted in Europe and Japan beyond the U.S. region where conversation analysis originated. Since 2000, Chinese applied linguistics research using conversation analysis has begun to appear in Korea, but there are no studies examining research trends in this regard.This study summarizes research trends and analyzes major discussions of previous studies on conversation analysis in applied linguistics. This study firstly established a database of related research lists through a complete eunmeration survey of research articles by Korean researchers published in Korean academic journals and books. Based on the database, this study summarized research trends of preceding studies by fields, by topics, by methodologies, and by research subjects. This study also explored the tasks and directions for future research. Conversation analysis as a mode of inquiry is addressed to all forms of talk and other conduct in interaction, and, accordingly, has increasingly contributed to several established fields in applied linguistics. This study indicates past or potential points of contact with applied linguistics.",
          "author": "이지원",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 36,
          "score": 0.5483258366584778,
          "doc_id": "NART130522867",
          "title": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective",
          "abstract": "<P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "source": "The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective The Impact of LLM-Based AI Chatbots on Industrial Structure: A Marcusean Perspective <P>This study explores the impact of large language model (LLM)-based AI chatbots, particularly focusing on OpenAI's ChatGPT, on the structure of industry from a Marcusean perspective. The emergence of ChatGPT has led to rapid changes across various industries, raising important questions about the relationship between individuals, society, and the media. The study aims to analyze the interaction between one-dimensional human beings and media, considering ChatGPT as a form of media itself. It examines the positive changes brought about by AI chatbot technologies, such as enhanced data rights, diversity in expressing opinions, and strengthened education and collaboration. On the other hand, this study also addresses the negative aspects, including potential job displacement, privacy concerns, algorithmic bias, and the suppression of creativity. Through a critical analysis from a Marcusean perspective, this study sheds light on the implications of AI technologies like ChatGPT on individual freedom, power structures, and the formation of one-dimensional individuals within the industrial structure. It concludes by emphasizing the need for transparent systems, open collaboration, and the safeguarding of individual rights and freedoms in the context of AI advancements. By doing so, this study seeks to stimulate further societal engagement and a reevaluation of the Marcusean perspective in the current era.</P>",
          "author": "Kwon, Hyeok Jun;Lee, Jong Tak;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 37,
          "score": 0.5449178218841553,
          "doc_id": "ATN0036732137",
          "title": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk",
          "abstract": "<jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "source": "How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk How Gamification Affects Crowdsourcing: The Case of Amazon Mechanical Turk <jats:p>Since its very first appearance the concept of crowdsourcing has undergone major variations, coming to include highly heterogeneous phenomena such as Google’s data mining, exchanges on sharing economy platforms (e.g. Airbnb or eBay), contents production within creative communities online (e.g. Wikipedia) and much more. If one assumes a very broad perspective, it is eventually possible to extend the category of crowdsourcing to cover whatsoever phenomena involving the participation of the crowd online, as in fact has been done. On the contrary, I will argue that crowdsourcing – and in particular its microwork branch – represents the specific practice of extending outsourcing processes to a large, low-cost, scalable and flexible workforce, in order to generate greater added value for a supply chain. To develop this analysis, I will especially focus on the case of Amazon Mechanical Turk, and on how the operations carried out on this platform are primarily intended to manage the huge flow of information which spans across a supply chain. The practice of subcontracting to the crowd tasks previously carried out by employees or third-party suppliers highlights how crowdsourcing involves a reshaping of the supply chain, further extending it to a large network of individuals. Through crowdsourcing processes, companies are either able to replace or train AI, integrating human computation skills in algorithmic structures through simple, and oftentimes tedious, microtasks. In this context, processes of gamification are capable to put further downward pressure on already small piece-wages, as long as crowdworkers are rather willing to earn an even lower economic compensation, if it’s associated to challenging tasks; thus, to make a task more enjoyable through gamification could be an effective way to further reduce a supply chain’s expenditures in crowdsourcing, pushing forward labor exploitation practices structurally embedded in this phenomenon.</jats:p>",
          "author": "De Lellis Lorenzo",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 38,
          "score": 0.5428063869476318,
          "doc_id": "JAKO202424074483478",
          "title": "수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전",
          "abstract": "인공지능(AI)과 디지털 기술의 도입 등과 같은 디지털 기반 변화의 시대를 맞아, 2025년에는 수학, 영어, 정보 교과에 AI 디지털교과서를 단계적으로 도입하는 교육혁신이 추진되고 있다. 본 연구는 2023년 11월 전국 132명의 초등학교 교사를 대상으로 실시한 설문조사를 통해 교사들의 수학 AI 디지털교과서에 대한 이해도, 핵심 기술의 필요성, 수업 활용에 대한 인식, 그리고 AI 디지털교과서의 학교 현장에의 안착을 위한 요구사항을 조사하였다. 분석 결과, 대다수 교사들은 수학 AI 디지털교과서의 도입과 필요성에 대해 낮은 인식을 보였지만, 일부 교사들은 개인별 맞춤형 학습 및 효과적인 교수&#x00B7;학습 지원 가능성을 인식하고 있었다. 또한, 교사들은 AI 디지털교과서의 학습 진단과 교사 재구성 기능의 필요성을 높게 평가했으며, 수업에서의 유용성을 긍정적으로 평가했지만, AI 디지털교과서의 도입으로 인해 교실에서의 상호작용성은 저하시킬 것이라고 우려했다. 이는 AI 디지털교과서의 성공적 도입 및 활용을 위해 교사연수 및 정보 제공을 통한 인식 변화의 필요성을 시사하며, 구체적이고 실용적인 활용 방안 제공, 디지털 과잉 사용 및 의존에 대한 대안 모색, 핵심 기술의 지속적 개발 등, 이와 관련한 연구의 지속적인 필요성을 제언한다.",
          "source": "수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 수학 AI 디지털교과서의 도입: 초등학교 교사가 바라본 인식, 요구사항, 그리고 도전 인공지능(AI)과 디지털 기술의 도입 등과 같은 디지털 기반 변화의 시대를 맞아, 2025년에는 수학, 영어, 정보 교과에 AI 디지털교과서를 단계적으로 도입하는 교육혁신이 추진되고 있다. 본 연구는 2023년 11월 전국 132명의 초등학교 교사를 대상으로 실시한 설문조사를 통해 교사들의 수학 AI 디지털교과서에 대한 이해도, 핵심 기술의 필요성, 수업 활용에 대한 인식, 그리고 AI 디지털교과서의 학교 현장에의 안착을 위한 요구사항을 조사하였다. 분석 결과, 대다수 교사들은 수학 AI 디지털교과서의 도입과 필요성에 대해 낮은 인식을 보였지만, 일부 교사들은 개인별 맞춤형 학습 및 효과적인 교수&#x00B7;학습 지원 가능성을 인식하고 있었다. 또한, 교사들은 AI 디지털교과서의 학습 진단과 교사 재구성 기능의 필요성을 높게 평가했으며, 수업에서의 유용성을 긍정적으로 평가했지만, AI 디지털교과서의 도입으로 인해 교실에서의 상호작용성은 저하시킬 것이라고 우려했다. 이는 AI 디지털교과서의 성공적 도입 및 활용을 위해 교사연수 및 정보 제공을 통한 인식 변화의 필요성을 시사하며, 구체적이고 실용적인 활용 방안 제공, 디지털 과잉 사용 및 의존에 대한 대안 모색, 핵심 기술의 지속적 개발 등, 이와 관련한 연구의 지속적인 필요성을 제언한다.",
          "author": "김소민;이기마;김희정;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 39,
          "score": 0.5425296425819397,
          "doc_id": "NART126358912",
          "title": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining",
          "abstract": "<P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "source": "Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining Analyzing the Alignment between AI Curriculum and AI Textbooks through Text Mining <P>The field of artificial intelligence (AI) is permeating education worldwide, reflecting societal changes driven by advancements in computing technology and the data revolution. Herein, we analyze the alignment between core AI educational curricula and textbooks to provide guidance on structuring AI knowledge. Text mining techniques using Python 3.10.3 and frame-based content analysis tailored to the computing field are employed to examine a substantial amount of text data within educational curriculum textbooks. We comprehensively examine the frequency of knowledge incorporated in AI curricula, topic structure, and practical tool utilization. The degree to which keywords are reflected in curriculum textbooks and in the textbook characteristics are determined using Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) analysis, respectively. The topic structure distribution is derived by Latent Dirichlet Allocation (LDA) topic modeling and the trained model is visualized using PyLDAvis. Furthermore, the variation in vertical content range or level is investigated by content analysis, considering the tools used to teach similar AI knowledge. Lastly, the implications for AI curriculum structure are discussed in terms of curriculum composition, knowledge construction, practical application, and curriculum utilization. This study provides practical guidance for structuring curricula that effectively foster AI competency based on a systematic research methodology.</P>",
          "author": "Yang, Hyeji;Kim, Jamee;Lee, Wongyu;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 40,
          "score": 0.5396727919578552,
          "doc_id": "ATN0037485880",
          "title": "한국수어 응용언어학 연구 동향 분석",
          "abstract": "The purpose of this study is to analyze the research trends of Korean Sign Language(KSL) applied linguistics from 2005 to 2020 and identify the implications and characteristics of existing studies, and suggest directions for future research. As a result of analyzing a total of 211 research papers, research topics were revealed by 11 research fields, and KSL applied linguistics has been the most researched in engineering with 116 papers(54.98%). Developmental researches were the most with 123 papers(58.29%).  The year in which research papers were published the most was 2019, with the largest number of 32 papers(15.16%). Of the total, 117 papers(55.45%) were published in the journal, followed by ‘Excellent registered’for 3 papers(2.56%), ‘Registered’for 91 papers(77.78%), ‘Registered candidate’for 23 papers(19.66%). KSL applied linguistics research was published the most in ‘The Journal of Special Education’with 15 papers(7.11%), two authors were the most with 60 papers(28.44%), the most frequently used key word was ‘Sign Language’with 25 papers(22.94%).",
          "source": "한국수어 응용언어학 연구 동향 분석 한국수어 응용언어학 연구 동향 분석 한국수어 응용언어학 연구 동향 분석 The purpose of this study is to analyze the research trends of Korean Sign Language(KSL) applied linguistics from 2005 to 2020 and identify the implications and characteristics of existing studies, and suggest directions for future research. As a result of analyzing a total of 211 research papers, research topics were revealed by 11 research fields, and KSL applied linguistics has been the most researched in engineering with 116 papers(54.98%). Developmental researches were the most with 123 papers(58.29%).  The year in which research papers were published the most was 2019, with the largest number of 32 papers(15.16%). Of the total, 117 papers(55.45%) were published in the journal, followed by ‘Excellent registered’for 3 papers(2.56%), ‘Registered’for 91 papers(77.78%), ‘Registered candidate’for 23 papers(19.66%). KSL applied linguistics research was published the most in ‘The Journal of Special Education’with 15 papers(7.11%), two authors were the most with 60 papers(28.44%), the most frequently used key word was ‘Sign Language’with 25 papers(22.94%).",
          "author": "고인경;윤병천;이보경;이지민;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 41,
          "score": 0.5383094549179077,
          "doc_id": "NART118344607",
          "title": "Affective Effects of English Digital Textbook Lessons Using AI Chatbots",
          "abstract": "nan",
          "source": "Affective Effects of English Digital Textbook Lessons Using AI Chatbots Affective Effects of English Digital Textbook Lessons Using AI Chatbots Affective Effects of English Digital Textbook Lessons Using AI Chatbots ",
          "author": "Kim, So-Yeon;Kim, Jeong-Ryeol;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 42,
          "score": 0.535957396030426,
          "doc_id": "NART126363952",
          "title": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses",
          "abstract": "<P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "source": "AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses AI Course Design Planning Framework: Developing Domain-Specific AI Education Courses <P>The use of artificial intelligence (AI) is becoming increasingly important in various domains, making education about AI a necessity. The interdisciplinary nature of AI and the relevance of AI in various fields require that university instructors and course developers integrate AI topics into the classroom and create so-called domain-specific AI courses. In this paper, we introduce the &ldquo;AI Course Design Planning Framework&rdquo; as a course planning framework to structure the development of domain-specific AI courses at the university level. The tool evolves non-specific course planning frameworks to address the context of domain-specific AI education. Following a design-based research approach, we evaluated a first prototype of the tool with instructors in the field of AI education who are developing domain-specific courses in this area. The results of our evaluation indicate that the tool allows instructors to create domain-specific AI courses in an efficient and comprehensible way. In general, instructors rated the tool as useful and user-friendly and made recommendations to improve its usability. Future research will focus on testing the application of the tool for domain-specific AI course developments in different domain contexts and examine the influence of using the tool on AI course quality and learning outcomes.</P>",
          "author": "Schleiss, Johannes;Laupichler, Matthias Carl;Raupach, Tobias;Stober, Sebastian;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 43,
          "score": 0.5355657935142517,
          "doc_id": "NPAP13663736",
          "title": "모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정",
          "abstract": "최근 모바일 기술이 실생활에 널리 활용하면서 점점 모바일 크라우드소싱 활용이 크게 기대되고 있다. 그래서 배달 인력이 아닌 일반인도 어플리케이션을 모바일 기기에 설치하면 배달 인력이 되어 작업을 수행할 수 있다. 본 연구에서는 일반인도 참여할 수 있는 모바일 크라우드소싱 기반 배달에서 딥러닝을 이용한 작업자 선정 기법을 소개한다. 그리고 실험을 통하여 합성곱 신경망(Convolutional Neural Network)을 적용한 본 기법이 효과적이라는 것을 보인다.",
          "source": "모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 모바일 크라우드소싱 기반 음식 배달에서 딥러닝을 이용한 작업자 선정 최근 모바일 기술이 실생활에 널리 활용하면서 점점 모바일 크라우드소싱 활용이 크게 기대되고 있다. 그래서 배달 인력이 아닌 일반인도 어플리케이션을 모바일 기기에 설치하면 배달 인력이 되어 작업을 수행할 수 있다. 본 연구에서는 일반인도 참여할 수 있는 모바일 크라우드소싱 기반 배달에서 딥러닝을 이용한 작업자 선정 기법을 소개한다. 그리고 실험을 통하여 합성곱 신경망(Convolutional Neural Network)을 적용한 본 기법이 효과적이라는 것을 보인다.",
          "author": "이윤열;김응모;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 44,
          "score": 0.5351975560188293,
          "doc_id": "JAKO202516136003211",
          "title": "유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성",
          "abstract": "본 연구는 유아들을 위한 인공지능 사고 기반의 창의적 문제해결력 요소를 구성하기 위해서 수행되었다. 이를 위해서 문헌을 분석하기 위해 선행연구를 탐색하였고, 그 결과 국문4편, 영문 5편의 자료를 수집하였다. 수집된 문헌을 분석하여 인공지능적 사고의 구성 요소를 AI 사고(데이터 분석, 알고리즘, 구축, 디버깅), 창의적 문제해결(발산적 사고, 수렴적 사고), AI 이해(AI 이해, AI 활용, AI 윤리)를 도출하였다. 도출된 구성 요소를 기반으로 인공지능적 사고의 구성 요소를 분류하고, 분류된 구성요소의 특성을 종합하여 정의를 '인공지능에 기반한 창의적 문제해결력'으로 규정하였다. 본 연구를 통해서 구성된 요소와 정의의 타당성을 검증하기 위해서 델파이 조사를 수행하였다. 델파이 조사에 참여한 전문가는 인공지능 교육 전문가 3명, 교육공학 전문가 1명, 유아교육 전문가 1명으로 모두 5명이 참여하였다. 1차 델파이 조사에서 수렴도와 합의도가 모두 양호하게 산출되었으며, 이에 2차 델파이 조사를 수행하지 않았다.",
          "source": "유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 유아들을 위한 인공-지능 사고 기반의 창의적 문제해결력 요소 구성 본 연구는 유아들을 위한 인공지능 사고 기반의 창의적 문제해결력 요소를 구성하기 위해서 수행되었다. 이를 위해서 문헌을 분석하기 위해 선행연구를 탐색하였고, 그 결과 국문4편, 영문 5편의 자료를 수집하였다. 수집된 문헌을 분석하여 인공지능적 사고의 구성 요소를 AI 사고(데이터 분석, 알고리즘, 구축, 디버깅), 창의적 문제해결(발산적 사고, 수렴적 사고), AI 이해(AI 이해, AI 활용, AI 윤리)를 도출하였다. 도출된 구성 요소를 기반으로 인공지능적 사고의 구성 요소를 분류하고, 분류된 구성요소의 특성을 종합하여 정의를 '인공지능에 기반한 창의적 문제해결력'으로 규정하였다. 본 연구를 통해서 구성된 요소와 정의의 타당성을 검증하기 위해서 델파이 조사를 수행하였다. 델파이 조사에 참여한 전문가는 인공지능 교육 전문가 3명, 교육공학 전문가 1명, 유아교육 전문가 1명으로 모두 5명이 참여하였다. 1차 델파이 조사에서 수렴도와 합의도가 모두 양호하게 산출되었으며, 이에 2차 델파이 조사를 수행하지 않았다.",
          "author": "이은철;변영신;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 45,
          "score": 0.5349013805389404,
          "doc_id": "JAKO202332657687316",
          "title": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구",
          "abstract": "본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "source": "유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 유아 인공지능 교육을 위한 인공지능 핵심 역량 요소 구성 연구 본 연구는 유아 인공지능 교육을 위해 유아 인공지능 역량 요소 및 하위 요소를 구성하는 것을 목적으로 하고 있다. 연구의 목적을 달성하기 위해 문헌 분석과 전문가 델파이 조사를 사용하였다. 문헌 분석을 위해 검색을 통해 국내 자료 4편, 국외 자료 3편을 수집하였다. 수집된 자료를 분석하여 4개의 요소와 25개의 하위 요소를 구성하였다. 최초로 구성된 요소는 인공지능 이해(하위 요소 5개), 인공지능 사고(하위 요소 6개), 인공지능 활용(하위 요소 8개), 인공지능 가치(하위 요소 6)가 도출 되었다. 최초 구성된 요소를 전문가 델파이로 검증하였고, 전문가들은 역량 요소와 하위 요소는 수용할 만한 수준이지만 하위 요소들이 보완되어야 한다는 의견을 제시하였다. 이에 본 연구는 전문가들의 의견을 수렴하여 수정하였다. 수정된 요소는 인공지능 이해(하위 요소 6개), 인공지능 사고(하위 요소 2개), 인공지능 활용(하위 요소 6개), 인공지능 가치(하위 요소 6)로 구성되었다. 수정된 요소는 전문가 델파이 조사를 수행하였고, 그 결과 타당한 것으로 검증되었다. 이에 본 연구는 수정된 요소를 최종 요소로 제안하였다. 본 연구의 결과는 유아 인공지능 교육과정을 구성하는데 중요한 근거를 제시한다는 것에서 많은 시사점을 가진다.",
          "author": "이은철;변영신;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 46,
          "score": 0.5343295335769653,
          "doc_id": "JAKO201017337344335",
          "title": "인공신경망모델을 이용한 교량의 상태평가",
          "abstract": "대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "source": "인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 인공신경망모델을 이용한 교량의 상태평가 대부분의 선진국에서 교량의 유지보수 및 보강(Maintenance Repair & Rehabilitation-MR&R)으로 인한 비용은 해마다 증가하고 있다. 전산화된 교량유지관리 및 의사결정시스템(Bridge Management System-BMS)은 가능한 최저의 생애주기비용(Life Cycle Cost - LCC)에 최적의 안정성를 확보하기 위해 개발되었다. 본 논문에서는 제한된 현존하는 교량진단기록을 이용하여 현존하지 않는 과거의 교량상태등급 데이타를 생성하기 위해 Backward Prediction Model(BPM)이라 불리는 인공신경망(Artificial Neural Network-ANN)에 기초한 예측모델을 제시한다. 제안된 BPM은 한정된 교량 정기점검기록으로부터 현존하는 교량진단기록과 연관성을 확립하기 위해 교통량과 인구, 그리고 기후 등과 같은 비구조적 요소를 이용하며, 제한된 교량진단기록과 비구조적 요소 사이에 맺어진 연관성을 통해 현존하지 않는 과거의 교량상태등급 데이타를 생성할 수 있다. BPM의 신뢰도를 측정하기 위하여 Maryland DOT로 부터 얻어진 National Bridge Inventory(NBI)와 BMS 교량진단자료를 이용하였다. 이중 NBI자료를 이용한 Backward comparison 에 있어서 실제 NBI기록과 BPM으로 생성된 교량상태등급과의 차이(상판: 6.68%, 상부구조부: 6.61%, 하부구조부: 7.52%)는 BPM으로 생성된 결과의 높은 신뢰도를 보여준다. 이 연구의 결과는 제한된 정기점검 기록으로 야기되는 BMS의 장기 교량손상 예측에 관련된 사용상의 문제를 최소화하고 전반적인 BMS 결과의 신뢰도를 높이는데 기여 할 수 있다.",
          "author": "오순택;이동준;이재호;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 47,
          "score": 0.5333558320999146,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "author": "Mason, Winter;Suri, Siddharth;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 48,
          "score": 0.5309051275253296,
          "doc_id": "NPAP13686745",
          "title": "Evaluating the accessibility of crowdsourcing tasks on Amazon's mechanical turk",
          "abstract": "nan",
          "source": "Evaluating the accessibility of crowdsourcing tasks on Amazon's mechanical turk Evaluating the accessibility of crowdsourcing tasks on Amazon's mechanical turk Evaluating the accessibility of crowdsourcing tasks on Amazon's mechanical turk ",
          "author": "Calvo, Roc&iacute;o;Kane, Shaun K.;Hurst, Amy;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 49,
          "score": 0.5281450748443604,
          "doc_id": "NART70754548",
          "title": "Amazon Mechanical Turk and the commodification of labour",
          "abstract": "<P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>",
          "source": "Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour <P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>",
          "author": "Bergvall&#8208;K&aring;reborn, Birgitta;Howcroft, Debra;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        },
        {
          "rank": 50,
          "score": 0.528050422668457,
          "doc_id": "ATN0027086510",
          "title": "인공신경망과 강건설계를 이용한 기계적 RMR 분류",
          "abstract": "Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "source": "인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 인공신경망과 강건설계를 이용한 기계적 RMR 분류 Rock mass rating (RMR) is a relatively simple method for classifying rock mass with the naked eye; however, it becomes inconvenient when the number of survey sections is large. In this study, we developed a learning model and a prediction model using an artificial neural network (ANN) to classify RMR mechanically. Using robust design, 3125 big data were optimized into 25 learning data. The test results after learning through the two methods were exactly the same. Through robust design, the learning data obtained by reducing the total number of cases to less than 1% had the same learning effect as the whole data, which means that the effort and cost of acquiring the learning data can be greatly reduced. For the perfect prediction of the RMR classification system, we tuned the primary predictions within a given range of rating levels. As a result, we implemented an RMR classification ANN system that perfectly predicts the RMR of 3125 big data using 25 learning data through robust design.",
          "author": "장명환;하태욱;최기훈;",
          "embedding_mode": "nan",
          "embedding_text": "3*title+abstract"
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}