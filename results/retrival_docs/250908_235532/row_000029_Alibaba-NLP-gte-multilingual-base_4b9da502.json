{
  "id": "row_000029",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:36.304653+09:00",
  "trial_id": "4b9da502",
  "queries": [
    {
      "query": "비정형 리뷰 데이터를 활용해 고객 평점을 예측하기 위해 설계된 딥 러닝 모델 구조와 주요 실험 결과(정확도·출력 카테고리)를 요약해 주실 수 있나요?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8864293694496155,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 2,
          "score": 0.7889343500137329,
          "doc_id": "DIKO0015775432",
          "title": "딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로",
          "abstract": "온라인 쇼핑몰, 영화, 호텔 등 전자상거래의 다양한 영역에서 고객은 다른 고객이 남긴 리뷰 혹은 평점을 통해 아이템의 품질을 판단해 구매한다. 이에 따라 많은 연구자가 아이템의 평점과 리뷰를 동시에 고려한 추천 시스템 연구를 진행하고 있다. 그러나, 리뷰와 평점이 불일치하여 추천의 신뢰성이 문제 되고 있다. 즉, 사용자가 리뷰에서 좋다고 기술하였지만, 평점은 3점만 주거나, 리뷰에서 좋지 않다고 기술하였지만, 평점을 4점 이상 주는 상황이 발생하기 때문에, 추천의 품질이 저하되는 문제점이 존재한다. 이런 문제를 해결하기 위해 본 연구는 수집한 호텔 평가 데이터를 사용하여 리뷰와 평점 불일치 데이터를 발견하고, 추천 정확도를 높이는 방법을 제시한다.&amp;#xD; &amp;#xD; 이러한 목적을 달성하기 위한 본 연구의 방법은 다음과 같이 3단계로 구성되어 있다. 첫 번째 단계에서는 다양한 호텔 리뷰 데이터로부터 UserID, ItemID, 리뷰, 평점이 포함하는 데이터를 수집하여 처리한다. 그리고 감성분석 모델 구축용 데이터, 추천 시스템 모델 용 2 개 데이터 셋으로 분할한다. 두 번째 단계에서는 리뷰로부터 감성 분석 모델 구축용 데이터로 감성(긍정/부정/중성)을 예측할 수 있는 딥러닝 모형을 구축한다. 세 번째 단계에서는, 추천 시스템 모델 용 데이터로 두번째 단계에서 구축한 모델을 이용하여 리뷰의 감성 분류를 예측한다. 예측 결과와 평점 결합해서 리뷰와 평점 일치 여부를 파악하며, 일치한 데이터와 전체 데이터 각각 추천 시스템 모델에서 따로 실험하고 성능을 비교한다. 연구 실험에서는 세계적으로 유명한 여행 사이트인 TripAdvisor의 홈페이지에서 뉴욕에 있는 호텔 평가 데이터를 수집하여 사용한다.&amp;#xD; &amp;#xD; 본 연구에서는 감성을 판단하는 딥러닝 모델을 구축하였다. 또한, 호텔 영역에 리뷰와 평점 불일치 문제 때문에 추천 시스템 연구에서 성능이 떨어지는 것을 해결하는 방법을 제시하였다. 따라서 추천 시스템 연구 중 정확하지 않은 리뷰와 평점을 피하는 데 도움이 된다. 본 연구는 직접 데이터를 수집 및 모델 구축하였기에 다른 호텔 평가에 활용할 수 있을 것으로 기대한다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015775432&target=NART&cn=DIKO0015775432",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 온라인 쇼핑몰, 영화, 호텔 등 전자상거래의 다양한 영역에서 고객은 다른 고객이 남긴 리뷰 혹은 평점을 통해 아이템의 품질을 판단해 구매한다. 이에 따라 많은 연구자가 아이템의 평점과 리뷰를 동시에 고려한 추천 시스템 연구를 진행하고 있다. 그러나, 리뷰와 평점이 불일치하여 추천의 신뢰성이 문제 되고 있다. 즉, 사용자가 리뷰에서 좋다고 기술하였지만, 평점은 3점만 주거나, 리뷰에서 좋지 않다고 기술하였지만, 평점을 4점 이상 주는 상황이 발생하기 때문에, 추천의 품질이 저하되는 문제점이 존재한다. 이런 문제를 해결하기 위해 본 연구는 수집한 호텔 평가 데이터를 사용하여 리뷰와 평점 불일치 데이터를 발견하고, 추천 정확도를 높이는 방법을 제시한다.&amp;#xD; &amp;#xD; 이러한 목적을 달성하기 위한 본 연구의 방법은 다음과 같이 3단계로 구성되어 있다. 첫 번째 단계에서는 다양한 호텔 리뷰 데이터로부터 UserID, ItemID, 리뷰, 평점이 포함하는 데이터를 수집하여 처리한다. 그리고 감성분석 모델 구축용 데이터, 추천 시스템 모델 용 2 개 데이터 셋으로 분할한다. 두 번째 단계에서는 리뷰로부터 감성 분석 모델 구축용 데이터로 감성(긍정/부정/중성)을 예측할 수 있는 딥러닝 모형을 구축한다. 세 번째 단계에서는, 추천 시스템 모델 용 데이터로 두번째 단계에서 구축한 모델을 이용하여 리뷰의 감성 분류를 예측한다. 예측 결과와 평점 결합해서 리뷰와 평점 일치 여부를 파악하며, 일치한 데이터와 전체 데이터 각각 추천 시스템 모델에서 따로 실험하고 성능을 비교한다. 연구 실험에서는 세계적으로 유명한 여행 사이트인 TripAdvisor의 홈페이지에서 뉴욕에 있는 호텔 평가 데이터를 수집하여 사용한다.&amp;#xD; &amp;#xD; 본 연구에서는 감성을 판단하는 딥러닝 모델을 구축하였다. 또한, 호텔 영역에 리뷰와 평점 불일치 문제 때문에 추천 시스템 연구에서 성능이 떨어지는 것을 해결하는 방법을 제시하였다. 따라서 추천 시스템 연구 중 정확하지 않은 리뷰와 평점을 피하는 데 도움이 된다. 본 연구는 직접 데이터를 수집 및 모델 구축하였기에 다른 호텔 평가에 활용할 수 있을 것으로 기대한다.&amp;#xD;"
        },
        {
          "rank": 3,
          "score": 0.7750271558761597,
          "doc_id": "DIKO0017011976",
          "title": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형",
          "abstract": "본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017011976&target=NART&cn=DIKO0017011976",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다."
        },
        {
          "rank": 4,
          "score": 0.770972728729248,
          "doc_id": "DIKO0016385622",
          "title": "온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구",
          "abstract": "전자상거래의 발전에 따라 소비가 더욱 활발히 이루어지면서 고객의 수요에 맞추기 위해 새로운 제품들이 계속 출시되고 있으며, 이에 따라 전자상거래는 더욱 활성화되고 있다. 그러나 고객들은 대부분 새로운 제품 또는 자신이 구매하지 않았던 제품에 대한 구매 경험이 없기 때문에 구매 의사결정을 내리기 어려운 문제점이 존재한다. 따라서 전자상거래 사이트는 이러한 문제점을 해결하기 위해 온라인 리뷰를 남길 수 있는 시스템을 제공하고 있다. 고객이 자신의 경험을 바탕으로 작성한 온라인 리뷰에는 제품에 대한 다양한 정보가 포함되어 있고, 이러한 리뷰들은 고객의 구매 의사결정에 있어서 매우 중요한 참고 정보가 된다. 고객들은 기존 고객들이 남긴 온라인 리뷰를 참고하여 제품에 대한 불확실성을 낮출 수 있다. 그러나 리뷰 수가 많을수록 리뷰에 대한 정보 과부하 문제가 발생하며, 이로 인해 고객이 자신에게 도움이 되는 리뷰를 탐색하는데 어려움을 겪고 있다. 이러한 문제점을 극복하기 위해 전자상거래 사이트는 리뷰 유용성을 평가할 수 있는 투표 시스템을 도입하였다. 이를 바탕으로 고객들은 유용한 리뷰를 탐색할 수 있고, 이 정보는 고객들의 구매 의사결정에 기여할 수 있다. 이러한 투표 시스템은 고객으로부터 직접적인 피드백을 받을 수 있지만, 최근에 작성된 리뷰는 리뷰 유용성 투표 수를 누적하기에는 많은 시간을 필요로 하기에 고객에게 신속한 정보로 추천되기에는 어려운 한계점이 존재한다. 따라서 전자상거래 사이트들은 자동으로 리뷰에 대한 유용성을 예측할 수 있는 시스템을 도입할 필요가 있다. &amp;#xD; 리뷰 유용성 예측의 목표는 고객의 구매의사 결정에 도움이 되는 고품질 리뷰를 자동으로 식별하고 고객에게 추천하는 것이다. 기존 연구에서는 리뷰에 대한 유용성을 예측하기 위해, 주로 리뷰 텍스트와 평점 정보를 사용하여 리뷰 유용성에 영향을 미칠 수 있는 요소를 추출하고 이를 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구에서는 리뷰 텍스트와 평점 정보 간의 일관성을 고려하지 않았다. 따라서 리뷰 텍스트와 평점 정보는 동일한 고객이 자신의 경험을 바탕으로 작성한 정보이므로, 리뷰 텍스트와 평점 정보 간의 일관성을 고려할 필요가 있다. 리뷰 텍스트와 평점 정보가 일치하지 않으면 고객은 구매 의사결정 과정에 필요한 정보를 효과적으로 탐색할 수 없고, 오히려 리뷰에 대한 신뢰성과 유용성이 감소될 수 있다. 이에 따라 일부 연구에서는 리뷰 유용성에 대한 예측 성능을 향상시키기 위해 리뷰 텍스트와 평점 정보 간의 일관성을 고려하였다. 그러나 기존 연구는 다음과 같은 한계점이 존재한다. 첫째, 평점 정보가 손실되어 평점 정보의 표현 수용력이 제한적이다. 둘째, 리뷰 텍스트와 평점 정보 간의 상호작용이 제한적으로 학습된다. &amp;#xD; 따라서 본 연구에서는 기존 리뷰 유용성 예측에 관한 연구의 한계점을 극복하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-TRI 아키텍처를 제안하였다. 평점 정보에 대한 손실을 방지하기 위해 리뷰 텍스트와 평점 정보를 각각 고차원 특성 벡터로 변환하였다. 또한 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 추출하고 학습하기 위해, 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려하여 리뷰에 대한 유용성을 예측하였다. 그리고 리뷰 유용성을 예측할 때 특정 정보 혹은 특정 관계에 대한 편향을 방지하고 동등한 역할을 수행할 수 있도록 하기 위해, 실험 단계에서는 동일한 특성 차원으로 변환하였다. 이후 실험 단계에서는 CNN-TRI 모델의 예측 성능을 향상시키기 위해 미세조정 기법을 수행하고, 기존 연구에서 사용되었던 리뷰 유용성 예측 모델의 성능과 비교하였다. CNN-TRI 모델의 예측 성능을 측정하기 위해 아마존에서 도서 제품에 관한 8,898,041개의 리뷰를 수집하였다. 실험 결과, Accuracy 평가지표에서는 본 연구에서 제안된 CNN-TRI 모델의 예측 성능이 CNN 기반 모델보다 2.9~7.6% 더 높은 것으로 나타났고, F1-Score 평가지표에서는 4.0~7.4% 더 높은 것으로 확인되었다. 또한 전통적인 머신러닝 모델에 비해 예측 성능이 현저히 우수함을 확인할 수 있었다. 그리고 리뷰 텍스트와 평점 정보 간의 상호작용 측면에서 리뷰 유용성을 예측할 때 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려한 경우가 선형관계 또는 비선형관계 중 하나만 고려한 방법보다 예측 성능이 더 우수함을 확인하였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016385622&target=NART&cn=DIKO0016385622",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 전자상거래의 발전에 따라 소비가 더욱 활발히 이루어지면서 고객의 수요에 맞추기 위해 새로운 제품들이 계속 출시되고 있으며, 이에 따라 전자상거래는 더욱 활성화되고 있다. 그러나 고객들은 대부분 새로운 제품 또는 자신이 구매하지 않았던 제품에 대한 구매 경험이 없기 때문에 구매 의사결정을 내리기 어려운 문제점이 존재한다. 따라서 전자상거래 사이트는 이러한 문제점을 해결하기 위해 온라인 리뷰를 남길 수 있는 시스템을 제공하고 있다. 고객이 자신의 경험을 바탕으로 작성한 온라인 리뷰에는 제품에 대한 다양한 정보가 포함되어 있고, 이러한 리뷰들은 고객의 구매 의사결정에 있어서 매우 중요한 참고 정보가 된다. 고객들은 기존 고객들이 남긴 온라인 리뷰를 참고하여 제품에 대한 불확실성을 낮출 수 있다. 그러나 리뷰 수가 많을수록 리뷰에 대한 정보 과부하 문제가 발생하며, 이로 인해 고객이 자신에게 도움이 되는 리뷰를 탐색하는데 어려움을 겪고 있다. 이러한 문제점을 극복하기 위해 전자상거래 사이트는 리뷰 유용성을 평가할 수 있는 투표 시스템을 도입하였다. 이를 바탕으로 고객들은 유용한 리뷰를 탐색할 수 있고, 이 정보는 고객들의 구매 의사결정에 기여할 수 있다. 이러한 투표 시스템은 고객으로부터 직접적인 피드백을 받을 수 있지만, 최근에 작성된 리뷰는 리뷰 유용성 투표 수를 누적하기에는 많은 시간을 필요로 하기에 고객에게 신속한 정보로 추천되기에는 어려운 한계점이 존재한다. 따라서 전자상거래 사이트들은 자동으로 리뷰에 대한 유용성을 예측할 수 있는 시스템을 도입할 필요가 있다. &amp;#xD; 리뷰 유용성 예측의 목표는 고객의 구매의사 결정에 도움이 되는 고품질 리뷰를 자동으로 식별하고 고객에게 추천하는 것이다. 기존 연구에서는 리뷰에 대한 유용성을 예측하기 위해, 주로 리뷰 텍스트와 평점 정보를 사용하여 리뷰 유용성에 영향을 미칠 수 있는 요소를 추출하고 이를 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구에서는 리뷰 텍스트와 평점 정보 간의 일관성을 고려하지 않았다. 따라서 리뷰 텍스트와 평점 정보는 동일한 고객이 자신의 경험을 바탕으로 작성한 정보이므로, 리뷰 텍스트와 평점 정보 간의 일관성을 고려할 필요가 있다. 리뷰 텍스트와 평점 정보가 일치하지 않으면 고객은 구매 의사결정 과정에 필요한 정보를 효과적으로 탐색할 수 없고, 오히려 리뷰에 대한 신뢰성과 유용성이 감소될 수 있다. 이에 따라 일부 연구에서는 리뷰 유용성에 대한 예측 성능을 향상시키기 위해 리뷰 텍스트와 평점 정보 간의 일관성을 고려하였다. 그러나 기존 연구는 다음과 같은 한계점이 존재한다. 첫째, 평점 정보가 손실되어 평점 정보의 표현 수용력이 제한적이다. 둘째, 리뷰 텍스트와 평점 정보 간의 상호작용이 제한적으로 학습된다. &amp;#xD; 따라서 본 연구에서는 기존 리뷰 유용성 예측에 관한 연구의 한계점을 극복하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-TRI 아키텍처를 제안하였다. 평점 정보에 대한 손실을 방지하기 위해 리뷰 텍스트와 평점 정보를 각각 고차원 특성 벡터로 변환하였다. 또한 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 추출하고 학습하기 위해, 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려하여 리뷰에 대한 유용성을 예측하였다. 그리고 리뷰 유용성을 예측할 때 특정 정보 혹은 특정 관계에 대한 편향을 방지하고 동등한 역할을 수행할 수 있도록 하기 위해, 실험 단계에서는 동일한 특성 차원으로 변환하였다. 이후 실험 단계에서는 CNN-TRI 모델의 예측 성능을 향상시키기 위해 미세조정 기법을 수행하고, 기존 연구에서 사용되었던 리뷰 유용성 예측 모델의 성능과 비교하였다. CNN-TRI 모델의 예측 성능을 측정하기 위해 아마존에서 도서 제품에 관한 8,898,041개의 리뷰를 수집하였다. 실험 결과, Accuracy 평가지표에서는 본 연구에서 제안된 CNN-TRI 모델의 예측 성능이 CNN 기반 모델보다 2.9~7.6% 더 높은 것으로 나타났고, F1-Score 평가지표에서는 4.0~7.4% 더 높은 것으로 확인되었다. 또한 전통적인 머신러닝 모델에 비해 예측 성능이 현저히 우수함을 확인할 수 있었다. 그리고 리뷰 텍스트와 평점 정보 간의 상호작용 측면에서 리뷰 유용성을 예측할 때 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려한 경우가 선형관계 또는 비선형관계 중 하나만 고려한 방법보다 예측 성능이 더 우수함을 확인하였다.&amp;#xD;"
        },
        {
          "rank": 5,
          "score": 0.7518652677536011,
          "doc_id": "JAKO202113157683309",
          "title": "온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구",
          "abstract": "세계적인 전자상거래 기업들은 지속 가능한 경쟁력을 확보하기 위해 사용자 맞춤형 추천 서비스를 제공하고 있다. 기존 관련 연구에서는 주로 평점, 구매 여부 등 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하였다. 하지만 이와 같은 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하면 추천 성능이 저하될 수 있다는 문제점이 제기되고 있다. 호텔을 이용한 사용자가 호텔 서비스, 청결 상태 등에 대하여 만족하지 못한다고 리뷰를 작성하였으나 선호도 평점 5점을 부여했을 때 정량적 선호도(평점)와 정성적 선호도(리뷰)가 불일치한 문제가 발생할 수 있다. 따라서 본 연구에서는 정량적 선호도 정보와 정성적 선호도 정보가 일치하는지를 확인하고 이를 바탕으로 선호도 정보가 일치하는 사용자를 바탕으로 새로운 프로파일을 구축하여 개인화 추천 서비스를 제공하고자 한다. 리뷰에서 정성적 선호도를 추출하기 위해 자연어 처리 관련 연구에서 널리 사용되고 있는 CNN, LSTM, CNN + LSTM 등 딥러닝 기법을 사용하여 감성분석 모델을 구축하였다. 이를 통해 사용자가 작성한 리뷰에서 정성적 선호도 정보를 정교하게 추출하여 정량적 선호도 정보와 비교하였다. 본 연구에서 제안한 추천 방법론의 성능을 평가하기 위해 세계 최대 여행 플랫폼 TripAdvisor에서 실제 호텔을 이용한 사용자 선호도 정보를 수집하여 사용하였다. 실험 결과 본 연구에서 제안한 추천 방법론이 기존의 정량적 선호도만을 고려하는 추천 방법론보다 우수한 추천 성능을 나타냄을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202113157683309&target=NART&cn=JAKO202113157683309",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 세계적인 전자상거래 기업들은 지속 가능한 경쟁력을 확보하기 위해 사용자 맞춤형 추천 서비스를 제공하고 있다. 기존 관련 연구에서는 주로 평점, 구매 여부 등 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하였다. 하지만 이와 같은 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하면 추천 성능이 저하될 수 있다는 문제점이 제기되고 있다. 호텔을 이용한 사용자가 호텔 서비스, 청결 상태 등에 대하여 만족하지 못한다고 리뷰를 작성하였으나 선호도 평점 5점을 부여했을 때 정량적 선호도(평점)와 정성적 선호도(리뷰)가 불일치한 문제가 발생할 수 있다. 따라서 본 연구에서는 정량적 선호도 정보와 정성적 선호도 정보가 일치하는지를 확인하고 이를 바탕으로 선호도 정보가 일치하는 사용자를 바탕으로 새로운 프로파일을 구축하여 개인화 추천 서비스를 제공하고자 한다. 리뷰에서 정성적 선호도를 추출하기 위해 자연어 처리 관련 연구에서 널리 사용되고 있는 CNN, LSTM, CNN + LSTM 등 딥러닝 기법을 사용하여 감성분석 모델을 구축하였다. 이를 통해 사용자가 작성한 리뷰에서 정성적 선호도 정보를 정교하게 추출하여 정량적 선호도 정보와 비교하였다. 본 연구에서 제안한 추천 방법론의 성능을 평가하기 위해 세계 최대 여행 플랫폼 TripAdvisor에서 실제 호텔을 이용한 사용자 선호도 정보를 수집하여 사용하였다. 실험 결과 본 연구에서 제안한 추천 방법론이 기존의 정량적 선호도만을 고려하는 추천 방법론보다 우수한 추천 성능을 나타냄을 확인할 수 있었다."
        },
        {
          "rank": 6,
          "score": 0.7395815253257751,
          "doc_id": "JAKO201726163356540",
          "title": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델",
          "abstract": "본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163356540&target=NART&cn=JAKO201726163356540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다."
        },
        {
          "rank": 7,
          "score": 0.7340439558029175,
          "doc_id": "NPAP13226818",
          "title": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset",
          "abstract": "<P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13226818&target=NART&cn=NPAP13226818",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset <P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>"
        },
        {
          "rank": 8,
          "score": 0.7337723970413208,
          "doc_id": "NART131019507",
          "title": "Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach",
          "abstract": "<P><B>Abstract</B><P>Rating prediction is a crucial element of business analytics as it enables decision-makers to assess service performance based on expressive customer feedback. Enhancing rating score predictions and demand forecasting through incorporating performance features from verbatim text fields, particularly in service quality measurement and customer satisfaction modelling is a key objective in various areas of analytics. A range of methods has been identified in the literature for improving the predictability of customer feedback, including simple bag-of-words-based approaches and advanced supervised machine learning models, which are designed to work with response variables such as Likert-based rating scores. This paper presents a dynamic model that incorporates values from topic membership, an outcome variable from Latent Dirichlet Allocation, with sentiment analysis in an Extreme Gradient Boosting (XGBoost) model used for rating prediction. The results show that, by incorporating features from simple unsupervised machine learning approaches (LDA-based), an 86% prediction accuracy (AUC based) can be achieved on objective rating values. At the same time, a combination of polarity and single-topic membership can yield an even higher accuracy when compared with sentiment text detection tasks both at the document and sentence levels. This study carries significant practical implications since sentiment analysis tasks often require dictionary coverage and domain-specific adjustments depending on the task at hand. To further investigate this result, we used Shapley Additive Values to determine the additive predictability of topic membership values in combination with sentiment-based methods using a dataset of customer reviews from food delivery services.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131019507&target=NART&cn=NART131019507",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach <P><B>Abstract</B><P>Rating prediction is a crucial element of business analytics as it enables decision-makers to assess service performance based on expressive customer feedback. Enhancing rating score predictions and demand forecasting through incorporating performance features from verbatim text fields, particularly in service quality measurement and customer satisfaction modelling is a key objective in various areas of analytics. A range of methods has been identified in the literature for improving the predictability of customer feedback, including simple bag-of-words-based approaches and advanced supervised machine learning models, which are designed to work with response variables such as Likert-based rating scores. This paper presents a dynamic model that incorporates values from topic membership, an outcome variable from Latent Dirichlet Allocation, with sentiment analysis in an Extreme Gradient Boosting (XGBoost) model used for rating prediction. The results show that, by incorporating features from simple unsupervised machine learning approaches (LDA-based), an 86% prediction accuracy (AUC based) can be achieved on objective rating values. At the same time, a combination of polarity and single-topic membership can yield an even higher accuracy when compared with sentiment text detection tasks both at the document and sentence levels. This study carries significant practical implications since sentiment analysis tasks often require dictionary coverage and domain-specific adjustments depending on the task at hand. To further investigate this result, we used Shapley Additive Values to determine the additive predictability of topic membership values in combination with sentiment-based methods using a dataset of customer reviews from food delivery services.</P></P>"
        },
        {
          "rank": 9,
          "score": 0.7327069640159607,
          "doc_id": "DIKO0012113511",
          "title": "인공신경망을 이용한 판매처 평가 프레임워크",
          "abstract": "인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012113511&target=NART&cn=DIKO0012113511",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다."
        },
        {
          "rank": 10,
          "score": 0.7267140746116638,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 11,
          "score": 0.7266160249710083,
          "doc_id": "DIKO0017198883",
          "title": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating",
          "abstract": "전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017198883&target=NART&cn=DIKO0017198883",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating 전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다."
        },
        {
          "rank": 12,
          "score": 0.7222386598587036,
          "doc_id": "NART135912853",
          "title": "A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction",
          "abstract": "<P>Churn prediction has become one of the core concepts in customer relationship management within the insurances, telecom, and internet service provider industries, which is essential in customer retention. Therefore, this study attempts to analyze the effectiveness of the advanced machine learning and deep learning models for churn prediction in the evaluation of the models&rsquo; performance across different sectors. This would help conclude whether the varied patterns of the churn throughout different sectors to the level that affects the model performance and to what extent. The work includes three datasets: namely, insurance churn, internet service provider customer churn, and Telecom churn datasets. The implementation and comparison conducted in this study of models include XGBoost, Convolutional Neural Networks (CNNs), and Ensemble Deep Learning with the pre-trained hybrid approach. The results show that the ensemble deep learning model outperforms other models in terms of accuracy and F1-score, achieving accuracies of up to 95.96% in the insurance churn dataset and of 98.42% in the telecom churn dataset. Moreover, traditional machine learning models like XGBoost also produced competitive results for selected datasets. The proposed deep learning ensembles reveal the strength and possibility for churn prediction and provide a benchmark for future research relevant to customer retention strategies. Also, the proposed ensemble deep learning model shows stable performance across different sectors, which reflects its ability to capture the varied churn patterns of different sectors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135912853&target=NART&cn=NART135912853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction <P>Churn prediction has become one of the core concepts in customer relationship management within the insurances, telecom, and internet service provider industries, which is essential in customer retention. Therefore, this study attempts to analyze the effectiveness of the advanced machine learning and deep learning models for churn prediction in the evaluation of the models&rsquo; performance across different sectors. This would help conclude whether the varied patterns of the churn throughout different sectors to the level that affects the model performance and to what extent. The work includes three datasets: namely, insurance churn, internet service provider customer churn, and Telecom churn datasets. The implementation and comparison conducted in this study of models include XGBoost, Convolutional Neural Networks (CNNs), and Ensemble Deep Learning with the pre-trained hybrid approach. The results show that the ensemble deep learning model outperforms other models in terms of accuracy and F1-score, achieving accuracies of up to 95.96% in the insurance churn dataset and of 98.42% in the telecom churn dataset. Moreover, traditional machine learning models like XGBoost also produced competitive results for selected datasets. The proposed deep learning ensembles reveal the strength and possibility for churn prediction and provide a benchmark for future research relevant to customer retention strategies. Also, the proposed ensemble deep learning model shows stable performance across different sectors, which reflects its ability to capture the varied churn patterns of different sectors.</P>"
        },
        {
          "rank": 13,
          "score": 0.7168841361999512,
          "doc_id": "NART118609293",
          "title": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction",
          "abstract": "<P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118609293&target=NART&cn=NART118609293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction <P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>"
        },
        {
          "rank": 14,
          "score": 0.7163960933685303,
          "doc_id": "DIKO0017291669",
          "title": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측",
          "abstract": "최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017291669&target=NART&cn=DIKO0017291669",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다."
        },
        {
          "rank": 15,
          "score": 0.7158179879188538,
          "doc_id": "JAKO202302557624224",
          "title": "평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로",
          "abstract": "코로나19 팬데믹 이후 관광 산업이 회복되면서 많은 관광객들이 다양한 플랫폼을 활용하고 리뷰를 남기고 있지만, 대량의 데이터 속에서 유용한 정보를 찾기 어려워 아직도 여행지 선정 과정에서 많은 시간과 비용이 낭비되고 있다. 이에 따라 많은 연구들이 진행되고 있지만, 평점이 없거나 플랫폼별로 다른 형태의 평점 제공으로 인해 연구에 한계를 가지고 있으며, 평점과 리뷰 내용이 일치하지 않는 경우도 있어 추천 모델 구축에 어려움을 주고 있다. 본 연구에서는 이러한 문제를 해결하기 위해 7,104개의 제주도 지역 관광지 리뷰를 활용하여 제주도에 특화된 관광지 만족도 정량 지수를 개발하고 이를 활용하여 '평점 예측 모델'을 구축하였다. 모델의 성능을 확인하기 위해 실험 데이터 700건의 평점을 본 연구에서 개발된 모델과 LSTM을 활용하여 예측 하였으며, 제안된 모델이 LSTM 보다 약 4.67% 높은 73.87%의 가중 정확도로 성능이 더 우수한 것을 확인하였다. 본 연구의 결과를 통해 평점과 리뷰 내용 사이의 불일치 문제를 해결하고, 평점이 없는 리뷰나 다양한 형태의 평점을 정형할 수 있으며, 다른 도메인에 적용하여 여행의 모든 분야에서 신뢰할 수 있는 평점 지표를 제공할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202302557624224&target=NART&cn=JAKO202302557624224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 코로나19 팬데믹 이후 관광 산업이 회복되면서 많은 관광객들이 다양한 플랫폼을 활용하고 리뷰를 남기고 있지만, 대량의 데이터 속에서 유용한 정보를 찾기 어려워 아직도 여행지 선정 과정에서 많은 시간과 비용이 낭비되고 있다. 이에 따라 많은 연구들이 진행되고 있지만, 평점이 없거나 플랫폼별로 다른 형태의 평점 제공으로 인해 연구에 한계를 가지고 있으며, 평점과 리뷰 내용이 일치하지 않는 경우도 있어 추천 모델 구축에 어려움을 주고 있다. 본 연구에서는 이러한 문제를 해결하기 위해 7,104개의 제주도 지역 관광지 리뷰를 활용하여 제주도에 특화된 관광지 만족도 정량 지수를 개발하고 이를 활용하여 '평점 예측 모델'을 구축하였다. 모델의 성능을 확인하기 위해 실험 데이터 700건의 평점을 본 연구에서 개발된 모델과 LSTM을 활용하여 예측 하였으며, 제안된 모델이 LSTM 보다 약 4.67% 높은 73.87%의 가중 정확도로 성능이 더 우수한 것을 확인하였다. 본 연구의 결과를 통해 평점과 리뷰 내용 사이의 불일치 문제를 해결하고, 평점이 없는 리뷰나 다양한 형태의 평점을 정형할 수 있으며, 다른 도메인에 적용하여 여행의 모든 분야에서 신뢰할 수 있는 평점 지표를 제공할 수 있을 것으로 기대된다."
        },
        {
          "rank": 16,
          "score": 0.71478670835495,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 17,
          "score": 0.7137219309806824,
          "doc_id": "JAKO202523439606404",
          "title": "사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증",
          "abstract": "온라인 환경에서 상품과 콘텐츠의 선택지가 폭발적으로 늘어나면서, 사용자가 원하는 정보를 제시하고, 구매로 이어질 수 있는 추천 시스템의 중요성이 커지고 있다. 기존에는 협업 필터링이 가장 많이 사용되는 추천 기법이었으나, 평점 정보만으로는 추천의 정확도가 한계에 부딪히는 문제가 있었다. 본 논문에서는 추천의 정확성을 높이기 위해, 영화 평점 데이터와 더불어 리뷰 텍스트에서 추출한 감성 점수를 결합한 하이브리드 추천 시스템을 제안한다. 콘텐츠 기반 필터링(CBF)은 영화의 장르와 태그 정보를 TF-IDF 벡터로 변환해 사용자 프로필과 영화 간의 유사도를 계산하는 방식으로 활용하였고, 아이템 기반 협업 필터링(IBCF)은 평점 행렬을 바탕으로 유사 아이템의 평점과 감성 점수를 가중 결합해 예측 값을 산출하였다. 실험 결과, 제안한 하이브리드 모델이 단일 모델이나 감성분석을 제외한 모델보다 추천 정확성 면에서 가장 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202523439606404&target=NART&cn=JAKO202523439606404",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 온라인 환경에서 상품과 콘텐츠의 선택지가 폭발적으로 늘어나면서, 사용자가 원하는 정보를 제시하고, 구매로 이어질 수 있는 추천 시스템의 중요성이 커지고 있다. 기존에는 협업 필터링이 가장 많이 사용되는 추천 기법이었으나, 평점 정보만으로는 추천의 정확도가 한계에 부딪히는 문제가 있었다. 본 논문에서는 추천의 정확성을 높이기 위해, 영화 평점 데이터와 더불어 리뷰 텍스트에서 추출한 감성 점수를 결합한 하이브리드 추천 시스템을 제안한다. 콘텐츠 기반 필터링(CBF)은 영화의 장르와 태그 정보를 TF-IDF 벡터로 변환해 사용자 프로필과 영화 간의 유사도를 계산하는 방식으로 활용하였고, 아이템 기반 협업 필터링(IBCF)은 평점 행렬을 바탕으로 유사 아이템의 평점과 감성 점수를 가중 결합해 예측 값을 산출하였다. 실험 결과, 제안한 하이브리드 모델이 단일 모델이나 감성분석을 제외한 모델보다 추천 정확성 면에서 가장 우수한 성능을 보였다."
        },
        {
          "rank": 18,
          "score": 0.7104558944702148,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 19,
          "score": 0.7085530757904053,
          "doc_id": "NART132071160",
          "title": "Integrating machine learning and deep learning for enhanced supplier risk prediction",
          "abstract": "<P>The importance of anticipating and preventing disruptions is underscored by the increased operational complexity and vulnerability caused by advancements in supply chain management (SCM). This has spurred interest in integrating machine learning (ML) and deep learning (DL) into supply chain risk management (SCRM). In this paper, we introduce a tailored method using ML and DL to improve SCRM by predicting supplier failures, thus boosting efficiency and resilience in SC operations. Our method involves five phases focused on classifying and predicting supplier failures in non-conforming deliveries. This involves forecasting failure quantities and estimating total disruption costs. Initially, data from an automotive company is selected, and appropriate potential features and algorithms are selected, performance metric aligns with case study objectives, facilitating method evaluation are used such as: Precision, recall, F1-score, and accuracy metrics assess classification models, while Mean Squared Error (MSE) is used for regression tasks. Finally, an experimental design optimizes models, assessing success rates of various algorithms and their parameters within the chosen feature space. Experimental results underscore the success of our methodology in model development. In the classification task, the Random Forest (RF) classifier achieved 86% accuracy. When combined with the Gradient Boosting classifier, the ensemble exhibited enhanced accuracy, highlighting the complementary strengths of both algorithms and their synergistic impact, surpassing the performance of RF, Support Vector Regression (SVR), k-Nearest Neighbors (KNN), and Artificial Neural Network (ANN). Noteworthy is the performance in regression tasks, where Linear Regression, ANN, and RF Regressor displayed exceptionally low MSE compared to other models.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART132071160&target=NART&cn=NART132071160",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating machine learning and deep learning for enhanced supplier risk prediction Integrating machine learning and deep learning for enhanced supplier risk prediction Integrating machine learning and deep learning for enhanced supplier risk prediction <P>The importance of anticipating and preventing disruptions is underscored by the increased operational complexity and vulnerability caused by advancements in supply chain management (SCM). This has spurred interest in integrating machine learning (ML) and deep learning (DL) into supply chain risk management (SCRM). In this paper, we introduce a tailored method using ML and DL to improve SCRM by predicting supplier failures, thus boosting efficiency and resilience in SC operations. Our method involves five phases focused on classifying and predicting supplier failures in non-conforming deliveries. This involves forecasting failure quantities and estimating total disruption costs. Initially, data from an automotive company is selected, and appropriate potential features and algorithms are selected, performance metric aligns with case study objectives, facilitating method evaluation are used such as: Precision, recall, F1-score, and accuracy metrics assess classification models, while Mean Squared Error (MSE) is used for regression tasks. Finally, an experimental design optimizes models, assessing success rates of various algorithms and their parameters within the chosen feature space. Experimental results underscore the success of our methodology in model development. In the classification task, the Random Forest (RF) classifier achieved 86% accuracy. When combined with the Gradient Boosting classifier, the ensemble exhibited enhanced accuracy, highlighting the complementary strengths of both algorithms and their synergistic impact, surpassing the performance of RF, Support Vector Regression (SVR), k-Nearest Neighbors (KNN), and Artificial Neural Network (ANN). Noteworthy is the performance in regression tasks, where Linear Regression, ANN, and RF Regressor displayed exceptionally low MSE compared to other models.</P>"
        },
        {
          "rank": 20,
          "score": 0.7059293985366821,
          "doc_id": "JAKO202325543363508",
          "title": "딥러닝 영상분석 시스템의 성능평가 산정식 개발",
          "abstract": "도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202325543363508&target=NART&cn=JAKO202325543363508",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다."
        },
        {
          "rank": 21,
          "score": 0.7047409415245056,
          "doc_id": "ATN0037496660",
          "title": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교",
          "abstract": "Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037496660&target=NART&cn=ATN0037496660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model."
        },
        {
          "rank": 22,
          "score": 0.7034053802490234,
          "doc_id": "JAKO201722163438451",
          "title": "딥러닝과 통계 모델을 이용한 T-커머스 매출 예측",
          "abstract": "T-커머스는 양방향 디지털 TV를 기반으로 양방향 데이터방송 기술을 활용하여 상거래를 하는 기술융합형 서비스이다. 채널 번호와 판매상품이 제한된 환경에서 T-커머스의 매출을 극대화 하기 위해서는 각 제품의 시간대별 경쟁력을 고려하여 매출이 최대화 되도록 프로그램을 편성해야 한다. 이를 위해, 본 논문에서는 딥러닝을 이용해 T-커머스에서 각 상품을 각 시간대에 편성하였을 때의 매출을 예측하는 방법을 제안한다. 제안하는 방법은 심층신경망을 이용해 판매 상품과 시간대, 주차, 휴일 여부, 그리고 날씨를 입력 받아 실제 방송으로 편성했을 때 기대되는 매출을 예측한다. 그리고, 통계적 모델과 SVD(Singular Value Decomposition)를 적용하여 판매 데이터의 편중 및 희박성 문제를 완화한다. 실제 T-커머스 운영자인 (주)더블유쇼핑의 판매 기록 데이터에 대하여 실험하였을 때 실제 매출과 예측치의 차이가 0.12의 NMAE(Normalized Mean Absolute Error)를 보여 제안하는 알고리즘이 효과적으로 동작함을 확인하였다. 제안된 시스템은 (주)더블유쇼핑의 T-커머스 시스템 적용되어 방송 편성에 활용되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201722163438451&target=NART&cn=JAKO201722163438451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 T-커머스는 양방향 디지털 TV를 기반으로 양방향 데이터방송 기술을 활용하여 상거래를 하는 기술융합형 서비스이다. 채널 번호와 판매상품이 제한된 환경에서 T-커머스의 매출을 극대화 하기 위해서는 각 제품의 시간대별 경쟁력을 고려하여 매출이 최대화 되도록 프로그램을 편성해야 한다. 이를 위해, 본 논문에서는 딥러닝을 이용해 T-커머스에서 각 상품을 각 시간대에 편성하였을 때의 매출을 예측하는 방법을 제안한다. 제안하는 방법은 심층신경망을 이용해 판매 상품과 시간대, 주차, 휴일 여부, 그리고 날씨를 입력 받아 실제 방송으로 편성했을 때 기대되는 매출을 예측한다. 그리고, 통계적 모델과 SVD(Singular Value Decomposition)를 적용하여 판매 데이터의 편중 및 희박성 문제를 완화한다. 실제 T-커머스 운영자인 (주)더블유쇼핑의 판매 기록 데이터에 대하여 실험하였을 때 실제 매출과 예측치의 차이가 0.12의 NMAE(Normalized Mean Absolute Error)를 보여 제안하는 알고리즘이 효과적으로 동작함을 확인하였다. 제안된 시스템은 (주)더블유쇼핑의 T-커머스 시스템 적용되어 방송 편성에 활용되었다."
        },
        {
          "rank": 23,
          "score": 0.7000311613082886,
          "doc_id": "NPAP12734426",
          "title": "Deep sequential model for review rating prediction",
          "abstract": "<P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12734426&target=NART&cn=NPAP12734426",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep sequential model for review rating prediction Deep sequential model for review rating prediction Deep sequential model for review rating prediction <P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>"
        },
        {
          "rank": 24,
          "score": 0.6988692283630371,
          "doc_id": "JAKO202128837904086",
          "title": "평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화",
          "abstract": "팬데믹(Pandemic)으로 인해 온라인 시장의 규모가 급속하게 커졌다. 일상에서의 비대면화는그동안 기술수용에 늦은 소비자마저 온라인구매의 편리함을 경험하게 하는 계기가 되었고, 이들은 팬데믹 이후에도 온라인구매의 이점을 선호하게 될 것이다. 하지만 이러한 변화의 시기에 소비자가 취할 수 있는 제품 정보는 편평한 디스플레이상의 시각적 정보만으로 축소되었다. 회사들은 차별적이고 경쟁력 있는 정보를 제공하기 위해 AR/VR, Streaming 기술 등을 도입하고 있지만, 정직한 사용자들이 남긴 리뷰는 회사가 제공하는 잘 가공된 정보만큼 소비자에게 강력하게 인식되고, 회사의 상품개발과 마케팅 및 판매 전략을 위한 인사이트를 얻을 수 있다는 점에서 중요하게 인식될 필요가 있다. 그렇다면 소비자의 입장에서, 구매 의사결정 전에 참고하는 리뷰의 평점이 크게 어긋난다면, 소비자들은 어떻게 리뷰정보를 처리할까? 수렴되지 않은 평점은 늘 신뢰할 수 없고 가치 없는 것일까? 본 연구에서는 소비자의 개인 성향으로 볼 수 있는 조절초점 성향이 어떻게 사고방식을 지배하여 수렴되지 않은 정보를 수용하고 처리하는지 보이고자 하였다. 실험은 화장품을 대상으로 제품 리뷰 평점의 분산(높음 vs 낮음)이 소비자의 조절초점(예방초점 vs. 향상초점)에 따라 제품 태도에 어떤 영향을 미치는지 2x2 연구로 설계하였다. 연구결과, 예방초점의 소비자는 분산이 작을 때 높은 제품 태도를 보이지만, 향상초점의 소비자는 분산이 클 때 높은 제품 태도를 보인다는 것을 발견하였다. 이와 같은 연구로, 본 논문은 동일한 평균값의 평가점수를 가진 제품이라도 후기의 분산 값에 따라 소비자의 조절초점 성향이 영향을 미쳐 제품 태도가 달라진다는 것을 설명할 수 있다. 본 논문은 평점이 수렴되지 않는 정보에 대한 소비자의 정보처리의 메커니즘을 밝힌 이론적 공헌이 있으며, 실무적으로 기업은 리뷰가 축적됨에 따라 개인화되고 최적화된 상품 정보를 제공하는 등 빅데이터를 바탕으로 지식경영을 응용한 고객경험설계가 가능함을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837904086&target=NART&cn=JAKO202128837904086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 팬데믹(Pandemic)으로 인해 온라인 시장의 규모가 급속하게 커졌다. 일상에서의 비대면화는그동안 기술수용에 늦은 소비자마저 온라인구매의 편리함을 경험하게 하는 계기가 되었고, 이들은 팬데믹 이후에도 온라인구매의 이점을 선호하게 될 것이다. 하지만 이러한 변화의 시기에 소비자가 취할 수 있는 제품 정보는 편평한 디스플레이상의 시각적 정보만으로 축소되었다. 회사들은 차별적이고 경쟁력 있는 정보를 제공하기 위해 AR/VR, Streaming 기술 등을 도입하고 있지만, 정직한 사용자들이 남긴 리뷰는 회사가 제공하는 잘 가공된 정보만큼 소비자에게 강력하게 인식되고, 회사의 상품개발과 마케팅 및 판매 전략을 위한 인사이트를 얻을 수 있다는 점에서 중요하게 인식될 필요가 있다. 그렇다면 소비자의 입장에서, 구매 의사결정 전에 참고하는 리뷰의 평점이 크게 어긋난다면, 소비자들은 어떻게 리뷰정보를 처리할까? 수렴되지 않은 평점은 늘 신뢰할 수 없고 가치 없는 것일까? 본 연구에서는 소비자의 개인 성향으로 볼 수 있는 조절초점 성향이 어떻게 사고방식을 지배하여 수렴되지 않은 정보를 수용하고 처리하는지 보이고자 하였다. 실험은 화장품을 대상으로 제품 리뷰 평점의 분산(높음 vs 낮음)이 소비자의 조절초점(예방초점 vs. 향상초점)에 따라 제품 태도에 어떤 영향을 미치는지 2x2 연구로 설계하였다. 연구결과, 예방초점의 소비자는 분산이 작을 때 높은 제품 태도를 보이지만, 향상초점의 소비자는 분산이 클 때 높은 제품 태도를 보인다는 것을 발견하였다. 이와 같은 연구로, 본 논문은 동일한 평균값의 평가점수를 가진 제품이라도 후기의 분산 값에 따라 소비자의 조절초점 성향이 영향을 미쳐 제품 태도가 달라진다는 것을 설명할 수 있다. 본 논문은 평점이 수렴되지 않는 정보에 대한 소비자의 정보처리의 메커니즘을 밝힌 이론적 공헌이 있으며, 실무적으로 기업은 리뷰가 축적됨에 따라 개인화되고 최적화된 상품 정보를 제공하는 등 빅데이터를 바탕으로 지식경영을 응용한 고객경험설계가 가능함을 시사한다."
        },
        {
          "rank": 25,
          "score": 0.6979888677597046,
          "doc_id": "JAKO201403359939237",
          "title": "개선된 배깅 앙상블을 활용한 기업부도예측",
          "abstract": "기업의 부도 예측은 재무 및 회계 분야에서 매우 중요한 연구 주제이다. 기업의 부도로 인해 발생하는 비용이 매우 크기 때문에 부도 예측의 정확성은 금융기관으로서는 매우 중요한 일이다. 최근에는 여러 개의 모형을 결합하는 앙상블 모형을 부도 예측에 적용해 보려는 연구가 큰 관심을 끌고 있다. 앙상블 모형은 개별 모형보다 더 좋은 성과를 내기 위해 여러 개의 분류기를 결합하는 것이다. 이와 같은 앙상블 분류기는 분류기의 일반화 성능을 개선하는 데 매우 유용한 것으로 알려져 있다. 본 논문은 부도 예측 모형의 성과 개선에 관한 연구이다. 이를 위해 사례 선택(Instance Selection)을 활용한 배깅(Bagging) 모형을 제안하였다. 사례 선택은 원 데이터에서 가장 대표성 있고 관련성 높은 데이터를 선택하고 예측 모형에 악영향을 줄 수 있는 불필요한 데이터를 제거하는 것으로 이를 통해 예측 성과 개선도 기대할 수 있다. 배깅은 학습데이터에 변화를 줌으로써 기저 분류기들을 다양화시키는 앙상블 기법으로 단순하면서도 성과가 매우 좋은 것으로 알려져 있다. 사례 선택과 배깅은 각각 모형의 성과를 개선시킬 수 있는 잠재력이 있지만 이들 두 기법의 결합에 관한 연구는 아직까지 없는 것이 현실이다. 본 연구에서는 부도 예측 모형의 성과를 개선하기 위해 사례 선택과 배깅을 연결하는 새로운 모형을 제안하였다. 최적의 사례 선택을 위해 유전자 알고리즘이 사용되었으며, 이를 통해 최적의 사례 선택 조합을 찾고 이 결과를 배깅 앙상블 모형에 전달하여 새로운 형태의 배깅 앙상블 모형을 구성하게 된다. 본 연구에서 제안한 새로운 앙상블 모형의 성과를 검증하기 위해 ROC 커브, AUC, 예측정확도 등과 같은 성과지표를 사용해 다양한 모형과 비교 분석해 보았다. 실제 기업데이터를 사용해 실험한 결과 본 논문에서 제안한 새로운 형태의 모형이 가장 좋은 성과를 보임을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201403359939237&target=NART&cn=JAKO201403359939237",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "개선된 배깅 앙상블을 활용한 기업부도예측 개선된 배깅 앙상블을 활용한 기업부도예측 개선된 배깅 앙상블을 활용한 기업부도예측 기업의 부도 예측은 재무 및 회계 분야에서 매우 중요한 연구 주제이다. 기업의 부도로 인해 발생하는 비용이 매우 크기 때문에 부도 예측의 정확성은 금융기관으로서는 매우 중요한 일이다. 최근에는 여러 개의 모형을 결합하는 앙상블 모형을 부도 예측에 적용해 보려는 연구가 큰 관심을 끌고 있다. 앙상블 모형은 개별 모형보다 더 좋은 성과를 내기 위해 여러 개의 분류기를 결합하는 것이다. 이와 같은 앙상블 분류기는 분류기의 일반화 성능을 개선하는 데 매우 유용한 것으로 알려져 있다. 본 논문은 부도 예측 모형의 성과 개선에 관한 연구이다. 이를 위해 사례 선택(Instance Selection)을 활용한 배깅(Bagging) 모형을 제안하였다. 사례 선택은 원 데이터에서 가장 대표성 있고 관련성 높은 데이터를 선택하고 예측 모형에 악영향을 줄 수 있는 불필요한 데이터를 제거하는 것으로 이를 통해 예측 성과 개선도 기대할 수 있다. 배깅은 학습데이터에 변화를 줌으로써 기저 분류기들을 다양화시키는 앙상블 기법으로 단순하면서도 성과가 매우 좋은 것으로 알려져 있다. 사례 선택과 배깅은 각각 모형의 성과를 개선시킬 수 있는 잠재력이 있지만 이들 두 기법의 결합에 관한 연구는 아직까지 없는 것이 현실이다. 본 연구에서는 부도 예측 모형의 성과를 개선하기 위해 사례 선택과 배깅을 연결하는 새로운 모형을 제안하였다. 최적의 사례 선택을 위해 유전자 알고리즘이 사용되었으며, 이를 통해 최적의 사례 선택 조합을 찾고 이 결과를 배깅 앙상블 모형에 전달하여 새로운 형태의 배깅 앙상블 모형을 구성하게 된다. 본 연구에서 제안한 새로운 앙상블 모형의 성과를 검증하기 위해 ROC 커브, AUC, 예측정확도 등과 같은 성과지표를 사용해 다양한 모형과 비교 분석해 보았다. 실제 기업데이터를 사용해 실험한 결과 본 논문에서 제안한 새로운 형태의 모형이 가장 좋은 성과를 보임을 알 수 있었다."
        },
        {
          "rank": 26,
          "score": 0.6970755457878113,
          "doc_id": "JAKO201620853199880",
          "title": "딥러닝의 모형과 응용사례",
          "abstract": "딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201620853199880&target=NART&cn=JAKO201620853199880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다."
        },
        {
          "rank": 27,
          "score": 0.6958533525466919,
          "doc_id": "ATN0052776138",
          "title": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구",
          "abstract": "첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0052776138&target=NART&cn=ATN0052776138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다."
        },
        {
          "rank": 28,
          "score": 0.69355309009552,
          "doc_id": "JAKO202404861562091",
          "title": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교",
          "abstract": "대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202404861562091&target=NART&cn=JAKO202404861562091",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다."
        },
        {
          "rank": 29,
          "score": 0.6923928260803223,
          "doc_id": "JAKO201912758458868",
          "title": "딥러닝 개념을 위한 인공지능 교육 프로그램",
          "abstract": "본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201912758458868&target=NART&cn=JAKO201912758458868",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다."
        },
        {
          "rank": 30,
          "score": 0.6917616724967957,
          "doc_id": "DIKO0015771393",
          "title": "딥러닝 기술을 이용한 전력 수요 예측 방법",
          "abstract": "정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015771393&target=NART&cn=DIKO0015771393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다."
        },
        {
          "rank": 31,
          "score": 0.6907082796096802,
          "doc_id": "ATN0051728135",
          "title": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구",
          "abstract": "하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0051728135&target=NART&cn=ATN0051728135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다."
        },
        {
          "rank": 32,
          "score": 0.6898880004882812,
          "doc_id": "ART003001921",
          "title": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning",
          "abstract": "Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003001921&target=NART&cn=ART003001921",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision."
        },
        {
          "rank": 33,
          "score": 0.6891191005706787,
          "doc_id": "ATN0031726879",
          "title": "딥러닝 기반 부실기업 예측모형에 관한 연구",
          "abstract": "Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0031726879&target=NART&cn=ATN0031726879",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 부실기업 예측모형에 관한 연구 딥러닝 기반 부실기업 예측모형에 관한 연구 딥러닝 기반 부실기업 예측모형에 관한 연구 Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future."
        },
        {
          "rank": 34,
          "score": 0.6863436698913574,
          "doc_id": "JAKO201909358629867",
          "title": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석",
          "abstract": "인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629867&target=NART&cn=JAKO201909358629867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다."
        },
        {
          "rank": 35,
          "score": 0.685375452041626,
          "doc_id": "JAKO202305062334676",
          "title": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측",
          "abstract": "본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202305062334676&target=NART&cn=JAKO202305062334676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다."
        },
        {
          "rank": 36,
          "score": 0.6848981380462646,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 37,
          "score": 0.684240996837616,
          "doc_id": "JAKO202009252092311",
          "title": "공공 빅데이터 플랫폼 성과평가 모형",
          "abstract": "본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009252092311&target=NART&cn=JAKO202009252092311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다."
        },
        {
          "rank": 38,
          "score": 0.6822835206985474,
          "doc_id": "JAKO202116047225054",
          "title": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어",
          "abstract": "최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116047225054&target=NART&cn=JAKO202116047225054",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다."
        },
        {
          "rank": 39,
          "score": 0.6793696880340576,
          "doc_id": "JAKO202109651162667",
          "title": "신경망기법을 활용한 선박 가치평가 모델 개발",
          "abstract": "본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109651162667&target=NART&cn=JAKO202109651162667",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다."
        },
        {
          "rank": 40,
          "score": 0.6792940497398376,
          "doc_id": "JAKO202116954704821",
          "title": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측",
          "abstract": "본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116954704821&target=NART&cn=JAKO202116954704821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다."
        },
        {
          "rank": 41,
          "score": 0.678987979888916,
          "doc_id": "NART130707218",
          "title": "Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction",
          "abstract": "<P>Sentiment analysis is the most basic and imperative work in mining the preference of user interest. In this work, a deep model with optimization, named &ldquo;Chimp Whale Optimization Algorithm-based Random Multimodal Deep Learning&rdquo; is devised for sentiment rating prediction. The process of tokenization, which divides the entire document into small units using Bidirectional Encoder Representations from Transformers (BERT) for better processing, is where the input review data is initially given. Aspects from review data and aspect term extraction are completed for mining. Additionally, Random Multimodal Deep Learning is used to forecast the sentiment rating. The ChWOA is used in this case to combine the Chimp Optimization Algorithm (ChOA) and the Whale Optimization Algorithm (WOA). With a precision of 93.1%, recall of 94.4%, and F-measure of 93.8%, the ChWOA-based RMDL demonstrated better efficiency.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART130707218&target=NART&cn=NART130707218",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction <P>Sentiment analysis is the most basic and imperative work in mining the preference of user interest. In this work, a deep model with optimization, named &ldquo;Chimp Whale Optimization Algorithm-based Random Multimodal Deep Learning&rdquo; is devised for sentiment rating prediction. The process of tokenization, which divides the entire document into small units using Bidirectional Encoder Representations from Transformers (BERT) for better processing, is where the input review data is initially given. Aspects from review data and aspect term extraction are completed for mining. Additionally, Random Multimodal Deep Learning is used to forecast the sentiment rating. The ChWOA is used in this case to combine the Chimp Optimization Algorithm (ChOA) and the Whale Optimization Algorithm (WOA). With a precision of 93.1%, recall of 94.4%, and F-measure of 93.8%, the ChWOA-based RMDL demonstrated better efficiency.</P>"
        },
        {
          "rank": 42,
          "score": 0.6780364513397217,
          "doc_id": "JAKO202123557632781",
          "title": "정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로",
          "abstract": "소비자의 식품소비행동은 소비자 패널 데이터와 같은 정형 데이터 뿐 아니라 매스미디어와 소셜미디어(SNS) 등 비정형 데이터로부터 영향을 받을 가능성이 높아지고 있다. 본 연구에서는 식품소비 관련된 정형 데이터와 비정형 데이터를 연계한 융합데이터 셋에 대하여 딥러닝 기반의 소비예측 모델을 생성하고 이를 검증한다. 연구의 결과는 정형 데이터와 비정형 데이터를 결합할 때 모델 정확도가 향상되었음을 보여주었다. 또한 비정형 데이터가 모델 예측 가능성을 향상시키는 것으로 나타났다. 변수들의 중요도를 식별하기 위해 SHAP 기법을 사용한 결과 블로그 및 비디오 데이터 관련 변수가 상위 목록에 있었고, 파프리카 구매 금액과 양의 상관관계가 있음을 알 수 있었다. 또한 실험 결과에 따르면 머신러닝 모델이 딥러닝 모델보다 높은 정확도를 보였고, 기존의 시계열 분석 모델링에 대한 효율적인 대안이 될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202123557632781&target=NART&cn=JAKO202123557632781",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로 정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로 정형 및 비정형 데이터를 이용한 농산물 구매량 예측: 파프리카를 중심으로 소비자의 식품소비행동은 소비자 패널 데이터와 같은 정형 데이터 뿐 아니라 매스미디어와 소셜미디어(SNS) 등 비정형 데이터로부터 영향을 받을 가능성이 높아지고 있다. 본 연구에서는 식품소비 관련된 정형 데이터와 비정형 데이터를 연계한 융합데이터 셋에 대하여 딥러닝 기반의 소비예측 모델을 생성하고 이를 검증한다. 연구의 결과는 정형 데이터와 비정형 데이터를 결합할 때 모델 정확도가 향상되었음을 보여주었다. 또한 비정형 데이터가 모델 예측 가능성을 향상시키는 것으로 나타났다. 변수들의 중요도를 식별하기 위해 SHAP 기법을 사용한 결과 블로그 및 비디오 데이터 관련 변수가 상위 목록에 있었고, 파프리카 구매 금액과 양의 상관관계가 있음을 알 수 있었다. 또한 실험 결과에 따르면 머신러닝 모델이 딥러닝 모델보다 높은 정확도를 보였고, 기존의 시계열 분석 모델링에 대한 효율적인 대안이 될 수 있음을 확인하였다."
        },
        {
          "rank": 43,
          "score": 0.6777603626251221,
          "doc_id": "JAKO202128837709024",
          "title": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법",
          "abstract": "딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837709024&target=NART&cn=JAKO202128837709024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다."
        },
        {
          "rank": 44,
          "score": 0.6776218414306641,
          "doc_id": "JAKO202305758375548",
          "title": "머신러닝 기반 대학생 중도 탈락 예측 모델의 성능 비교",
          "abstract": "전국 대학생의 중도 탈락 비율의 증가는 학생 개인 뿐만 아니라 대학과 사회에 심각한 부정적 영향을 끼친다. 본 연구에서는 중도 탈락이 예상되는 학생을 사전에 식별하기 위하여, 각 대학의 학사관리 시스템에서 손쉽게 얻을 수 있는 학적 데이터를 기반으로 머신러닝 분야의 결정트리, 랜덤 포레스트, 로지스틱 회귀 및 딥러닝 기반의 중도 탈락 예측 모델을 구축하고, 그 성능을 비교&#x00B7;분석하였다. 분석 결과 로지스틱 회귀 기반 예측 모델의 재현율이 가장 높았으나 f-1 및 auc 값이 낮은 한계를 보였고, 랜덤 포레스트 기반의 예측 모델의 경우 재현율을 제외한 다른 모든 지표에서 가장 우수한 성능을 보였다. 또한 예측 기간에 따른 예측 모델의 성능을 확인하기 위하여 예측 기간을 단기(1개 학기 이내), 중기(2개 학기 이내) 및 장기(3개 학기 이내)로 나누어 분석해 본 결과, 장기 예측 시 가장 높은 예측력을 보였다. 본 연구를 통해 각 대학은 중도 탈락이 예상되는 학생들을 조기에 식별하고, 이들에 대한 집중 관리를 통해 중도 탈락 비율을 줄이며 나아가 대학 재정 안정화에 기여할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202305758375548&target=NART&cn=JAKO202305758375548",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝 기반 대학생 중도 탈락 예측 모델의 성능 비교 머신러닝 기반 대학생 중도 탈락 예측 모델의 성능 비교 머신러닝 기반 대학생 중도 탈락 예측 모델의 성능 비교 전국 대학생의 중도 탈락 비율의 증가는 학생 개인 뿐만 아니라 대학과 사회에 심각한 부정적 영향을 끼친다. 본 연구에서는 중도 탈락이 예상되는 학생을 사전에 식별하기 위하여, 각 대학의 학사관리 시스템에서 손쉽게 얻을 수 있는 학적 데이터를 기반으로 머신러닝 분야의 결정트리, 랜덤 포레스트, 로지스틱 회귀 및 딥러닝 기반의 중도 탈락 예측 모델을 구축하고, 그 성능을 비교&#x00B7;분석하였다. 분석 결과 로지스틱 회귀 기반 예측 모델의 재현율이 가장 높았으나 f-1 및 auc 값이 낮은 한계를 보였고, 랜덤 포레스트 기반의 예측 모델의 경우 재현율을 제외한 다른 모든 지표에서 가장 우수한 성능을 보였다. 또한 예측 기간에 따른 예측 모델의 성능을 확인하기 위하여 예측 기간을 단기(1개 학기 이내), 중기(2개 학기 이내) 및 장기(3개 학기 이내)로 나누어 분석해 본 결과, 장기 예측 시 가장 높은 예측력을 보였다. 본 연구를 통해 각 대학은 중도 탈락이 예상되는 학생들을 조기에 식별하고, 이들에 대한 집중 관리를 통해 중도 탈락 비율을 줄이며 나아가 대학 재정 안정화에 기여할 수 있을 것으로 기대된다."
        },
        {
          "rank": 45,
          "score": 0.6766645908355713,
          "doc_id": "ATN0045840152",
          "title": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구",
          "abstract": "현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0045840152&target=NART&cn=ATN0045840152",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다."
        },
        {
          "rank": 46,
          "score": 0.6761167049407959,
          "doc_id": "JAKO202421251156831",
          "title": "LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석",
          "abstract": "This research is a comprehensive analysis of wind power prediction sensitivity using a Long Short-Term Memory (LSTM) deep learning neural network model, accounting for the inherent uncertainties in wind speed estimation. Utilizing a year's worth of operational data from an operational wind farm, the study forecasts the power output of both individual wind turbines and the farm collectively. Predictions were made daily at intervals of 10 minutes and 1 hour over a span of three months. The model's forecast accuracy was evaluated by comparing the root mean square error (RMSE), normalized RMSE (NRMSE), and correlation coefficients with actual power output data. Moreover, the research investigated how inaccuracies in wind speed inputs affect the power prediction sensitivity of the model. By simulating wind speed errors within a normal distribution range of 1% to 15%, the study analyzed their influence on the accuracy of power predictions. This investigation provided insights into the required wind speed prediction error rate to achieve an 8% power prediction error threshold, meeting the incentive standards for forecasting systems in renewable energy generation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202421251156831&target=NART&cn=JAKO202421251156831",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 This research is a comprehensive analysis of wind power prediction sensitivity using a Long Short-Term Memory (LSTM) deep learning neural network model, accounting for the inherent uncertainties in wind speed estimation. Utilizing a year's worth of operational data from an operational wind farm, the study forecasts the power output of both individual wind turbines and the farm collectively. Predictions were made daily at intervals of 10 minutes and 1 hour over a span of three months. The model's forecast accuracy was evaluated by comparing the root mean square error (RMSE), normalized RMSE (NRMSE), and correlation coefficients with actual power output data. Moreover, the research investigated how inaccuracies in wind speed inputs affect the power prediction sensitivity of the model. By simulating wind speed errors within a normal distribution range of 1% to 15%, the study analyzed their influence on the accuracy of power predictions. This investigation provided insights into the required wind speed prediction error rate to achieve an 8% power prediction error threshold, meeting the incentive standards for forecasting systems in renewable energy generation."
        },
        {
          "rank": 47,
          "score": 0.6758899092674255,
          "doc_id": "JAKO202326257736885",
          "title": "심층 강화학습 기반의 대학 전공과목 추천 시스템",
          "abstract": "기존의 단순 통계 기반 추천 시스템은 학생들의 수강 이력 데이터만을 활용하기 때문에 선호하는 수업을 찾는 것에 많은 어려움을 겪고 있다. 이를 해결하기 위해, 본 연구에서는 심층 강화학습 기반의 개인화된 전공과목 추천 시스템을 제안한다. 이 시스템은 학생의 학과, 학년, 수강 이력 등의 정형 데이터를 기반으로 학생들 간의 유사도를 측정하며, 이를 통해 각 전공과목에 대한 정보와 학생들의 강의 평가를 종합적으로 고려하여 가장 적합한 전공과목을 추천한다. 본 논문에서는 이 DRL 기반의 추천 시스템을 통해 대학생들이 전공과목을 선택하는 데에 유용한 정보를 제공하며, 이를 통계 기반 추천 시스템과 비교하였을 때 더 우수한 성능을 보여주는 것을 확인하였다. 시뮬레이션 결과, 심층 강화학습 기반의 추천 시스템은 통계 기반 추천 시스템에 비해 수강 과목 예측률에서 약 20%의 성능 향상을 보였다. 이러한 결과를 바탕으로, 학생들의 강의 평가를 반영하여 개인화된 과목 추천을 제공하는 새로운 시스템을 제안한다. 이 시스템은 학생들이 자신의 선호와 목표에 맞는 전공과목을 찾는 데에 큰 도움이 될 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202326257736885&target=NART&cn=JAKO202326257736885",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기반의 대학 전공과목 추천 시스템 심층 강화학습 기반의 대학 전공과목 추천 시스템 심층 강화학습 기반의 대학 전공과목 추천 시스템 기존의 단순 통계 기반 추천 시스템은 학생들의 수강 이력 데이터만을 활용하기 때문에 선호하는 수업을 찾는 것에 많은 어려움을 겪고 있다. 이를 해결하기 위해, 본 연구에서는 심층 강화학습 기반의 개인화된 전공과목 추천 시스템을 제안한다. 이 시스템은 학생의 학과, 학년, 수강 이력 등의 정형 데이터를 기반으로 학생들 간의 유사도를 측정하며, 이를 통해 각 전공과목에 대한 정보와 학생들의 강의 평가를 종합적으로 고려하여 가장 적합한 전공과목을 추천한다. 본 논문에서는 이 DRL 기반의 추천 시스템을 통해 대학생들이 전공과목을 선택하는 데에 유용한 정보를 제공하며, 이를 통계 기반 추천 시스템과 비교하였을 때 더 우수한 성능을 보여주는 것을 확인하였다. 시뮬레이션 결과, 심층 강화학습 기반의 추천 시스템은 통계 기반 추천 시스템에 비해 수강 과목 예측률에서 약 20%의 성능 향상을 보였다. 이러한 결과를 바탕으로, 학생들의 강의 평가를 반영하여 개인화된 과목 추천을 제공하는 새로운 시스템을 제안한다. 이 시스템은 학생들이 자신의 선호와 목표에 맞는 전공과목을 찾는 데에 큰 도움이 될 것으로 기대한다."
        },
        {
          "rank": 48,
          "score": 0.6755053997039795,
          "doc_id": "JAKO201718054814596",
          "title": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석",
          "abstract": "딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201718054814596&target=NART&cn=JAKO201718054814596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다."
        },
        {
          "rank": 49,
          "score": 0.6748067140579224,
          "doc_id": "JAKO202315032964275",
          "title": "딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발",
          "abstract": "본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(10<sup>8</sup> 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 10<sup>8</sup>으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202315032964275&target=NART&cn=JAKO202315032964275",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(10<sup>8</sup> 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 10<sup>8</sup>으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다."
        },
        {
          "rank": 50,
          "score": 0.6742599010467529,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        }
      ]
    },
    {
      "query": "비정형 리뷰 데이터를 활용해 고객 평점을 예측하기 위해 설계된 딥 러닝 모델의 구조는 무엇인가요?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8935614824295044,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 2,
          "score": 0.8074585199356079,
          "doc_id": "DIKO0015775432",
          "title": "딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로",
          "abstract": "온라인 쇼핑몰, 영화, 호텔 등 전자상거래의 다양한 영역에서 고객은 다른 고객이 남긴 리뷰 혹은 평점을 통해 아이템의 품질을 판단해 구매한다. 이에 따라 많은 연구자가 아이템의 평점과 리뷰를 동시에 고려한 추천 시스템 연구를 진행하고 있다. 그러나, 리뷰와 평점이 불일치하여 추천의 신뢰성이 문제 되고 있다. 즉, 사용자가 리뷰에서 좋다고 기술하였지만, 평점은 3점만 주거나, 리뷰에서 좋지 않다고 기술하였지만, 평점을 4점 이상 주는 상황이 발생하기 때문에, 추천의 품질이 저하되는 문제점이 존재한다. 이런 문제를 해결하기 위해 본 연구는 수집한 호텔 평가 데이터를 사용하여 리뷰와 평점 불일치 데이터를 발견하고, 추천 정확도를 높이는 방법을 제시한다.&amp;#xD; &amp;#xD; 이러한 목적을 달성하기 위한 본 연구의 방법은 다음과 같이 3단계로 구성되어 있다. 첫 번째 단계에서는 다양한 호텔 리뷰 데이터로부터 UserID, ItemID, 리뷰, 평점이 포함하는 데이터를 수집하여 처리한다. 그리고 감성분석 모델 구축용 데이터, 추천 시스템 모델 용 2 개 데이터 셋으로 분할한다. 두 번째 단계에서는 리뷰로부터 감성 분석 모델 구축용 데이터로 감성(긍정/부정/중성)을 예측할 수 있는 딥러닝 모형을 구축한다. 세 번째 단계에서는, 추천 시스템 모델 용 데이터로 두번째 단계에서 구축한 모델을 이용하여 리뷰의 감성 분류를 예측한다. 예측 결과와 평점 결합해서 리뷰와 평점 일치 여부를 파악하며, 일치한 데이터와 전체 데이터 각각 추천 시스템 모델에서 따로 실험하고 성능을 비교한다. 연구 실험에서는 세계적으로 유명한 여행 사이트인 TripAdvisor의 홈페이지에서 뉴욕에 있는 호텔 평가 데이터를 수집하여 사용한다.&amp;#xD; &amp;#xD; 본 연구에서는 감성을 판단하는 딥러닝 모델을 구축하였다. 또한, 호텔 영역에 리뷰와 평점 불일치 문제 때문에 추천 시스템 연구에서 성능이 떨어지는 것을 해결하는 방법을 제시하였다. 따라서 추천 시스템 연구 중 정확하지 않은 리뷰와 평점을 피하는 데 도움이 된다. 본 연구는 직접 데이터를 수집 및 모델 구축하였기에 다른 호텔 평가에 활용할 수 있을 것으로 기대한다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015775432&target=NART&cn=DIKO0015775432",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 딥러닝 모델을 이용한 고객 선호도 예측 연구 : 온라인 호텔 리뷰와 평점 중심으로 온라인 쇼핑몰, 영화, 호텔 등 전자상거래의 다양한 영역에서 고객은 다른 고객이 남긴 리뷰 혹은 평점을 통해 아이템의 품질을 판단해 구매한다. 이에 따라 많은 연구자가 아이템의 평점과 리뷰를 동시에 고려한 추천 시스템 연구를 진행하고 있다. 그러나, 리뷰와 평점이 불일치하여 추천의 신뢰성이 문제 되고 있다. 즉, 사용자가 리뷰에서 좋다고 기술하였지만, 평점은 3점만 주거나, 리뷰에서 좋지 않다고 기술하였지만, 평점을 4점 이상 주는 상황이 발생하기 때문에, 추천의 품질이 저하되는 문제점이 존재한다. 이런 문제를 해결하기 위해 본 연구는 수집한 호텔 평가 데이터를 사용하여 리뷰와 평점 불일치 데이터를 발견하고, 추천 정확도를 높이는 방법을 제시한다.&amp;#xD; &amp;#xD; 이러한 목적을 달성하기 위한 본 연구의 방법은 다음과 같이 3단계로 구성되어 있다. 첫 번째 단계에서는 다양한 호텔 리뷰 데이터로부터 UserID, ItemID, 리뷰, 평점이 포함하는 데이터를 수집하여 처리한다. 그리고 감성분석 모델 구축용 데이터, 추천 시스템 모델 용 2 개 데이터 셋으로 분할한다. 두 번째 단계에서는 리뷰로부터 감성 분석 모델 구축용 데이터로 감성(긍정/부정/중성)을 예측할 수 있는 딥러닝 모형을 구축한다. 세 번째 단계에서는, 추천 시스템 모델 용 데이터로 두번째 단계에서 구축한 모델을 이용하여 리뷰의 감성 분류를 예측한다. 예측 결과와 평점 결합해서 리뷰와 평점 일치 여부를 파악하며, 일치한 데이터와 전체 데이터 각각 추천 시스템 모델에서 따로 실험하고 성능을 비교한다. 연구 실험에서는 세계적으로 유명한 여행 사이트인 TripAdvisor의 홈페이지에서 뉴욕에 있는 호텔 평가 데이터를 수집하여 사용한다.&amp;#xD; &amp;#xD; 본 연구에서는 감성을 판단하는 딥러닝 모델을 구축하였다. 또한, 호텔 영역에 리뷰와 평점 불일치 문제 때문에 추천 시스템 연구에서 성능이 떨어지는 것을 해결하는 방법을 제시하였다. 따라서 추천 시스템 연구 중 정확하지 않은 리뷰와 평점을 피하는 데 도움이 된다. 본 연구는 직접 데이터를 수집 및 모델 구축하였기에 다른 호텔 평가에 활용할 수 있을 것으로 기대한다.&amp;#xD;"
        },
        {
          "rank": 3,
          "score": 0.7760672569274902,
          "doc_id": "DIKO0016385622",
          "title": "온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구",
          "abstract": "전자상거래의 발전에 따라 소비가 더욱 활발히 이루어지면서 고객의 수요에 맞추기 위해 새로운 제품들이 계속 출시되고 있으며, 이에 따라 전자상거래는 더욱 활성화되고 있다. 그러나 고객들은 대부분 새로운 제품 또는 자신이 구매하지 않았던 제품에 대한 구매 경험이 없기 때문에 구매 의사결정을 내리기 어려운 문제점이 존재한다. 따라서 전자상거래 사이트는 이러한 문제점을 해결하기 위해 온라인 리뷰를 남길 수 있는 시스템을 제공하고 있다. 고객이 자신의 경험을 바탕으로 작성한 온라인 리뷰에는 제품에 대한 다양한 정보가 포함되어 있고, 이러한 리뷰들은 고객의 구매 의사결정에 있어서 매우 중요한 참고 정보가 된다. 고객들은 기존 고객들이 남긴 온라인 리뷰를 참고하여 제품에 대한 불확실성을 낮출 수 있다. 그러나 리뷰 수가 많을수록 리뷰에 대한 정보 과부하 문제가 발생하며, 이로 인해 고객이 자신에게 도움이 되는 리뷰를 탐색하는데 어려움을 겪고 있다. 이러한 문제점을 극복하기 위해 전자상거래 사이트는 리뷰 유용성을 평가할 수 있는 투표 시스템을 도입하였다. 이를 바탕으로 고객들은 유용한 리뷰를 탐색할 수 있고, 이 정보는 고객들의 구매 의사결정에 기여할 수 있다. 이러한 투표 시스템은 고객으로부터 직접적인 피드백을 받을 수 있지만, 최근에 작성된 리뷰는 리뷰 유용성 투표 수를 누적하기에는 많은 시간을 필요로 하기에 고객에게 신속한 정보로 추천되기에는 어려운 한계점이 존재한다. 따라서 전자상거래 사이트들은 자동으로 리뷰에 대한 유용성을 예측할 수 있는 시스템을 도입할 필요가 있다. &amp;#xD; 리뷰 유용성 예측의 목표는 고객의 구매의사 결정에 도움이 되는 고품질 리뷰를 자동으로 식별하고 고객에게 추천하는 것이다. 기존 연구에서는 리뷰에 대한 유용성을 예측하기 위해, 주로 리뷰 텍스트와 평점 정보를 사용하여 리뷰 유용성에 영향을 미칠 수 있는 요소를 추출하고 이를 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구에서는 리뷰 텍스트와 평점 정보 간의 일관성을 고려하지 않았다. 따라서 리뷰 텍스트와 평점 정보는 동일한 고객이 자신의 경험을 바탕으로 작성한 정보이므로, 리뷰 텍스트와 평점 정보 간의 일관성을 고려할 필요가 있다. 리뷰 텍스트와 평점 정보가 일치하지 않으면 고객은 구매 의사결정 과정에 필요한 정보를 효과적으로 탐색할 수 없고, 오히려 리뷰에 대한 신뢰성과 유용성이 감소될 수 있다. 이에 따라 일부 연구에서는 리뷰 유용성에 대한 예측 성능을 향상시키기 위해 리뷰 텍스트와 평점 정보 간의 일관성을 고려하였다. 그러나 기존 연구는 다음과 같은 한계점이 존재한다. 첫째, 평점 정보가 손실되어 평점 정보의 표현 수용력이 제한적이다. 둘째, 리뷰 텍스트와 평점 정보 간의 상호작용이 제한적으로 학습된다. &amp;#xD; 따라서 본 연구에서는 기존 리뷰 유용성 예측에 관한 연구의 한계점을 극복하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-TRI 아키텍처를 제안하였다. 평점 정보에 대한 손실을 방지하기 위해 리뷰 텍스트와 평점 정보를 각각 고차원 특성 벡터로 변환하였다. 또한 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 추출하고 학습하기 위해, 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려하여 리뷰에 대한 유용성을 예측하였다. 그리고 리뷰 유용성을 예측할 때 특정 정보 혹은 특정 관계에 대한 편향을 방지하고 동등한 역할을 수행할 수 있도록 하기 위해, 실험 단계에서는 동일한 특성 차원으로 변환하였다. 이후 실험 단계에서는 CNN-TRI 모델의 예측 성능을 향상시키기 위해 미세조정 기법을 수행하고, 기존 연구에서 사용되었던 리뷰 유용성 예측 모델의 성능과 비교하였다. CNN-TRI 모델의 예측 성능을 측정하기 위해 아마존에서 도서 제품에 관한 8,898,041개의 리뷰를 수집하였다. 실험 결과, Accuracy 평가지표에서는 본 연구에서 제안된 CNN-TRI 모델의 예측 성능이 CNN 기반 모델보다 2.9~7.6% 더 높은 것으로 나타났고, F1-Score 평가지표에서는 4.0~7.4% 더 높은 것으로 확인되었다. 또한 전통적인 머신러닝 모델에 비해 예측 성능이 현저히 우수함을 확인할 수 있었다. 그리고 리뷰 텍스트와 평점 정보 간의 상호작용 측면에서 리뷰 유용성을 예측할 때 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려한 경우가 선형관계 또는 비선형관계 중 하나만 고려한 방법보다 예측 성능이 더 우수함을 확인하였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016385622&target=NART&cn=DIKO0016385622",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 온라인 리뷰 텍스트와 평점을 고려한 리뷰 유용성 예측을 위한 딥러닝 모델 설계에 관한 연구 전자상거래의 발전에 따라 소비가 더욱 활발히 이루어지면서 고객의 수요에 맞추기 위해 새로운 제품들이 계속 출시되고 있으며, 이에 따라 전자상거래는 더욱 활성화되고 있다. 그러나 고객들은 대부분 새로운 제품 또는 자신이 구매하지 않았던 제품에 대한 구매 경험이 없기 때문에 구매 의사결정을 내리기 어려운 문제점이 존재한다. 따라서 전자상거래 사이트는 이러한 문제점을 해결하기 위해 온라인 리뷰를 남길 수 있는 시스템을 제공하고 있다. 고객이 자신의 경험을 바탕으로 작성한 온라인 리뷰에는 제품에 대한 다양한 정보가 포함되어 있고, 이러한 리뷰들은 고객의 구매 의사결정에 있어서 매우 중요한 참고 정보가 된다. 고객들은 기존 고객들이 남긴 온라인 리뷰를 참고하여 제품에 대한 불확실성을 낮출 수 있다. 그러나 리뷰 수가 많을수록 리뷰에 대한 정보 과부하 문제가 발생하며, 이로 인해 고객이 자신에게 도움이 되는 리뷰를 탐색하는데 어려움을 겪고 있다. 이러한 문제점을 극복하기 위해 전자상거래 사이트는 리뷰 유용성을 평가할 수 있는 투표 시스템을 도입하였다. 이를 바탕으로 고객들은 유용한 리뷰를 탐색할 수 있고, 이 정보는 고객들의 구매 의사결정에 기여할 수 있다. 이러한 투표 시스템은 고객으로부터 직접적인 피드백을 받을 수 있지만, 최근에 작성된 리뷰는 리뷰 유용성 투표 수를 누적하기에는 많은 시간을 필요로 하기에 고객에게 신속한 정보로 추천되기에는 어려운 한계점이 존재한다. 따라서 전자상거래 사이트들은 자동으로 리뷰에 대한 유용성을 예측할 수 있는 시스템을 도입할 필요가 있다. &amp;#xD; 리뷰 유용성 예측의 목표는 고객의 구매의사 결정에 도움이 되는 고품질 리뷰를 자동으로 식별하고 고객에게 추천하는 것이다. 기존 연구에서는 리뷰에 대한 유용성을 예측하기 위해, 주로 리뷰 텍스트와 평점 정보를 사용하여 리뷰 유용성에 영향을 미칠 수 있는 요소를 추출하고 이를 바탕으로 리뷰 유용성을 예측하였다. 그러나 기존 연구에서는 리뷰 텍스트와 평점 정보 간의 일관성을 고려하지 않았다. 따라서 리뷰 텍스트와 평점 정보는 동일한 고객이 자신의 경험을 바탕으로 작성한 정보이므로, 리뷰 텍스트와 평점 정보 간의 일관성을 고려할 필요가 있다. 리뷰 텍스트와 평점 정보가 일치하지 않으면 고객은 구매 의사결정 과정에 필요한 정보를 효과적으로 탐색할 수 없고, 오히려 리뷰에 대한 신뢰성과 유용성이 감소될 수 있다. 이에 따라 일부 연구에서는 리뷰 유용성에 대한 예측 성능을 향상시키기 위해 리뷰 텍스트와 평점 정보 간의 일관성을 고려하였다. 그러나 기존 연구는 다음과 같은 한계점이 존재한다. 첫째, 평점 정보가 손실되어 평점 정보의 표현 수용력이 제한적이다. 둘째, 리뷰 텍스트와 평점 정보 간의 상호작용이 제한적으로 학습된다. &amp;#xD; 따라서 본 연구에서는 기존 리뷰 유용성 예측에 관한 연구의 한계점을 극복하기 위해 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 학습할 수 있는 CNN-TRI 아키텍처를 제안하였다. 평점 정보에 대한 손실을 방지하기 위해 리뷰 텍스트와 평점 정보를 각각 고차원 특성 벡터로 변환하였다. 또한 리뷰 텍스트와 평점 정보 간의 상호작용을 효과적으로 추출하고 학습하기 위해, 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려하여 리뷰에 대한 유용성을 예측하였다. 그리고 리뷰 유용성을 예측할 때 특정 정보 혹은 특정 관계에 대한 편향을 방지하고 동등한 역할을 수행할 수 있도록 하기 위해, 실험 단계에서는 동일한 특성 차원으로 변환하였다. 이후 실험 단계에서는 CNN-TRI 모델의 예측 성능을 향상시키기 위해 미세조정 기법을 수행하고, 기존 연구에서 사용되었던 리뷰 유용성 예측 모델의 성능과 비교하였다. CNN-TRI 모델의 예측 성능을 측정하기 위해 아마존에서 도서 제품에 관한 8,898,041개의 리뷰를 수집하였다. 실험 결과, Accuracy 평가지표에서는 본 연구에서 제안된 CNN-TRI 모델의 예측 성능이 CNN 기반 모델보다 2.9~7.6% 더 높은 것으로 나타났고, F1-Score 평가지표에서는 4.0~7.4% 더 높은 것으로 확인되었다. 또한 전통적인 머신러닝 모델에 비해 예측 성능이 현저히 우수함을 확인할 수 있었다. 그리고 리뷰 텍스트와 평점 정보 간의 상호작용 측면에서 리뷰 유용성을 예측할 때 리뷰 텍스트와 평점 정보 간의 선형관계와 비선형관계를 모두 고려한 경우가 선형관계 또는 비선형관계 중 하나만 고려한 방법보다 예측 성능이 더 우수함을 확인하였다.&amp;#xD;"
        },
        {
          "rank": 4,
          "score": 0.7646198272705078,
          "doc_id": "JAKO202113157683309",
          "title": "온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구",
          "abstract": "세계적인 전자상거래 기업들은 지속 가능한 경쟁력을 확보하기 위해 사용자 맞춤형 추천 서비스를 제공하고 있다. 기존 관련 연구에서는 주로 평점, 구매 여부 등 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하였다. 하지만 이와 같은 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하면 추천 성능이 저하될 수 있다는 문제점이 제기되고 있다. 호텔을 이용한 사용자가 호텔 서비스, 청결 상태 등에 대하여 만족하지 못한다고 리뷰를 작성하였으나 선호도 평점 5점을 부여했을 때 정량적 선호도(평점)와 정성적 선호도(리뷰)가 불일치한 문제가 발생할 수 있다. 따라서 본 연구에서는 정량적 선호도 정보와 정성적 선호도 정보가 일치하는지를 확인하고 이를 바탕으로 선호도 정보가 일치하는 사용자를 바탕으로 새로운 프로파일을 구축하여 개인화 추천 서비스를 제공하고자 한다. 리뷰에서 정성적 선호도를 추출하기 위해 자연어 처리 관련 연구에서 널리 사용되고 있는 CNN, LSTM, CNN + LSTM 등 딥러닝 기법을 사용하여 감성분석 모델을 구축하였다. 이를 통해 사용자가 작성한 리뷰에서 정성적 선호도 정보를 정교하게 추출하여 정량적 선호도 정보와 비교하였다. 본 연구에서 제안한 추천 방법론의 성능을 평가하기 위해 세계 최대 여행 플랫폼 TripAdvisor에서 실제 호텔을 이용한 사용자 선호도 정보를 수집하여 사용하였다. 실험 결과 본 연구에서 제안한 추천 방법론이 기존의 정량적 선호도만을 고려하는 추천 방법론보다 우수한 추천 성능을 나타냄을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202113157683309&target=NART&cn=JAKO202113157683309",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 온라인 호텔 리뷰와 평점 불일치 문제 해결을 위한 딥러닝 기반 개인화 추천 서비스 연구 세계적인 전자상거래 기업들은 지속 가능한 경쟁력을 확보하기 위해 사용자 맞춤형 추천 서비스를 제공하고 있다. 기존 관련 연구에서는 주로 평점, 구매 여부 등 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하였다. 하지만 이와 같은 정량적 선호도 정보를 사용하여 개인화 추천 서비스를 제공하면 추천 성능이 저하될 수 있다는 문제점이 제기되고 있다. 호텔을 이용한 사용자가 호텔 서비스, 청결 상태 등에 대하여 만족하지 못한다고 리뷰를 작성하였으나 선호도 평점 5점을 부여했을 때 정량적 선호도(평점)와 정성적 선호도(리뷰)가 불일치한 문제가 발생할 수 있다. 따라서 본 연구에서는 정량적 선호도 정보와 정성적 선호도 정보가 일치하는지를 확인하고 이를 바탕으로 선호도 정보가 일치하는 사용자를 바탕으로 새로운 프로파일을 구축하여 개인화 추천 서비스를 제공하고자 한다. 리뷰에서 정성적 선호도를 추출하기 위해 자연어 처리 관련 연구에서 널리 사용되고 있는 CNN, LSTM, CNN + LSTM 등 딥러닝 기법을 사용하여 감성분석 모델을 구축하였다. 이를 통해 사용자가 작성한 리뷰에서 정성적 선호도 정보를 정교하게 추출하여 정량적 선호도 정보와 비교하였다. 본 연구에서 제안한 추천 방법론의 성능을 평가하기 위해 세계 최대 여행 플랫폼 TripAdvisor에서 실제 호텔을 이용한 사용자 선호도 정보를 수집하여 사용하였다. 실험 결과 본 연구에서 제안한 추천 방법론이 기존의 정량적 선호도만을 고려하는 추천 방법론보다 우수한 추천 성능을 나타냄을 확인할 수 있었다."
        },
        {
          "rank": 5,
          "score": 0.7502074241638184,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 6,
          "score": 0.7446533441543579,
          "doc_id": "DIKO0017011976",
          "title": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형",
          "abstract": "본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017011976&target=NART&cn=DIKO0017011976",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다."
        },
        {
          "rank": 7,
          "score": 0.7365444302558899,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 8,
          "score": 0.7307847142219543,
          "doc_id": "DIKO0012113511",
          "title": "인공신경망을 이용한 판매처 평가 프레임워크",
          "abstract": "인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012113511&target=NART&cn=DIKO0012113511",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다."
        },
        {
          "rank": 9,
          "score": 0.7307226657867432,
          "doc_id": "NART131019507",
          "title": "Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach",
          "abstract": "<P><B>Abstract</B><P>Rating prediction is a crucial element of business analytics as it enables decision-makers to assess service performance based on expressive customer feedback. Enhancing rating score predictions and demand forecasting through incorporating performance features from verbatim text fields, particularly in service quality measurement and customer satisfaction modelling is a key objective in various areas of analytics. A range of methods has been identified in the literature for improving the predictability of customer feedback, including simple bag-of-words-based approaches and advanced supervised machine learning models, which are designed to work with response variables such as Likert-based rating scores. This paper presents a dynamic model that incorporates values from topic membership, an outcome variable from Latent Dirichlet Allocation, with sentiment analysis in an Extreme Gradient Boosting (XGBoost) model used for rating prediction. The results show that, by incorporating features from simple unsupervised machine learning approaches (LDA-based), an 86% prediction accuracy (AUC based) can be achieved on objective rating values. At the same time, a combination of polarity and single-topic membership can yield an even higher accuracy when compared with sentiment text detection tasks both at the document and sentence levels. This study carries significant practical implications since sentiment analysis tasks often require dictionary coverage and domain-specific adjustments depending on the task at hand. To further investigate this result, we used Shapley Additive Values to determine the additive predictability of topic membership values in combination with sentiment-based methods using a dataset of customer reviews from food delivery services.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131019507&target=NART&cn=NART131019507",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach Incorporating topic membership in review rating prediction from unstructured data: a gradient boosting approach <P><B>Abstract</B><P>Rating prediction is a crucial element of business analytics as it enables decision-makers to assess service performance based on expressive customer feedback. Enhancing rating score predictions and demand forecasting through incorporating performance features from verbatim text fields, particularly in service quality measurement and customer satisfaction modelling is a key objective in various areas of analytics. A range of methods has been identified in the literature for improving the predictability of customer feedback, including simple bag-of-words-based approaches and advanced supervised machine learning models, which are designed to work with response variables such as Likert-based rating scores. This paper presents a dynamic model that incorporates values from topic membership, an outcome variable from Latent Dirichlet Allocation, with sentiment analysis in an Extreme Gradient Boosting (XGBoost) model used for rating prediction. The results show that, by incorporating features from simple unsupervised machine learning approaches (LDA-based), an 86% prediction accuracy (AUC based) can be achieved on objective rating values. At the same time, a combination of polarity and single-topic membership can yield an even higher accuracy when compared with sentiment text detection tasks both at the document and sentence levels. This study carries significant practical implications since sentiment analysis tasks often require dictionary coverage and domain-specific adjustments depending on the task at hand. To further investigate this result, we used Shapley Additive Values to determine the additive predictability of topic membership values in combination with sentiment-based methods using a dataset of customer reviews from food delivery services.</P></P>"
        },
        {
          "rank": 10,
          "score": 0.7263684272766113,
          "doc_id": "NPAP13226818",
          "title": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset",
          "abstract": "<P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13226818&target=NART&cn=NPAP13226818",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset <P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>"
        },
        {
          "rank": 11,
          "score": 0.7214395999908447,
          "doc_id": "NPAP12734426",
          "title": "Deep sequential model for review rating prediction",
          "abstract": "<P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12734426&target=NART&cn=NPAP12734426",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep sequential model for review rating prediction Deep sequential model for review rating prediction Deep sequential model for review rating prediction <P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>"
        },
        {
          "rank": 12,
          "score": 0.7204288840293884,
          "doc_id": "JAKO202302557624224",
          "title": "평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로",
          "abstract": "코로나19 팬데믹 이후 관광 산업이 회복되면서 많은 관광객들이 다양한 플랫폼을 활용하고 리뷰를 남기고 있지만, 대량의 데이터 속에서 유용한 정보를 찾기 어려워 아직도 여행지 선정 과정에서 많은 시간과 비용이 낭비되고 있다. 이에 따라 많은 연구들이 진행되고 있지만, 평점이 없거나 플랫폼별로 다른 형태의 평점 제공으로 인해 연구에 한계를 가지고 있으며, 평점과 리뷰 내용이 일치하지 않는 경우도 있어 추천 모델 구축에 어려움을 주고 있다. 본 연구에서는 이러한 문제를 해결하기 위해 7,104개의 제주도 지역 관광지 리뷰를 활용하여 제주도에 특화된 관광지 만족도 정량 지수를 개발하고 이를 활용하여 '평점 예측 모델'을 구축하였다. 모델의 성능을 확인하기 위해 실험 데이터 700건의 평점을 본 연구에서 개발된 모델과 LSTM을 활용하여 예측 하였으며, 제안된 모델이 LSTM 보다 약 4.67% 높은 73.87%의 가중 정확도로 성능이 더 우수한 것을 확인하였다. 본 연구의 결과를 통해 평점과 리뷰 내용 사이의 불일치 문제를 해결하고, 평점이 없는 리뷰나 다양한 형태의 평점을 정형할 수 있으며, 다른 도메인에 적용하여 여행의 모든 분야에서 신뢰할 수 있는 평점 지표를 제공할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202302557624224&target=NART&cn=JAKO202302557624224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 평점 예측 모델 개발을 위한 관광지 만족도 정량 지수 구축: 제주도 관광지 리뷰를 중심으로 코로나19 팬데믹 이후 관광 산업이 회복되면서 많은 관광객들이 다양한 플랫폼을 활용하고 리뷰를 남기고 있지만, 대량의 데이터 속에서 유용한 정보를 찾기 어려워 아직도 여행지 선정 과정에서 많은 시간과 비용이 낭비되고 있다. 이에 따라 많은 연구들이 진행되고 있지만, 평점이 없거나 플랫폼별로 다른 형태의 평점 제공으로 인해 연구에 한계를 가지고 있으며, 평점과 리뷰 내용이 일치하지 않는 경우도 있어 추천 모델 구축에 어려움을 주고 있다. 본 연구에서는 이러한 문제를 해결하기 위해 7,104개의 제주도 지역 관광지 리뷰를 활용하여 제주도에 특화된 관광지 만족도 정량 지수를 개발하고 이를 활용하여 '평점 예측 모델'을 구축하였다. 모델의 성능을 확인하기 위해 실험 데이터 700건의 평점을 본 연구에서 개발된 모델과 LSTM을 활용하여 예측 하였으며, 제안된 모델이 LSTM 보다 약 4.67% 높은 73.87%의 가중 정확도로 성능이 더 우수한 것을 확인하였다. 본 연구의 결과를 통해 평점과 리뷰 내용 사이의 불일치 문제를 해결하고, 평점이 없는 리뷰나 다양한 형태의 평점을 정형할 수 있으며, 다른 도메인에 적용하여 여행의 모든 분야에서 신뢰할 수 있는 평점 지표를 제공할 수 있을 것으로 기대된다."
        },
        {
          "rank": 13,
          "score": 0.7197697162628174,
          "doc_id": "NART118609293",
          "title": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction",
          "abstract": "<P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118609293&target=NART&cn=NART118609293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction <P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>"
        },
        {
          "rank": 14,
          "score": 0.713058590888977,
          "doc_id": "JAKO202523439606404",
          "title": "사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증",
          "abstract": "온라인 환경에서 상품과 콘텐츠의 선택지가 폭발적으로 늘어나면서, 사용자가 원하는 정보를 제시하고, 구매로 이어질 수 있는 추천 시스템의 중요성이 커지고 있다. 기존에는 협업 필터링이 가장 많이 사용되는 추천 기법이었으나, 평점 정보만으로는 추천의 정확도가 한계에 부딪히는 문제가 있었다. 본 논문에서는 추천의 정확성을 높이기 위해, 영화 평점 데이터와 더불어 리뷰 텍스트에서 추출한 감성 점수를 결합한 하이브리드 추천 시스템을 제안한다. 콘텐츠 기반 필터링(CBF)은 영화의 장르와 태그 정보를 TF-IDF 벡터로 변환해 사용자 프로필과 영화 간의 유사도를 계산하는 방식으로 활용하였고, 아이템 기반 협업 필터링(IBCF)은 평점 행렬을 바탕으로 유사 아이템의 평점과 감성 점수를 가중 결합해 예측 값을 산출하였다. 실험 결과, 제안한 하이브리드 모델이 단일 모델이나 감성분석을 제외한 모델보다 추천 정확성 면에서 가장 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202523439606404&target=NART&cn=JAKO202523439606404",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 사용자 리뷰 감성분석 기반 하이브리드 영화 추천 시스템의 이론적 기반 및 실증적 검증 온라인 환경에서 상품과 콘텐츠의 선택지가 폭발적으로 늘어나면서, 사용자가 원하는 정보를 제시하고, 구매로 이어질 수 있는 추천 시스템의 중요성이 커지고 있다. 기존에는 협업 필터링이 가장 많이 사용되는 추천 기법이었으나, 평점 정보만으로는 추천의 정확도가 한계에 부딪히는 문제가 있었다. 본 논문에서는 추천의 정확성을 높이기 위해, 영화 평점 데이터와 더불어 리뷰 텍스트에서 추출한 감성 점수를 결합한 하이브리드 추천 시스템을 제안한다. 콘텐츠 기반 필터링(CBF)은 영화의 장르와 태그 정보를 TF-IDF 벡터로 변환해 사용자 프로필과 영화 간의 유사도를 계산하는 방식으로 활용하였고, 아이템 기반 협업 필터링(IBCF)은 평점 행렬을 바탕으로 유사 아이템의 평점과 감성 점수를 가중 결합해 예측 값을 산출하였다. 실험 결과, 제안한 하이브리드 모델이 단일 모델이나 감성분석을 제외한 모델보다 추천 정확성 면에서 가장 우수한 성능을 보였다."
        },
        {
          "rank": 15,
          "score": 0.7069556713104248,
          "doc_id": "DIKO0017198883",
          "title": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating",
          "abstract": "전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017198883&target=NART&cn=DIKO0017198883",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating 전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다."
        },
        {
          "rank": 16,
          "score": 0.7058043479919434,
          "doc_id": "JAKO202128837904086",
          "title": "평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화",
          "abstract": "팬데믹(Pandemic)으로 인해 온라인 시장의 규모가 급속하게 커졌다. 일상에서의 비대면화는그동안 기술수용에 늦은 소비자마저 온라인구매의 편리함을 경험하게 하는 계기가 되었고, 이들은 팬데믹 이후에도 온라인구매의 이점을 선호하게 될 것이다. 하지만 이러한 변화의 시기에 소비자가 취할 수 있는 제품 정보는 편평한 디스플레이상의 시각적 정보만으로 축소되었다. 회사들은 차별적이고 경쟁력 있는 정보를 제공하기 위해 AR/VR, Streaming 기술 등을 도입하고 있지만, 정직한 사용자들이 남긴 리뷰는 회사가 제공하는 잘 가공된 정보만큼 소비자에게 강력하게 인식되고, 회사의 상품개발과 마케팅 및 판매 전략을 위한 인사이트를 얻을 수 있다는 점에서 중요하게 인식될 필요가 있다. 그렇다면 소비자의 입장에서, 구매 의사결정 전에 참고하는 리뷰의 평점이 크게 어긋난다면, 소비자들은 어떻게 리뷰정보를 처리할까? 수렴되지 않은 평점은 늘 신뢰할 수 없고 가치 없는 것일까? 본 연구에서는 소비자의 개인 성향으로 볼 수 있는 조절초점 성향이 어떻게 사고방식을 지배하여 수렴되지 않은 정보를 수용하고 처리하는지 보이고자 하였다. 실험은 화장품을 대상으로 제품 리뷰 평점의 분산(높음 vs 낮음)이 소비자의 조절초점(예방초점 vs. 향상초점)에 따라 제품 태도에 어떤 영향을 미치는지 2x2 연구로 설계하였다. 연구결과, 예방초점의 소비자는 분산이 작을 때 높은 제품 태도를 보이지만, 향상초점의 소비자는 분산이 클 때 높은 제품 태도를 보인다는 것을 발견하였다. 이와 같은 연구로, 본 논문은 동일한 평균값의 평가점수를 가진 제품이라도 후기의 분산 값에 따라 소비자의 조절초점 성향이 영향을 미쳐 제품 태도가 달라진다는 것을 설명할 수 있다. 본 논문은 평점이 수렴되지 않는 정보에 대한 소비자의 정보처리의 메커니즘을 밝힌 이론적 공헌이 있으며, 실무적으로 기업은 리뷰가 축적됨에 따라 개인화되고 최적화된 상품 정보를 제공하는 등 빅데이터를 바탕으로 지식경영을 응용한 고객경험설계가 가능함을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837904086&target=NART&cn=JAKO202128837904086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 평점이 수렴되지 않는 리뷰의 제품들이 더 좋을 수도 있을까?: 제품 리뷰평점의 분산과 소비자의 조절초점 성향에 따른 소비자 태도 변화 팬데믹(Pandemic)으로 인해 온라인 시장의 규모가 급속하게 커졌다. 일상에서의 비대면화는그동안 기술수용에 늦은 소비자마저 온라인구매의 편리함을 경험하게 하는 계기가 되었고, 이들은 팬데믹 이후에도 온라인구매의 이점을 선호하게 될 것이다. 하지만 이러한 변화의 시기에 소비자가 취할 수 있는 제품 정보는 편평한 디스플레이상의 시각적 정보만으로 축소되었다. 회사들은 차별적이고 경쟁력 있는 정보를 제공하기 위해 AR/VR, Streaming 기술 등을 도입하고 있지만, 정직한 사용자들이 남긴 리뷰는 회사가 제공하는 잘 가공된 정보만큼 소비자에게 강력하게 인식되고, 회사의 상품개발과 마케팅 및 판매 전략을 위한 인사이트를 얻을 수 있다는 점에서 중요하게 인식될 필요가 있다. 그렇다면 소비자의 입장에서, 구매 의사결정 전에 참고하는 리뷰의 평점이 크게 어긋난다면, 소비자들은 어떻게 리뷰정보를 처리할까? 수렴되지 않은 평점은 늘 신뢰할 수 없고 가치 없는 것일까? 본 연구에서는 소비자의 개인 성향으로 볼 수 있는 조절초점 성향이 어떻게 사고방식을 지배하여 수렴되지 않은 정보를 수용하고 처리하는지 보이고자 하였다. 실험은 화장품을 대상으로 제품 리뷰 평점의 분산(높음 vs 낮음)이 소비자의 조절초점(예방초점 vs. 향상초점)에 따라 제품 태도에 어떤 영향을 미치는지 2x2 연구로 설계하였다. 연구결과, 예방초점의 소비자는 분산이 작을 때 높은 제품 태도를 보이지만, 향상초점의 소비자는 분산이 클 때 높은 제품 태도를 보인다는 것을 발견하였다. 이와 같은 연구로, 본 논문은 동일한 평균값의 평가점수를 가진 제품이라도 후기의 분산 값에 따라 소비자의 조절초점 성향이 영향을 미쳐 제품 태도가 달라진다는 것을 설명할 수 있다. 본 논문은 평점이 수렴되지 않는 정보에 대한 소비자의 정보처리의 메커니즘을 밝힌 이론적 공헌이 있으며, 실무적으로 기업은 리뷰가 축적됨에 따라 개인화되고 최적화된 상품 정보를 제공하는 등 빅데이터를 바탕으로 지식경영을 응용한 고객경험설계가 가능함을 시사한다."
        },
        {
          "rank": 17,
          "score": 0.7024353742599487,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 18,
          "score": 0.7013897895812988,
          "doc_id": "JAKO201722163438451",
          "title": "딥러닝과 통계 모델을 이용한 T-커머스 매출 예측",
          "abstract": "T-커머스는 양방향 디지털 TV를 기반으로 양방향 데이터방송 기술을 활용하여 상거래를 하는 기술융합형 서비스이다. 채널 번호와 판매상품이 제한된 환경에서 T-커머스의 매출을 극대화 하기 위해서는 각 제품의 시간대별 경쟁력을 고려하여 매출이 최대화 되도록 프로그램을 편성해야 한다. 이를 위해, 본 논문에서는 딥러닝을 이용해 T-커머스에서 각 상품을 각 시간대에 편성하였을 때의 매출을 예측하는 방법을 제안한다. 제안하는 방법은 심층신경망을 이용해 판매 상품과 시간대, 주차, 휴일 여부, 그리고 날씨를 입력 받아 실제 방송으로 편성했을 때 기대되는 매출을 예측한다. 그리고, 통계적 모델과 SVD(Singular Value Decomposition)를 적용하여 판매 데이터의 편중 및 희박성 문제를 완화한다. 실제 T-커머스 운영자인 (주)더블유쇼핑의 판매 기록 데이터에 대하여 실험하였을 때 실제 매출과 예측치의 차이가 0.12의 NMAE(Normalized Mean Absolute Error)를 보여 제안하는 알고리즘이 효과적으로 동작함을 확인하였다. 제안된 시스템은 (주)더블유쇼핑의 T-커머스 시스템 적용되어 방송 편성에 활용되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201722163438451&target=NART&cn=JAKO201722163438451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 딥러닝과 통계 모델을 이용한 T-커머스 매출 예측 T-커머스는 양방향 디지털 TV를 기반으로 양방향 데이터방송 기술을 활용하여 상거래를 하는 기술융합형 서비스이다. 채널 번호와 판매상품이 제한된 환경에서 T-커머스의 매출을 극대화 하기 위해서는 각 제품의 시간대별 경쟁력을 고려하여 매출이 최대화 되도록 프로그램을 편성해야 한다. 이를 위해, 본 논문에서는 딥러닝을 이용해 T-커머스에서 각 상품을 각 시간대에 편성하였을 때의 매출을 예측하는 방법을 제안한다. 제안하는 방법은 심층신경망을 이용해 판매 상품과 시간대, 주차, 휴일 여부, 그리고 날씨를 입력 받아 실제 방송으로 편성했을 때 기대되는 매출을 예측한다. 그리고, 통계적 모델과 SVD(Singular Value Decomposition)를 적용하여 판매 데이터의 편중 및 희박성 문제를 완화한다. 실제 T-커머스 운영자인 (주)더블유쇼핑의 판매 기록 데이터에 대하여 실험하였을 때 실제 매출과 예측치의 차이가 0.12의 NMAE(Normalized Mean Absolute Error)를 보여 제안하는 알고리즘이 효과적으로 동작함을 확인하였다. 제안된 시스템은 (주)더블유쇼핑의 T-커머스 시스템 적용되어 방송 편성에 활용되었다."
        },
        {
          "rank": 19,
          "score": 0.6963728666305542,
          "doc_id": "ART003001921",
          "title": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning",
          "abstract": "Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003001921&target=NART&cn=ART003001921",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision."
        },
        {
          "rank": 20,
          "score": 0.6948215961456299,
          "doc_id": "JAKO201726163356540",
          "title": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델",
          "abstract": "본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163356540&target=NART&cn=JAKO201726163356540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다."
        },
        {
          "rank": 21,
          "score": 0.6926363706588745,
          "doc_id": "NART135912853",
          "title": "A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction",
          "abstract": "<P>Churn prediction has become one of the core concepts in customer relationship management within the insurances, telecom, and internet service provider industries, which is essential in customer retention. Therefore, this study attempts to analyze the effectiveness of the advanced machine learning and deep learning models for churn prediction in the evaluation of the models&rsquo; performance across different sectors. This would help conclude whether the varied patterns of the churn throughout different sectors to the level that affects the model performance and to what extent. The work includes three datasets: namely, insurance churn, internet service provider customer churn, and Telecom churn datasets. The implementation and comparison conducted in this study of models include XGBoost, Convolutional Neural Networks (CNNs), and Ensemble Deep Learning with the pre-trained hybrid approach. The results show that the ensemble deep learning model outperforms other models in terms of accuracy and F1-score, achieving accuracies of up to 95.96% in the insurance churn dataset and of 98.42% in the telecom churn dataset. Moreover, traditional machine learning models like XGBoost also produced competitive results for selected datasets. The proposed deep learning ensembles reveal the strength and possibility for churn prediction and provide a benchmark for future research relevant to customer retention strategies. Also, the proposed ensemble deep learning model shows stable performance across different sectors, which reflects its ability to capture the varied churn patterns of different sectors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135912853&target=NART&cn=NART135912853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction A Comprehensive Evaluation of Machine Learning and Deep Learning Models for Churn Prediction <P>Churn prediction has become one of the core concepts in customer relationship management within the insurances, telecom, and internet service provider industries, which is essential in customer retention. Therefore, this study attempts to analyze the effectiveness of the advanced machine learning and deep learning models for churn prediction in the evaluation of the models&rsquo; performance across different sectors. This would help conclude whether the varied patterns of the churn throughout different sectors to the level that affects the model performance and to what extent. The work includes three datasets: namely, insurance churn, internet service provider customer churn, and Telecom churn datasets. The implementation and comparison conducted in this study of models include XGBoost, Convolutional Neural Networks (CNNs), and Ensemble Deep Learning with the pre-trained hybrid approach. The results show that the ensemble deep learning model outperforms other models in terms of accuracy and F1-score, achieving accuracies of up to 95.96% in the insurance churn dataset and of 98.42% in the telecom churn dataset. Moreover, traditional machine learning models like XGBoost also produced competitive results for selected datasets. The proposed deep learning ensembles reveal the strength and possibility for churn prediction and provide a benchmark for future research relevant to customer retention strategies. Also, the proposed ensemble deep learning model shows stable performance across different sectors, which reflects its ability to capture the varied churn patterns of different sectors.</P>"
        },
        {
          "rank": 22,
          "score": 0.689683198928833,
          "doc_id": "JAKO201403359939237",
          "title": "개선된 배깅 앙상블을 활용한 기업부도예측",
          "abstract": "기업의 부도 예측은 재무 및 회계 분야에서 매우 중요한 연구 주제이다. 기업의 부도로 인해 발생하는 비용이 매우 크기 때문에 부도 예측의 정확성은 금융기관으로서는 매우 중요한 일이다. 최근에는 여러 개의 모형을 결합하는 앙상블 모형을 부도 예측에 적용해 보려는 연구가 큰 관심을 끌고 있다. 앙상블 모형은 개별 모형보다 더 좋은 성과를 내기 위해 여러 개의 분류기를 결합하는 것이다. 이와 같은 앙상블 분류기는 분류기의 일반화 성능을 개선하는 데 매우 유용한 것으로 알려져 있다. 본 논문은 부도 예측 모형의 성과 개선에 관한 연구이다. 이를 위해 사례 선택(Instance Selection)을 활용한 배깅(Bagging) 모형을 제안하였다. 사례 선택은 원 데이터에서 가장 대표성 있고 관련성 높은 데이터를 선택하고 예측 모형에 악영향을 줄 수 있는 불필요한 데이터를 제거하는 것으로 이를 통해 예측 성과 개선도 기대할 수 있다. 배깅은 학습데이터에 변화를 줌으로써 기저 분류기들을 다양화시키는 앙상블 기법으로 단순하면서도 성과가 매우 좋은 것으로 알려져 있다. 사례 선택과 배깅은 각각 모형의 성과를 개선시킬 수 있는 잠재력이 있지만 이들 두 기법의 결합에 관한 연구는 아직까지 없는 것이 현실이다. 본 연구에서는 부도 예측 모형의 성과를 개선하기 위해 사례 선택과 배깅을 연결하는 새로운 모형을 제안하였다. 최적의 사례 선택을 위해 유전자 알고리즘이 사용되었으며, 이를 통해 최적의 사례 선택 조합을 찾고 이 결과를 배깅 앙상블 모형에 전달하여 새로운 형태의 배깅 앙상블 모형을 구성하게 된다. 본 연구에서 제안한 새로운 앙상블 모형의 성과를 검증하기 위해 ROC 커브, AUC, 예측정확도 등과 같은 성과지표를 사용해 다양한 모형과 비교 분석해 보았다. 실제 기업데이터를 사용해 실험한 결과 본 논문에서 제안한 새로운 형태의 모형이 가장 좋은 성과를 보임을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201403359939237&target=NART&cn=JAKO201403359939237",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "개선된 배깅 앙상블을 활용한 기업부도예측 개선된 배깅 앙상블을 활용한 기업부도예측 개선된 배깅 앙상블을 활용한 기업부도예측 기업의 부도 예측은 재무 및 회계 분야에서 매우 중요한 연구 주제이다. 기업의 부도로 인해 발생하는 비용이 매우 크기 때문에 부도 예측의 정확성은 금융기관으로서는 매우 중요한 일이다. 최근에는 여러 개의 모형을 결합하는 앙상블 모형을 부도 예측에 적용해 보려는 연구가 큰 관심을 끌고 있다. 앙상블 모형은 개별 모형보다 더 좋은 성과를 내기 위해 여러 개의 분류기를 결합하는 것이다. 이와 같은 앙상블 분류기는 분류기의 일반화 성능을 개선하는 데 매우 유용한 것으로 알려져 있다. 본 논문은 부도 예측 모형의 성과 개선에 관한 연구이다. 이를 위해 사례 선택(Instance Selection)을 활용한 배깅(Bagging) 모형을 제안하였다. 사례 선택은 원 데이터에서 가장 대표성 있고 관련성 높은 데이터를 선택하고 예측 모형에 악영향을 줄 수 있는 불필요한 데이터를 제거하는 것으로 이를 통해 예측 성과 개선도 기대할 수 있다. 배깅은 학습데이터에 변화를 줌으로써 기저 분류기들을 다양화시키는 앙상블 기법으로 단순하면서도 성과가 매우 좋은 것으로 알려져 있다. 사례 선택과 배깅은 각각 모형의 성과를 개선시킬 수 있는 잠재력이 있지만 이들 두 기법의 결합에 관한 연구는 아직까지 없는 것이 현실이다. 본 연구에서는 부도 예측 모형의 성과를 개선하기 위해 사례 선택과 배깅을 연결하는 새로운 모형을 제안하였다. 최적의 사례 선택을 위해 유전자 알고리즘이 사용되었으며, 이를 통해 최적의 사례 선택 조합을 찾고 이 결과를 배깅 앙상블 모형에 전달하여 새로운 형태의 배깅 앙상블 모형을 구성하게 된다. 본 연구에서 제안한 새로운 앙상블 모형의 성과를 검증하기 위해 ROC 커브, AUC, 예측정확도 등과 같은 성과지표를 사용해 다양한 모형과 비교 분석해 보았다. 실제 기업데이터를 사용해 실험한 결과 본 논문에서 제안한 새로운 형태의 모형이 가장 좋은 성과를 보임을 알 수 있었다."
        },
        {
          "rank": 23,
          "score": 0.6891798973083496,
          "doc_id": "JAKO202325543363508",
          "title": "딥러닝 영상분석 시스템의 성능평가 산정식 개발",
          "abstract": "도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202325543363508&target=NART&cn=JAKO202325543363508",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다."
        },
        {
          "rank": 24,
          "score": 0.6887930631637573,
          "doc_id": "JAKO202305062334676",
          "title": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측",
          "abstract": "본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202305062334676&target=NART&cn=JAKO202305062334676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다."
        },
        {
          "rank": 25,
          "score": 0.6887767314910889,
          "doc_id": "ATN0031726879",
          "title": "딥러닝 기반 부실기업 예측모형에 관한 연구",
          "abstract": "Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0031726879&target=NART&cn=ATN0031726879",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 부실기업 예측모형에 관한 연구 딥러닝 기반 부실기업 예측모형에 관한 연구 딥러닝 기반 부실기업 예측모형에 관한 연구 Predicting insolvent companies is a research topic that has been important in accounting and finance. Especially, due to the rapidly changing business environments and the recent COVID-19 pandemic, many domestic companies are facing financial adversity. Thus, the necessity of research on corporate insolvency is being emphasized. As a related research, there is a prediction of corporate bankruptcy, however, a bankrupt company is the company whose business activities have been suspended, and there is a limitation in which it is inappropriate to determine which companies show signs of bankruptcy among continuing companies. Therefore, marginal company, one of the categories of insolvent companies, is selected as the prediction target. Marginal companies are the firms that are operating income interest compensation ratio are less than 1 for three consecutive years, and are engaged in business activities but have not consistently secured adequate profits. In this study, deep learning techniques are used to predict them. It is one of the machine learning techniques that has recently attracted attention because of its excellence in various fields. Nonetheless, has not been applied in research to predict marginal companies. This study applies RNN and CNN among deep learning techniques using several financial ratios as independent variables. Their performance are compared with machine learning ensemble models that have been reported to have excellent predictive power in previous studies. As a result of analysis on corporate data from 2017 to 2019 as training and test data, deep learning models such as RNN-LSTM, RNN-GRU, and CNN are better in forecasting of marginal companies than the ensemble models in terms of Recall score. Therefore, the deep learning models are expected to become widely used in the prediction of marginal companies in the future."
        },
        {
          "rank": 26,
          "score": 0.6861945986747742,
          "doc_id": "JAKO202314857616824",
          "title": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석",
          "abstract": "클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202314857616824&target=NART&cn=JAKO202314857616824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다."
        },
        {
          "rank": 27,
          "score": 0.6860648393630981,
          "doc_id": "JAKO201912758458868",
          "title": "딥러닝 개념을 위한 인공지능 교육 프로그램",
          "abstract": "본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201912758458868&target=NART&cn=JAKO201912758458868",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다."
        },
        {
          "rank": 28,
          "score": 0.6854095458984375,
          "doc_id": "ATN0037496660",
          "title": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교",
          "abstract": "Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037496660&target=NART&cn=ATN0037496660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model."
        },
        {
          "rank": 29,
          "score": 0.6852282285690308,
          "doc_id": "JAKO201620853199880",
          "title": "딥러닝의 모형과 응용사례",
          "abstract": "딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201620853199880&target=NART&cn=JAKO201620853199880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다."
        },
        {
          "rank": 30,
          "score": 0.685042142868042,
          "doc_id": "JAKO202404861562091",
          "title": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교",
          "abstract": "대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202404861562091&target=NART&cn=JAKO202404861562091",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다."
        },
        {
          "rank": 31,
          "score": 0.6812037229537964,
          "doc_id": "JAKO201909358629867",
          "title": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석",
          "abstract": "인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629867&target=NART&cn=JAKO201909358629867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다."
        },
        {
          "rank": 32,
          "score": 0.679355263710022,
          "doc_id": "JAKO202109651162667",
          "title": "신경망기법을 활용한 선박 가치평가 모델 개발",
          "abstract": "본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109651162667&target=NART&cn=JAKO202109651162667",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다."
        },
        {
          "rank": 33,
          "score": 0.6782382726669312,
          "doc_id": "NART130707218",
          "title": "Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction",
          "abstract": "<P>Sentiment analysis is the most basic and imperative work in mining the preference of user interest. In this work, a deep model with optimization, named &ldquo;Chimp Whale Optimization Algorithm-based Random Multimodal Deep Learning&rdquo; is devised for sentiment rating prediction. The process of tokenization, which divides the entire document into small units using Bidirectional Encoder Representations from Transformers (BERT) for better processing, is where the input review data is initially given. Aspects from review data and aspect term extraction are completed for mining. Additionally, Random Multimodal Deep Learning is used to forecast the sentiment rating. The ChWOA is used in this case to combine the Chimp Optimization Algorithm (ChOA) and the Whale Optimization Algorithm (WOA). With a precision of 93.1%, recall of 94.4%, and F-measure of 93.8%, the ChWOA-based RMDL demonstrated better efficiency.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART130707218&target=NART&cn=NART130707218",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction Hybrid optimization enabled Random multimodal deep learning for sentiment rating prediction <P>Sentiment analysis is the most basic and imperative work in mining the preference of user interest. In this work, a deep model with optimization, named &ldquo;Chimp Whale Optimization Algorithm-based Random Multimodal Deep Learning&rdquo; is devised for sentiment rating prediction. The process of tokenization, which divides the entire document into small units using Bidirectional Encoder Representations from Transformers (BERT) for better processing, is where the input review data is initially given. Aspects from review data and aspect term extraction are completed for mining. Additionally, Random Multimodal Deep Learning is used to forecast the sentiment rating. The ChWOA is used in this case to combine the Chimp Optimization Algorithm (ChOA) and the Whale Optimization Algorithm (WOA). With a precision of 93.1%, recall of 94.4%, and F-measure of 93.8%, the ChWOA-based RMDL demonstrated better efficiency.</P>"
        },
        {
          "rank": 34,
          "score": 0.6775263547897339,
          "doc_id": "DIKO0017291669",
          "title": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측",
          "abstract": "최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017291669&target=NART&cn=DIKO0017291669",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다."
        },
        {
          "rank": 35,
          "score": 0.676210880279541,
          "doc_id": "ATN0051728135",
          "title": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구",
          "abstract": "하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0051728135&target=NART&cn=ATN0051728135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다."
        },
        {
          "rank": 36,
          "score": 0.6758324503898621,
          "doc_id": "NART38095312",
          "title": "Evaluation Model of Data Warehouse System",
          "abstract": "<P>By dividing the evaluation index system for data warehouse system into several layers,we can get a three-dimensional evaluation index matrix and setup an evaluation model of DW.Taking advantages of improved entropy-based TOPSIS algorithm, the weights of indices are optimized.We apply distance-method in the multi-objectives decision-mak-ing, and give a comprehensive evaluation of DW by using the distances from ideal and negative ideal solutions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART38095312&target=NART&cn=NART38095312",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Evaluation Model of Data Warehouse System Evaluation Model of Data Warehouse System Evaluation Model of Data Warehouse System <P>By dividing the evaluation index system for data warehouse system into several layers,we can get a three-dimensional evaluation index matrix and setup an evaluation model of DW.Taking advantages of improved entropy-based TOPSIS algorithm, the weights of indices are optimized.We apply distance-method in the multi-objectives decision-mak-ing, and give a comprehensive evaluation of DW by using the distances from ideal and negative ideal solutions.</P>"
        },
        {
          "rank": 37,
          "score": 0.6733986735343933,
          "doc_id": "JAKO202116047225054",
          "title": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어",
          "abstract": "최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116047225054&target=NART&cn=JAKO202116047225054",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다."
        },
        {
          "rank": 38,
          "score": 0.6723941564559937,
          "doc_id": "NART132071160",
          "title": "Integrating machine learning and deep learning for enhanced supplier risk prediction",
          "abstract": "<P>The importance of anticipating and preventing disruptions is underscored by the increased operational complexity and vulnerability caused by advancements in supply chain management (SCM). This has spurred interest in integrating machine learning (ML) and deep learning (DL) into supply chain risk management (SCRM). In this paper, we introduce a tailored method using ML and DL to improve SCRM by predicting supplier failures, thus boosting efficiency and resilience in SC operations. Our method involves five phases focused on classifying and predicting supplier failures in non-conforming deliveries. This involves forecasting failure quantities and estimating total disruption costs. Initially, data from an automotive company is selected, and appropriate potential features and algorithms are selected, performance metric aligns with case study objectives, facilitating method evaluation are used such as: Precision, recall, F1-score, and accuracy metrics assess classification models, while Mean Squared Error (MSE) is used for regression tasks. Finally, an experimental design optimizes models, assessing success rates of various algorithms and their parameters within the chosen feature space. Experimental results underscore the success of our methodology in model development. In the classification task, the Random Forest (RF) classifier achieved 86% accuracy. When combined with the Gradient Boosting classifier, the ensemble exhibited enhanced accuracy, highlighting the complementary strengths of both algorithms and their synergistic impact, surpassing the performance of RF, Support Vector Regression (SVR), k-Nearest Neighbors (KNN), and Artificial Neural Network (ANN). Noteworthy is the performance in regression tasks, where Linear Regression, ANN, and RF Regressor displayed exceptionally low MSE compared to other models.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART132071160&target=NART&cn=NART132071160",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating machine learning and deep learning for enhanced supplier risk prediction Integrating machine learning and deep learning for enhanced supplier risk prediction Integrating machine learning and deep learning for enhanced supplier risk prediction <P>The importance of anticipating and preventing disruptions is underscored by the increased operational complexity and vulnerability caused by advancements in supply chain management (SCM). This has spurred interest in integrating machine learning (ML) and deep learning (DL) into supply chain risk management (SCRM). In this paper, we introduce a tailored method using ML and DL to improve SCRM by predicting supplier failures, thus boosting efficiency and resilience in SC operations. Our method involves five phases focused on classifying and predicting supplier failures in non-conforming deliveries. This involves forecasting failure quantities and estimating total disruption costs. Initially, data from an automotive company is selected, and appropriate potential features and algorithms are selected, performance metric aligns with case study objectives, facilitating method evaluation are used such as: Precision, recall, F1-score, and accuracy metrics assess classification models, while Mean Squared Error (MSE) is used for regression tasks. Finally, an experimental design optimizes models, assessing success rates of various algorithms and their parameters within the chosen feature space. Experimental results underscore the success of our methodology in model development. In the classification task, the Random Forest (RF) classifier achieved 86% accuracy. When combined with the Gradient Boosting classifier, the ensemble exhibited enhanced accuracy, highlighting the complementary strengths of both algorithms and their synergistic impact, surpassing the performance of RF, Support Vector Regression (SVR), k-Nearest Neighbors (KNN), and Artificial Neural Network (ANN). Noteworthy is the performance in regression tasks, where Linear Regression, ANN, and RF Regressor displayed exceptionally low MSE compared to other models.</P>"
        },
        {
          "rank": 39,
          "score": 0.6688457727432251,
          "doc_id": "JAKO202108360626662",
          "title": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측",
          "abstract": "본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108360626662&target=NART&cn=JAKO202108360626662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다."
        },
        {
          "rank": 40,
          "score": 0.6677193641662598,
          "doc_id": "DIKO0015771393",
          "title": "딥러닝 기술을 이용한 전력 수요 예측 방법",
          "abstract": "정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015771393&target=NART&cn=DIKO0015771393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다."
        },
        {
          "rank": 41,
          "score": 0.6676557064056396,
          "doc_id": "JAKO202225948452506",
          "title": "딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델",
          "abstract": "수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한 모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의 분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데 딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여 여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202225948452506&target=NART&cn=JAKO202225948452506",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한 모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의 분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데 딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여 여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은 성능을 보였다."
        },
        {
          "rank": 42,
          "score": 0.6676262617111206,
          "doc_id": "JAKO201336161064414",
          "title": "앙상블 SVM 모형을 이용한 기업 부도 예측",
          "abstract": "기업의 부도를 예측하는 것은 회계나 재무 분야에서 중요한 연구주제이다. 지금까지 기업 부도예측을 위해 여러 가지 데이터마이닝 기법들이 적용되었으나 주로 단일 모형을 사용함으로서 복잡한 분류 문제에의 적용에 한계를 갖고 있었다. 본 논문에서는 최근에 각광받고 있는 SVM (support vector machine) 모형들을 결합한 앙상블 SVM 모형 (ensemble SVM model)을 부도예측에 사용하고자 한다. 제안된 앙상블 모형은 v-조각 교차 타당성 (v-fold cross-validation)에 의해 얻어진 여러 가지 모형 중에서 성능이 좋은 상위 k개의 단일 모형으로 구성하고 과반수 투표 방식 (majority voting)을 사용하여 미지의 클래스를 분류한다. 본 논문에서 제안된 앙상블 SVM 모형의 성능을 평가하기 위해 실제 기업의 재무비율 자료와 모의실험자료를 가지고 실험하였고, 실험결과 제안된 앙상블 모형이 여러 가지 평가척도 하에서 단일 SVM 모형들보다 좋은 성능을 보임을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201336161064414&target=NART&cn=JAKO201336161064414",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "앙상블 SVM 모형을 이용한 기업 부도 예측 앙상블 SVM 모형을 이용한 기업 부도 예측 앙상블 SVM 모형을 이용한 기업 부도 예측 기업의 부도를 예측하는 것은 회계나 재무 분야에서 중요한 연구주제이다. 지금까지 기업 부도예측을 위해 여러 가지 데이터마이닝 기법들이 적용되었으나 주로 단일 모형을 사용함으로서 복잡한 분류 문제에의 적용에 한계를 갖고 있었다. 본 논문에서는 최근에 각광받고 있는 SVM (support vector machine) 모형들을 결합한 앙상블 SVM 모형 (ensemble SVM model)을 부도예측에 사용하고자 한다. 제안된 앙상블 모형은 v-조각 교차 타당성 (v-fold cross-validation)에 의해 얻어진 여러 가지 모형 중에서 성능이 좋은 상위 k개의 단일 모형으로 구성하고 과반수 투표 방식 (majority voting)을 사용하여 미지의 클래스를 분류한다. 본 논문에서 제안된 앙상블 SVM 모형의 성능을 평가하기 위해 실제 기업의 재무비율 자료와 모의실험자료를 가지고 실험하였고, 실험결과 제안된 앙상블 모형이 여러 가지 평가척도 하에서 단일 SVM 모형들보다 좋은 성능을 보임을 알 수 있었다."
        },
        {
          "rank": 43,
          "score": 0.6666139960289001,
          "doc_id": "ATN0025427236",
          "title": "딥러닝을 이용한 열 수요예측 모델 개발",
          "abstract": "In order to provide stable district heat supplying service to the certain limited residential area, it is the most important to forecast the short-term future demand more accurately and produce and supply heat in efficient way. However, it is very difficult to develop a universal heat demand forecasting model that can be applied to general situations because the factors affecting the heat consumption are very diverse and the consumption patterns are changed according to individual consumers and regional characteristics. In particular, considering all of the various variables that can affect heat demand does not help improve performance in terms of accuracy and versatility. Therefore, this study aims to develop a demand forecasting model using deep learning based on only limited information that can be acquired in real time. A demand forecasting model was developed by learning the artificial neural network of the Tensorflow using past data consisting only of the outdoor temperature of the area and date as input variables. The performance of the proposed model was evaluated by comparing the accuracy of demand predicted with the previous regression model. The proposed heat demand forecasting model in this research showed that it is possible to enhance the accuracy using only limited variables which can be secured in real time. For the demand forecasting in a certain region, the proposed model can be customized by adding some features which can reflect the regional characteristics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025427236&target=NART&cn=ATN0025427236",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 열 수요예측 모델 개발 딥러닝을 이용한 열 수요예측 모델 개발 딥러닝을 이용한 열 수요예측 모델 개발 In order to provide stable district heat supplying service to the certain limited residential area, it is the most important to forecast the short-term future demand more accurately and produce and supply heat in efficient way. However, it is very difficult to develop a universal heat demand forecasting model that can be applied to general situations because the factors affecting the heat consumption are very diverse and the consumption patterns are changed according to individual consumers and regional characteristics. In particular, considering all of the various variables that can affect heat demand does not help improve performance in terms of accuracy and versatility. Therefore, this study aims to develop a demand forecasting model using deep learning based on only limited information that can be acquired in real time. A demand forecasting model was developed by learning the artificial neural network of the Tensorflow using past data consisting only of the outdoor temperature of the area and date as input variables. The performance of the proposed model was evaluated by comparing the accuracy of demand predicted with the previous regression model. The proposed heat demand forecasting model in this research showed that it is possible to enhance the accuracy using only limited variables which can be secured in real time. For the demand forecasting in a certain region, the proposed model can be customized by adding some features which can reflect the regional characteristics."
        },
        {
          "rank": 44,
          "score": 0.6665821671485901,
          "doc_id": "JAKO201208438434752",
          "title": "부도 예측을 위한 앙상블 분류기 개발",
          "abstract": "분류기의 앙상블 학습은 여러 개의 서로 다른 분류기들의 조합을 통해 만들어진다. 앙상블 학습은 기계학습 분야에서 많은 관심을 끌고 있는 중요한 연구주제이며 대부분의 경우에 있어서 앙상블 모형은 개별 기저 분류기보다 더 좋은 성과를 내는 것으로 알려져 있다. 본 연구는 부도 예측 모형의 성능개선에 관한 연구이다. 이를 위해 본 연구에서는 단일 모형으로 그 우수성을 인정받고 있는 SVM을 기저 분류기로 사용하는 앙상블 모형에 대해 고찰하였다. SVM 모형의 성능 개선을 위해 bagging과 random subspace 모형을 부도 예측 문제에 적용해 보았으며 bagging 모형과 random subspace 모형의 성과 개선을 위해 bagging과 random subspace의 통합 모형을 제안하였다. 제안한 모형의 성과를 검증하기 위해 실제 기업의 부도 예측 데이터를 사용하여 실험하였고, 실험 결과 본 연구에서 제안한 새로운 형태의 통합 모형이 가장 좋은 성과를 보임을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201208438434752&target=NART&cn=JAKO201208438434752",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부도 예측을 위한 앙상블 분류기 개발 부도 예측을 위한 앙상블 분류기 개발 부도 예측을 위한 앙상블 분류기 개발 분류기의 앙상블 학습은 여러 개의 서로 다른 분류기들의 조합을 통해 만들어진다. 앙상블 학습은 기계학습 분야에서 많은 관심을 끌고 있는 중요한 연구주제이며 대부분의 경우에 있어서 앙상블 모형은 개별 기저 분류기보다 더 좋은 성과를 내는 것으로 알려져 있다. 본 연구는 부도 예측 모형의 성능개선에 관한 연구이다. 이를 위해 본 연구에서는 단일 모형으로 그 우수성을 인정받고 있는 SVM을 기저 분류기로 사용하는 앙상블 모형에 대해 고찰하였다. SVM 모형의 성능 개선을 위해 bagging과 random subspace 모형을 부도 예측 문제에 적용해 보았으며 bagging 모형과 random subspace 모형의 성과 개선을 위해 bagging과 random subspace의 통합 모형을 제안하였다. 제안한 모형의 성과를 검증하기 위해 실제 기업의 부도 예측 데이터를 사용하여 실험하였고, 실험 결과 본 연구에서 제안한 새로운 형태의 통합 모형이 가장 좋은 성과를 보임을 알 수 있었다."
        },
        {
          "rank": 45,
          "score": 0.6659758687019348,
          "doc_id": "JAKO202326257736885",
          "title": "심층 강화학습 기반의 대학 전공과목 추천 시스템",
          "abstract": "기존의 단순 통계 기반 추천 시스템은 학생들의 수강 이력 데이터만을 활용하기 때문에 선호하는 수업을 찾는 것에 많은 어려움을 겪고 있다. 이를 해결하기 위해, 본 연구에서는 심층 강화학습 기반의 개인화된 전공과목 추천 시스템을 제안한다. 이 시스템은 학생의 학과, 학년, 수강 이력 등의 정형 데이터를 기반으로 학생들 간의 유사도를 측정하며, 이를 통해 각 전공과목에 대한 정보와 학생들의 강의 평가를 종합적으로 고려하여 가장 적합한 전공과목을 추천한다. 본 논문에서는 이 DRL 기반의 추천 시스템을 통해 대학생들이 전공과목을 선택하는 데에 유용한 정보를 제공하며, 이를 통계 기반 추천 시스템과 비교하였을 때 더 우수한 성능을 보여주는 것을 확인하였다. 시뮬레이션 결과, 심층 강화학습 기반의 추천 시스템은 통계 기반 추천 시스템에 비해 수강 과목 예측률에서 약 20%의 성능 향상을 보였다. 이러한 결과를 바탕으로, 학생들의 강의 평가를 반영하여 개인화된 과목 추천을 제공하는 새로운 시스템을 제안한다. 이 시스템은 학생들이 자신의 선호와 목표에 맞는 전공과목을 찾는 데에 큰 도움이 될 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202326257736885&target=NART&cn=JAKO202326257736885",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기반의 대학 전공과목 추천 시스템 심층 강화학습 기반의 대학 전공과목 추천 시스템 심층 강화학습 기반의 대학 전공과목 추천 시스템 기존의 단순 통계 기반 추천 시스템은 학생들의 수강 이력 데이터만을 활용하기 때문에 선호하는 수업을 찾는 것에 많은 어려움을 겪고 있다. 이를 해결하기 위해, 본 연구에서는 심층 강화학습 기반의 개인화된 전공과목 추천 시스템을 제안한다. 이 시스템은 학생의 학과, 학년, 수강 이력 등의 정형 데이터를 기반으로 학생들 간의 유사도를 측정하며, 이를 통해 각 전공과목에 대한 정보와 학생들의 강의 평가를 종합적으로 고려하여 가장 적합한 전공과목을 추천한다. 본 논문에서는 이 DRL 기반의 추천 시스템을 통해 대학생들이 전공과목을 선택하는 데에 유용한 정보를 제공하며, 이를 통계 기반 추천 시스템과 비교하였을 때 더 우수한 성능을 보여주는 것을 확인하였다. 시뮬레이션 결과, 심층 강화학습 기반의 추천 시스템은 통계 기반 추천 시스템에 비해 수강 과목 예측률에서 약 20%의 성능 향상을 보였다. 이러한 결과를 바탕으로, 학생들의 강의 평가를 반영하여 개인화된 과목 추천을 제공하는 새로운 시스템을 제안한다. 이 시스템은 학생들이 자신의 선호와 목표에 맞는 전공과목을 찾는 데에 큰 도움이 될 것으로 기대한다."
        },
        {
          "rank": 46,
          "score": 0.6658602952957153,
          "doc_id": "JAKO202116954704821",
          "title": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측",
          "abstract": "본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116954704821&target=NART&cn=JAKO202116954704821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다."
        },
        {
          "rank": 47,
          "score": 0.6651192307472229,
          "doc_id": "JAKO202128837709024",
          "title": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법",
          "abstract": "딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837709024&target=NART&cn=JAKO202128837709024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다."
        },
        {
          "rank": 48,
          "score": 0.6647974252700806,
          "doc_id": "NART117306842",
          "title": "딥러닝 기반 사용자 특징 정보 모델링을 통한 사용자 안전 프로파일링",
          "abstract": "산업 현장에서 발생하는 다양한 안전사고의 원인이 되는 위험 요소를 분석하여 사용자에게 발생하는 안전사고를 줄일 수 있는 지능형 기술 개발에 대한 필요성이 커지고 있다. 본 논문에서는 산업 현장에서 발생하는 안전사고와 관련된 사용자 정보를 특정하고 모델링하여 사용자에게 일어나는 안전 사고를 미리 예방할 수 있는 사용자 안전 프로파일링에 대한 기술을 제안하였다. 사용자 프로파일링은 사용자의 혈압, 맥박, 움직임 등의 정보로부터 사용자의 생체, 작업 패턴, 작업 유형에 대한 안전 상태를 정(positive)과 부(negative)로 특정 및 모델링하고 딥러닝 인공지능 분석기술을 이용하여 사용자의 안전 상태를 정상과 비정상 상태로 분류할 수 있도록 하였다. 제안된 기술의 타당성을 검증하기 위하여 산업 현장에서 근무하는 사용자 5명을 대상으로 10종 이상의 사용자 정보를 리빙랩에서 획득하여 지능형 분석 시스템을 학습한 후 5개의 테스트 셋을 이용하여 정확도 시험을 반복 시행하여 93.6%의 사용자 안전 프로파일링 시스템의 정확도를 얻을 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART117306842&target=NART&cn=NART117306842",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 사용자 특징 정보 모델링을 통한 사용자 안전 프로파일링 딥러닝 기반 사용자 특징 정보 모델링을 통한 사용자 안전 프로파일링 딥러닝 기반 사용자 특징 정보 모델링을 통한 사용자 안전 프로파일링 산업 현장에서 발생하는 다양한 안전사고의 원인이 되는 위험 요소를 분석하여 사용자에게 발생하는 안전사고를 줄일 수 있는 지능형 기술 개발에 대한 필요성이 커지고 있다. 본 논문에서는 산업 현장에서 발생하는 안전사고와 관련된 사용자 정보를 특정하고 모델링하여 사용자에게 일어나는 안전 사고를 미리 예방할 수 있는 사용자 안전 프로파일링에 대한 기술을 제안하였다. 사용자 프로파일링은 사용자의 혈압, 맥박, 움직임 등의 정보로부터 사용자의 생체, 작업 패턴, 작업 유형에 대한 안전 상태를 정(positive)과 부(negative)로 특정 및 모델링하고 딥러닝 인공지능 분석기술을 이용하여 사용자의 안전 상태를 정상과 비정상 상태로 분류할 수 있도록 하였다. 제안된 기술의 타당성을 검증하기 위하여 산업 현장에서 근무하는 사용자 5명을 대상으로 10종 이상의 사용자 정보를 리빙랩에서 획득하여 지능형 분석 시스템을 학습한 후 5개의 테스트 셋을 이용하여 정확도 시험을 반복 시행하여 93.6%의 사용자 안전 프로파일링 시스템의 정확도를 얻을 수 있었다."
        },
        {
          "rank": 49,
          "score": 0.6645309925079346,
          "doc_id": "ART003193557",
          "title": "Design a personalized recommendation system using deep learning and reinforcement learning",
          "abstract": "As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System  using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003193557&target=NART&cn=ART003193557",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design a personalized recommendation system using deep learning and reinforcement learning Design a personalized recommendation system using deep learning and reinforcement learning Design a personalized recommendation system using deep learning and reinforcement learning As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System  using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing."
        },
        {
          "rank": 50,
          "score": 0.664527416229248,
          "doc_id": "JAKO202121055483964",
          "title": "딥러닝을 통한 드론의 비정상 진동 예측",
          "abstract": "본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202121055483964&target=NART&cn=JAKO202121055483964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다."
        }
      ]
    },
    {
      "query": "해당 딥 러닝 모델의 주요 실험 결과 중 정확도는 어떻게 되나요?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7893826961517334,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 2,
          "score": 0.7777349948883057,
          "doc_id": "JAKO201718054814596",
          "title": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석",
          "abstract": "딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201718054814596&target=NART&cn=JAKO201718054814596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다."
        },
        {
          "rank": 3,
          "score": 0.7777346968650818,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.7717962265014648,
          "doc_id": "JAKO202116047225054",
          "title": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어",
          "abstract": "최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116047225054&target=NART&cn=JAKO202116047225054",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다."
        },
        {
          "rank": 5,
          "score": 0.7558227777481079,
          "doc_id": "JAKO201912758458868",
          "title": "딥러닝 개념을 위한 인공지능 교육 프로그램",
          "abstract": "본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201912758458868&target=NART&cn=JAKO201912758458868",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다."
        },
        {
          "rank": 6,
          "score": 0.7537700533866882,
          "doc_id": "ATN0051728135",
          "title": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구",
          "abstract": "하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0051728135&target=NART&cn=ATN0051728135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다."
        },
        {
          "rank": 7,
          "score": 0.7517985105514526,
          "doc_id": "JAKO202116954704821",
          "title": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측",
          "abstract": "본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116954704821&target=NART&cn=JAKO202116954704821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다."
        },
        {
          "rank": 8,
          "score": 0.7517191171646118,
          "doc_id": "JAKO202404861562091",
          "title": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교",
          "abstract": "대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202404861562091&target=NART&cn=JAKO202404861562091",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 연약지반 침하예측을 위한 딥러닝 및 계측기반 기법의 예측 정확도 비교 대심도 연약지반에 선행재하 공법을 적용하는 경우 재하토 제거 시점을 예측하고 잔류침하량을 최소화하기 위해 연약지반의 침하거동을 정밀히 예측하는 것이 중요하다. 국내에서는 일반적으로 계측기반 침하예측 기법을 적용하고 있으나, 장기간 계측 결과가 필요하고 분석구간에 따라 예측이 달라지는 한계가 있다. 기존 침하예측 기법들의 한계를 보완하기 위해 가중 비선형 회귀 쌍곡선법과 여러 딥러닝 기반 최신 기법 및 모델들이 제시되었으나, 기법들간의 비교&#x00B7;분석이 부족한 실정이다. 그러므로, 본 연구에서는 최근 제안된 딥러닝 모델들과 계측기반 침하예측 기법들의 정확도를 비교&#x00B7;분석하기 위해, 4개의 딥러닝 알고리즘(ANN, LSTM, GRU, Transformer)과 3개의 계측기반 침하예측 기법(쌍곡선법, Asaoka법, 가중 비선형 회귀 쌍곡선법)을 적용하여 학습 및 회귀 일수(60일-150일)에 따라 총 392개 조건에서 침하예측을 수행하였다. 분석 결과, 가중 비선형 회귀 쌍곡선법과 GRU 모델은 모든 조건에서 전반적으로 가장 높은 예측 정확도를 나타내었고 계측 데이터 사용 기간이 증가할수록 모든 기법의 예측 정확도가 향상되었다. 150일간의 데이터를 사용할 경우 모든 기법에서 3cm 이하의 오차를 달성하여 정확한 예측 결과를 제공하였다."
        },
        {
          "rank": 9,
          "score": 0.7462091445922852,
          "doc_id": "ATN0038661375",
          "title": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험",
          "abstract": "Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038661375&target=NART&cn=ATN0038661375",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
        },
        {
          "rank": 10,
          "score": 0.7398161888122559,
          "doc_id": "DIKO0017011976",
          "title": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형",
          "abstract": "본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017011976&target=NART&cn=DIKO0017011976",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다."
        },
        {
          "rank": 11,
          "score": 0.7368975877761841,
          "doc_id": "JAKO201620853199880",
          "title": "딥러닝의 모형과 응용사례",
          "abstract": "딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201620853199880&target=NART&cn=JAKO201620853199880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다."
        },
        {
          "rank": 12,
          "score": 0.7351328134536743,
          "doc_id": "JAKO202009759219313",
          "title": "콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교",
          "abstract": "The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256&#x00D7;256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160&#x00D7;3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256&#x00D7;256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009759219313&target=NART&cn=JAKO202009759219313",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256&#x00D7;256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160&#x00D7;3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256&#x00D7;256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks."
        },
        {
          "rank": 13,
          "score": 0.7345327138900757,
          "doc_id": "JAKO202334662554660",
          "title": "증강형 딥러닝 기반 미세먼지 예측 시스템",
          "abstract": "딥러닝은 심층신경망(Deep Neural Network)을 구축하고 대량의 훈련 데이터를 수집한 후, 구축된 신경망을 오랫동안 학습 시켜야 한다. 만약, 학습이 제대로 진행되지 않거나 과적합이 발생하면, 학습은 실패하게 된다. 현재까지 개발되고 있는 딥러닝 도구들을 사용할 경우, 훈련데이터 수집과 학습에 많은 시간이 소요된다. 하지만, 모바일 환경의 급격한 도래와 센서 데이터의 증가로 인해, 신경망 학습에 걸리는 시간을 획기적으로 줄일 수 있는 실시간 증강형 딥러닝 기술에 대한 요구가 급격하게 증가하고 있다. 본 연구에서는 미세먼지 센서를 장착한 아두이노 시스템을 사용하여 실시간 증강형 딥러닝 시스템을 구현 하였다. 구현된 시스템에서는 미세먼지 데이터를 5초마다 측정하고 최대 120개가 축적이 되면, 기존에 축적된 데이터와 새로이 축적된 데이터를 데이터셋으로 사용하여 학습을 수행하도록 하였다. 학습 수행을 위한 신경망은 입력층 1개, 은닉층 1개, 출력등 1개로 구성하였다. 구현된 시스템에 대한 성능을 평가하기 위해 학습 시간과 평균 제곱근 오차(root mean square error, RMSE)를 측정 하였다. 실험 결과, 평균 학습 오차는 0.04053796이었으며, 학습주기당(1 에포크) 평균 학습 시간은 3,447 초 정도의 시간이 걸렸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202334662554660&target=NART&cn=JAKO202334662554660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "증강형 딥러닝 기반 미세먼지 예측 시스템 증강형 딥러닝 기반 미세먼지 예측 시스템 증강형 딥러닝 기반 미세먼지 예측 시스템 딥러닝은 심층신경망(Deep Neural Network)을 구축하고 대량의 훈련 데이터를 수집한 후, 구축된 신경망을 오랫동안 학습 시켜야 한다. 만약, 학습이 제대로 진행되지 않거나 과적합이 발생하면, 학습은 실패하게 된다. 현재까지 개발되고 있는 딥러닝 도구들을 사용할 경우, 훈련데이터 수집과 학습에 많은 시간이 소요된다. 하지만, 모바일 환경의 급격한 도래와 센서 데이터의 증가로 인해, 신경망 학습에 걸리는 시간을 획기적으로 줄일 수 있는 실시간 증강형 딥러닝 기술에 대한 요구가 급격하게 증가하고 있다. 본 연구에서는 미세먼지 센서를 장착한 아두이노 시스템을 사용하여 실시간 증강형 딥러닝 시스템을 구현 하였다. 구현된 시스템에서는 미세먼지 데이터를 5초마다 측정하고 최대 120개가 축적이 되면, 기존에 축적된 데이터와 새로이 축적된 데이터를 데이터셋으로 사용하여 학습을 수행하도록 하였다. 학습 수행을 위한 신경망은 입력층 1개, 은닉층 1개, 출력등 1개로 구성하였다. 구현된 시스템에 대한 성능을 평가하기 위해 학습 시간과 평균 제곱근 오차(root mean square error, RMSE)를 측정 하였다. 실험 결과, 평균 학습 오차는 0.04053796이었으며, 학습주기당(1 에포크) 평균 학습 시간은 3,447 초 정도의 시간이 걸렸다."
        },
        {
          "rank": 14,
          "score": 0.7343239188194275,
          "doc_id": "JAKO202201253146351",
          "title": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가",
          "abstract": "본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202201253146351&target=NART&cn=JAKO202201253146351",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다."
        },
        {
          "rank": 15,
          "score": 0.7339860200881958,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 16,
          "score": 0.733479380607605,
          "doc_id": "JAKO202225948452506",
          "title": "딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델",
          "abstract": "수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한 모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의 분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데 딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여 여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202225948452506&target=NART&cn=JAKO202225948452506",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 딥러닝 기법을 사용하는 소프트웨어 결함 예측 모델 수십년간 매우 많은 소프트웨어 결함 예측 모델에 관한 연구들이 수행되었으며, 그들 중 기계학습 기법을 사용한 모델들이 가장 좋은 성능을 보였다. 딥러닝 기법은 기계학습 분야에서 가장 각광받는 기술이 되었지만 결함 예측 모델의 분류기로 사용된 연구는 거의 없었다. 몇몇 연구들은 모델의 입력 소스나 구문 데이터로부터 시맨틱 정보를 얻어내는데 딥러닝을 사용하였다. 본 논문은 3개 이상의 은닉층을 갖는 MLP를 이용하여 모델 구조와 하이퍼 파라미터를 변경하여 여러 모델들을 제작하였다. 모델 평가 실험 결과 MLP 기반 딥러닝 모델들은 기존 결함 예측 모델들과 Accuracy는 비슷한 성능을 보였으나 AUC는 유의미하게 더 우수한 성능을 보였다. 또한 또다른 딥러닝 모델인 CNN 모델보다도 더 나은 성능을 보였다."
        },
        {
          "rank": 17,
          "score": 0.7331175208091736,
          "doc_id": "JAKO202128837709024",
          "title": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법",
          "abstract": "딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837709024&target=NART&cn=JAKO202128837709024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다."
        },
        {
          "rank": 18,
          "score": 0.7305730581283569,
          "doc_id": "JAKO202012758284659",
          "title": "딥러닝을 활용한 다목적댐 유입량 예측",
          "abstract": "최근 데이터 예측 방법으로 인공신경망(Artificial Neural Network, ANN)분야에 대한 관심이 높아졌으며, 그 중 시계열 데이터 예측에 특화된 LSTM(Long Short-Term Memory)모형은 수문 시계열자료의 예측방법으로도 활용되고 있다. 본 연구에서는 구글에서 제공하는 딥러닝 오픈소스 라이브러리인 텐서플로우(TensorFlow)를 활용하여 LSTM모형을 구축하고 금강 상류에 위치한 용담다목적댐의 유입량을 예측하였다. 분석 자료로는 WAMIS에서 제공하는 용담댐의 2006년부터 2018년까지의 시간당 유입량 자료를 사용하였으며, 예측된 유입량과 관측 유입량의 비교를 통하여 평균제곱오차(RMSE), 평균절대오차(MAE), 용적오차(VE)를 계산하고 모형의 학습변수에 따른 정확도를 평가하였다. 분석결과, 모든 모형이 고유량에서의 정확도가 낮은 것으로 나타났으며, 이와 같은 문제를 해결하기 위하여 용담댐 유역의 시간당 강수량 자료를 추가 학습 자료로 활용하여 분석한 결과, 고유량에 대한 예측의 정확도가 높아지는 것을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012758284659&target=NART&cn=JAKO202012758284659",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 활용한 다목적댐 유입량 예측 딥러닝을 활용한 다목적댐 유입량 예측 딥러닝을 활용한 다목적댐 유입량 예측 최근 데이터 예측 방법으로 인공신경망(Artificial Neural Network, ANN)분야에 대한 관심이 높아졌으며, 그 중 시계열 데이터 예측에 특화된 LSTM(Long Short-Term Memory)모형은 수문 시계열자료의 예측방법으로도 활용되고 있다. 본 연구에서는 구글에서 제공하는 딥러닝 오픈소스 라이브러리인 텐서플로우(TensorFlow)를 활용하여 LSTM모형을 구축하고 금강 상류에 위치한 용담다목적댐의 유입량을 예측하였다. 분석 자료로는 WAMIS에서 제공하는 용담댐의 2006년부터 2018년까지의 시간당 유입량 자료를 사용하였으며, 예측된 유입량과 관측 유입량의 비교를 통하여 평균제곱오차(RMSE), 평균절대오차(MAE), 용적오차(VE)를 계산하고 모형의 학습변수에 따른 정확도를 평가하였다. 분석결과, 모든 모형이 고유량에서의 정확도가 낮은 것으로 나타났으며, 이와 같은 문제를 해결하기 위하여 용담댐 유역의 시간당 강수량 자료를 추가 학습 자료로 활용하여 분석한 결과, 고유량에 대한 예측의 정확도가 높아지는 것을 알 수 있었다."
        },
        {
          "rank": 19,
          "score": 0.7287848591804504,
          "doc_id": "JAKO201726163356540",
          "title": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델",
          "abstract": "본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163356540&target=NART&cn=JAKO201726163356540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다."
        },
        {
          "rank": 20,
          "score": 0.7286392450332642,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 21,
          "score": 0.7268399000167847,
          "doc_id": "JAKO202421251156831",
          "title": "LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석",
          "abstract": "This research is a comprehensive analysis of wind power prediction sensitivity using a Long Short-Term Memory (LSTM) deep learning neural network model, accounting for the inherent uncertainties in wind speed estimation. Utilizing a year's worth of operational data from an operational wind farm, the study forecasts the power output of both individual wind turbines and the farm collectively. Predictions were made daily at intervals of 10 minutes and 1 hour over a span of three months. The model's forecast accuracy was evaluated by comparing the root mean square error (RMSE), normalized RMSE (NRMSE), and correlation coefficients with actual power output data. Moreover, the research investigated how inaccuracies in wind speed inputs affect the power prediction sensitivity of the model. By simulating wind speed errors within a normal distribution range of 1% to 15%, the study analyzed their influence on the accuracy of power predictions. This investigation provided insights into the required wind speed prediction error rate to achieve an 8% power prediction error threshold, meeting the incentive standards for forecasting systems in renewable energy generation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202421251156831&target=NART&cn=JAKO202421251156831",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 LSTM 딥러닝 신경망 모델을 이용한 풍력발전단지 풍속 오차에 따른 출력 예측 민감도 분석 This research is a comprehensive analysis of wind power prediction sensitivity using a Long Short-Term Memory (LSTM) deep learning neural network model, accounting for the inherent uncertainties in wind speed estimation. Utilizing a year's worth of operational data from an operational wind farm, the study forecasts the power output of both individual wind turbines and the farm collectively. Predictions were made daily at intervals of 10 minutes and 1 hour over a span of three months. The model's forecast accuracy was evaluated by comparing the root mean square error (RMSE), normalized RMSE (NRMSE), and correlation coefficients with actual power output data. Moreover, the research investigated how inaccuracies in wind speed inputs affect the power prediction sensitivity of the model. By simulating wind speed errors within a normal distribution range of 1% to 15%, the study analyzed their influence on the accuracy of power predictions. This investigation provided insights into the required wind speed prediction error rate to achieve an 8% power prediction error threshold, meeting the incentive standards for forecasting systems in renewable energy generation."
        },
        {
          "rank": 22,
          "score": 0.7243919372558594,
          "doc_id": "JAKO202407064802797",
          "title": "딥러닝 기법을 이용한 연안 양식 시설 탐지의 정확도 평가",
          "abstract": "급격한 기후 변화로 인한 어획량 감소와 양식 기술의 발전으로 양식 생산물 수요가 전세계적으로 계속해서 증가하고 있다. 그러나 이에 따른 무분별한 시설물 확장이 연안 생태계와 어족 자원 가격 책정에 악영향을 미치기 때문에, 주기적인 연안 환경 모니터링을 통한 양식시설물 관리가 필수적이다. 본 연구에서는 Sentinel-2 광학 영상과 다양한 딥러닝 기반 탐지 기법을 활용하여 경상남도의 패류 양식시설물 탐지 정확도를 분석하였다. DeepLabv3+, ResUNet++ 그리고 Attention U-Net 모델을 적용하였으며, 실험 결과 Attention U-Net 모델이 F1 score 0.8708, Intersection over Union 0.7708로 가장 우수한 탐지 성능을 보였다. 연구에서 제시한 탐지 방법론은 조류 및 부유 물질에 영향을 받는 양식시설물을 주기적으로 관측할 수 있고, 다양한 양식 품종에 적용할 수 있어 넓은 지역으로의 확장 가능성이 높다. 따라서 본 연구 방법을 통해 도출된 양식 시설물 정보는 향후 해양 공간 활용에 관한 정책 결정에 유용하게 활용할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407064802797&target=NART&cn=JAKO202407064802797",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기법을 이용한 연안 양식 시설 탐지의 정확도 평가 딥러닝 기법을 이용한 연안 양식 시설 탐지의 정확도 평가 딥러닝 기법을 이용한 연안 양식 시설 탐지의 정확도 평가 급격한 기후 변화로 인한 어획량 감소와 양식 기술의 발전으로 양식 생산물 수요가 전세계적으로 계속해서 증가하고 있다. 그러나 이에 따른 무분별한 시설물 확장이 연안 생태계와 어족 자원 가격 책정에 악영향을 미치기 때문에, 주기적인 연안 환경 모니터링을 통한 양식시설물 관리가 필수적이다. 본 연구에서는 Sentinel-2 광학 영상과 다양한 딥러닝 기반 탐지 기법을 활용하여 경상남도의 패류 양식시설물 탐지 정확도를 분석하였다. DeepLabv3+, ResUNet++ 그리고 Attention U-Net 모델을 적용하였으며, 실험 결과 Attention U-Net 모델이 F1 score 0.8708, Intersection over Union 0.7708로 가장 우수한 탐지 성능을 보였다. 연구에서 제시한 탐지 방법론은 조류 및 부유 물질에 영향을 받는 양식시설물을 주기적으로 관측할 수 있고, 다양한 양식 품종에 적용할 수 있어 넓은 지역으로의 확장 가능성이 높다. 따라서 본 연구 방법을 통해 도출된 양식 시설물 정보는 향후 해양 공간 활용에 관한 정책 결정에 유용하게 활용할 수 있을 것으로 기대된다."
        },
        {
          "rank": 23,
          "score": 0.7242125272750854,
          "doc_id": "JAKO202433861648179",
          "title": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교",
          "abstract": "본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202433861648179&target=NART&cn=JAKO202433861648179",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다."
        },
        {
          "rank": 24,
          "score": 0.7238976955413818,
          "doc_id": "ATN0037497712",
          "title": "딥러닝 기반 감정인식 성능향상 방법",
          "abstract": "With the development of the Internet and the increase of non-face-to-face services, the number of users communicating through text messages or SNS is increasing. As a large amount of data is generated by users, research on recognizing emotions by analyzing user information or opinions is being actively conducted. Among them, most of the text emotion recognition recognizes a single emotion of a word or sentence. However, since multiple emotions exist complexly in a single sentence, a multi-emotion recognition method is required. Therefore, in this paper, we propose a data correction method for more accurate text emotion recognition and a method to improve emotion recognition performance by applying a deep learning-based multi-emotion recognition method. As a result of comparing deep learning models to confirm the usefulness of the proposed model, when the attention model was used, Accuracy showed the best performance with 76.7%.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037497712&target=NART&cn=ATN0037497712",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 감정인식 성능향상 방법 딥러닝 기반 감정인식 성능향상 방법 딥러닝 기반 감정인식 성능향상 방법 With the development of the Internet and the increase of non-face-to-face services, the number of users communicating through text messages or SNS is increasing. As a large amount of data is generated by users, research on recognizing emotions by analyzing user information or opinions is being actively conducted. Among them, most of the text emotion recognition recognizes a single emotion of a word or sentence. However, since multiple emotions exist complexly in a single sentence, a multi-emotion recognition method is required. Therefore, in this paper, we propose a data correction method for more accurate text emotion recognition and a method to improve emotion recognition performance by applying a deep learning-based multi-emotion recognition method. As a result of comparing deep learning models to confirm the usefulness of the proposed model, when the attention model was used, Accuracy showed the best performance with 76.7%."
        },
        {
          "rank": 25,
          "score": 0.7229763865470886,
          "doc_id": "JAKO202325543363508",
          "title": "딥러닝 영상분석 시스템의 성능평가 산정식 개발",
          "abstract": "도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202325543363508&target=NART&cn=JAKO202325543363508",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 딥러닝 영상분석 시스템의 성능평가 산정식 개발 도시부 교통정보 수집은 VDS, DSRC, 레이더 등 다양한 시스템에 의해 수집되고 있다. 최근 딥러닝 기술의 발전으로 스마트교차로시스템이 확대 보급되고 있으며 교통량, 속도, 차종 등 다양한 정보수집이 가능하다. 그러나 관련 문헌을 고찰한 결과 지금까지의 성능평가 기준은 딥러닝 영역을 고려하지 않은 RBS기반 평가체계로 '기준값-측정값'의 퍼센트 오차만 고려하고 있어 기존 평가방식으로는 딥러닝 부분의 평가를 수행할 수 없어 새로운 성능평가 방법이 필요하다. 따라서, 본 연구에서는 데이터 비율 및 가중치를 고려하여 Precision과 Recall 등 딥러닝 성능지표를 고려한 오차산정식을 개발하여 개별오차와 구간 오차, 전체오차를 산정하였다. 연구결과, 측정값 1의 오차율은 3.99와 3.54, 측정값 2는 5.34와 5.07로 기존 산정식과 오차율에 차이가 있는 것으로 나타났으며, 반복측정 분석결과 개발 산정식이 우수한 것으로 나타났다."
        },
        {
          "rank": 26,
          "score": 0.7223939895629883,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 27,
          "score": 0.7204385995864868,
          "doc_id": "JAKO201614137727823",
          "title": "딥러닝 기법을 이용한 내일강수 예측",
          "abstract": "정확한 강수예측을 위해서는 예측인자 선정과 예측방법에 대한 선택이 매우 중요하다. 최근에는 강수예측 방법으로 기계학습 기법이 많이 사용되고 있으며, 그 중에서도 특히 인공신경망을 사용한 강수예측 방법은 좋은 성능을 보였다. 본 논문에서는 딥러닝 기법 중 하나인 DBN(deep belief network)를 이용한 새로운 강수예측 방법을 제안한다. DBN는 비지도 사전 학습을 통해 초기 가중치를 설정하여 기존 인공신경망의 문제점을 보완한다. 예측인자로는 기온, 전일-전주 강수일, 태양과 달 궤도 관련 자료를 선정하였다. 기온과 전일-전주 강수일은 서울에서의 1974년부터 2013년까지 총 40년간의 AWS(automatic weather system) 관측 자료를 사용하였고, 태양과 달의 궤도 관련 자료는 서울을 중심으로 계산한 결과를 사용하였다. 전체 기간에서 일부는 학습 자료로 사용하여 예측모델을 생성하였고, 나머지를 생성한 모델의 검증 자료로 사용하였다. 모델 검증 결과로 나온 예측값들은 확률값을 가지며 임계치를 이용하여 강수유무를 판별하였다. 강수 정확도의 척도로 양분예보기법 중 CSI(critical successive index)와 Bias(frequency bias)를 계산하였다. 이를 통해 DBN와 MLP(multilayer perceptron)의 성능을 비교한 결과 DBN의 강수 예측 정확도가 높았고, 수행속도 또한 2배 이상 빨랐다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201614137727823&target=NART&cn=JAKO201614137727823",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기법을 이용한 내일강수 예측 딥러닝 기법을 이용한 내일강수 예측 딥러닝 기법을 이용한 내일강수 예측 정확한 강수예측을 위해서는 예측인자 선정과 예측방법에 대한 선택이 매우 중요하다. 최근에는 강수예측 방법으로 기계학습 기법이 많이 사용되고 있으며, 그 중에서도 특히 인공신경망을 사용한 강수예측 방법은 좋은 성능을 보였다. 본 논문에서는 딥러닝 기법 중 하나인 DBN(deep belief network)를 이용한 새로운 강수예측 방법을 제안한다. DBN는 비지도 사전 학습을 통해 초기 가중치를 설정하여 기존 인공신경망의 문제점을 보완한다. 예측인자로는 기온, 전일-전주 강수일, 태양과 달 궤도 관련 자료를 선정하였다. 기온과 전일-전주 강수일은 서울에서의 1974년부터 2013년까지 총 40년간의 AWS(automatic weather system) 관측 자료를 사용하였고, 태양과 달의 궤도 관련 자료는 서울을 중심으로 계산한 결과를 사용하였다. 전체 기간에서 일부는 학습 자료로 사용하여 예측모델을 생성하였고, 나머지를 생성한 모델의 검증 자료로 사용하였다. 모델 검증 결과로 나온 예측값들은 확률값을 가지며 임계치를 이용하여 강수유무를 판별하였다. 강수 정확도의 척도로 양분예보기법 중 CSI(critical successive index)와 Bias(frequency bias)를 계산하였다. 이를 통해 DBN와 MLP(multilayer perceptron)의 성능을 비교한 결과 DBN의 강수 예측 정확도가 높았고, 수행속도 또한 2배 이상 빨랐다."
        },
        {
          "rank": 28,
          "score": 0.7184229493141174,
          "doc_id": "JAKO201834663385145",
          "title": "딥 러닝 기반의 가짜 얼굴 검출",
          "abstract": "최근 바이오인식 기술이 대중화됨에 따라 위 변조에 대응하는 연구 및 시도들이 많이 진행되고 있다. 본 논문에서 인공지능으로 만든 합성된 얼굴을 진짜 얼굴인지 합성된 가짜 얼굴인지를 판별하는 방법을 제안하고자 한다. 제안하는 알고리즘은 크게 2가지 단계로 구성되어 있다. 먼저, 실제 얼굴 사진에 여러 가지 GAN(Generative Adversarial Networks)알고리즘을 통해 합성된 가짜 얼굴을 생성하게 된다. 이후, 실제 얼굴 영상과 생성된 얼굴 영상을 딥러닝 알고리즘에 입력하여 진짜 또는 가짜인지 판별하도록 한다. 제안한 알고리즘은 실제 육안으로도 구별하기 어려운 합성 영상도 잘 구분하고, 테스트 결과 88.7%의 정확도를 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201834663385145&target=NART&cn=JAKO201834663385145",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 가짜 얼굴 검출 딥 러닝 기반의 가짜 얼굴 검출 딥 러닝 기반의 가짜 얼굴 검출 최근 바이오인식 기술이 대중화됨에 따라 위 변조에 대응하는 연구 및 시도들이 많이 진행되고 있다. 본 논문에서 인공지능으로 만든 합성된 얼굴을 진짜 얼굴인지 합성된 가짜 얼굴인지를 판별하는 방법을 제안하고자 한다. 제안하는 알고리즘은 크게 2가지 단계로 구성되어 있다. 먼저, 실제 얼굴 사진에 여러 가지 GAN(Generative Adversarial Networks)알고리즘을 통해 합성된 가짜 얼굴을 생성하게 된다. 이후, 실제 얼굴 영상과 생성된 얼굴 영상을 딥러닝 알고리즘에 입력하여 진짜 또는 가짜인지 판별하도록 한다. 제안한 알고리즘은 실제 육안으로도 구별하기 어려운 합성 영상도 잘 구분하고, 테스트 결과 88.7%의 정확도를 확인하였다."
        },
        {
          "rank": 29,
          "score": 0.7170747518539429,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 30,
          "score": 0.7149088382720947,
          "doc_id": "ATN0040090940",
          "title": "딥러닝 기반 취업가능성 예측 모델 연구",
          "abstract": "Today, thanks to the development of artificial intelligence technology, research on predictive models using artificial intelligence is actively conducted in various fields of society. In particular, artificial intelligence technology called deep learning is leading many changes in many fields by providing more accurate predictions compared to existing artificial intelligence. Recently, in Korea, the youth unemployment rate is emerging as a social problem due to the prolonged economic recession and the war in Ukraine. As the youth employment rate can affect the marriage rate and fertility rate in the long term, attention is needed to improve it. However, since the conditions for employment are unclear, it is difficult for prospective job seekers. Therefore, this paper proposes a model for predicting employability using deep learning. The model proposed in this paper was verified using data from 790 people, and the accuracy of the verification data was 87.34% and the error rate of the verification data was 8.14%. The model proposed in this paper can be used to establish employment strategies and predict employability of prospective job seekers in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0040090940&target=NART&cn=ATN0040090940",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 취업가능성 예측 모델 연구 딥러닝 기반 취업가능성 예측 모델 연구 딥러닝 기반 취업가능성 예측 모델 연구 Today, thanks to the development of artificial intelligence technology, research on predictive models using artificial intelligence is actively conducted in various fields of society. In particular, artificial intelligence technology called deep learning is leading many changes in many fields by providing more accurate predictions compared to existing artificial intelligence. Recently, in Korea, the youth unemployment rate is emerging as a social problem due to the prolonged economic recession and the war in Ukraine. As the youth employment rate can affect the marriage rate and fertility rate in the long term, attention is needed to improve it. However, since the conditions for employment are unclear, it is difficult for prospective job seekers. Therefore, this paper proposes a model for predicting employability using deep learning. The model proposed in this paper was verified using data from 790 people, and the accuracy of the verification data was 87.34% and the error rate of the verification data was 8.14%. The model proposed in this paper can be used to establish employment strategies and predict employability of prospective job seekers in the future."
        },
        {
          "rank": 31,
          "score": 0.7144775390625,
          "doc_id": "ATN0052776138",
          "title": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구",
          "abstract": "첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0052776138&target=NART&cn=ATN0052776138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다."
        },
        {
          "rank": 32,
          "score": 0.7141566872596741,
          "doc_id": "JAKO202108848920380",
          "title": "딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구",
          "abstract": "The increased turbidity in rivers during flood events has various effects on water environmental management, including drinking water supply systems. Thus, prediction of turbid water is essential for water environmental management. Recently, various advanced machine learning algorithms have been increasingly used in water environmental management. Ensemble machine learning algorithms such as random forest (RF) and gradient boosting decision tree (GBDT) are some of the most popular machine learning algorithms used for water environmental management, along with deep learning algorithms such as recurrent neural networks. In this study GBDT, an ensemble machine learning algorithm, and gated recurrent unit (GRU), a recurrent neural networks algorithm, are used for model development to predict turbidity in a river. The observation frequencies of input data used for the model were 2, 4, 8, 24, 48, 120 and 168 h. The root-mean-square error-observations standard deviation ratio (RSR) of GRU and GBDT ranges between 0.182~0.766 and 0.400~0.683, respectively. Both models show similar prediction accuracy with RSR of 0.682 for GRU and 0.683 for GBDT. The GRU shows better prediction accuracy when the observation frequency is relatively short (i.e., 2, 4, and 8 h) where GBDT shows better prediction accuracy when the observation frequency is relatively long (i.e. 48, 120, 160 h). The results suggest that the characteristics of input data should be considered to develop an appropriate model to predict turbidity.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108848920380&target=NART&cn=JAKO202108848920380",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 The increased turbidity in rivers during flood events has various effects on water environmental management, including drinking water supply systems. Thus, prediction of turbid water is essential for water environmental management. Recently, various advanced machine learning algorithms have been increasingly used in water environmental management. Ensemble machine learning algorithms such as random forest (RF) and gradient boosting decision tree (GBDT) are some of the most popular machine learning algorithms used for water environmental management, along with deep learning algorithms such as recurrent neural networks. In this study GBDT, an ensemble machine learning algorithm, and gated recurrent unit (GRU), a recurrent neural networks algorithm, are used for model development to predict turbidity in a river. The observation frequencies of input data used for the model were 2, 4, 8, 24, 48, 120 and 168 h. The root-mean-square error-observations standard deviation ratio (RSR) of GRU and GBDT ranges between 0.182~0.766 and 0.400~0.683, respectively. Both models show similar prediction accuracy with RSR of 0.682 for GRU and 0.683 for GBDT. The GRU shows better prediction accuracy when the observation frequency is relatively short (i.e., 2, 4, and 8 h) where GBDT shows better prediction accuracy when the observation frequency is relatively long (i.e. 48, 120, 160 h). The results suggest that the characteristics of input data should be considered to develop an appropriate model to predict turbidity."
        },
        {
          "rank": 33,
          "score": 0.7133240103721619,
          "doc_id": "JAKO199215875841266",
          "title": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교",
          "abstract": "음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199215875841266&target=NART&cn=JAKO199215875841266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다."
        },
        {
          "rank": 34,
          "score": 0.7123346328735352,
          "doc_id": "JAKO202013261023095",
          "title": "딥러닝을 위한 경사하강법 비교",
          "abstract": "본 논문에서는 신경망을 학습하는 데 가장 많이 사용되고 있는 경사하강법에 대해 분석하였다. 학습이란 손실함수가 최소값이 되도록 매개변수를 갱신하는 것이다. 손실함수는 실제값과 예측값의 차이를 수치화 해주는 함수이다. 경사하강법은 오차가 최소화되도록 매개변수를 갱신하는데 손실함수의 기울기를 사용하는 것으로 현재 최고의 딥러닝 학습알고리즘을 제공하는 라이브러리에서 사용되고 있다. 그러나 이 알고리즘들은 블랙박스형태로 제공되고 있어서 다양한 경사하강법들의 장단점을 파악하는 것이 쉽지 않다. 경사하강법에서 현재 대표적으로 사용되고 있는 확률적 경사하강법(Stochastic Gradient Descent method), 모멘텀법(Momentum method), AdaGrad법 그리고 Adadelta법의 특성에 대하여 분석하였다. 실험 데이터는 신경망을 검증하는 데 널리 사용되는 MNIST 데이터 셋을 사용하였다. 은닉층은 2개의 층으로 첫 번째 층은 500개 그리고 두 번째 층은 300개의 뉴런으로 구성하였다. 출력 층의 활성화함수는 소프트 맥스함수이고 나머지 입력 층과 은닉 층의 활성화함수는 ReLu함수를 사용하였다. 그리고 손실함수는 교차 엔트로피 오차를 사용하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013261023095&target=NART&cn=JAKO202013261023095",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 위한 경사하강법 비교 딥러닝을 위한 경사하강법 비교 딥러닝을 위한 경사하강법 비교 본 논문에서는 신경망을 학습하는 데 가장 많이 사용되고 있는 경사하강법에 대해 분석하였다. 학습이란 손실함수가 최소값이 되도록 매개변수를 갱신하는 것이다. 손실함수는 실제값과 예측값의 차이를 수치화 해주는 함수이다. 경사하강법은 오차가 최소화되도록 매개변수를 갱신하는데 손실함수의 기울기를 사용하는 것으로 현재 최고의 딥러닝 학습알고리즘을 제공하는 라이브러리에서 사용되고 있다. 그러나 이 알고리즘들은 블랙박스형태로 제공되고 있어서 다양한 경사하강법들의 장단점을 파악하는 것이 쉽지 않다. 경사하강법에서 현재 대표적으로 사용되고 있는 확률적 경사하강법(Stochastic Gradient Descent method), 모멘텀법(Momentum method), AdaGrad법 그리고 Adadelta법의 특성에 대하여 분석하였다. 실험 데이터는 신경망을 검증하는 데 널리 사용되는 MNIST 데이터 셋을 사용하였다. 은닉층은 2개의 층으로 첫 번째 층은 500개 그리고 두 번째 층은 300개의 뉴런으로 구성하였다. 출력 층의 활성화함수는 소프트 맥스함수이고 나머지 입력 층과 은닉 층의 활성화함수는 ReLu함수를 사용하였다. 그리고 손실함수는 교차 엔트로피 오차를 사용하였다."
        },
        {
          "rank": 35,
          "score": 0.7118957042694092,
          "doc_id": "JAKO202314857616824",
          "title": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석",
          "abstract": "클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202314857616824&target=NART&cn=JAKO202314857616824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다."
        },
        {
          "rank": 36,
          "score": 0.7117348909378052,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 37,
          "score": 0.7105445861816406,
          "doc_id": "JAKO202222059037013",
          "title": "기온 데이터를 반영한 전력수요 예측 딥러닝 모델",
          "abstract": "최근 전력수요를 예측하기 위해 통계기반 시계열 분석 기법을 대체하기 위해 딥러닝 기법을 활용한 연구가 활발히 진행되고 있다. 딥러닝 기반 전력수요 예측 연구 결과를 분석한 결과, LSTM 기반 예측 모델의 성능이 우수한 것으로 규명되었으나 장기간의 지역 범위 전력수요 예측에 대해 LSTM 기반 모델의 성능이 충분하지 않음을 확인할 수 있다. 본 연구에서는 기온 데이터를 반영하여 24시간 이전에 전력수요를 예측하는 WaveNet 기반 딥러닝 모델을 개발하여, 실제 사용하고 있는 통계적 시계열 예측 기법의 정확도(MAPE 값 2%)보다 우수한 예측 성능을 달성하는 모델을 개발하고자 한다. 먼저 WaveNet의 핵심 구조인 팽창인과 1차원 합성곱 신경망 구조를 소개하고, 전력수요와 기온 데이터를 입력값으로 모델에 주입하기 위한 데이터 전처리 과정을 제시한다. 다음으로, 개선된 WaveNet 모델을 학습하고 검증하는 방법을 제시한다. 성능 비교 결과, WaveNet 기반 모델에 기온 데이터를 반영한 방법은 전체 검증데이터에 대해 MAPE 값 1.33%를 달성하였고, 동일한 구조의 모델에서 기온 데이터를 반영하지 않는 것(MAPE 값 2.31%)보다 우수한 전력수요 예측 결과를 나타내고 있음을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202222059037013&target=NART&cn=JAKO202222059037013",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기온 데이터를 반영한 전력수요 예측 딥러닝 모델 기온 데이터를 반영한 전력수요 예측 딥러닝 모델 기온 데이터를 반영한 전력수요 예측 딥러닝 모델 최근 전력수요를 예측하기 위해 통계기반 시계열 분석 기법을 대체하기 위해 딥러닝 기법을 활용한 연구가 활발히 진행되고 있다. 딥러닝 기반 전력수요 예측 연구 결과를 분석한 결과, LSTM 기반 예측 모델의 성능이 우수한 것으로 규명되었으나 장기간의 지역 범위 전력수요 예측에 대해 LSTM 기반 모델의 성능이 충분하지 않음을 확인할 수 있다. 본 연구에서는 기온 데이터를 반영하여 24시간 이전에 전력수요를 예측하는 WaveNet 기반 딥러닝 모델을 개발하여, 실제 사용하고 있는 통계적 시계열 예측 기법의 정확도(MAPE 값 2%)보다 우수한 예측 성능을 달성하는 모델을 개발하고자 한다. 먼저 WaveNet의 핵심 구조인 팽창인과 1차원 합성곱 신경망 구조를 소개하고, 전력수요와 기온 데이터를 입력값으로 모델에 주입하기 위한 데이터 전처리 과정을 제시한다. 다음으로, 개선된 WaveNet 모델을 학습하고 검증하는 방법을 제시한다. 성능 비교 결과, WaveNet 기반 모델에 기온 데이터를 반영한 방법은 전체 검증데이터에 대해 MAPE 값 1.33%를 달성하였고, 동일한 구조의 모델에서 기온 데이터를 반영하지 않는 것(MAPE 값 2.31%)보다 우수한 전력수요 예측 결과를 나타내고 있음을 확인할 수 있다."
        },
        {
          "rank": 38,
          "score": 0.7102029323577881,
          "doc_id": "ATN0044029065",
          "title": "TCN 딥러닝 모델을 이용한 최대전력 예측에 관한 연구",
          "abstract": "It is necessary to predict peak load accurately in order to supply electric power and operate the power system stably. Especially,it is more important to predict peak load accurately in winter and summer because peak load is higher than other seasons. If peakload is predicted to be higher than actual peak load, the start-up costs of power plants would increase. It causes economic loss to thecompany. On the other hand, if the peak load is predicted to be lower than the actual peak load, blackout may occur due to a lackof power plants capable of generating electricity. Economic losses and blackouts can be prevented by minimizing the prediction errorof the peak load. In this paper, the latest deep learning model such as TCN is used to minimize the prediction error of peak load. Evenif the same deep learning model is used, there is a difference in performance depending on the hyper-parameters. So, I propose methodsfor optimizing hyper-parameters of TCN for predicting the peak load. Data from 2006 to 2021 were input into the model and trained,and prediction error was tested using data in 2022. It was confirmed that the performance of the deep learning model optimized bythe methods proposed in this study is superior to other deep learning models.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0044029065&target=NART&cn=ATN0044029065",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "TCN 딥러닝 모델을 이용한 최대전력 예측에 관한 연구 TCN 딥러닝 모델을 이용한 최대전력 예측에 관한 연구 TCN 딥러닝 모델을 이용한 최대전력 예측에 관한 연구 It is necessary to predict peak load accurately in order to supply electric power and operate the power system stably. Especially,it is more important to predict peak load accurately in winter and summer because peak load is higher than other seasons. If peakload is predicted to be higher than actual peak load, the start-up costs of power plants would increase. It causes economic loss to thecompany. On the other hand, if the peak load is predicted to be lower than the actual peak load, blackout may occur due to a lackof power plants capable of generating electricity. Economic losses and blackouts can be prevented by minimizing the prediction errorof the peak load. In this paper, the latest deep learning model such as TCN is used to minimize the prediction error of peak load. Evenif the same deep learning model is used, there is a difference in performance depending on the hyper-parameters. So, I propose methodsfor optimizing hyper-parameters of TCN for predicting the peak load. Data from 2006 to 2021 were input into the model and trained,and prediction error was tested using data in 2022. It was confirmed that the performance of the deep learning model optimized bythe methods proposed in this study is superior to other deep learning models."
        },
        {
          "rank": 39,
          "score": 0.7092180252075195,
          "doc_id": "ART003001921",
          "title": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning",
          "abstract": "Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003001921&target=NART&cn=ART003001921",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Prediction Model of Inclination to Visit Jeju Tourist Attractions based on CNN Deep Learning Sentiment analysis can be applied to all texts generated from websites, blogs, messengers, etc. The study fulfills an artificial intelligence sentiment analysis estimating visiting evaluation opinions (reviews) and visitor ratings, and suggests a deep learning model which foretells either an affirmative or a negative inclination for new reviews. This study operates review big data about Jeju tourist attractions which are extracted from Google from October 1st, 2021 to November 30th, 2021. The normalization data used in the propensity prediction modeling of this study were divided into training data and test data at a 7.5:2.5 ratio, and the CNN classification neural network was used for learning. The predictive model of the research indicates an accuracy of approximately 84.72%, which shows that it can upgrade performance in the future as evaluating its error rate and learning precision."
        },
        {
          "rank": 40,
          "score": 0.707527220249176,
          "doc_id": "JAKO199911921528980",
          "title": "다층회귀예측신경망의 음성인식성능에 관한 연구",
          "abstract": "4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921528980&target=NART&cn=JAKO199911921528980",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다."
        },
        {
          "rank": 41,
          "score": 0.7058845162391663,
          "doc_id": "JAKO202305062334676",
          "title": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측",
          "abstract": "본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202305062334676&target=NART&cn=JAKO202305062334676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다."
        },
        {
          "rank": 42,
          "score": 0.7036384344100952,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 43,
          "score": 0.7029832601547241,
          "doc_id": "JAKO202518361202534",
          "title": "PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측",
          "abstract": "본 연구는 수도권(서울)의 2017~2024년 납(Pb) 농도 및 기상 데이터를 활용하여 일 단위 납 농도를 예측하는 딥러닝 기반 모델을 비교 분석하였다. 입력 변수로는 8개의 기상 요소와 과거 3일간 납 농도 값을 활용하였다. CNN, LSTM, GRU, TCN, Transformer, PNC 모델을 적용한 결과, PNC 모델이 시험 데이터 기준 RMSE 17.34, MAE 10.45로 가장 우수한 성능을 보였다. 본 연구는 중금속 예측에 있어 데이터 기반 모델의 적용 가능성을 확인하였으며, 향후 지역 확장 및 고농도 대응 성능 개선에 대한 연구가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202518361202534&target=NART&cn=JAKO202518361202534",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 본 연구는 수도권(서울)의 2017~2024년 납(Pb) 농도 및 기상 데이터를 활용하여 일 단위 납 농도를 예측하는 딥러닝 기반 모델을 비교 분석하였다. 입력 변수로는 8개의 기상 요소와 과거 3일간 납 농도 값을 활용하였다. CNN, LSTM, GRU, TCN, Transformer, PNC 모델을 적용한 결과, PNC 모델이 시험 데이터 기준 RMSE 17.34, MAE 10.45로 가장 우수한 성능을 보였다. 본 연구는 중금속 예측에 있어 데이터 기반 모델의 적용 가능성을 확인하였으며, 향후 지역 확장 및 고농도 대응 성능 개선에 대한 연구가 필요하다."
        },
        {
          "rank": 44,
          "score": 0.7026126980781555,
          "doc_id": "NPAP13451795",
          "title": "Continual Learning을 이용한 한국어 기계독해",
          "abstract": "기계 독해는 주어진 지문 내에서 질문에 대한 답을 기계가 찾아 답하는 문제이다. 딥러닝에서는 여러 데이터셋을 학습시킬 때에 이전에 학습했던 데이터의 weight값이 점차 사라지고 사라진 데이터에 대해 테스트 하였을때 성능이 떨어진 결과를 보인다. 이를 과거에 학습시킨 데이터의 정보를 계속 가진 채로 새로운 데이터를 학습할 수 있는 Continual learning을 통해 해결할 수 있고, 본 논문에서는 이 방법을 MRC에 적용시켜 학습시킨 후 한국어 자연어처리 Task인 Korquad 1.0의 MRC dev set을 통해 성능을 측정하였다. 세 개의 데이터셋중에서 랜덤하게 5만개를 추출하여 10stage를 학습시킨 50K 모델에서 추가로 Continual Learning의 Learning without Forgetting를 사용하여 학습시킨 50K-LWF 모델이 F1 92.57, EM 80.14의 성능을 보였고, BERT 베이스라인 모델의 성능 F1 91.68, EM 79.92에 비교하였을 때 F1, EM 각 0.89, 0.22의 향상이 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13451795&target=NART&cn=NPAP13451795",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Continual Learning을 이용한 한국어 기계독해 Continual Learning을 이용한 한국어 기계독해 Continual Learning을 이용한 한국어 기계독해 기계 독해는 주어진 지문 내에서 질문에 대한 답을 기계가 찾아 답하는 문제이다. 딥러닝에서는 여러 데이터셋을 학습시킬 때에 이전에 학습했던 데이터의 weight값이 점차 사라지고 사라진 데이터에 대해 테스트 하였을때 성능이 떨어진 결과를 보인다. 이를 과거에 학습시킨 데이터의 정보를 계속 가진 채로 새로운 데이터를 학습할 수 있는 Continual learning을 통해 해결할 수 있고, 본 논문에서는 이 방법을 MRC에 적용시켜 학습시킨 후 한국어 자연어처리 Task인 Korquad 1.0의 MRC dev set을 통해 성능을 측정하였다. 세 개의 데이터셋중에서 랜덤하게 5만개를 추출하여 10stage를 학습시킨 50K 모델에서 추가로 Continual Learning의 Learning without Forgetting를 사용하여 학습시킨 50K-LWF 모델이 F1 92.57, EM 80.14의 성능을 보였고, BERT 베이스라인 모델의 성능 F1 91.68, EM 79.92에 비교하였을 때 F1, EM 각 0.89, 0.22의 향상이 있었다."
        },
        {
          "rank": 45,
          "score": 0.7017248868942261,
          "doc_id": "ATN0037496660",
          "title": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교",
          "abstract": "Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037496660&target=NART&cn=ATN0037496660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model."
        },
        {
          "rank": 46,
          "score": 0.7009931206703186,
          "doc_id": "ATN0035906971",
          "title": "딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구",
          "abstract": "In this research, we compare the explanatory power between linear regression model and deep-learning model when estimating stock returns. As predicted, the deep-learning model shows statistically significant improvement over linear regression model, although the improvement is not economically meaningful. We further investigate the effects of deep-learning model using different parameters and pre-processing. The results show that the predictive power of deep-learning model can be worse-off than that of linear model if it fails to select optimal parameters. Especially, it is important to choose adequate deep-learning parameters not to overfit the data, because the accounting data (which is at most quarterly) may not be sufficient enough for the deep model structure. Further, we show that the predictive power using researchers’ domain knowledge is sometimes better off than that relying simply on the deep-learning model. For instance, denomination with total assets brings better results than non-denomination. Another interesting finding is that winsorizing extreme values brings lower explanatory power when we use the deep-learning model. Such finding implies that, by removing extreme values, we may lose useful information in the parameter estimation. The results of this paper will help future research decide whether to utilize deep learning model or linear regression model",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0035906971&target=NART&cn=ATN0035906971",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 In this research, we compare the explanatory power between linear regression model and deep-learning model when estimating stock returns. As predicted, the deep-learning model shows statistically significant improvement over linear regression model, although the improvement is not economically meaningful. We further investigate the effects of deep-learning model using different parameters and pre-processing. The results show that the predictive power of deep-learning model can be worse-off than that of linear model if it fails to select optimal parameters. Especially, it is important to choose adequate deep-learning parameters not to overfit the data, because the accounting data (which is at most quarterly) may not be sufficient enough for the deep model structure. Further, we show that the predictive power using researchers’ domain knowledge is sometimes better off than that relying simply on the deep-learning model. For instance, denomination with total assets brings better results than non-denomination. Another interesting finding is that winsorizing extreme values brings lower explanatory power when we use the deep-learning model. Such finding implies that, by removing extreme values, we may lose useful information in the parameter estimation. The results of this paper will help future research decide whether to utilize deep learning model or linear regression model"
        },
        {
          "rank": 47,
          "score": 0.7008033394813538,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 48,
          "score": 0.7005646824836731,
          "doc_id": "ATN0049305983",
          "title": "머신러닝과 딥러닝 언어모델을 활용한 한국어 학습자 작문의 주제 자동 분류 연구",
          "abstract": "본 연구의 목적은 머신러닝과 딥러닝 언어모델을 활용하여 한국어 학습자 쓰기의 주제를 자동으로 분류할 수 있을지 그 가능성을 탐색해 보는 데 있다. 머신러닝 기반의 언어모델인 랜덤 포레스트를 기준 모델로 삼아 딥러닝 기반의 언어모델의 한국어 학습자 쓰기 주제 분류 성능을 평가해 보았는데 머신러닝 기반의 언어모델인 랜덤 포레스트의 경우 정확도가 약 96.5%로 나타났다. 반면에 딥러닝 기반의 언어모델인 KoBERT의 정확도는 약 64.25%로 랜덤 포레스트에 비해 훨씬 낮은 정확도를 보였으며 KoELECTRA의 정확도는 약 97.25%로 랜덤 포레스트와 비교해 약간 높은 정확도를 보였다. 3가지 모델 간의 주제 예측 결과를 비교해 본 결과 KoBERT의 경우, 낮은 정확도에서도 알 수 있듯이 인간의 직관으로 이해가 어려운 예측 결과를 보였고 나머지 두 모델이 정확히 주제를 예측한 작문에 대해서도 예측을 실패한 사례가 나타났다. 랜덤 포레스트와 KoELECTRA의 경우에는 예측 오류 양상에 있어서 비슷한 양상을 보였는데 두 알고리듬 간의 성능 차이는 크지 않았다. 3가지 알고리듬에서 공통적으로 나타난 예측 오류 양상은 주제에 특화된 어휘가 주로 사용되는 작문이 아닌 일반적으로 흔히 쓰이는 어휘가 주로 사용되는 작문의 경우에 주제 판별 성능이 떨어진다는 점이다. 또한, 작문의 일부 내용이 다른 주제의 내용을 포함하고 있을 때 주제 예측에 실패하는 사례들이 많이 나타났다. 이러한 한계점을 극복하기 위해서는 다양한 장르의 작문을 세부적으로 분석할 필요가 있으며 기존 구축된 학습자의 작문을 활용하는 방법론 외에 다양한 방법론에 대한 실험이 지속되어야 할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0049305983&target=NART&cn=ATN0049305983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝 언어모델을 활용한 한국어 학습자 작문의 주제 자동 분류 연구 머신러닝과 딥러닝 언어모델을 활용한 한국어 학습자 작문의 주제 자동 분류 연구 머신러닝과 딥러닝 언어모델을 활용한 한국어 학습자 작문의 주제 자동 분류 연구 본 연구의 목적은 머신러닝과 딥러닝 언어모델을 활용하여 한국어 학습자 쓰기의 주제를 자동으로 분류할 수 있을지 그 가능성을 탐색해 보는 데 있다. 머신러닝 기반의 언어모델인 랜덤 포레스트를 기준 모델로 삼아 딥러닝 기반의 언어모델의 한국어 학습자 쓰기 주제 분류 성능을 평가해 보았는데 머신러닝 기반의 언어모델인 랜덤 포레스트의 경우 정확도가 약 96.5%로 나타났다. 반면에 딥러닝 기반의 언어모델인 KoBERT의 정확도는 약 64.25%로 랜덤 포레스트에 비해 훨씬 낮은 정확도를 보였으며 KoELECTRA의 정확도는 약 97.25%로 랜덤 포레스트와 비교해 약간 높은 정확도를 보였다. 3가지 모델 간의 주제 예측 결과를 비교해 본 결과 KoBERT의 경우, 낮은 정확도에서도 알 수 있듯이 인간의 직관으로 이해가 어려운 예측 결과를 보였고 나머지 두 모델이 정확히 주제를 예측한 작문에 대해서도 예측을 실패한 사례가 나타났다. 랜덤 포레스트와 KoELECTRA의 경우에는 예측 오류 양상에 있어서 비슷한 양상을 보였는데 두 알고리듬 간의 성능 차이는 크지 않았다. 3가지 알고리듬에서 공통적으로 나타난 예측 오류 양상은 주제에 특화된 어휘가 주로 사용되는 작문이 아닌 일반적으로 흔히 쓰이는 어휘가 주로 사용되는 작문의 경우에 주제 판별 성능이 떨어진다는 점이다. 또한, 작문의 일부 내용이 다른 주제의 내용을 포함하고 있을 때 주제 예측에 실패하는 사례들이 많이 나타났다. 이러한 한계점을 극복하기 위해서는 다양한 장르의 작문을 세부적으로 분석할 필요가 있으며 기존 구축된 학습자의 작문을 활용하는 방법론 외에 다양한 방법론에 대한 실험이 지속되어야 할 것이다."
        },
        {
          "rank": 49,
          "score": 0.6996656656265259,
          "doc_id": "JAKO201723840541311",
          "title": "딥러닝을 이용한 영상 수평 보정",
          "abstract": "본 논문은 딥 러닝(deep learning)을 이용하여 입력 영상의 기울어진 정도를 측정하고 수평에 맞게 바로 세우는 방법을 제시한다. 기존 방법들은 일반적으로 영상 내에서 선분, 평면 등 하위 레벨의 특징들을 추출한 후 이를 이용해 영상의 기울어진 정도를 측정한다. 이러한 방법들은 영상 내에 선이나 평면이 존재하지 않는 경우에는 제대로 동작하지 않는다. 본 논문에서는 대규모 데이터 셋을 통해 영상의 다양한 특징들에 대해 학습 가능한 Convolutional Neural Network (CNN)를 이용하여 인물이나 복잡한 배경으로 구성된 기울어진 영상에 대해서도 강인하게 동작하는 프레임워크를 제시한다. 또한, 네트워크에 가변 공간적 (adaptive spatial) pooling 레이어를 추가하여 영상의 다중 스케일 특징을 동시에 고려할 수 있게 하여 영상의 기울어진 정도를 측정하는 성능을 높인다. 실험 결과를 통해 다양한 콘텐츠를 포함한 영상의 기울어짐을 높은 정확도로 바로 세울 수 있음을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840541311&target=NART&cn=JAKO201723840541311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 영상 수평 보정 딥러닝을 이용한 영상 수평 보정 딥러닝을 이용한 영상 수평 보정 본 논문은 딥 러닝(deep learning)을 이용하여 입력 영상의 기울어진 정도를 측정하고 수평에 맞게 바로 세우는 방법을 제시한다. 기존 방법들은 일반적으로 영상 내에서 선분, 평면 등 하위 레벨의 특징들을 추출한 후 이를 이용해 영상의 기울어진 정도를 측정한다. 이러한 방법들은 영상 내에 선이나 평면이 존재하지 않는 경우에는 제대로 동작하지 않는다. 본 논문에서는 대규모 데이터 셋을 통해 영상의 다양한 특징들에 대해 학습 가능한 Convolutional Neural Network (CNN)를 이용하여 인물이나 복잡한 배경으로 구성된 기울어진 영상에 대해서도 강인하게 동작하는 프레임워크를 제시한다. 또한, 네트워크에 가변 공간적 (adaptive spatial) pooling 레이어를 추가하여 영상의 다중 스케일 특징을 동시에 고려할 수 있게 하여 영상의 기울어진 정도를 측정하는 성능을 높인다. 실험 결과를 통해 다양한 콘텐츠를 포함한 영상의 기울어짐을 높은 정확도로 바로 세울 수 있음을 확인할 수 있다."
        },
        {
          "rank": 50,
          "score": 0.6994249224662781,
          "doc_id": "NART126947704",
          "title": "Hybrid CNN-LSTM for Predicting Diabetes: A Review",
          "abstract": "<P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART126947704&target=NART&cn=NART126947704",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review <P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>"
        }
      ]
    },
    {
      "query": "해당 딥 러닝 모델의 출력 카테고리는 무엇인가요?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7759596109390259,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 2,
          "score": 0.7556201219558716,
          "doc_id": "JAKO201620853199880",
          "title": "딥러닝의 모형과 응용사례",
          "abstract": "딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201620853199880&target=NART&cn=JAKO201620853199880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다."
        },
        {
          "rank": 3,
          "score": 0.737244725227356,
          "doc_id": "JAKO201726163356540",
          "title": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델",
          "abstract": "본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163356540&target=NART&cn=JAKO201726163356540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 특수일 분리와 예측요소 확장을 이용한 전력수요 예측 딥 러닝 모델 본 연구는 전력수요 패턴이 다른 평일과 특수일 데이터가 가지는 상관관계를 분석하여, 별도의 데이터 셋을 구축하고, 각 데이터 셋에 적합한 딥 러닝 네트워크를 이용하여, 전력수요예측 오차를 감소하는 방안을 제시하였다. 또한, 기본적인 전력수요 예측요소인 기상요소에 환경요소, 구분요소 등 다양한 예측요소를 추가하여 예측율을 향상하는 방안을 제시하였다. 전체데이터는 시계열 데이터 학습에 적합한 LSTM을 이용하여 전력수요예측을 하였으며, 특수일 데이터는 DNN을 이용하여 전력수요예측을 하였다. 실험결과 기상요소 이외의 예측요소 추가를 통해 예측율이 향상되었다. 전체 데이터 셋의 평균 RMSE는 LSTM이 0.2597이며, DNN이 0.5474로 LSTM이 우수한 예측율을 보였다. 특수일 데이터 셋의 평균 RMSE는 0.2201로 DNN이 LSTM보다 우수한 예측율을 보였다. 또한, 전체 데이터 셋의 LSTM의 MAPE는 2.74 %이며, 특수 일의 MAPE는 3.07 %를 나타냈다."
        },
        {
          "rank": 4,
          "score": 0.717049241065979,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 5,
          "score": 0.7123323082923889,
          "doc_id": "JAKO201923233204235",
          "title": "딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구",
          "abstract": "Classification of radar signals in the field of electronic warfare is a problem of discriminating threat types by analyzing enemy threat radar signals such as aircraft, radar, and missile received through electronic warfare equipment. Recent radar systems have adopted a variety of modulation schemes that are different from those used in conventional systems, and are often difficult to analyze using existing algorithms. Also, it is necessary to design a robust algorithm for the signal received in the real environment due to the environmental influence and the measurement error due to the characteristics of the hardware. In this paper, we propose a radar signal classification method which are not affected by radar signal modulation methods and noise generation by using deep learning techniques.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201923233204235&target=NART&cn=JAKO201923233204235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구 딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구 딥 러닝 기법을 이용한 레이더 신호 분류 모델 연구 Classification of radar signals in the field of electronic warfare is a problem of discriminating threat types by analyzing enemy threat radar signals such as aircraft, radar, and missile received through electronic warfare equipment. Recent radar systems have adopted a variety of modulation schemes that are different from those used in conventional systems, and are often difficult to analyze using existing algorithms. Also, it is necessary to design a robust algorithm for the signal received in the real environment due to the environmental influence and the measurement error due to the characteristics of the hardware. In this paper, we propose a radar signal classification method which are not affected by radar signal modulation methods and noise generation by using deep learning techniques."
        },
        {
          "rank": 6,
          "score": 0.7034979462623596,
          "doc_id": "ATN0038661375",
          "title": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험",
          "abstract": "Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038661375&target=NART&cn=ATN0038661375",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
        },
        {
          "rank": 7,
          "score": 0.6998230218887329,
          "doc_id": "NART111572455",
          "title": "동풍 예측을 위한 딥러닝 기반의 예측 모델",
          "abstract": "Understanding the characteristics of the easterly-related weather phenomena in the eastern coast in Korean Peninsula is very important to analyze abnormal atmospheric phenomena such as heavy rain, heavy snow, and hot-dry wind. As data science techniques have steadily improved, data driven prediction models are becoming more powerful in the quantitative forecasting weather. In this paper, we apply the deep learning based methods to predict the presence or absence of the easterly wind around the Korean peninsula. The DNN, CNN, and LSTM based deep learning approaches for prediction of easterly wind are experimented and compared for the Korean Peninsula and East Sea. Vertical pressure levels of ERA5 data in year 2013 and 2014 are used.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111572455&target=NART&cn=NART111572455",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "동풍 예측을 위한 딥러닝 기반의 예측 모델 동풍 예측을 위한 딥러닝 기반의 예측 모델 동풍 예측을 위한 딥러닝 기반의 예측 모델 Understanding the characteristics of the easterly-related weather phenomena in the eastern coast in Korean Peninsula is very important to analyze abnormal atmospheric phenomena such as heavy rain, heavy snow, and hot-dry wind. As data science techniques have steadily improved, data driven prediction models are becoming more powerful in the quantitative forecasting weather. In this paper, we apply the deep learning based methods to predict the presence or absence of the easterly wind around the Korean peninsula. The DNN, CNN, and LSTM based deep learning approaches for prediction of easterly wind are experimented and compared for the Korean Peninsula and East Sea. Vertical pressure levels of ERA5 data in year 2013 and 2014 are used."
        },
        {
          "rank": 8,
          "score": 0.699508786201477,
          "doc_id": "JAKO202126048601456",
          "title": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구",
          "abstract": "딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202126048601456&target=NART&cn=JAKO202126048601456",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다."
        },
        {
          "rank": 9,
          "score": 0.699418306350708,
          "doc_id": "JAKO201912758458868",
          "title": "딥러닝 개념을 위한 인공지능 교육 프로그램",
          "abstract": "본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201912758458868&target=NART&cn=JAKO201912758458868",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 딥러닝 개념을 위한 인공지능 교육 프로그램 본 연구는 초등학생의 딥러닝 개념 학습을 위한 교육 프로그램을 개발하는 것이다. 교육 프로그램의 모델은 CT요소 중심 모델을 토대로 딥러닝 교수학습모델을 개발하였다. 개발한 프로그램의 주제는 인공지능의 이미지 인식 CNN알고리즘으로 정하고, 9개 차시 교육프로그램을 개발하였다. 프로그램은 6학년을 대상으로 2주간에 걸쳐 적용을 하였다. 프로그램에 대한 학습 적합도 검사는 전문가 타당도 분석 결과로 CVR이 타당하게 나왔다. 학습자 수준 적합도와 교사 지도 수준의 적합도 문항의 경우 .80이하로 나타났으며 .96이 넘은 학습 환경과 매체의 적합도 문항에서는 높게 나타났다. 학생들의 만족도 분석 결과 학습의 이해도와 유익성, 흥미도, 학습자료 등에 대해서 평균 4.0이상을 보여 긍정적인 평가를 하여 본 연구의 가치를 확인할 수 있었다."
        },
        {
          "rank": 10,
          "score": 0.6983076333999634,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 11,
          "score": 0.6962634921073914,
          "doc_id": "JAKO202433861648179",
          "title": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교",
          "abstract": "본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202433861648179&target=NART&cn=JAKO202433861648179",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다."
        },
        {
          "rank": 12,
          "score": 0.6954266428947449,
          "doc_id": "JAKO201734158606474",
          "title": "제조업의 심층신경망 기계학습(딥러닝)",
          "abstract": "인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734158606474&target=NART&cn=JAKO201734158606474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다."
        },
        {
          "rank": 13,
          "score": 0.6944394111633301,
          "doc_id": "ATN0051728135",
          "title": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구",
          "abstract": "하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0051728135&target=NART&cn=ATN0051728135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 딥러닝 기반 실시간 하천 홍수 예측 정확도 개선을 위한 학습데이터 최적화 연구 하천 수위 예측의 주요 목적 중 하나는 홍수예경보 발령을 위한 기준으로 활용하는 것이다. 본 연구에서는 딥러닝 기반의 하천 수위 예측 모델을 홍수예경보 측면에서 효과적으로 활용하기 위해 학습데이터를 최적화하고, 딥러닝 모델의 정확도 향상을 평가하기 위해 딥러닝 모델의 자동 설계 및 최적화를 지원하는 AutoKeras를 활용하여 인위적인 요인을 배제한 모델을 구축하였다. 한탄강 상류유역을 대상지역으로 선정하고, 3개의 수위관측소와 유역평균강우 데이터를 구축하였고, 구축된 데이터를 이용하여 수위 변화 여부와 관계없이 강우가 발생한 모든 학습 데이터 셋을 사용한 모델(Model 1)과 일정 수준 이상의 수위 상승 변화가 있는 학습데이터 셋을 사용한 딥러닝 모델(Model 2)을 개발하여 한탄강 상류 한탄대교의 수위 및 홍수 예측 성능을 평가하였다. 실시간 하천 홍수예측 결과, 시계열 수위 예측에서 Model 1이 더 많은 데이터를 활용함으로써 상관계수와 평균제곱근오차(RMSE)에서 다소 우수한 성능을 보였다. 반면, Model 2는 홍수 예측에서 재현율(recall), F1-score, 임계성공지수(CSI) 등의 지표에서 더 뛰어난 성과를 보였다. 본 결과는 학습데이터의 특성과 구성 방식이 딥러닝 모델의 예측 능력에 큰 영향을 미친다는 것을 보여주며, 홍수와 같은 특정 사건을 예측하려면 수위 상승과 같은 핵심 요인 위주의 데이터를 더 집중적으로 학습시킬 필요가 있음을 시사한다."
        },
        {
          "rank": 14,
          "score": 0.6939776539802551,
          "doc_id": "DIKO0015889140",
          "title": "딥 러닝 프레임워크 성능 비교 및 개선 방안",
          "abstract": "현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015889140&target=NART&cn=DIKO0015889140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다."
        },
        {
          "rank": 15,
          "score": 0.6917592287063599,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 16,
          "score": 0.691649317741394,
          "doc_id": "JAKO202314857616824",
          "title": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석",
          "abstract": "클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202314857616824&target=NART&cn=JAKO202314857616824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다."
        },
        {
          "rank": 17,
          "score": 0.6907380223274231,
          "doc_id": "JAKO202334662554660",
          "title": "증강형 딥러닝 기반 미세먼지 예측 시스템",
          "abstract": "딥러닝은 심층신경망(Deep Neural Network)을 구축하고 대량의 훈련 데이터를 수집한 후, 구축된 신경망을 오랫동안 학습 시켜야 한다. 만약, 학습이 제대로 진행되지 않거나 과적합이 발생하면, 학습은 실패하게 된다. 현재까지 개발되고 있는 딥러닝 도구들을 사용할 경우, 훈련데이터 수집과 학습에 많은 시간이 소요된다. 하지만, 모바일 환경의 급격한 도래와 센서 데이터의 증가로 인해, 신경망 학습에 걸리는 시간을 획기적으로 줄일 수 있는 실시간 증강형 딥러닝 기술에 대한 요구가 급격하게 증가하고 있다. 본 연구에서는 미세먼지 센서를 장착한 아두이노 시스템을 사용하여 실시간 증강형 딥러닝 시스템을 구현 하였다. 구현된 시스템에서는 미세먼지 데이터를 5초마다 측정하고 최대 120개가 축적이 되면, 기존에 축적된 데이터와 새로이 축적된 데이터를 데이터셋으로 사용하여 학습을 수행하도록 하였다. 학습 수행을 위한 신경망은 입력층 1개, 은닉층 1개, 출력등 1개로 구성하였다. 구현된 시스템에 대한 성능을 평가하기 위해 학습 시간과 평균 제곱근 오차(root mean square error, RMSE)를 측정 하였다. 실험 결과, 평균 학습 오차는 0.04053796이었으며, 학습주기당(1 에포크) 평균 학습 시간은 3,447 초 정도의 시간이 걸렸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202334662554660&target=NART&cn=JAKO202334662554660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "증강형 딥러닝 기반 미세먼지 예측 시스템 증강형 딥러닝 기반 미세먼지 예측 시스템 증강형 딥러닝 기반 미세먼지 예측 시스템 딥러닝은 심층신경망(Deep Neural Network)을 구축하고 대량의 훈련 데이터를 수집한 후, 구축된 신경망을 오랫동안 학습 시켜야 한다. 만약, 학습이 제대로 진행되지 않거나 과적합이 발생하면, 학습은 실패하게 된다. 현재까지 개발되고 있는 딥러닝 도구들을 사용할 경우, 훈련데이터 수집과 학습에 많은 시간이 소요된다. 하지만, 모바일 환경의 급격한 도래와 센서 데이터의 증가로 인해, 신경망 학습에 걸리는 시간을 획기적으로 줄일 수 있는 실시간 증강형 딥러닝 기술에 대한 요구가 급격하게 증가하고 있다. 본 연구에서는 미세먼지 센서를 장착한 아두이노 시스템을 사용하여 실시간 증강형 딥러닝 시스템을 구현 하였다. 구현된 시스템에서는 미세먼지 데이터를 5초마다 측정하고 최대 120개가 축적이 되면, 기존에 축적된 데이터와 새로이 축적된 데이터를 데이터셋으로 사용하여 학습을 수행하도록 하였다. 학습 수행을 위한 신경망은 입력층 1개, 은닉층 1개, 출력등 1개로 구성하였다. 구현된 시스템에 대한 성능을 평가하기 위해 학습 시간과 평균 제곱근 오차(root mean square error, RMSE)를 측정 하였다. 실험 결과, 평균 학습 오차는 0.04053796이었으며, 학습주기당(1 에포크) 평균 학습 시간은 3,447 초 정도의 시간이 걸렸다."
        },
        {
          "rank": 18,
          "score": 0.6894307136535645,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 19,
          "score": 0.6890231370925903,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 20,
          "score": 0.6875836849212646,
          "doc_id": "JAKO202223540366088",
          "title": "이미지 학습을 위한 딥러닝 프레임워크 비교분석",
          "abstract": "딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202223540366088&target=NART&cn=JAKO202223540366088",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다."
        },
        {
          "rank": 21,
          "score": 0.6860251426696777,
          "doc_id": "JAKO201713056893580",
          "title": "딥 러닝 프레임워크의 비교 및 분석",
          "abstract": "딥 러닝은 사람이 가르치지 않아도 컴퓨터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 딥 러닝은 세상을 이해하고 감지하는 인공지능을 개발하는데 가장 촉망받는 기술이 되고 있으며, 구글, 바이두, 페이스북 등이 가장 앞서서 개발을 하고 있다. 본 논문에서는 딥 러닝을 구현하는 딥 러닝 프레임워크의 종류에 대해 논의하고, 딥 러닝 프레임워크의 영상과 음성 인식 분야의 효율성에 대해 비교, 분석하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713056893580&target=NART&cn=JAKO201713056893580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 프레임워크의 비교 및 분석 딥 러닝 프레임워크의 비교 및 분석 딥 러닝 프레임워크의 비교 및 분석 딥 러닝은 사람이 가르치지 않아도 컴퓨터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 딥 러닝은 세상을 이해하고 감지하는 인공지능을 개발하는데 가장 촉망받는 기술이 되고 있으며, 구글, 바이두, 페이스북 등이 가장 앞서서 개발을 하고 있다. 본 논문에서는 딥 러닝을 구현하는 딥 러닝 프레임워크의 종류에 대해 논의하고, 딥 러닝 프레임워크의 영상과 음성 인식 분야의 효율성에 대해 비교, 분석하고자 한다."
        },
        {
          "rank": 22,
          "score": 0.6853681802749634,
          "doc_id": "JAKO202108360626662",
          "title": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측",
          "abstract": "본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108360626662&target=NART&cn=JAKO202108360626662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다."
        },
        {
          "rank": 23,
          "score": 0.6847522258758545,
          "doc_id": "DIKO0017011976",
          "title": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형",
          "abstract": "본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017011976&target=NART&cn=DIKO0017011976",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다."
        },
        {
          "rank": 24,
          "score": 0.6842927932739258,
          "doc_id": "JAKO202518361202534",
          "title": "PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측",
          "abstract": "본 연구는 수도권(서울)의 2017~2024년 납(Pb) 농도 및 기상 데이터를 활용하여 일 단위 납 농도를 예측하는 딥러닝 기반 모델을 비교 분석하였다. 입력 변수로는 8개의 기상 요소와 과거 3일간 납 농도 값을 활용하였다. CNN, LSTM, GRU, TCN, Transformer, PNC 모델을 적용한 결과, PNC 모델이 시험 데이터 기준 RMSE 17.34, MAE 10.45로 가장 우수한 성능을 보였다. 본 연구는 중금속 예측에 있어 데이터 기반 모델의 적용 가능성을 확인하였으며, 향후 지역 확장 및 고농도 대응 성능 개선에 대한 연구가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202518361202534&target=NART&cn=JAKO202518361202534",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 PNC 딥러닝 모델을 이용한 미세먼지 납 농도 예측 본 연구는 수도권(서울)의 2017~2024년 납(Pb) 농도 및 기상 데이터를 활용하여 일 단위 납 농도를 예측하는 딥러닝 기반 모델을 비교 분석하였다. 입력 변수로는 8개의 기상 요소와 과거 3일간 납 농도 값을 활용하였다. CNN, LSTM, GRU, TCN, Transformer, PNC 모델을 적용한 결과, PNC 모델이 시험 데이터 기준 RMSE 17.34, MAE 10.45로 가장 우수한 성능을 보였다. 본 연구는 중금속 예측에 있어 데이터 기반 모델의 적용 가능성을 확인하였으며, 향후 지역 확장 및 고농도 대응 성능 개선에 대한 연구가 필요하다."
        },
        {
          "rank": 25,
          "score": 0.6836073398590088,
          "doc_id": "NPAP12898051",
          "title": "딥러닝 프레임워크 비교 및 분석",
          "abstract": "딥러닝(Deep Learning)을 효과적으로 연구하고 개발할 수 있도록 도와주는 다양한 딥러닝 프레임워크(Deep Learning Framework)가 있다. 딥러닝 프레임워크는 현재 100 가지도 넘는 종류가 있다. 그렇기 때문에 개발의 목적에 가장 적합한 딥러닝 프레임워크를 선택하는 것은 쉽지 않다. 본고에서는 5가지 대표적인 딥러닝 프레임워크에 대해서 각각의 특징을 분석하고 비교한다. 이를 통하여 딥러닝을 개발하기 전에 개발 목적에 적합한 프레임워크를 선택할 수 있는 간단한 안목을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12898051&target=NART&cn=NPAP12898051",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 프레임워크 비교 및 분석 딥러닝 프레임워크 비교 및 분석 딥러닝 프레임워크 비교 및 분석 딥러닝(Deep Learning)을 효과적으로 연구하고 개발할 수 있도록 도와주는 다양한 딥러닝 프레임워크(Deep Learning Framework)가 있다. 딥러닝 프레임워크는 현재 100 가지도 넘는 종류가 있다. 그렇기 때문에 개발의 목적에 가장 적합한 딥러닝 프레임워크를 선택하는 것은 쉽지 않다. 본고에서는 5가지 대표적인 딥러닝 프레임워크에 대해서 각각의 특징을 분석하고 비교한다. 이를 통하여 딥러닝을 개발하기 전에 개발 목적에 적합한 프레임워크를 선택할 수 있는 간단한 안목을 제시한다."
        },
        {
          "rank": 26,
          "score": 0.6832438707351685,
          "doc_id": "NART118947969",
          "title": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction",
          "abstract": "<P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118947969&target=NART&cn=NART118947969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction <P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>"
        },
        {
          "rank": 27,
          "score": 0.6832374334335327,
          "doc_id": "JAKO202116047225054",
          "title": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어",
          "abstract": "최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116047225054&target=NART&cn=JAKO202116047225054",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 신뢰성있는 딥러닝 기반 분석 모델을 참조하기 위한 딥러닝 기술 언어 최근 딥러닝은 하드웨어 성능이 향상됨에 따라 자연어 처리, 영상 인식 등의 다양한 기술에 접목되어 활용되고 있다. 이러한 기술들을 활용해 지능형 교통 시스템(ITS), 스마트홈, 헬스케어 등의 산업분야에서 데이터를 분석하여 고속도로 속도위반 차량 검출, 에너지 사용량 제어, 응급상황 등과 같은 고품질의 서비스를 제공하며, 고품질의 서비스를 제공하기 위해서는 정확도가 향상된 딥러닝 모델이 적용되어야 한다. 이를 위해 서비스 환경의 데이터를 분석하기 위한 딥러닝 모델을 개발할 때, 개발자는 신뢰성이 검증된 최신의 딥러닝 모델을 적용할 수 있어야 한다. 이는 개발자가 참조하는 딥러닝 모델에 적용된 학습 데이터셋의 정확도를 측정하여 검증할 수 있다. 이러한 검증을 위해서 개발자는 학습 데이터셋, 딥러닝의 계층구조 및 개발 환경 등과 같은 내용을 포함하는 딥러닝 모델을 문서화하여 적용하기 위한 구조적인 정보가 필요하다. 본 논문에서는 신뢰성있는 딥러닝 기반 데이터 분석 모델을 참조하기 위한 딥러닝 기술 언어를 제안한다. 제안하는 기술 언어는 신뢰성 있는 딥러닝 모델을 개발하는데 필요한 학습데이터셋, 개발 환경 및 설정 등의 정보와 더불어 딥러닝 모델의 계층구조를 표현할 수 있다. 제안하는 딥러닝 기술 언어를 이용하여 개발자는 지능형 교통 시스템에서 참조하는 분석 모델의 정확도를 검증할 수 있다. 실험에서는 제안하는 언어의 유효성을 검증하기 위해, 번호판 인식 모델을 중심으로 딥러닝 기술 문서의 적용과정을 보인다."
        },
        {
          "rank": 28,
          "score": 0.6816741228103638,
          "doc_id": "JAKO202128837709024",
          "title": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법",
          "abstract": "딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837709024&target=NART&cn=JAKO202128837709024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다."
        },
        {
          "rank": 29,
          "score": 0.6812539100646973,
          "doc_id": "JAKO202108848920380",
          "title": "딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구",
          "abstract": "The increased turbidity in rivers during flood events has various effects on water environmental management, including drinking water supply systems. Thus, prediction of turbid water is essential for water environmental management. Recently, various advanced machine learning algorithms have been increasingly used in water environmental management. Ensemble machine learning algorithms such as random forest (RF) and gradient boosting decision tree (GBDT) are some of the most popular machine learning algorithms used for water environmental management, along with deep learning algorithms such as recurrent neural networks. In this study GBDT, an ensemble machine learning algorithm, and gated recurrent unit (GRU), a recurrent neural networks algorithm, are used for model development to predict turbidity in a river. The observation frequencies of input data used for the model were 2, 4, 8, 24, 48, 120 and 168 h. The root-mean-square error-observations standard deviation ratio (RSR) of GRU and GBDT ranges between 0.182~0.766 and 0.400~0.683, respectively. Both models show similar prediction accuracy with RSR of 0.682 for GRU and 0.683 for GBDT. The GRU shows better prediction accuracy when the observation frequency is relatively short (i.e., 2, 4, and 8 h) where GBDT shows better prediction accuracy when the observation frequency is relatively long (i.e. 48, 120, 160 h). The results suggest that the characteristics of input data should be considered to develop an appropriate model to predict turbidity.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108848920380&target=NART&cn=JAKO202108848920380",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 딥러닝과 앙상블 머신러닝 모형의 하천 탁도 예측 특성 비교 연구 The increased turbidity in rivers during flood events has various effects on water environmental management, including drinking water supply systems. Thus, prediction of turbid water is essential for water environmental management. Recently, various advanced machine learning algorithms have been increasingly used in water environmental management. Ensemble machine learning algorithms such as random forest (RF) and gradient boosting decision tree (GBDT) are some of the most popular machine learning algorithms used for water environmental management, along with deep learning algorithms such as recurrent neural networks. In this study GBDT, an ensemble machine learning algorithm, and gated recurrent unit (GRU), a recurrent neural networks algorithm, are used for model development to predict turbidity in a river. The observation frequencies of input data used for the model were 2, 4, 8, 24, 48, 120 and 168 h. The root-mean-square error-observations standard deviation ratio (RSR) of GRU and GBDT ranges between 0.182~0.766 and 0.400~0.683, respectively. Both models show similar prediction accuracy with RSR of 0.682 for GRU and 0.683 for GBDT. The GRU shows better prediction accuracy when the observation frequency is relatively short (i.e., 2, 4, and 8 h) where GBDT shows better prediction accuracy when the observation frequency is relatively long (i.e. 48, 120, 160 h). The results suggest that the characteristics of input data should be considered to develop an appropriate model to predict turbidity."
        },
        {
          "rank": 30,
          "score": 0.6808494329452515,
          "doc_id": "ATN0037496660",
          "title": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교",
          "abstract": "Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037496660&target=NART&cn=ATN0037496660",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 수요 패턴 별 최적 머신러닝 수요예측 모델 성능 비교 Demand forecasting is a way to manage resources by forecasting demands for products, so it has direct impacts on corporate resources and budget management. Based on these reasons, research on improving forecasting performances of demand forecasting models. In this research, 4 demand patterns for items were analyzed to improve demand prediction performance, and the optimal model was proposed. The data used to compare the performance were the demand data from each quarter for maintenance items for a T-50 aircraft of Republic of Korea air force. First, the demand patterns for the items adopted average demand interval(ADI) and coefficient of variation(CV) and were categorized into smooth, lumpy, intermittent, and erratic items. In this research, to compare the performance of demand forecasting models derived from different algorithms, 5 types of machine learning algorithms and 2 types of deep learning algorithms were used to construct demand forecasting models. In machine learning algorithms, there are ensemble learning such as random forest regression, adaboost, extra trees regression, bagging, gradient boosting regression and deep learning algorithm such as long-short term memory(LSTM) and deep neural network(DNN). We can confirm that item accuracy is 0.61% and quantity accuracy is 0.09% better than that of consistent models when the demand forecast results are derived by selecting models suitable for four types according to demand patterns. We expect that efficient demand management by experts will be achieved if the application of the proposed model."
        },
        {
          "rank": 31,
          "score": 0.6801949739456177,
          "doc_id": "JAKO202116954704821",
          "title": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측",
          "abstract": "본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202116954704821&target=NART&cn=JAKO202116954704821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 시간 연속성을 고려한 딥러닝 기반 레이더 강우예측 본 연구에서는 시계열 순서의 의미가 희석될 수 있는 기존의 U-net 기반 딥러닝 강우예측 모델의 성능을 개선하고자 하였다. 이를 위해서 데이터의 연속성을 고려한 ConvLSTM2D U-Net 신경망 구조를 갖는 모델을 적용하고, RainNet 모델 및 외삽 기반의 이류모델을 이용하여 예측정확도 개선 정도를 평가하였다. 또한 신경망 기반 모델 학습과정에서의 불확실성을 개선하기 위해 단일 모델뿐만 아니라 10개의 앙상블 모델로 학습을 수행하였다. 학습된 신경망 강우예측모델은 현재를 기준으로 과거 30분 전까지의 연속된 4개의 자료를 이용하여 10분 선행 예측자료를 생성하는데 최적화되었다. 최적화된 딥러닝 강우예측모델을 이용하여 강우예측을 수행한 결과, ConvLSTM2D U-Net을 사용하였을 때 예측 오차의 크기가 가장 작고, 강우 이동 위치를 상대적으로 정확히 구현하였다. 특히, 앙상블 ConvLSTM2D U-Net이 타 예측모델에 비해 높은 CSI와 낮은 MAE를 보이며, 상대적으로 정확하게 강우를 예측하였으며, 좁은 오차범위로 안정적인 예측성능을 보여주었다. 다만, 특정 지점만을 대상으로 한 예측성능은 전체 강우 영역에 대한 예측성능에 비해 낮게 나타나, 상세한 영역의 강우예측에 대한 딥러닝 강우예측모델의 한계도 확인하였다. 본 연구를 통해 시간의 변화를 고려하기 위한 ConvLSTM2D U-Net 신경망 구조가 예측정확도를 높일 수 있었으나, 여전히 강한 강우영역이나 상세한 강우예측에는 공간 평활로 인한 합성곱 신경망 모델의 한계가 있음을 확인하였다."
        },
        {
          "rank": 32,
          "score": 0.6793861389160156,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 33,
          "score": 0.6793753504753113,
          "doc_id": "DIKO0015771393",
          "title": "딥러닝 기술을 이용한 전력 수요 예측 방법",
          "abstract": "정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015771393&target=NART&cn=DIKO0015771393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 딥러닝 기술을 이용한 전력 수요 예측 방법 정확한 전력 수요 예측은 전력수급시스템의 안정을 위해 중요하다. 또한, 불필요한 비용 및 재난 안전사고를 최소화하기 위해 필수적이다. 그러나 전력 수요는 기후, 시간대, 공휴일 등의 영향을 받아 변동성이 있으며 비선형적인 특성이 있기에 예측에 어려움을 겪는다.&amp;#xD; 본 논문에서는 전력 수요 예측 과정에서 발생하는 불확실성을 최소화하기 위한 전력 수요 예측 모델을 제시한다. 국내 전력 공급업체 중 하나인 ㈜JB의 발전기 전력 데이터를 사용해 발전기 전력 수요 예측 모델을 구현하였으며, AMI(Advanced Metering Infrastructure) 데이터를 사용해 AMI 전력 수요 예측 모델을 구현하였다. &amp;#xD; 발전기 전력 수요 예측에는 전력 수요량에 영향을 줄 수 있는 기상 변수와 공휴일 변수 등을 사용한다. 그리고 LSTM에 Attention Mechanism을 추가한 알고리즘을 사용해 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 가장 낮은 평균 제곱근 오차와 절대 평균 백분율 오차를 가지며 우수한 성능을 보인다. 또한, 결과에 영향을 미치는 중요 변수를 확인함으로써 설명이 가능한 모델을 제안한다. &amp;#xD; AMI 전력 수요 예측은 전체 71세대의 전력 사용량을 HDBSCAN 클러스터링을 통해 분석한다. 그리고 클러스터별로 Bayesian Optimization 기법을 적용해 LSTM 알고리즘의 최적 하이퍼 파라미터를 선정한다. 선정한 하이퍼 파라미터를 적용한 클러스터별 예측 모델을 구현한다. 실험을 통해 성능을 측정한 결과, 제안한 모델이 기본 하이퍼 파라미터를 적용한 모델보다 낮은 평균 제곱근 오차를 가지며 우수한 성능을 보인다.&amp;#xD; 본 연구에서 제안하는 방법을 사용했을 때 더욱 정확한 전력 수요 예측을 기대할 수 있으며, 상황에 따른 전력 수요량 예측이 가능하므로 안정적인 전력의 공급, 전력 시스템의 효율적인 운영관리 및 안전 운행을 기대할 수 있다."
        },
        {
          "rank": 34,
          "score": 0.6788371801376343,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 35,
          "score": 0.6787326335906982,
          "doc_id": "JAKO202305062334676",
          "title": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측",
          "abstract": "본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202305062334676&target=NART&cn=JAKO202305062334676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 딥러닝 모델을 이용한 전자 입찰에서의 예정가격 예측 본 논문은 입찰사이트 전기넷과 OK EMS에서 입수한 입찰데이터로 DNBP(Deep learning Network to predict Budget Price) 모델을 통해 예정가격을 예측한다. 우리는 DNBP 모델을 활용하여 4개의 추첨예비가격을 예측을 하고, 이를 산술평균 한 뒤 예정가격 사정률을 계산하여, 실제 예정가격 사정률과 비교하여 모델의 성능을 평가한다. DNBP의 15개의 입력노드 중 일부 입력노드를 제거하여 모델을 학습시켰다. 예측 결과 예측 결과 입력노드가 6개(a, g, h, i, j, k) 일 때 DNBP의 RMSE가 0.75788% 로 가장 낮았다."
        },
        {
          "rank": 36,
          "score": 0.6786037683486938,
          "doc_id": "JAKO201953457807295",
          "title": "경량 딥러닝 기술 동향",
          "abstract": "Considerable accuracy improvements in deep learning have recently been achieved in many applications that require large amounts of computation and expensive memory. However, recent advanced techniques for compacting and accelerating the deep learning model have been developed for deployment in lightweight devices with constrained resources. Lightweight deep learning techniques can be categorized into two schemes: lightweight deep learning algorithms (model simplification and efficient convolutional filters) in nature and transferring models into compact/small ones (model compression and knowledge distillation). In this report, we briefly summarize various lightweight deep learning techniques and possible research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201953457807295&target=NART&cn=JAKO201953457807295",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "경량 딥러닝 기술 동향 경량 딥러닝 기술 동향 경량 딥러닝 기술 동향 Considerable accuracy improvements in deep learning have recently been achieved in many applications that require large amounts of computation and expensive memory. However, recent advanced techniques for compacting and accelerating the deep learning model have been developed for deployment in lightweight devices with constrained resources. Lightweight deep learning techniques can be categorized into two schemes: lightweight deep learning algorithms (model simplification and efficient convolutional filters) in nature and transferring models into compact/small ones (model compression and knowledge distillation). In this report, we briefly summarize various lightweight deep learning techniques and possible research directions."
        },
        {
          "rank": 37,
          "score": 0.6780068874359131,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 38,
          "score": 0.677166223526001,
          "doc_id": "DIKO0017291669",
          "title": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측",
          "abstract": "최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017291669&target=NART&cn=DIKO0017291669",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 다중 변수 융합을 통한 Hybrid Gated Fusion 기반 딥러닝 모델을 활용한 전력 수요 예측 최근 환경오염으로 인한 기후 이상 현상, 산업구조의 디지털 전환, 에너지 정책 및 인구 변화 등 복합적인 외부 요인으로 인해 전력수요는 과거보다 더 복잡하고 예측이 어려운 양상을 띄고 있다. &amp;#xD; 특히, 우리나라 전력 시장은 하루 전 수요예측 데이터를 기반으로 전력 공급이 이루어지기 때문에, 예측의 정확도가 낮을 경우 불필요한 전력 생산 또는 공급 부족같은 문제로 이어질 수 있다. 이는 발전 비용 및 출력 제어 비용 낭비, 급전 비용 상승으로 인한 전력 요금 인상, 정전 위험 등 많은 손실을 초래하므로 보다 정밀하고 신뢰성 높은 예측 모델이 필요하다. &amp;#xD; 이에 본 연구는 전력 수요 예측의 정확도 한계를 극복하고 전력 수요 패턴의 변동성에 능동적으로 대응하기 위해, 다양한 외생 변수를 통합하고 이를 효과적으로 학습할 수 있는 Hybrid 딥러닝 모델을 제안하고자 한다. &amp;#xD; 특히 시계열 데이터 흐름을 잘 반영하는 LSTM(Long Short-Term Memory)과 전역적 패턴 학습에 특화된 Transformer 의 장점을 동시에 활용하기 위해 두 모델의 구조를 통합한 Hybrid 모델을 구성하였으며, 여러가지 Fusion 기법을 적용하여 두 모델 간 정보를 효과적으로 조합하여 예측의 정확성과 안정성을 동시에 향상시켰다. &amp;#xD; 예측 모델은 전력 사용량, 캘린더 정보, 기온 민감도(CDD/HDD), 대중교통 이용량 등 6 개 외생 변수를 중심으로 설계된 5 가지 시나리오에 따라 학습되었으며, MAE, RMSE, MAPE를 기준으로 성능을 비교하였다.&amp;#xD; 단일 모델은 외생 변수가 없는 경우 높은 오차율을 보인 반면, Hybrid 모델은 모든 시나리오에서 우수한 예측 성능을 보였다. 특히 Gated Fusion 기반 Hybrid 모델은 최종 시나리오에서 MAPE 4.3%로 가장 낮은 오차를 기록하였다. 추가적으로 수행한 잔차 분석, 정규성 검정, 대응표본 t-검정 결과를 통해 해당 모델의 통계적 유의성과 예측 신뢰도를 뒷받침하였다. &amp;#xD; 결론적으로 본 연구는 전력 수요 예측에서 외생 변수 융합과 Hybrid 모델 구조가 실질적인 예측 성능 향상에 기여함을 입증하였으며, 향후 에너지 수급 계획 및 정책 수립 등에 실무적으로 적용 가능한 정교한 수요 예측 모델 개발의 기반을 제공하고자 한다."
        },
        {
          "rank": 39,
          "score": 0.677111029624939,
          "doc_id": "JAKO202201253146351",
          "title": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가",
          "abstract": "본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202201253146351&target=NART&cn=JAKO202201253146351",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다."
        },
        {
          "rank": 40,
          "score": 0.6764815449714661,
          "doc_id": "JAKO201718054814596",
          "title": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석",
          "abstract": "딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201718054814596&target=NART&cn=JAKO201718054814596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다."
        },
        {
          "rank": 41,
          "score": 0.6759504675865173,
          "doc_id": "NART103136065",
          "title": "Portfolio optimization with return prediction using deep learning and machine learning",
          "abstract": "<P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103136065&target=NART&cn=NART103136065",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning <P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>"
        },
        {
          "rank": 42,
          "score": 0.6757262945175171,
          "doc_id": "JAKO202315032964275",
          "title": "딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발",
          "abstract": "본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(10<sup>8</sup> 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 10<sup>8</sup>으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202315032964275&target=NART&cn=JAKO202315032964275",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(10<sup>8</sup> 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 10<sup>8</sup>으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다."
        },
        {
          "rank": 43,
          "score": 0.6747009754180908,
          "doc_id": "NPAP12734426",
          "title": "Deep sequential model for review rating prediction",
          "abstract": "<P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12734426&target=NART&cn=NPAP12734426",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep sequential model for review rating prediction Deep sequential model for review rating prediction Deep sequential model for review rating prediction <P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>"
        },
        {
          "rank": 44,
          "score": 0.6730750799179077,
          "doc_id": "JAKO202117242399954",
          "title": "심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델",
          "abstract": "토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202117242399954&target=NART&cn=JAKO202117242399954",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델 심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델 심층 CNN 기반 구조를 이용한 토마토 작물 병해충 분류 모델 토마토 작물은 병해충의 영향을 많이 받기 때문에 이를 예방하지 않으면 농업 경제에 막대한 손실을 초래할 수 있다. 따라서 토마토의 다양한 병해충의 진단을 빠르고 정확하게 진단하는 시스템이 요구된다. 본 논문에서는 ImageNet 데이터 셋 상에서 다양하게 사전 학습된 딥러닝 기반 CNN 모델을 적용하여 토마토의 9가지 병해충 및 정상인 경우의 클래스를 분류하는 시스템을 제안한다. PlantVillage 데이터 셋으로부터 발췌한 토마토 잎의 이미지 셋을 3가지 딥러닝 기반 CNN 구조를 갖는 ResNet, Xception, DenseNet의 입력으로 사용한다. 기본 CNN 모델 위에 톱-레벨 분류기를 추가하여 제안 모델을 구성하였으며, 훈련 데이터 셋에 대해 5-fold 교차검증 기법을 적용하여 학습시켰다. 3가지 제안 모델의 학습은 모두 기본 CNN 모델의 계층을 동결하여 학습시키는 전이 학습과 동결을 해제한 후 학습률을 매우 작은 수로 설정하여 학습시키는 미세 조정 학습 두 단계로 진행하였다. 모델 최적화 알고리즘으로는 SGD, RMSprop, Adam을 적용하였다. 실험 결과는 RMSprop 알고리즘이 적용된 DenseNet CNN 모델이 98.63%의 정확도로 가장 우수한 결과를 보였다."
        },
        {
          "rank": 45,
          "score": 0.6717337369918823,
          "doc_id": "NART118609293",
          "title": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction",
          "abstract": "<P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118609293&target=NART&cn=NART118609293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction Spider Taylor-ChOA: Optimized Deep Learning Based Sentiment Classification for Review Rating Prediction <P>The prediction of review rating is an imperative sentiment assessment task that aims to discover the intensity of users&rsquo; sentiment toward a target product from several reviews. This paper devises a technique based on sentiment classification for predicting the review rating. Here, the review data are taken from the database. The significant features, such as SentiWordNet-based statistical features, term frequency-inverse document frequency (TF-IDF), number of capitalized words, numerical words, punctuation marks, elongated words, hashtags, emoticons, and number of sentences are mined in feature extraction. The features are mined for sentiment classification, which is performed by random multimodal deep learning (RMDL). The training of RMDL is done using the proposed Spider Taylor-ChOA, which is devised by combining spider monkey optimization (SMO) and Taylor-based chimp optimization algorithm (Taylor-ChOA). Concurrently, the features are considered input for the review rating prediction, which determines positive and negative reviews using the hierarchical attention network (HAN), and training is done using proposed Spider Taylor-ChOA. The proposed Spider Taylor-ChOA-based RMDL performed best with the highest precision of 94.1%, recall of 96.5%, and highest F-measure of 95.3%. The proposed spider Taylor-ChOA-based HAN performed best with the highest precision of 93.1%, recall of 95.4% and highest F-measure of 94.3%.</P>"
        },
        {
          "rank": 46,
          "score": 0.6711308360099792,
          "doc_id": "ATN0035906971",
          "title": "딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구",
          "abstract": "In this research, we compare the explanatory power between linear regression model and deep-learning model when estimating stock returns. As predicted, the deep-learning model shows statistically significant improvement over linear regression model, although the improvement is not economically meaningful. We further investigate the effects of deep-learning model using different parameters and pre-processing. The results show that the predictive power of deep-learning model can be worse-off than that of linear model if it fails to select optimal parameters. Especially, it is important to choose adequate deep-learning parameters not to overfit the data, because the accounting data (which is at most quarterly) may not be sufficient enough for the deep model structure. Further, we show that the predictive power using researchers’ domain knowledge is sometimes better off than that relying simply on the deep-learning model. For instance, denomination with total assets brings better results than non-denomination. Another interesting finding is that winsorizing extreme values brings lower explanatory power when we use the deep-learning model. Such finding implies that, by removing extreme values, we may lose useful information in the parameter estimation. The results of this paper will help future research decide whether to utilize deep learning model or linear regression model",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0035906971&target=NART&cn=ATN0035906971",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 딥러닝 방법론을 사용한 주가예측에 대한 탐색적 연구 In this research, we compare the explanatory power between linear regression model and deep-learning model when estimating stock returns. As predicted, the deep-learning model shows statistically significant improvement over linear regression model, although the improvement is not economically meaningful. We further investigate the effects of deep-learning model using different parameters and pre-processing. The results show that the predictive power of deep-learning model can be worse-off than that of linear model if it fails to select optimal parameters. Especially, it is important to choose adequate deep-learning parameters not to overfit the data, because the accounting data (which is at most quarterly) may not be sufficient enough for the deep model structure. Further, we show that the predictive power using researchers’ domain knowledge is sometimes better off than that relying simply on the deep-learning model. For instance, denomination with total assets brings better results than non-denomination. Another interesting finding is that winsorizing extreme values brings lower explanatory power when we use the deep-learning model. Such finding implies that, by removing extreme values, we may lose useful information in the parameter estimation. The results of this paper will help future research decide whether to utilize deep learning model or linear regression model"
        },
        {
          "rank": 47,
          "score": 0.670459508895874,
          "doc_id": "JAKO201719950757340",
          "title": "딥러닝 프레임워크의 비교: 티아노, 텐서플로, CNTK를 중심으로",
          "abstract": "딥러닝 프레임워크의 대표적인 기능으로는 '자동미분'과 'GPU의 활용' 등을 들 수 있다. 본 논문은 파이썬의 라이브러리 형태로 사용 가능한 프레임워크 중에서 구글의 텐서플로와 마이크로소프트의 CNTK, 그리고 텐서플로의 원조라고 할 수 있는 티아노를 비교하였다. 본문에서는 자동미분의 개념과 GPU의 활용형태를 간단히 설명하고, 그 다음에 logistic regression을 실행하는 예를 통하여 각 프레임워크의 문법을 알아본 뒤에, 마지막으로 대표적인 딥러닝 응용인 CNN의 예제를 실행시켜보고 코딩의 편의성과 실행속도 등을 확인해 보았다. 그 결과, 편의성의 관점에서 보면 티아노가 가장 코딩 하기가 어렵고, CNTK와 텐서플로는 많은 부분이 비슷하게 추상화 되어 있어서 코딩이 비슷하지만 가중치와 편향을 직접 정의하느냐의 여부에서 차이를 보였다. 그리고 각 프레임워크의 실행속도에 대한 평가는 '큰 차이는 없다'는 것이다. 텐서플로는 티아노에 비하여 속도가 느리다는 평가가 있어왔는데, 본 연구의 실험에 의하면, 비록 CNN 모형에 국한되었지만, 텐서플로가 아주 조금이지만 빠른 것으로 나타났다. CNTK의 경우에도, 비록 실험환경이 달랐지만, 실험환경의 차이에 의한 속도의 차이의 편차범위 이내에 있는 것으로 판단이 되었다. 본 연구에서는 세 종류의 딥러닝 프레임워크만을 살펴보았는데, 위키피디아에 따르면 딥러닝 프레임워크의 종류는 12가지가 있으며, 각 프레임워크의 특징을 15가지 속성으로 구분하여 차이를 특정하고 있다. 그 많은 속성 중에서 사용자의 입장에서 볼 때 중요한 속성은 어떤 언어(파이썬, C++, Java, 등)로 사용가능한지, 어떤 딥러닝 모형에 대한 라이브러리가 잘 구현되어 있는지 등일 것이다. 그리고 사용자가 대규모의 딥러닝 모형을 구축한다면, 다중 GPU 혹은 다중 서버를 지원하는지의 여부도 중요할 것이다. 또한 딥러닝 모형을 처음 학습하는 경우에는 사용설명서가 많은지 예제 프로그램이 많은지 여부도 중요한 기준이 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201719950757340&target=NART&cn=JAKO201719950757340",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 프레임워크의 비교: 티아노, 텐서플로, CNTK를 중심으로 딥러닝 프레임워크의 비교: 티아노, 텐서플로, CNTK를 중심으로 딥러닝 프레임워크의 비교: 티아노, 텐서플로, CNTK를 중심으로 딥러닝 프레임워크의 대표적인 기능으로는 '자동미분'과 'GPU의 활용' 등을 들 수 있다. 본 논문은 파이썬의 라이브러리 형태로 사용 가능한 프레임워크 중에서 구글의 텐서플로와 마이크로소프트의 CNTK, 그리고 텐서플로의 원조라고 할 수 있는 티아노를 비교하였다. 본문에서는 자동미분의 개념과 GPU의 활용형태를 간단히 설명하고, 그 다음에 logistic regression을 실행하는 예를 통하여 각 프레임워크의 문법을 알아본 뒤에, 마지막으로 대표적인 딥러닝 응용인 CNN의 예제를 실행시켜보고 코딩의 편의성과 실행속도 등을 확인해 보았다. 그 결과, 편의성의 관점에서 보면 티아노가 가장 코딩 하기가 어렵고, CNTK와 텐서플로는 많은 부분이 비슷하게 추상화 되어 있어서 코딩이 비슷하지만 가중치와 편향을 직접 정의하느냐의 여부에서 차이를 보였다. 그리고 각 프레임워크의 실행속도에 대한 평가는 '큰 차이는 없다'는 것이다. 텐서플로는 티아노에 비하여 속도가 느리다는 평가가 있어왔는데, 본 연구의 실험에 의하면, 비록 CNN 모형에 국한되었지만, 텐서플로가 아주 조금이지만 빠른 것으로 나타났다. CNTK의 경우에도, 비록 실험환경이 달랐지만, 실험환경의 차이에 의한 속도의 차이의 편차범위 이내에 있는 것으로 판단이 되었다. 본 연구에서는 세 종류의 딥러닝 프레임워크만을 살펴보았는데, 위키피디아에 따르면 딥러닝 프레임워크의 종류는 12가지가 있으며, 각 프레임워크의 특징을 15가지 속성으로 구분하여 차이를 특정하고 있다. 그 많은 속성 중에서 사용자의 입장에서 볼 때 중요한 속성은 어떤 언어(파이썬, C++, Java, 등)로 사용가능한지, 어떤 딥러닝 모형에 대한 라이브러리가 잘 구현되어 있는지 등일 것이다. 그리고 사용자가 대규모의 딥러닝 모형을 구축한다면, 다중 GPU 혹은 다중 서버를 지원하는지의 여부도 중요할 것이다. 또한 딥러닝 모형을 처음 학습하는 경우에는 사용설명서가 많은지 예제 프로그램이 많은지 여부도 중요한 기준이 될 것이다."
        },
        {
          "rank": 48,
          "score": 0.6696594953536987,
          "doc_id": "ATN0052776138",
          "title": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구",
          "abstract": "첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0052776138&target=NART&cn=ATN0052776138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다."
        },
        {
          "rank": 49,
          "score": 0.6695868968963623,
          "doc_id": "JAKO202308931715019",
          "title": "딥러닝을 이용한 화재 발생 예측 이미지 분할",
          "abstract": "본 논문에서는 화재로부터 실시간으로 화염과 연기를 감지하고 분할하기 위해 딥러닝 모델을 사용하였다. 이를 위해 의미론적 분할에서 우수한 성능을 보이는 U-NET을 사용하고 다중 클래스를 이용하여 화재의 불꽃과 연기를 구분 하였다. 제안된 기법을 이용하여 학습한 결과, 손실 오차와 정확도 값이 각각 0.0486과 0.97996으로 매우 양호하였다. 객체 감지에 사용되는 IOU 값도 0.849로 매우 좋았다. 학습된 모델을 이용하여 학습에 사용하지 않은 화재 이미지를 예측한 결과, 화재의 불꽃과 연기가 잘 감지되고 분할되었으며, 연기의 색상도 잘 구분되었다. 제안된 기법을 이용하여 화재 예측 및 감지 시스템 구축 등에 사용될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202308931715019&target=NART&cn=JAKO202308931715019",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 화재 발생 예측 이미지 분할 딥러닝을 이용한 화재 발생 예측 이미지 분할 딥러닝을 이용한 화재 발생 예측 이미지 분할 본 논문에서는 화재로부터 실시간으로 화염과 연기를 감지하고 분할하기 위해 딥러닝 모델을 사용하였다. 이를 위해 의미론적 분할에서 우수한 성능을 보이는 U-NET을 사용하고 다중 클래스를 이용하여 화재의 불꽃과 연기를 구분 하였다. 제안된 기법을 이용하여 학습한 결과, 손실 오차와 정확도 값이 각각 0.0486과 0.97996으로 매우 양호하였다. 객체 감지에 사용되는 IOU 값도 0.849로 매우 좋았다. 학습된 모델을 이용하여 학습에 사용하지 않은 화재 이미지를 예측한 결과, 화재의 불꽃과 연기가 잘 감지되고 분할되었으며, 연기의 색상도 잘 구분되었다. 제안된 기법을 이용하여 화재 예측 및 감지 시스템 구축 등에 사용될 수 있다."
        },
        {
          "rank": 50,
          "score": 0.6695151329040527,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}