{
  "id": "row_000011",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:33.599837+09:00",
  "trial_id": "39ec75e2",
  "queries": [
    {
      "query": "How would you summarize the proposed enabling framework for achieving the second Sustainable Development Goal, emphasizing the role of data sharing and near real-time analytics?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.670712411403656,
          "doc_id": "NART112066192",
          "title": "Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics",
          "abstract": "<P><B>Abstract</B></P>  <P>The momentum has been building toward the realisation of the United Nations Development Programme's Sustainable Development Goals (SDGs). In this regard, technological upgrading through the adoption of innovative technologies, as in big data analytics (BDA), can be seen as a key enabler of helping to address societal challenges. While there is some evidence for realising value created from BDA adoption, organisational issues associated with societal challenges, specifically those targeting the SDGs, are yet to be appreciated. This study utilises a technology&ndash;organisation&ndash;environment framework to examine the role of top management support in facilitating value creation from BDA adoption for the realisation SDGs. Based on a survey of 320 UK managers, this study found that the technological driver of BDA coupled with top management support, can significantly help in the adoption process. Therefore, crafting the value needed for effectively supporting the realisation of these goals.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART112066192&target=NART&cn=NART112066192",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics <P><B>Abstract</B></P>  <P>The momentum has been building toward the realisation of the United Nations Development Programme's Sustainable Development Goals (SDGs). In this regard, technological upgrading through the adoption of innovative technologies, as in big data analytics (BDA), can be seen as a key enabler of helping to address societal challenges. While there is some evidence for realising value created from BDA adoption, organisational issues associated with societal challenges, specifically those targeting the SDGs, are yet to be appreciated. This study utilises a technology&ndash;organisation&ndash;environment framework to examine the role of top management support in facilitating value creation from BDA adoption for the realisation SDGs. Based on a survey of 320 UK managers, this study found that the technological driver of BDA coupled with top management support, can significantly help in the adoption process. Therefore, crafting the value needed for effectively supporting the realisation of these goals.</P>"
        },
        {
          "rank": 2,
          "score": 0.6470478773117065,
          "doc_id": "DIKO0016854880",
          "title": "지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용",
          "abstract": "인류사의 새로운 물결인 제4차 산업혁명에 대응하고 당면한 문제를 해결하기 위해 세계 각국은 인공지능교육에 역량을 집중하는 한편 환경오염, 자원 고갈, 빈부격차, 불평등, 기후변화 등의 다양한 현실 문제를 인식하고, 변화를 위한 행동을 촉구하는 방안으로 지속가능발전교육의 필요성이 강조되고 있다. &amp;#xD; 지속가능발전교육은 지속가능발전 및 지속가능발전목표를 이해하고 삶 속에서 자기주도적으로 현실의 문제를 해결하려는 기능과 태도를 갖춰 지속가능 발전역량을 강화하는 것이 목표이다. 이에 구체적인 실행 방안으로 현실 인식 및 미래 예측을 돕고 지속 가능한 발전을 이끄는 인공지능 교육을 들 수 있다. 인공지능은 이미 직면한 문제를 해결하고 지속 가능한 사회를 만들고 있기 때문이다. &amp;#xD; 따라서 본 연구는 인공지능 교육을 통해 인공지능의 기초·원리를 이해하고 윤리적인 측면을 고려하여 올바르게 활용하는 능력인 인공지능 리터러시 및 전 지구적 문제해결을 위한 지속가능 발전역량 함양을 목적으로 한다. 이를 위해 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램을 개발 및 적용하여 인공지능 리터러시와 지속가능 발전역량에 미치는 효과를 확인하였다. &amp;#xD; 본 연구의 대상은 초등학교 6학년 학생 40명이며 6주간 15차시에 걸쳐 개발된 프로그램이 적용되었다. 교육 프로그램은 ADDIE 수업 모형을 바탕으로 분석, 설계, 개발, 실행 평가의 5단계로 설계되어 사전 및 프로젝트 학습으로 구성되었다. &amp;#xD; 사전학습에서 인공지능의 이해와 윤리를 바탕으로 올바르게 활용하는 방법을 익힌다. 프로젝트 학습은 인공지능과 지속가능 발전의 연관성을 탐구하며 데이터 기반 의사결정으로 지속가능 발전을 위한 인공지능 모델 개발 등 프로젝트를 수행하고 평가하는 활동으로 구성되었다. &amp;#xD; 본 연구는 사전 요구 분석 조사 및 교육 프로그램 적용 전후 인공지능 리터러시와 지속가능 발전역량을 측정하는 검사를 실시하여 그 결과를 분석하였다. &amp;#xD; 연구 결과, 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램은 학생들의 인공지능 리터러시 및 지속가능 발전역량 향상에 통계적으로 유의미한 효과가 있음을 확인하였다(p&amp;lt;.001). &amp;#xD; 본 연구가 2022 개정 교육과정에서 강조되는 인공지능 리터러시 및 지속가능 발전역량 함양과 관련된 연구 확산에 초석이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016854880&target=NART&cn=DIKO0016854880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 인류사의 새로운 물결인 제4차 산업혁명에 대응하고 당면한 문제를 해결하기 위해 세계 각국은 인공지능교육에 역량을 집중하는 한편 환경오염, 자원 고갈, 빈부격차, 불평등, 기후변화 등의 다양한 현실 문제를 인식하고, 변화를 위한 행동을 촉구하는 방안으로 지속가능발전교육의 필요성이 강조되고 있다. &amp;#xD; 지속가능발전교육은 지속가능발전 및 지속가능발전목표를 이해하고 삶 속에서 자기주도적으로 현실의 문제를 해결하려는 기능과 태도를 갖춰 지속가능 발전역량을 강화하는 것이 목표이다. 이에 구체적인 실행 방안으로 현실 인식 및 미래 예측을 돕고 지속 가능한 발전을 이끄는 인공지능 교육을 들 수 있다. 인공지능은 이미 직면한 문제를 해결하고 지속 가능한 사회를 만들고 있기 때문이다. &amp;#xD; 따라서 본 연구는 인공지능 교육을 통해 인공지능의 기초·원리를 이해하고 윤리적인 측면을 고려하여 올바르게 활용하는 능력인 인공지능 리터러시 및 전 지구적 문제해결을 위한 지속가능 발전역량 함양을 목적으로 한다. 이를 위해 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램을 개발 및 적용하여 인공지능 리터러시와 지속가능 발전역량에 미치는 효과를 확인하였다. &amp;#xD; 본 연구의 대상은 초등학교 6학년 학생 40명이며 6주간 15차시에 걸쳐 개발된 프로그램이 적용되었다. 교육 프로그램은 ADDIE 수업 모형을 바탕으로 분석, 설계, 개발, 실행 평가의 5단계로 설계되어 사전 및 프로젝트 학습으로 구성되었다. &amp;#xD; 사전학습에서 인공지능의 이해와 윤리를 바탕으로 올바르게 활용하는 방법을 익힌다. 프로젝트 학습은 인공지능과 지속가능 발전의 연관성을 탐구하며 데이터 기반 의사결정으로 지속가능 발전을 위한 인공지능 모델 개발 등 프로젝트를 수행하고 평가하는 활동으로 구성되었다. &amp;#xD; 본 연구는 사전 요구 분석 조사 및 교육 프로그램 적용 전후 인공지능 리터러시와 지속가능 발전역량을 측정하는 검사를 실시하여 그 결과를 분석하였다. &amp;#xD; 연구 결과, 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램은 학생들의 인공지능 리터러시 및 지속가능 발전역량 향상에 통계적으로 유의미한 효과가 있음을 확인하였다(p&amp;lt;.001). &amp;#xD; 본 연구가 2022 개정 교육과정에서 강조되는 인공지능 리터러시 및 지속가능 발전역량 함양과 관련된 연구 확산에 초석이 되기를 기대한다."
        },
        {
          "rank": 3,
          "score": 0.6439899206161499,
          "doc_id": "JAKO202024758672089",
          "title": "Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information",
          "abstract": "In this study, the information from environmental impact statements was converted into spatial data because environmental data from development sites are collected during the environmental impact assessment (EIA) process. Spatiotemporal big data were built from environmental spatial data for each environmental medium for 2,235 development sites during 2007-2018, available from public data portals. Comparing air-quality monitoring stations, 33,863 measurement points were constructed, which is approximately 75 times more measurement points than that 452 in Air Korea's real-time measurement network. Here, spatiotemporal big data from 2,677,260 EIAs were constructed. In the future, such data might be used not only for EIAs but also for various spatial plans.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202024758672089&target=NART&cn=JAKO202024758672089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information In this study, the information from environmental impact statements was converted into spatial data because environmental data from development sites are collected during the environmental impact assessment (EIA) process. Spatiotemporal big data were built from environmental spatial data for each environmental medium for 2,235 development sites during 2007-2018, available from public data portals. Comparing air-quality monitoring stations, 33,863 measurement points were constructed, which is approximately 75 times more measurement points than that 452 in Air Korea's real-time measurement network. Here, spatiotemporal big data from 2,677,260 EIAs were constructed. In the future, such data might be used not only for EIAs but also for various spatial plans."
        },
        {
          "rank": 4,
          "score": 0.6367491483688354,
          "doc_id": "JAKO201117463449578",
          "title": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크",
          "abstract": "T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201117463449578&target=NART&cn=JAKO201117463449578",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다."
        },
        {
          "rank": 5,
          "score": 0.6366997957229614,
          "doc_id": "JAKO201716269582877",
          "title": "딥러닝 시티: 스마트 시티의 빅데이터 분석 프레임워크 제안",
          "abstract": "도시 기능이 복합적으로 발전함에 따라 스마트 시티에 대한 관심이 높아지고 있다. 스마트 시티란 정보통신기술을 활용하여 교통, 안전, 복지, 생활 등 도시 문제를 효과적으로 해결하는 것을 말한다. 최근 세계 각국은 빅데이터, 사물인터넷, 인공지능 기술을 스마트 시티에 도입하는 시도를 하고 있으나 종합적인 도시 서비스로는 발전하지 못하고 있다. 본 논문에서는 국내외 스마트 시티 추진 현황을 살펴보고 핵심 문제로 부각된, 데이터 공유문제, 서비스 호환성 문제를 해결하는 방안을 제시하였다. 이를 위해 딥러닝 기술을 스마트 시티 서비스에 접목한 '딥러닝 시티 프레임워크'를 제안하고 도시 여러 영역의 시공간 데이터를 안전하게 공유하고 여러 도시의 학습 데이터를 융합하는 새로운 스마트 시티 추진 전략을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201716269582877&target=NART&cn=JAKO201716269582877",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 시티: 스마트 시티의 빅데이터 분석 프레임워크 제안 딥러닝 시티: 스마트 시티의 빅데이터 분석 프레임워크 제안 딥러닝 시티: 스마트 시티의 빅데이터 분석 프레임워크 제안 도시 기능이 복합적으로 발전함에 따라 스마트 시티에 대한 관심이 높아지고 있다. 스마트 시티란 정보통신기술을 활용하여 교통, 안전, 복지, 생활 등 도시 문제를 효과적으로 해결하는 것을 말한다. 최근 세계 각국은 빅데이터, 사물인터넷, 인공지능 기술을 스마트 시티에 도입하는 시도를 하고 있으나 종합적인 도시 서비스로는 발전하지 못하고 있다. 본 논문에서는 국내외 스마트 시티 추진 현황을 살펴보고 핵심 문제로 부각된, 데이터 공유문제, 서비스 호환성 문제를 해결하는 방안을 제시하였다. 이를 위해 딥러닝 기술을 스마트 시티 서비스에 접목한 '딥러닝 시티 프레임워크'를 제안하고 도시 여러 영역의 시공간 데이터를 안전하게 공유하고 여러 도시의 학습 데이터를 융합하는 새로운 스마트 시티 추진 전략을 제시하였다."
        },
        {
          "rank": 6,
          "score": 0.6362594366073608,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 7,
          "score": 0.6335896253585815,
          "doc_id": "NART106300987",
          "title": "An ethical framework for big data and smart cities",
          "abstract": "<P><B>Abstract</B></P>  <P>This paper presents an ethical framework for Big Data and Smart cities, focusing on contemporary ethical and non-ethical issues in big data analytics applications in smart cities and public transportation systems. The framework provides reviews and analysis of ethical and emerging issues and provides a summary of recommendations and discussions for four emerging areas. By reviewing recent studies on both the technological development and emerging ethical problems in the emerging industries, this paper seeks to find and raise public awareness of ethical issues lying in urban big data analytics and public transportation systems. In order to deal with emerging issues, four recommendations have been explained and subsequently, two areas of discussion have been described in detail to support the ethical framework. This paper addresses emerging issues and their ethical concerns for big data and smart cities. Possible recommendations and solutions have been demonstrated to promote the competency of companies and organizations in this big data era. How the ethical framework can be used by six smart cities have been described. Our findings and analysis for big data for high growth, innovation and core competencies and validity of the ethical framework have been justified.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We present an ethical framework for big data and smart cities. </LI> <LI>  We identify four emerging areas, particularly big data analytics and its impacts. </LI> <LI>  We provide detailed recommendations and discussions. </LI> <LI>  We explain how the ethical framework can be used in six smart cities. </LI> <LI>  We explain how framework can be used for countries with lower ethical requirements. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106300987&target=NART&cn=NART106300987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "An ethical framework for big data and smart cities An ethical framework for big data and smart cities An ethical framework for big data and smart cities <P><B>Abstract</B></P>  <P>This paper presents an ethical framework for Big Data and Smart cities, focusing on contemporary ethical and non-ethical issues in big data analytics applications in smart cities and public transportation systems. The framework provides reviews and analysis of ethical and emerging issues and provides a summary of recommendations and discussions for four emerging areas. By reviewing recent studies on both the technological development and emerging ethical problems in the emerging industries, this paper seeks to find and raise public awareness of ethical issues lying in urban big data analytics and public transportation systems. In order to deal with emerging issues, four recommendations have been explained and subsequently, two areas of discussion have been described in detail to support the ethical framework. This paper addresses emerging issues and their ethical concerns for big data and smart cities. Possible recommendations and solutions have been demonstrated to promote the competency of companies and organizations in this big data era. How the ethical framework can be used by six smart cities have been described. Our findings and analysis for big data for high growth, innovation and core competencies and validity of the ethical framework have been justified.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We present an ethical framework for big data and smart cities. </LI> <LI>  We identify four emerging areas, particularly big data analytics and its impacts. </LI> <LI>  We provide detailed recommendations and discussions. </LI> <LI>  We explain how the ethical framework can be used in six smart cities. </LI> <LI>  We explain how framework can be used for countries with lower ethical requirements. </LI> </UL> </P>"
        },
        {
          "rank": 8,
          "score": 0.6324654817581177,
          "doc_id": "NART98292774",
          "title": "Deliberate storytelling in big data analytics adoption",
          "abstract": "<P><B>Abstract</B></P><P>The emergence of big data analytics (BDA) has posed opportunities as well as multiple challenges to business practitioners, who have called for research on the behavioural factors underlying BDA adoption at the individual level. The purpose of this study is to extend the information systems (IS) research on storytelling and to explore the role and characteristics of deliberate storytelling in individual&#8208;level BDA adoption. This case study used the grounded theory approach to extract qualitative data from 24 interviews, field notes, and documentary data. The explicit contributions of the study to the literature include (a) increasing our understanding of the facilitating role of deliberate storytelling in individual&#8208;level BDA adoption, (b) identifying four deliberate storytelling patterns and seven underlying corporate stories disseminated by organizations to influence individual behaviour, and (c) defining the core characteristics of effective deliberate storytelling. This study has multiple implications for business practitioners and demonstrates how deliberate storytelling can be used as a facilitating mechanism in daily business practice.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98292774&target=NART&cn=NART98292774",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deliberate storytelling in big data analytics adoption Deliberate storytelling in big data analytics adoption Deliberate storytelling in big data analytics adoption <P><B>Abstract</B></P><P>The emergence of big data analytics (BDA) has posed opportunities as well as multiple challenges to business practitioners, who have called for research on the behavioural factors underlying BDA adoption at the individual level. The purpose of this study is to extend the information systems (IS) research on storytelling and to explore the role and characteristics of deliberate storytelling in individual&#8208;level BDA adoption. This case study used the grounded theory approach to extract qualitative data from 24 interviews, field notes, and documentary data. The explicit contributions of the study to the literature include (a) increasing our understanding of the facilitating role of deliberate storytelling in individual&#8208;level BDA adoption, (b) identifying four deliberate storytelling patterns and seven underlying corporate stories disseminated by organizations to influence individual behaviour, and (c) defining the core characteristics of effective deliberate storytelling. This study has multiple implications for business practitioners and demonstrates how deliberate storytelling can be used as a facilitating mechanism in daily business practice.</P>"
        },
        {
          "rank": 9,
          "score": 0.6315274238586426,
          "doc_id": "DIKO0014170353",
          "title": "링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크",
          "abstract": "건설 프로젝트에서 발생하는 하자는 프로젝트의 성과에 심각한 영향을 미치는 요인으로 인식되고 있다. 이에 학계와 실무에서는 하자저감을 위해 과거부터 지속적인 노력을 기울여왔다. 하지만, 현재에도 과거에 발생된 하자가 반복해서 발생되고 있다는 점을 고려볼 때, 지금까지의 하자정보 관리 및 활용 체계가 비효율적이고 비생산적임을 의미한다. &amp;#xD; 이에 본 연구는 프로젝트 수행 시 발생되는 하자를 체계적으로 저장하고, 효율적으로 검색 및 공유하여 하자정보 활용의 선순환 체계를 구축하기 위한 수단으로 최신 정보 통신 기술을 복합적으로 적용하여, 기존 방식을 획기적으로 개선시킬 수 있는 시스템 프레임워크 개발을 목적으로 수행되었다. &amp;#xD; 이를 위해 선행연구와 하자정보 활용현황을 분석하여, 지식관리 프로세스 관점에서 현 하자정보 활용의 한계를 도출하였다. 정보 생성 영역에서는 비체계적인 방식으로 정보가 수집되고 있으며, 정보 저장 영역에서는 문서기반의 비구조적인 방식으로 정보가 저장되고 있으며, 정보 검색 영역에서는 키워드, 카테고리 기반의 검색 방식만을 제공하고 있으며, 정보 공유 및 활용 영역에서는 정보를 제공받아야 할 주체에게 정보가 전달될 수 없는 환경이다. 이러한 기존 하자정보 활용체계를 개선하기 위해서는 각 단계별 요구사항을 만족시킬 수 있을 뿐만 아니라 하자정보의 생성부터 저장 및 활용에 이르는 개별 정보 흐름이 시스템적으로 연계될 필요가 있다. &amp;#xD; 이를 위해 본 연구에서는 정보통신 분야와 건설 분야에서 활용되고 있는 최신 기술을 고찰하여, 기존 하자정보 활용체계를 획기적으로 개선시킬 수 있는 방안을 제시하였다. 먼저 정보 통신 분야에서는 해당 분야의 지식을 체계화하여 컴퓨터가 이해할 수 있도록 하는 새로운 정보표현 기술인 온톨로지와 이를 기반으로 서로 다른 시스템이나 웹상에 분산된 정보를 단일한 플랫폼에서 검색하고 분석할 수 있는 링크드 데이터 기술을 활용하였다. 건설 분야에서는 기존 문서중심의 2D 환경을 3D 객체기반 디지털 환경으로 전환하여 정보의 통합 및 호환성 향상을 위해 개발된 플랫폼인 BIM 기술을 활용하였다. 이에 본 연구에서는 BIM의 디지털 정보와 온톨로지와 링크드 데이터 기술을 융합하여 하자정보 공유 및 활용체계를 획기적으로 개선할 수 있는 시스템 프레임워크를 제안하였으며, 세부 기술 구현을 통해 기술 적용 가능성을 검증하였다. 본 연구에서 구현한 기술과 기능을 요약하면 다음과 같다.&amp;#xD; 먼저 정보 생성 모듈에서는 하자정보 구성체계를 제안하고 이를 구조화된 지시표현 방식으로 전환하기 위해 온톨로지 저작툴인 Protege를 활용하여 하자 온톨로지를 개발하였다. 정보 저장 모듈에서는 RDF 전환 프로그램을 개발하여, BIM 객체로부터 추출된 작업상황 정보를 위 프로그램을 활용하여 RDF 파일을 자동으로 생성할 수 있는 시스템을 구현하였다. 정보 검색 모듈에서는 SPARQL 쿼리를 활용하여 정보의 검색 및 통계가 가능함을 확인하였고, 마지막으로 정보 공유 및 활용 모듈에서는 링크드 데이터 환경을 구현하기 위해 Sesame 프로그램을 활용하여, 실제 웹 사이트에 저장된 정보를 RDF 파일로 변환하고, 이를 RDF store에 업로드 한 후, SPARQL endpoint를 통해 해당 웹사이트로 접근이 가능함을 확인하였다. 또한, 하자사례를 규칙화하여 SWRL룰로 변환하고, 이를 BIM 정보를 활용하여 하자발생 상황을 자동으로 추론할 수 있음을 확인하였다. &amp;#xD; 본 연구는 과거 수십 년간 강조해왔던 하자정보 피드백 환경을 구현하기 위해 최신기술인 링크드 데이터, 온톨로지, BIM의 기능을 융합한 시스템 프레임워크를 제시하였다. 본 연구는 하자정보의 흐름을 지식관리 프로세스 관점에서 바라보았으며, 각 단계별로 요구되는 기능을 규명하여 이를 기술적 방법론을 제시하였다는 것과 하자관리 업무에 참고해야 될 사례로만 여겨졌던 하자정보도 규칙화 될 수 있다는 것을 검증한 측면에서 학술적 기여가 있는 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014170353&target=NART&cn=DIKO0014170353",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 건설 프로젝트에서 발생하는 하자는 프로젝트의 성과에 심각한 영향을 미치는 요인으로 인식되고 있다. 이에 학계와 실무에서는 하자저감을 위해 과거부터 지속적인 노력을 기울여왔다. 하지만, 현재에도 과거에 발생된 하자가 반복해서 발생되고 있다는 점을 고려볼 때, 지금까지의 하자정보 관리 및 활용 체계가 비효율적이고 비생산적임을 의미한다. &amp;#xD; 이에 본 연구는 프로젝트 수행 시 발생되는 하자를 체계적으로 저장하고, 효율적으로 검색 및 공유하여 하자정보 활용의 선순환 체계를 구축하기 위한 수단으로 최신 정보 통신 기술을 복합적으로 적용하여, 기존 방식을 획기적으로 개선시킬 수 있는 시스템 프레임워크 개발을 목적으로 수행되었다. &amp;#xD; 이를 위해 선행연구와 하자정보 활용현황을 분석하여, 지식관리 프로세스 관점에서 현 하자정보 활용의 한계를 도출하였다. 정보 생성 영역에서는 비체계적인 방식으로 정보가 수집되고 있으며, 정보 저장 영역에서는 문서기반의 비구조적인 방식으로 정보가 저장되고 있으며, 정보 검색 영역에서는 키워드, 카테고리 기반의 검색 방식만을 제공하고 있으며, 정보 공유 및 활용 영역에서는 정보를 제공받아야 할 주체에게 정보가 전달될 수 없는 환경이다. 이러한 기존 하자정보 활용체계를 개선하기 위해서는 각 단계별 요구사항을 만족시킬 수 있을 뿐만 아니라 하자정보의 생성부터 저장 및 활용에 이르는 개별 정보 흐름이 시스템적으로 연계될 필요가 있다. &amp;#xD; 이를 위해 본 연구에서는 정보통신 분야와 건설 분야에서 활용되고 있는 최신 기술을 고찰하여, 기존 하자정보 활용체계를 획기적으로 개선시킬 수 있는 방안을 제시하였다. 먼저 정보 통신 분야에서는 해당 분야의 지식을 체계화하여 컴퓨터가 이해할 수 있도록 하는 새로운 정보표현 기술인 온톨로지와 이를 기반으로 서로 다른 시스템이나 웹상에 분산된 정보를 단일한 플랫폼에서 검색하고 분석할 수 있는 링크드 데이터 기술을 활용하였다. 건설 분야에서는 기존 문서중심의 2D 환경을 3D 객체기반 디지털 환경으로 전환하여 정보의 통합 및 호환성 향상을 위해 개발된 플랫폼인 BIM 기술을 활용하였다. 이에 본 연구에서는 BIM의 디지털 정보와 온톨로지와 링크드 데이터 기술을 융합하여 하자정보 공유 및 활용체계를 획기적으로 개선할 수 있는 시스템 프레임워크를 제안하였으며, 세부 기술 구현을 통해 기술 적용 가능성을 검증하였다. 본 연구에서 구현한 기술과 기능을 요약하면 다음과 같다.&amp;#xD; 먼저 정보 생성 모듈에서는 하자정보 구성체계를 제안하고 이를 구조화된 지시표현 방식으로 전환하기 위해 온톨로지 저작툴인 Protege를 활용하여 하자 온톨로지를 개발하였다. 정보 저장 모듈에서는 RDF 전환 프로그램을 개발하여, BIM 객체로부터 추출된 작업상황 정보를 위 프로그램을 활용하여 RDF 파일을 자동으로 생성할 수 있는 시스템을 구현하였다. 정보 검색 모듈에서는 SPARQL 쿼리를 활용하여 정보의 검색 및 통계가 가능함을 확인하였고, 마지막으로 정보 공유 및 활용 모듈에서는 링크드 데이터 환경을 구현하기 위해 Sesame 프로그램을 활용하여, 실제 웹 사이트에 저장된 정보를 RDF 파일로 변환하고, 이를 RDF store에 업로드 한 후, SPARQL endpoint를 통해 해당 웹사이트로 접근이 가능함을 확인하였다. 또한, 하자사례를 규칙화하여 SWRL룰로 변환하고, 이를 BIM 정보를 활용하여 하자발생 상황을 자동으로 추론할 수 있음을 확인하였다. &amp;#xD; 본 연구는 과거 수십 년간 강조해왔던 하자정보 피드백 환경을 구현하기 위해 최신기술인 링크드 데이터, 온톨로지, BIM의 기능을 융합한 시스템 프레임워크를 제시하였다. 본 연구는 하자정보의 흐름을 지식관리 프로세스 관점에서 바라보았으며, 각 단계별로 요구되는 기능을 규명하여 이를 기술적 방법론을 제시하였다는 것과 하자관리 업무에 참고해야 될 사례로만 여겨졌던 하자정보도 규칙화 될 수 있다는 것을 검증한 측면에서 학술적 기여가 있는 것으로 판단된다."
        },
        {
          "rank": 10,
          "score": 0.6310193538665771,
          "doc_id": "JAKO202407845889961",
          "title": "공간정보 표준기반 스마트시티 프레임워크",
          "abstract": "현대 도시는 다양한 도시 문제에 대응하기 위해 적극적으로 스마트시티 서비스를 도입하고 있다. 공간정보는 스마트시티의 기반 인프라로 작용하며, 도시의 지속 가능한 발전을 촉진한다. 공간정보의 표준화와 활용이 증가함에 따라 스마트시티의 효율적인 운영과 지속가능성이 향상되는데, 이를 위해서는 다양한 이해관계자들간의 협력을 통한 최적의 공간정보 기반 스마트시티 서비스 제공이 중요하다. 본 연구에서는 교통 및 건축-에너지 도메인 중심의 스마트시티 서비스를 공간정보 기술의 생애주기 기반으로 정의하고, 이를 공간정보 표준에 적용하고 활용하는 중요성을 강조한다. 또한, 공간정보 표준기반 스마트시티(SCGI, Smart City based on Geospatial Information standards) 프레임워크를 제안하여, 공간정보 표준에 매핑 가능한 스마트시티 서비스의 표준화에 관한 인사이트를 제시하였다. 본 연구는 공간정보 표준을 활용하여 커스터마이징된 솔루션을 제공함으로써 스마트시티 서비스의 표준화를 위한 새로운 패러다임을 제시하며, 스마트시티의 미래 발전 가능성을 논의한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407845889961&target=NART&cn=JAKO202407845889961",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보 표준기반 스마트시티 프레임워크 공간정보 표준기반 스마트시티 프레임워크 공간정보 표준기반 스마트시티 프레임워크 현대 도시는 다양한 도시 문제에 대응하기 위해 적극적으로 스마트시티 서비스를 도입하고 있다. 공간정보는 스마트시티의 기반 인프라로 작용하며, 도시의 지속 가능한 발전을 촉진한다. 공간정보의 표준화와 활용이 증가함에 따라 스마트시티의 효율적인 운영과 지속가능성이 향상되는데, 이를 위해서는 다양한 이해관계자들간의 협력을 통한 최적의 공간정보 기반 스마트시티 서비스 제공이 중요하다. 본 연구에서는 교통 및 건축-에너지 도메인 중심의 스마트시티 서비스를 공간정보 기술의 생애주기 기반으로 정의하고, 이를 공간정보 표준에 적용하고 활용하는 중요성을 강조한다. 또한, 공간정보 표준기반 스마트시티(SCGI, Smart City based on Geospatial Information standards) 프레임워크를 제안하여, 공간정보 표준에 매핑 가능한 스마트시티 서비스의 표준화에 관한 인사이트를 제시하였다. 본 연구는 공간정보 표준을 활용하여 커스터마이징된 솔루션을 제공함으로써 스마트시티 서비스의 표준화를 위한 새로운 패러다임을 제시하며, 스마트시티의 미래 발전 가능성을 논의한다."
        },
        {
          "rank": 11,
          "score": 0.6294112205505371,
          "doc_id": "JAKO201228439147521",
          "title": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할",
          "abstract": "현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201228439147521&target=NART&cn=JAKO201228439147521",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다."
        },
        {
          "rank": 12,
          "score": 0.6292382478713989,
          "doc_id": "NART112054592",
          "title": "Satellite Data and Crowdsourcing",
          "abstract": "<P><B>Abstract</B></P>  <P>Crowdsourcing increases the value of satellite data by supplying human resources for processing them and providing complementary data. This article reviews previous research to clarify the stakeholders and their relationships in business ecosystems where satellite data and crowdsourcing are combined for new products and services. Crowdsourcing has three functions in satellite data businesses: analyzing, monitoring, and collecting data. The functions of collecting and monitoring complementary ground data that are used with satellite data have become increasingly important in recent years. The conclusions indicate that the business ecosystems have evolved from being led by satellite data platforms to being coordinated by third parties.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Crowdsourcing has three functions in satellite data business; analyzing, monitoring, and collecting data. </LI> <LI>  There are direct and indirect crowdsourcing involvement pattern in satellite data. </LI> <LI>  Ground data have increasingly important complimentary roles to satellite data. </LI> <LI>  Business models have evolved from being led by satellite data platforms to being coordinated by third parties. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART112054592&target=NART&cn=NART112054592",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Satellite Data and Crowdsourcing Satellite Data and Crowdsourcing Satellite Data and Crowdsourcing <P><B>Abstract</B></P>  <P>Crowdsourcing increases the value of satellite data by supplying human resources for processing them and providing complementary data. This article reviews previous research to clarify the stakeholders and their relationships in business ecosystems where satellite data and crowdsourcing are combined for new products and services. Crowdsourcing has three functions in satellite data businesses: analyzing, monitoring, and collecting data. The functions of collecting and monitoring complementary ground data that are used with satellite data have become increasingly important in recent years. The conclusions indicate that the business ecosystems have evolved from being led by satellite data platforms to being coordinated by third parties.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Crowdsourcing has three functions in satellite data business; analyzing, monitoring, and collecting data. </LI> <LI>  There are direct and indirect crowdsourcing involvement pattern in satellite data. </LI> <LI>  Ground data have increasingly important complimentary roles to satellite data. </LI> <LI>  Business models have evolved from being led by satellite data platforms to being coordinated by third parties. </LI> </UL> </P>"
        },
        {
          "rank": 13,
          "score": 0.6268588900566101,
          "doc_id": "JAKO202009252092311",
          "title": "공공 빅데이터 플랫폼 성과평가 모형",
          "abstract": "본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009252092311&target=NART&cn=JAKO202009252092311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다."
        },
        {
          "rank": 14,
          "score": 0.6259179711341858,
          "doc_id": "NART104750886",
          "title": "Considerations for a More Ethical Approach to Data in AI: On Data Representation and Infrastructure",
          "abstract": "<P>Data shapes the development of Artificial Intelligence (AI) as we currently know it, and for many years centralized networking infrastructures have dominated both the sourcing and subsequent use of such data. Research suggests that centralized approaches result in poor representation, and as AI is now integrated more in daily life, there is a need for efforts to improve on this. The AI research community has begun to explore managing data infrastructures more democratically, finding that decentralized networking allows for more transparency which can alleviate core ethical concerns, such as selection-bias. With this in mind, herein, we present a mini-survey framed around data representation and data infrastructures in AI. We outline four key considerations (<I>auditing, benchmarking, confidence and trust, explainability and interpretability</I>) as they pertain to data-driven AI, and propose that reflection of them, along with improved interdisciplinary discussion may aid the mitigation of data-based AI ethical concerns, and ultimately improve individual wellbeing when interacting with AI.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART104750886&target=NART&cn=NART104750886",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Considerations for a More Ethical Approach to Data in AI: On Data Representation and Infrastructure Considerations for a More Ethical Approach to Data in AI: On Data Representation and Infrastructure Considerations for a More Ethical Approach to Data in AI: On Data Representation and Infrastructure <P>Data shapes the development of Artificial Intelligence (AI) as we currently know it, and for many years centralized networking infrastructures have dominated both the sourcing and subsequent use of such data. Research suggests that centralized approaches result in poor representation, and as AI is now integrated more in daily life, there is a need for efforts to improve on this. The AI research community has begun to explore managing data infrastructures more democratically, finding that decentralized networking allows for more transparency which can alleviate core ethical concerns, such as selection-bias. With this in mind, herein, we present a mini-survey framed around data representation and data infrastructures in AI. We outline four key considerations (<I>auditing, benchmarking, confidence and trust, explainability and interpretability</I>) as they pertain to data-driven AI, and propose that reflection of them, along with improved interdisciplinary discussion may aid the mitigation of data-based AI ethical concerns, and ultimately improve individual wellbeing when interacting with AI.</P>"
        },
        {
          "rank": 15,
          "score": 0.6212100386619568,
          "doc_id": "ART002829753",
          "title": "Factors Affecting the Use of Big Data: Focusing on the UTAUT2",
          "abstract": "This study examines the effects of organizational and individual factors on the use of big data. Specifically, we look at key factors affecting the corporate use of big data amidst the rapidly changing business trends with the advent of the 4th Revolution, and explore mutually beneficial causal relationships between variables. A research model was designed based on the Unified Theory of Acceptance and Use of Technology2 (UTAUT2) model and the related factors derived. Two major implications of this study are: (i) it provides basic data for future research on the causal relationships between organizational and individual factors and the use of big data and (ii) it offers a possibility to study the relationship between big data and organizational performance. The results of this study can serve as useful data for theoretical research such as the introduction and use of big data in companies as well as the central and local governments. This will help companies strive to gain a competitive edge from both the practical and theoretical standpoints to find an efficient way.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002829753&target=NART&cn=ART002829753",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Factors Affecting the Use of Big Data: Focusing on the UTAUT2 Factors Affecting the Use of Big Data: Focusing on the UTAUT2 Factors Affecting the Use of Big Data: Focusing on the UTAUT2 This study examines the effects of organizational and individual factors on the use of big data. Specifically, we look at key factors affecting the corporate use of big data amidst the rapidly changing business trends with the advent of the 4th Revolution, and explore mutually beneficial causal relationships between variables. A research model was designed based on the Unified Theory of Acceptance and Use of Technology2 (UTAUT2) model and the related factors derived. Two major implications of this study are: (i) it provides basic data for future research on the causal relationships between organizational and individual factors and the use of big data and (ii) it offers a possibility to study the relationship between big data and organizational performance. The results of this study can serve as useful data for theoretical research such as the introduction and use of big data in companies as well as the central and local governments. This will help companies strive to gain a competitive edge from both the practical and theoretical standpoints to find an efficient way."
        },
        {
          "rank": 16,
          "score": 0.6188564300537109,
          "doc_id": "ART002127072",
          "title": "Development of a Big Data Capability Assessment Model",
          "abstract": "Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002127072&target=NART&cn=ART002127072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback."
        },
        {
          "rank": 17,
          "score": 0.6169410347938538,
          "doc_id": "NART98480176",
          "title": "Factors influencing effective use of big data: A research framework",
          "abstract": "<P><B>Abstract</B></P>  <P>Information systems (IS) research has explored &ldquo;effective use&rdquo; in a variety of contexts. However, it is yet to specifically consider it in the context of the unique characteristics of big data. Yet, organizations have a high appetite for big data, and there is growing evidence that investments in big data solutions do not always lead to the derivation of intended value. Accordingly, there is a need for rigorous academic guidance on what factors enable effective use of big data. With this paper, we aim to guide IS researchers such that the expansion of the body of knowledge on the effective use of big data can proceed in a structured and systematic manner and can subsequently lead to empirically driven guidance for organizations. Namely, with this paper, we cast a wide net to understand and consolidate from literature the potential factors that can influence the effective use of big data, so they may be further studied. To do so, we first conduct a systematic literature review. Our review identifies 41 factors, which we categorize into 7 themes, namely data quality; data privacy and security and governance; perceived organizational benefit; process management; people aspects; systems, tools, and technologies; and organizational aspects. To explore the existence of these themes in practice, we then analyze 45 published case studies that document insights into how specific companies use big data successfully. Finally, we propose a framework for the study of effective use of big data as a basis for future research. Our contributions aim to guide researchers in establishing the relevance and relationships within the identified themes and factors and are a step toward developing a deeper understanding of effective use of big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Comprehensive review of the literature relating to the effective use of big data. </LI> <LI>  Identification of 7 themes, from the current body of literature. </LI> <LI>  We propose a framework and highlight research areas that require attention. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98480176&target=NART&cn=NART98480176",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Factors influencing effective use of big data: A research framework Factors influencing effective use of big data: A research framework Factors influencing effective use of big data: A research framework <P><B>Abstract</B></P>  <P>Information systems (IS) research has explored &ldquo;effective use&rdquo; in a variety of contexts. However, it is yet to specifically consider it in the context of the unique characteristics of big data. Yet, organizations have a high appetite for big data, and there is growing evidence that investments in big data solutions do not always lead to the derivation of intended value. Accordingly, there is a need for rigorous academic guidance on what factors enable effective use of big data. With this paper, we aim to guide IS researchers such that the expansion of the body of knowledge on the effective use of big data can proceed in a structured and systematic manner and can subsequently lead to empirically driven guidance for organizations. Namely, with this paper, we cast a wide net to understand and consolidate from literature the potential factors that can influence the effective use of big data, so they may be further studied. To do so, we first conduct a systematic literature review. Our review identifies 41 factors, which we categorize into 7 themes, namely data quality; data privacy and security and governance; perceived organizational benefit; process management; people aspects; systems, tools, and technologies; and organizational aspects. To explore the existence of these themes in practice, we then analyze 45 published case studies that document insights into how specific companies use big data successfully. Finally, we propose a framework for the study of effective use of big data as a basis for future research. Our contributions aim to guide researchers in establishing the relevance and relationships within the identified themes and factors and are a step toward developing a deeper understanding of effective use of big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Comprehensive review of the literature relating to the effective use of big data. </LI> <LI>  Identification of 7 themes, from the current body of literature. </LI> <LI>  We propose a framework and highlight research areas that require attention. </LI> </UL> </P>"
        },
        {
          "rank": 18,
          "score": 0.6155194640159607,
          "doc_id": "JAKO201905653788881",
          "title": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안",
          "abstract": "오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905653788881&target=NART&cn=JAKO201905653788881",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다."
        },
        {
          "rank": 19,
          "score": 0.6143724322319031,
          "doc_id": "JAKO200310912304785",
          "title": "위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구",
          "abstract": "차세대 무선 인터넷의 킬러 어플리케이션으로 주목받고 있는 위치기반서비스는 시간에 따른 시공간 객체의 위치 및 영역 변화에 대한 분석 기능이 필수적이다. 시공간 데이터베이스 시스템은 대용량 시공간객체의 실시간 위치 정보를 효과적으로 저장하고 빠른 검색을 제공하는 시스템으로 그 필요성이 증가하고 있다. 또한, 시공간 데이터베이스 시스템에서는 시공간 객체의 비공간정보와 공간정보 및 시간정보를 통합 관리할 수 있고, 시간 정보와 관련된 연산을 효율적으로 처리할 수 있는 시공간 데이터모델에 대한 연구가 활발히 진행중이다. 본 논문에서는 시간 흐름에 따라 동적으로 변화하는 시공간 객체 정보들을 현재 시점의 상태와 과거의 변화 과정에 대한 정보를 효과적으로 관리할 수 있는 시공간 데이터 모델을 제안한다. 또한 제안하는 시공간 데이터 모델을 위한 다양한 시공간 연산을 설계하며, 시공간 데이터와 시공간 객체 연산의 무결성을 유지하기 위한 제약조건을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200310912304785&target=NART&cn=JAKO200310912304785",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 차세대 무선 인터넷의 킬러 어플리케이션으로 주목받고 있는 위치기반서비스는 시간에 따른 시공간 객체의 위치 및 영역 변화에 대한 분석 기능이 필수적이다. 시공간 데이터베이스 시스템은 대용량 시공간객체의 실시간 위치 정보를 효과적으로 저장하고 빠른 검색을 제공하는 시스템으로 그 필요성이 증가하고 있다. 또한, 시공간 데이터베이스 시스템에서는 시공간 객체의 비공간정보와 공간정보 및 시간정보를 통합 관리할 수 있고, 시간 정보와 관련된 연산을 효율적으로 처리할 수 있는 시공간 데이터모델에 대한 연구가 활발히 진행중이다. 본 논문에서는 시간 흐름에 따라 동적으로 변화하는 시공간 객체 정보들을 현재 시점의 상태와 과거의 변화 과정에 대한 정보를 효과적으로 관리할 수 있는 시공간 데이터 모델을 제안한다. 또한 제안하는 시공간 데이터 모델을 위한 다양한 시공간 연산을 설계하며, 시공간 데이터와 시공간 객체 연산의 무결성을 유지하기 위한 제약조건을 제시한다."
        },
        {
          "rank": 20,
          "score": 0.6125800609588623,
          "doc_id": "JAKO200211921093731",
          "title": "시간 데이타마이닝 프레임워크",
          "abstract": "시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921093731&target=NART&cn=JAKO200211921093731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다."
        },
        {
          "rank": 21,
          "score": 0.6123735904693604,
          "doc_id": "NART125772135",
          "title": "Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data",
          "abstract": "<P>Big data is quickly becoming a new area where administrative work can be improved. Even so, it is still in the early stages of being used in hospitals in countries with less technology. Therefore, there is an inadequate grasp of the evaluation of big data adoption preparedness in the healthcare sector as data-point-determined insights become crucially useful in healthcare institutions in underdeveloped nations. This process, called &ldquo;digital transformation,&rdquo; has a lot of benefits; for example, it helps healthcare organizations to create more efficient processes, offer different services, give better care, make more money, and cut costs. This paper aims to suggest and assess a conceptual framework that focuses on technological factors and can assist in determining the readiness of healthcare institutions in developing nations to utilize big data. Although the study can offer valuable perspectives on the advantages that can arise from adopting big data in the healthcare sector, it is important to highlight that leveraging big data analytics in healthcare has the potential to enhance the efficiency and effectiveness of healthcare services. This, in turn, can indirectly contribute to sustainability objectives by optimizing the allocation of resources, minimizing waste, and improving patient outcomes. A total of 328 healthcare workers from Malaysia were subjected to experimental testing of the model. The collected data were evaluated using the Smart PLS 3 program and the structural equation model (SEM). The study&rsquo;s findings supported our hypotheses. The results showed that technological factors affected the participants&rsquo; perception of their readiness for big data, which ultimately influenced their interest in utilizing it. By concentrating on big data preparedness in the healthcare industry and ambition to utilize big data, this research provides an important theoretical contribution. Employees who are &ldquo;big data ready&rdquo; would benefit from the study&rsquo;s results, as, through their recognition, said employees are more likely to increase the desire to use big data in Malaysia&rsquo;s healthcare sectors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125772135&target=NART&cn=NART125772135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data <P>Big data is quickly becoming a new area where administrative work can be improved. Even so, it is still in the early stages of being used in hospitals in countries with less technology. Therefore, there is an inadequate grasp of the evaluation of big data adoption preparedness in the healthcare sector as data-point-determined insights become crucially useful in healthcare institutions in underdeveloped nations. This process, called &ldquo;digital transformation,&rdquo; has a lot of benefits; for example, it helps healthcare organizations to create more efficient processes, offer different services, give better care, make more money, and cut costs. This paper aims to suggest and assess a conceptual framework that focuses on technological factors and can assist in determining the readiness of healthcare institutions in developing nations to utilize big data. Although the study can offer valuable perspectives on the advantages that can arise from adopting big data in the healthcare sector, it is important to highlight that leveraging big data analytics in healthcare has the potential to enhance the efficiency and effectiveness of healthcare services. This, in turn, can indirectly contribute to sustainability objectives by optimizing the allocation of resources, minimizing waste, and improving patient outcomes. A total of 328 healthcare workers from Malaysia were subjected to experimental testing of the model. The collected data were evaluated using the Smart PLS 3 program and the structural equation model (SEM). The study&rsquo;s findings supported our hypotheses. The results showed that technological factors affected the participants&rsquo; perception of their readiness for big data, which ultimately influenced their interest in utilizing it. By concentrating on big data preparedness in the healthcare industry and ambition to utilize big data, this research provides an important theoretical contribution. Employees who are &ldquo;big data ready&rdquo; would benefit from the study&rsquo;s results, as, through their recognition, said employees are more likely to increase the desire to use big data in Malaysia&rsquo;s healthcare sectors.</P>"
        },
        {
          "rank": 22,
          "score": 0.6120390892028809,
          "doc_id": "JAKO201814446221611",
          "title": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현",
          "abstract": "본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201814446221611&target=NART&cn=JAKO201814446221611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다."
        },
        {
          "rank": 23,
          "score": 0.6100233793258667,
          "doc_id": "NART69871315",
          "title": "국내 기업의 업종별 지속가능성 순위 평가",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;‘지속가능성 보고’ 또는 ‘지속가능경영 보고서’는 지속가능한 발전을 위한 조직의 성과를 측정, 공개하고 이해관계자에게 그에 걸맞은 책임을 약속하는 활동을 의미한다. 지속가능보고서의 경우 제3자 검증을 거치지만, 보고서 간행 국제기준의 부합성 여부와 내용의 충실성을 일반인이 판단하기는 쉽지 않은 편이다. 본 연구는 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위한 목적을 가지고 실시되었다. 국내 15개 업종별 지속가능성 보고서를 기초로 GRI(Global Reporting Initiatives) G3 Guideline 기준 부합도 및 내용의 충실 정도를 비교 평가하였다. 그리고 해당 결과를 통해 지속가능 우수 업종을 판단하여 업종별 수행 미흡 지표분석 및 향후 지속가능성 보고의 발전방향을 제시하고자 하였다. 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위해 2010-2011년에 간행된 각 업종별 기업들의 지속가능성 보고서를 수집한 후 ‘원료’, ‘에너지’, ‘생물다양성’, ‘대기오염 물질과 폐수 및 폐기물’, ‘기타’ 등 GRI G3 가이드라인 환경지표(EN)에 기준한 6개 지표로 평가하였다. 적합성 및 충실도를 5점 척도에 적용 산출한 후 그 결과를 비교 평가하였다. 국내 기업의 환경부문 지속가능 경영 수준을 각 업종별 지속가능성 보고서를 통해 분석한 결과 대형유통업 &amp;gt; 철도운수업 &amp;gt; 금융업 &amp;gt; 생활용품제조업 &amp;gt; 전기전자제품제조업 &amp;gt; 종합건설업 &amp;gt; 정유업 = 자동차제조업 &amp;gt; 공기업A(국토해양부 산하) &amp;gt; 발전업 &amp;gt; 공기업B(지식경제부 산하) &amp;gt; 기계제조업 &amp;gt; 항공운수업 &amp;gt; 보험업 &amp;gt; 제철업 순으로 나타났다. 지속가능보고서 작성 기준의 체계화를 위해 GRI 가이드라인의 보완, 명확한 경계의 설정과 핵심지표와 부가지표의 수정이 필요하다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69871315&target=NART&cn=NART69871315",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국내 기업의 업종별 지속가능성 순위 평가 국내 기업의 업종별 지속가능성 순위 평가 국내 기업의 업종별 지속가능성 순위 평가 <P>&amp;nbsp;&amp;nbsp;‘지속가능성 보고’ 또는 ‘지속가능경영 보고서’는 지속가능한 발전을 위한 조직의 성과를 측정, 공개하고 이해관계자에게 그에 걸맞은 책임을 약속하는 활동을 의미한다. 지속가능보고서의 경우 제3자 검증을 거치지만, 보고서 간행 국제기준의 부합성 여부와 내용의 충실성을 일반인이 판단하기는 쉽지 않은 편이다. 본 연구는 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위한 목적을 가지고 실시되었다. 국내 15개 업종별 지속가능성 보고서를 기초로 GRI(Global Reporting Initiatives) G3 Guideline 기준 부합도 및 내용의 충실 정도를 비교 평가하였다. 그리고 해당 결과를 통해 지속가능 우수 업종을 판단하여 업종별 수행 미흡 지표분석 및 향후 지속가능성 보고의 발전방향을 제시하고자 하였다. 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위해 2010-2011년에 간행된 각 업종별 기업들의 지속가능성 보고서를 수집한 후 ‘원료’, ‘에너지’, ‘생물다양성’, ‘대기오염 물질과 폐수 및 폐기물’, ‘기타’ 등 GRI G3 가이드라인 환경지표(EN)에 기준한 6개 지표로 평가하였다. 적합성 및 충실도를 5점 척도에 적용 산출한 후 그 결과를 비교 평가하였다. 국내 기업의 환경부문 지속가능 경영 수준을 각 업종별 지속가능성 보고서를 통해 분석한 결과 대형유통업 &amp;gt; 철도운수업 &amp;gt; 금융업 &amp;gt; 생활용품제조업 &amp;gt; 전기전자제품제조업 &amp;gt; 종합건설업 &amp;gt; 정유업 = 자동차제조업 &amp;gt; 공기업A(국토해양부 산하) &amp;gt; 발전업 &amp;gt; 공기업B(지식경제부 산하) &amp;gt; 기계제조업 &amp;gt; 항공운수업 &amp;gt; 보험업 &amp;gt; 제철업 순으로 나타났다. 지속가능보고서 작성 기준의 체계화를 위해 GRI 가이드라인의 보완, 명확한 경계의 설정과 핵심지표와 부가지표의 수정이 필요하다.</P>"
        },
        {
          "rank": 24,
          "score": 0.609320878982544,
          "doc_id": "NART71734652",
          "title": "Big data analytics in healthcare: promise and potential",
          "abstract": "<P><B>Objective</B></P><P>To describe the promise and potential of big data analytics in healthcare.</P><P><B>Methods</B></P><P>The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions.</P><P><B>Results</B></P><P>The paper provides a broad overview of big data analytics for healthcare researchers and practitioners.</P><P><B>Conclusions</B></P><P>Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART71734652&target=NART&cn=NART71734652",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics in healthcare: promise and potential Big data analytics in healthcare: promise and potential Big data analytics in healthcare: promise and potential <P><B>Objective</B></P><P>To describe the promise and potential of big data analytics in healthcare.</P><P><B>Methods</B></P><P>The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions.</P><P><B>Results</B></P><P>The paper provides a broad overview of big data analytics for healthcare researchers and practitioners.</P><P><B>Conclusions</B></P><P>Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.</P>"
        },
        {
          "rank": 25,
          "score": 0.6092851758003235,
          "doc_id": "JAKO202130053207367",
          "title": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출",
          "abstract": "'빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202130053207367&target=NART&cn=JAKO202130053207367",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 '빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다."
        },
        {
          "rank": 26,
          "score": 0.6091272234916687,
          "doc_id": "JAKO201012259057254",
          "title": "데이터 품질관리 프레임워크와 비즈니스 시나리오",
          "abstract": "e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201012259057254&target=NART&cn=JAKO201012259057254",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다."
        },
        {
          "rank": 27,
          "score": 0.6089323163032532,
          "doc_id": "NART118817514",
          "title": "Ensuring the ethical use of big data: lessons from secure data access",
          "abstract": "<▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118817514&target=NART&cn=NART118817514",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access <▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>"
        },
        {
          "rank": 28,
          "score": 0.6087203025817871,
          "doc_id": "NART99544525",
          "title": "Healthcare informatics and analytics in big data",
          "abstract": "<P><B>Abstract</B></P>  <P>Healthcare informatics and analytics (HCI&amp;A), also known as healthcare information technology (HIT), healthcare IS (HIS), and so on, has rapidly evolved with the emerge of advanced data analytics technologies applied to the medical domain. Currently, HCI&amp;A has emerged as an important area of study for both practitioners and academic researchers. Accordingly, this emerging field has prompted for an inquiry of the opportunities and challenges related to management of healthcare data, and the application of advanced data analytics to the contemporary healthcare industry. In order to contribute to the literature of healthcare informatics and analytics, this study proposes an HCI&amp;A framework under the context of big data, which covers four important segments such as the underlying technologies, system applications, system evaluations, and emerging research areas. Based on the key features and capabilities of underpinning technologies, the evolution of HCI&amp;A are conceptualized by three stages, namely HCI&amp;A 1.0, HCI&amp;A 2.0, and HCI&amp;A 3.0. By analyzing the technological growth and current research trends, this study outlines the trend map of HCI&amp;A for education and knowledge transfer. We also contributed to conduct a bibliographic study on healthcare informatics and healthcare information systems. To the best of our knowledge, our study is among the very few comprehensive bibliographic studies about HCI&amp;A. We hope that our study can contribute to supplement contemporary thoughts on HCI&amp;A research, and facilitate the related knowledge transfer to the healthcare industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposed a framework for healthcare informatics in Big data context. </LI> <LI>  Presented an overall Synopsis of healthcare informatics and analytics. </LI> <LI>  Reported a bibliographic study on health informatics and information system. </LI> <LI>  Presented some problems and prospects of healthcare education &amp; development. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99544525&target=NART&cn=NART99544525",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Healthcare informatics and analytics in big data Healthcare informatics and analytics in big data Healthcare informatics and analytics in big data <P><B>Abstract</B></P>  <P>Healthcare informatics and analytics (HCI&amp;A), also known as healthcare information technology (HIT), healthcare IS (HIS), and so on, has rapidly evolved with the emerge of advanced data analytics technologies applied to the medical domain. Currently, HCI&amp;A has emerged as an important area of study for both practitioners and academic researchers. Accordingly, this emerging field has prompted for an inquiry of the opportunities and challenges related to management of healthcare data, and the application of advanced data analytics to the contemporary healthcare industry. In order to contribute to the literature of healthcare informatics and analytics, this study proposes an HCI&amp;A framework under the context of big data, which covers four important segments such as the underlying technologies, system applications, system evaluations, and emerging research areas. Based on the key features and capabilities of underpinning technologies, the evolution of HCI&amp;A are conceptualized by three stages, namely HCI&amp;A 1.0, HCI&amp;A 2.0, and HCI&amp;A 3.0. By analyzing the technological growth and current research trends, this study outlines the trend map of HCI&amp;A for education and knowledge transfer. We also contributed to conduct a bibliographic study on healthcare informatics and healthcare information systems. To the best of our knowledge, our study is among the very few comprehensive bibliographic studies about HCI&amp;A. We hope that our study can contribute to supplement contemporary thoughts on HCI&amp;A research, and facilitate the related knowledge transfer to the healthcare industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposed a framework for healthcare informatics in Big data context. </LI> <LI>  Presented an overall Synopsis of healthcare informatics and analytics. </LI> <LI>  Reported a bibliographic study on health informatics and information system. </LI> <LI>  Presented some problems and prospects of healthcare education &amp; development. </LI> </UL> </P>"
        },
        {
          "rank": 29,
          "score": 0.6086705923080444,
          "doc_id": "NART54831464",
          "title": "Crowdsourcing geospatial data",
          "abstract": "In this paper we review recent developments of crowdsourcing geospatial    data. While traditional mapping is nearly exclusively coordinated and often    also carried out by large organisations, crowdsourcing geospatial data    refers to generating a map using informal social networks and web 2.0    technology. Key differences are the fact that users lacking formal training    in map making create the geospatial data themselves rather than relying on    professional services; that potentially very large user groups collaborate    voluntarily and often without financial compensation with the result that    at a very low monetary cost open datasets become available and that mapping    and change detection occur in real time. This situation is similar to that    found in the Open Source software environment. We shortly explain the basic    technology needed for crowdsourcing geospatial data, discuss the underlying    concepts including quality issues and give some examples for this novel way    of generating geospatial data. We also point at applications where    alternatives do not exist such as life traffic information systems. Finally    we explore the future of crowdsourcing geospatial data and give some    concluding remarks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART54831464&target=NART&cn=NART54831464",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing geospatial data Crowdsourcing geospatial data Crowdsourcing geospatial data In this paper we review recent developments of crowdsourcing geospatial    data. While traditional mapping is nearly exclusively coordinated and often    also carried out by large organisations, crowdsourcing geospatial data    refers to generating a map using informal social networks and web 2.0    technology. Key differences are the fact that users lacking formal training    in map making create the geospatial data themselves rather than relying on    professional services; that potentially very large user groups collaborate    voluntarily and often without financial compensation with the result that    at a very low monetary cost open datasets become available and that mapping    and change detection occur in real time. This situation is similar to that    found in the Open Source software environment. We shortly explain the basic    technology needed for crowdsourcing geospatial data, discuss the underlying    concepts including quality issues and give some examples for this novel way    of generating geospatial data. We also point at applications where    alternatives do not exist such as life traffic information systems. Finally    we explore the future of crowdsourcing geospatial data and give some    concluding remarks."
        },
        {
          "rank": 30,
          "score": 0.6081985831260681,
          "doc_id": "NART103720250",
          "title": "Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives",
          "abstract": "<P>This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103720250&target=NART&cn=NART103720250",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives <P>This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production.</P>"
        },
        {
          "rank": 31,
          "score": 0.6068410873413086,
          "doc_id": "NART111678324",
          "title": "Open Source Framework for Enabling HPC and Cloud Geoprocessing Services",
          "abstract": "<P>Geoprocessing is a set of tools that can be used to efficiently address several pressing chal-lenges for the global economy ranging from agricultural productivity, the design of transport networks, to the prediction of climate change and natural disasters. This paper describes an Open Source Framework developed, within three European projects, for Ena-bling High-Performance Computing (HPC) and Cloud geoprocessing services applied to agricultural challenges. The main goals of the European Union projects EUXDAT (EUro-pean e-infrastructure for eXtreme Data Analytics in sustainable developmenT), CYBELE (fostering precision agriculture and livestock farming through secure access to large-scale HPC-enabled virtual industrial experimentation environment empowering scalable big data analytics), and EOPEN (opEn interOperable Platform for unified access and analysis of Earth observatioN data) are to enable the use of large HPC systems, as well as big data management, user-friendly access and visualization of results. In addition, these projects focus on the development of software frameworks, and fuse Earth-observation data, such as Copernicus data, with non-Earth-observation data, such as weather, environmental and social media information. In this paper, we describe the agroclimatic-zones pilot used to validate the framework. Finally, performance metrics collected during the execution (up to 182 times speedup with 256 MPI processes) of the pilot are presented.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111678324&target=NART&cn=NART111678324",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Open Source Framework for Enabling HPC and Cloud Geoprocessing Services Open Source Framework for Enabling HPC and Cloud Geoprocessing Services Open Source Framework for Enabling HPC and Cloud Geoprocessing Services <P>Geoprocessing is a set of tools that can be used to efficiently address several pressing chal-lenges for the global economy ranging from agricultural productivity, the design of transport networks, to the prediction of climate change and natural disasters. This paper describes an Open Source Framework developed, within three European projects, for Ena-bling High-Performance Computing (HPC) and Cloud geoprocessing services applied to agricultural challenges. The main goals of the European Union projects EUXDAT (EUro-pean e-infrastructure for eXtreme Data Analytics in sustainable developmenT), CYBELE (fostering precision agriculture and livestock farming through secure access to large-scale HPC-enabled virtual industrial experimentation environment empowering scalable big data analytics), and EOPEN (opEn interOperable Platform for unified access and analysis of Earth observatioN data) are to enable the use of large HPC systems, as well as big data management, user-friendly access and visualization of results. In addition, these projects focus on the development of software frameworks, and fuse Earth-observation data, such as Copernicus data, with non-Earth-observation data, such as weather, environmental and social media information. In this paper, we describe the agroclimatic-zones pilot used to validate the framework. Finally, performance metrics collected during the execution (up to 182 times speedup with 256 MPI processes) of the pilot are presented.</P>"
        },
        {
          "rank": 32,
          "score": 0.60670006275177,
          "doc_id": "NART93845311",
          "title": "Security Benefits of Little Data From the Socio-Technical Perspective :",
          "abstract": "<P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART93845311&target=NART&cn=NART93845311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : <P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>"
        },
        {
          "rank": 33,
          "score": 0.6061517596244812,
          "doc_id": "DIKO0016665439",
          "title": "이기종 장치간 협업을 위한 데이터 공유 프레임워크",
          "abstract": "본 연구는 다중 장치 환경에서 장치 간의 협업을 위한 프레임워크를 제안한다. 응용프로그램 수준에서 직접 데이터를 전송하려면 데이터를 처리할 장치에도 해당 응용프로그램이 설치되어 있어야 한다. 이런 접근 방법은 응용프로그램에 종속적이며 데이터를 전송하고자 하는 응용프로그램마다 이를 위한 코드를 개별적으로 작성해야 한다. 본 논문이 제안하는 데이터 공유 프레임워크는 다중 장치 환경에서 사용자가 응용프로그램의 설치 및 변경 없이 데이터를 전송할 수 있는 환경을 제공한다. 프레임워크에서 데이터 전송을 지원함으로써 특정 기능을 투명하게 원격에서 실행할 수 있다. 실험을 통해 프레임워크의 데이터 원격 전송의 속도를 향상하기 위한 외부 라이브러리의 도입을 검증하였고, 제안하는 프레임워크의 데이터 전송 및 인텐트 원격 실행 속도를 측정하여 실효성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016665439&target=NART&cn=DIKO0016665439",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 장치간 협업을 위한 데이터 공유 프레임워크 이기종 장치간 협업을 위한 데이터 공유 프레임워크 이기종 장치간 협업을 위한 데이터 공유 프레임워크 본 연구는 다중 장치 환경에서 장치 간의 협업을 위한 프레임워크를 제안한다. 응용프로그램 수준에서 직접 데이터를 전송하려면 데이터를 처리할 장치에도 해당 응용프로그램이 설치되어 있어야 한다. 이런 접근 방법은 응용프로그램에 종속적이며 데이터를 전송하고자 하는 응용프로그램마다 이를 위한 코드를 개별적으로 작성해야 한다. 본 논문이 제안하는 데이터 공유 프레임워크는 다중 장치 환경에서 사용자가 응용프로그램의 설치 및 변경 없이 데이터를 전송할 수 있는 환경을 제공한다. 프레임워크에서 데이터 전송을 지원함으로써 특정 기능을 투명하게 원격에서 실행할 수 있다. 실험을 통해 프레임워크의 데이터 원격 전송의 속도를 향상하기 위한 외부 라이브러리의 도입을 검증하였고, 제안하는 프레임워크의 데이터 전송 및 인텐트 원격 실행 속도를 측정하여 실효성을 입증하였다."
        },
        {
          "rank": 34,
          "score": 0.6056994199752808,
          "doc_id": "DIKO0013973515",
          "title": "DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구",
          "abstract": "한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다.  SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013973515&target=NART&cn=DIKO0013973515",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구 DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구 DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다.  SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다."
        },
        {
          "rank": 35,
          "score": 0.605144739151001,
          "doc_id": "NART108501356",
          "title": "Environmental air pollution management system: Predicting user adoption behavior of big data analytics",
          "abstract": "<P><B>Abstract</B></P>  <P>This study has a dual purpose: to explore the novel phenomenon of a big data analytics-environmental air pollution (BDA-EAP) management system, and to propose a research model of factors influencing adoption of such a system. The research model is based on task-technology fit (TTF) and unified theory of acceptance and use of technology (UTAUT) concepts. A comprehensive BDA-EAP management system is proposed and the potential adoption speed of such a system evaluated by sending structured questionnaires to the employees of relevant environmental agencies, yielding 412 valid responses, using the structural equation modeling approach. The results of the study predict that factors of TTF including task characteristics and technology characteristics are strong influencers of TTF, and TTF is a strong predictor of the behavioral intention of users to adopt a BDA-EAP management system. The results demonstrated that the combination of TTF and UTAUT is a stronger predictor of behavioral intention than either TTF or UTAUT alone. Furthermore, resistance to change negatively moderates and extrinsic motivation positively moderates the significant positive relationship between behavioral intention and adoption of a BDA-EAP management system. Meanwhile, behavioral intention, resistance to change, and extrinsic motivation have a significant three-way interaction impact on adoption of a BDA-EAP management system such that an increase in users&rsquo; extrinsic motivation will decrease the negative impact of resistance to change during the process of adoption. The study findings contribute to the literature regarding the use of BDA to manage EAP, and provide a basis for future research in this area.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Explores the novel big data analytics-environmental air pollutionmanagement system. </LI> <LI>  Proposes a research model of factors influencing adoption of such a system. </LI> <LI>  Model based on <I>task-technology fit</I> and <I>unified theory of acceptance and use of technology</I> concepts. </LI> <LI>  Combination of TTF and UTAUT is a stronger predictor of behavioral intention. </LI> <LI>  Contributes to literature about use of big data analytics to manage environmental air pollution. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108501356&target=NART&cn=NART108501356",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Environmental air pollution management system: Predicting user adoption behavior of big data analytics Environmental air pollution management system: Predicting user adoption behavior of big data analytics Environmental air pollution management system: Predicting user adoption behavior of big data analytics <P><B>Abstract</B></P>  <P>This study has a dual purpose: to explore the novel phenomenon of a big data analytics-environmental air pollution (BDA-EAP) management system, and to propose a research model of factors influencing adoption of such a system. The research model is based on task-technology fit (TTF) and unified theory of acceptance and use of technology (UTAUT) concepts. A comprehensive BDA-EAP management system is proposed and the potential adoption speed of such a system evaluated by sending structured questionnaires to the employees of relevant environmental agencies, yielding 412 valid responses, using the structural equation modeling approach. The results of the study predict that factors of TTF including task characteristics and technology characteristics are strong influencers of TTF, and TTF is a strong predictor of the behavioral intention of users to adopt a BDA-EAP management system. The results demonstrated that the combination of TTF and UTAUT is a stronger predictor of behavioral intention than either TTF or UTAUT alone. Furthermore, resistance to change negatively moderates and extrinsic motivation positively moderates the significant positive relationship between behavioral intention and adoption of a BDA-EAP management system. Meanwhile, behavioral intention, resistance to change, and extrinsic motivation have a significant three-way interaction impact on adoption of a BDA-EAP management system such that an increase in users&rsquo; extrinsic motivation will decrease the negative impact of resistance to change during the process of adoption. The study findings contribute to the literature regarding the use of BDA to manage EAP, and provide a basis for future research in this area.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Explores the novel big data analytics-environmental air pollutionmanagement system. </LI> <LI>  Proposes a research model of factors influencing adoption of such a system. </LI> <LI>  Model based on <I>task-technology fit</I> and <I>unified theory of acceptance and use of technology</I> concepts. </LI> <LI>  Combination of TTF and UTAUT is a stronger predictor of behavioral intention. </LI> <LI>  Contributes to literature about use of big data analytics to manage environmental air pollution. </LI> </UL> </P>"
        },
        {
          "rank": 36,
          "score": 0.6048188805580139,
          "doc_id": "NART76320729",
          "title": "Demystifying big data: Anatomy of big data developmental process",
          "abstract": "<P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART76320729&target=NART&cn=NART76320729",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process <P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>"
        },
        {
          "rank": 37,
          "score": 0.6044092178344727,
          "doc_id": "ATN0037490138",
          "title": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크",
          "abstract": "In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037490138&target=NART&cn=ATN0037490138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains."
        },
        {
          "rank": 38,
          "score": 0.6040891408920288,
          "doc_id": "ATN0048509631",
          "title": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안",
          "abstract": "빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0048509631&target=NART&cn=ATN0048509631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다."
        },
        {
          "rank": 39,
          "score": 0.6035046577453613,
          "doc_id": "DIKO0017054067",
          "title": "교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구",
          "abstract": "빅데이터와 인공지능 기술의 비약적인 발전으로 시대가 데이터를 바라보는 관점이 달라졌다. 이제 데이터는 모두의 합리적인 의사결정 과정에 활용될 수 있는 귀중한 자원이다. 이는 교육에서도 마찬가지며 특히 교사는 데이터를 잘 수집, 분석, 해석하는 절차를 통해 교수적 의사결정 능력을 향상할 수 있다. 이러한 추세에 따라 정부에서도 AI 디지털교과서 같은 교육 데이터 기반의 맞춤형 수업 지원 방안을 위한 인프라를 조성하고 있고, 민간 기업 차원에서도 학습 관리 시스템(Learning Management System) 같은 플랫폼에 개별 학습자 데이터 보관 및 활용을 강화하여 이를 기반으로 개별화 교수전략을 지원하는 등의 움직임을 보인다. 이를 바탕으로 학계에서는 교사의 데이터 리터러시를 어떻게 향상할 지에 대한 논 의 또한 끊임없이 진행되고 있다. 교사를 위한 데이터 리터러시 역량에는 단순히 데이터를 잘 활용하는 것만을 의미하지는 않는다. 궁극적으로 목표하는 행동인 데이터 기반 의사결정을 촉진하기 위해 문제 확인 및 목표 설정, 데이터 수집, 데이터 분석, 데이터 해석 그리고 교수적 의사결정의 요소를 고려한다. 이러한 역량을 기반으로 교사들의 맞춤형 수업 진행도, 개별화 교수전략 지원도 효과적으로 이뤄질 수 있는 것이다. 반면, 교사들은 데이터 분석 학습에는 높은 비용과 에너지가 요구된다. 대다수 교사는 데이터 분석에 대한 비전공자일 뿐만 아니라 현업을 병행하는 학습자로서 데이터 리터러시 향상을 위한 교육 프로그램을 장기간 체계적으로 이수하기 어려운 상황에 있다. 더불어, 선행연구를 고찰하였을 때, 교육 프로그램을 수강할지라 도 데이터 분석 과정 중에서 통계, 머신러닝 등의 지식 위주로만 학습되고 있었으며, 현장에서의 데이터 분석 활용에 대한 역량 계발 지원이 미흡한 실정이다. 따라서 본 연구는 교사의 데이터 리터러시 향상을 위해 데이터 기반 의사결정의 단 계에 따라 생성형 AI 챗봇을 개발하고 이를 활용하는 방식을 제안하고자 한다. 이를 위해 우선, 프롬프트 엔지니어링 전략을 통해 생성형 AI를 훈련하여 교사의 데이터 기반 의사결정을 위한 챗봇을 개발하고자 하였다. 프롬프트 엔지니어링은 생성형 AI와 같은 대규모 언어모델이 사용자의 명령을 피드백 삼아서 높은 확률과 명확한 예측값을 생성할 수 있도록 훈련하는 것이다. 이러한 방식은 생성형 AI 챗봇을 교육적으로 활용하는 데에 문제가 될 만한 환각(hallucination) 요소를 줄이는 데 효과적이다. 다음으로, 교사가 1:1로 생성형 AI 챗봇을 주체적으로 활용하도록 촉진하기 위해 의사결정 기반 학습을 지원하고자 한다. 데이터 분석에 관한 초보자인 대다수 교사에게 데이터 기반 의사결정 절차에 따라 생성형 AI를 활용하여 데이터 분석을 하도록 함으로써 데이터 기반 의사결정의 효능감을 촉진할 수 있도록 한다. 따라서, 본 연구의 목적은 교사를 대상으로 데이터 리터러시 향상을 위한 생성형 AI 챗봇을 개발하고, 데이터 리터러시 및 데이터 기반 의사결정의 효과성을 양적으로 검증한 후 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정의 요소, 절차 등에 관해 학습한 학습자의 반응을 질적으로 분석하고자 한다. 이를 위해 본 연구에서 설정한 연구 문제는 다음과 같다. 1. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇은 어떻게 구현할 것인가? 2. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇의 효과는 어떠한가? 2.1. 생성형 AI 챗봇을 활용함으로써 데이터 리터러시가 향상되는가? 2.2. 생성형 AI 챗봇을 활용함으로써 데이터 기반 의사결정 효능감이 향상되는가? 3. 데이터 기반 의사결정을 위한 생성형 AI 챗봇에 대한 학습자 반응은 어떠한가? 위 연구 문제에 따른 결과를 검증하기 위해 본 연구는 Richey와 Klein의 설계· 개발 연구방법에 따라 진행하였다. 설계·개발 연구방법 중에서도 유형I의 산출물 및 도구 개발을 택하여 분석, 설계, 개발 및 평가의 4단계를 따랐다. 분석 단계에서는 프롬프트, 데이터 리터러시, 의사결정 학습 절차에 관한 선행연구를 고찰하여 생성형 AI 챗봇 개발을 위한 데이터 기반 의사결정 학습 절차를 구조화했다. 그리고 현장 교사 31명을 대상으로 요구 분석을 진행하여 교사 대상의 생성형 AI 챗봇 활용 데이터 분석에 적합한 교육 데이터 분석 사례를 탐색하고자 했다. 설계 단계에서는 앞서 진행한 문헌 분석과 요구 분석에 따라 생성형 AI 활용 데이터 기반 의사결정 학습 절차를 확고히 했고, 이에 따라 프롬프트 패턴 및 전략 을 참고하여 생성형 AI를 훈련할 프롬프트를 설계했다. 그리고 개발 및 평가 단계 에서는 다량의 프롬프트 입력을 통해 훈련된 생성형 AI 챗봇을 개발하였다. 이후 5인의 전문가 검토와 4인의 파일럿 테스트를 거쳐서 최종적으로 챗봇을 보완한 뒤 단일집단을 대상으로 효과성 검증을 위한 실험을 진행하였다. 총 25명의 교사를 대상으로 1차, 2차 실험을 대략 2주 동안 ZOOM 실험 환경에서 진행하였다. 이후 데이터 리터러시와 데이터 기반 의사결정 효능감에 관한 사전-사후 효과성 검증을 대응표본 t 검정을 통해 진행하였다. 그리고 학습자 반응 분석을 위해 실험에 참여한 교사들이 응답한 성찰일지를 분석하였다. 이를 바탕으로 도출한 본 연구의 주된 결과와 논의 사항은 다음과 같다. 첫째, 9단계의 데이터 기반 의사결정 학습 절차에 따른 교사의 데이터 기반 의 사결정을 위한 생성형 AI 챗봇을 개발하였다. 이를 위해 우선 D0. 사전 안내, D1. 문제 정의 및 가설 설정, D2. 데이터 수집, D3. 데이터 품질 확인을 위한 전처리, D4. 예측 모델을 통한 데이터 분석, D5. 데이터 해석 및 결론 도출, D6. 데이터 평가, D7. 데이터 시각화, D8. 교수적 처치 계획의 총 9단계 데이터 기반 의사결정 학습 절차를 구성하였다. 그 뒤 각 절차에 따른 생성형 AI 챗봇을 구현하기 위해 대화 기반의 프롬프트를 설계하고 이를 훈련했다. 이때 학습 맥락 조정, 학습 키워드 강조, 오류 점검을 위주로 퓨샷(few-shot), 형식지정(format), 핵심어(seed-word), 제로샷(zero-shot), 마크다운(markdown), 사고의 연쇄 기법(CoT), 다시 생각하기(Let’s think about this), 다시 생성하기(ReAct)의 프롬프트 엔지니어링 전략을 활용하였다. 그렇게 GPTs 환경에서 생성형 AI 챗봇이 개발되었다. 둘째, 교사를 대상으로 데이터 기반 의사결정을 위한 생성형 AI 챗봇을 사용하였을 때, 데이터 리터러시와 데이터 기반 의사결정 효능감의 효과성을 검증하였다. 데이터 리터러시는 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 데이터 리터러시의 하위 요소인 문제 확인 및 정의, 데이터 수집 및 관리, 데이터 분석 및 표현, 교수적 의사결정, 평가 및 성찰 요소 모두 통계적으로 유의미하게 향상되었다. 더불어 위 결과에 관하여 생성형 AI 챗봇을 통해 주체적으로 데이터 분석을 진행하고, 데이터 분석에 관한 지식을 유연하고 효율적으로 학습할 수 있었다는 학습자 응답 결과가 뒷받침될 수 있었다. 데이터 기반 의사결정 효능 감 또한 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 그리고 이러한 결과는 생성형 AI 챗봇을 활용하여 데이터 리터러시가 향상된다면, 데이터 기반 의사결정 효능감 또한 향상된 점을 시사한다. 더불어 위의 결과는 생성형 AI 챗봇을 통해 데이터 기반 교수적 의사결정과 처방의 가능성을 탐색했다는 학습자 응답 결과에서도 뒷받침될 수 있었다. 셋째, 생성형 AI 챗봇을 활용한 교사를 대상으로 학습자 반응을 분석하여 학습자가 인식한 단점, 개선할 점을 통해 챗봇의 보완 방향을 도출하였다. 보완 방향에는 총 4가지가 언급되었으며, 주요 내용은 다음과 같다. 인지 부하 조절을 위한 여러 스캐폴딩 요소 지원, 생성형 AI 챗봇이 더욱 직관적이고 편리한 UX와 UI 지원, 한글 사용에 불편함이 없는 생성형 AI 챗봇 지원, 생성형 AI의 활용범위를 확장하여 사용자에게 맞춤화된 경험 지원에 관해 논할 수 있었다. 이를 바탕으로 본 연구의 이론적, 실천적, 방법적인 시사점은 다음과 같다. 첫째, 이론적 시사점으로써 교사를 대상으로 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정 학습 절차에 따라 진행하였을 때 데이터 리터러시 및 데이터 기반 의사결정 효능감이 향상되었다는 것을 밝혀낸 실증 연구로서 기여한 점이다. 둘째, 실천적 시사점으로써 학교 현장 속 교사들의 데이터 기반 의사결정 과정을 지 원해줄 수 있는 생성형 AI 챗봇을 개발한 것이다. 셋째, 방법적 시사점으로써 프롬프트 엔지니어링을 통해 생성형 AI를 훈련하여 챗봇 형태로 구현하고 이를 교사를 위한 데이터 기반 의사결정 학습 차원에서 적용한 것이다. 마지막으로 본 연구의 제한점과 후속 연구를 위한 제언은 다음과 같다. 첫째, 개발된 생성형 AI 챗봇 사용을 위한 접근성 측면에서 ChatGPT 멤버십에 관한 제약이 있었다. 그렇지만, 최근 GPT-4o 버전이 출시되면서 무료화되었다. 따라서 앞으로 교사들이 더욱 접근성 있게 생성형 AI 챗봇을 활용할 수 있도록 여러 기회 와 자원이 지원되어야 할 것이다. 둘째, 연구 참여자의 다양성 측면에서 교사에 관한 전체 모집단을 고려하기엔 본 연구의 표본은 부족했다. 이에 따라 향후 연구에서는 교사들의 연령대, 교직 경력, 학교급, 담당 과목 등을 균등하게 고려하여 더욱 많은 교사를 모집하는 것이 필요하다. 셋째, 교육현장의 훨씬 다양한 맥락에서 데이터 기반 의사결정을 고려하지 못하였다. 이에 따라 앞으로는 학습자 군집에 따른 맞춤형 교수전략 외에 현장에서 접할 수 있는 다양한 맥락을 고려하여 생성형 AI 챗봇을 통한 데이터 기반 의사결정 과정을 지원할 필요가 있다.Big data and artificial intelligence have revolutionized our approach to data, establishing it as a valuable resource for informed decision-making across various fields, including education. Specifically, teachers can improve their ability to make instructional decisions by learning to collect, analyze, and interpret data effectively. For these reasons, the Korean government is developing an infrastructure to support personalized instruction based on educational data, such as AI digital textbooks. At the same time, companies are integrating individual learner data into platforms like learning management systems to support personalized teaching strategies. In addition, there is ongoing research and discussion on how to improve teachers' data literacy, aiming to equip teachers with the necessary skills to effectively interpret and utilize data in their teaching practices. Teachers' data literacy skills encompass more than mere proficiency with data. They are about facilitating data-driven decision-making, which is the ultimate goal. Subcomponents include problem identification and goal setting, data collection, data analysis, data interpretation, and instructional decision-making. With these competencies, teachers can effectively tailor their instruction to meet individual needs and implement personalized teaching strategies. On the other hand, equipping teachers with data analytics skills to enhance their data literacy has proven to be costly and energy-intensive. Most teachers, being novices in data analytics and learning while on the job, find it challenging to systematically complete data literacy training programs over an extended period. In addition, a review of previous studies shows that data analytics courses tend to focus on imparting knowledge in areas like statistics and machine learning, but they fail to provide adequate support for developing competencies in the use of data analytics in practice. Therefore, this study proposes a method to develop and use a generative AI for data-driven decision-making to effectively and efficiently enhance teachers' data literacy. To do so, this study first aimed to develop a chatbot to improve teachers' data literacy by employing a prompt engineering strategy to train generative AI. Prompt engineering involves training large-scale language models, such as generative AI, to generate high probability and more accurate predictions by using user command prompts as feedback. This approach helps reduce issues such as hallucination, which pose significant challenges in the educational application of generative AI chatbots. Next, this study aims to support teachers in using generative AI chatbots in one-on-one settings, following a decision-learning process, to effectively enhance data literacy. By guiding teachers, many of whom are novices in data analysis, through the steps of a data-driven decision-making process using generative AI, teachers’ competency in data-driven decision-making can be promoted. Therefore, the purpose of this study is to develop a generative AI chatbot to improve teachers' data literacy, quantitatively verify the effectiveness of data literacy and data-driven decision-making, and qualitatively analyze teachers' responses to the generative AI chatbot. For this purpose, the following research questions were derived. RQ1. How can a generative AI chatbot be developed for teachers’ data-driven decision-making? RQ2. Is a generative AI chatbot effective for teachers' data-driven decision-making? RQ2.1. Does utilizing generative AI chatbots improve data literacy? RQ2.2. Does utilizing generative AI chatbots improve data-driven decision-making efficacy? RQ3. How do teachers respond to generative AI chatbots for data-driven decision-making? To address the research questions above, this study adopted Richey and Klein's design and development research method. Specifically, following their Type I method for developing products and tools, the study was conducted across four phases: analysis, design, development, and evaluation. In the analysis phase, previous studies on prompts, data literacy, and decision-learning procedures were reviewed to structure a data-driven decision-learning procedure for developing generative AI chatbots. Then, a needs analysis was conducted with 31 teachers in the field to explore educational data analysis cases suitable for data analysis utilizing generative AI chatbots for teachers. In the design phase, the data-driven decision-learning procedure for generative AI was solidified based on the literature review and needs analysis. Prompts were designed to train generative AI by referring to prompt patterns and strategies. In the development and evaluation phase, a generative AI chatbot trained with a large amount of prompt input was developed. The chatbot was then reviewed by five experts and pilot-tested by four participants. Finally, after refining the chatbot, an experiment was conducted to verify its effectiveness. A one-group pre-post paired sample t-test was conducted with a total of 25 teachers on ZOOM for about two weeks. Afterward, the effectiveness of data literacy and data-driven decision-making efficacy were evaluated using paired-sample t-tests. To further analyze teachers’ responses, reflection journals from the teachers who participated in the experiment were examined using open-coding techniques. The main findings and discussions of this study are as follows. First, a generative AI chatbot was developed based on nine data-driven decision-making learning procedures to enhance and support data-driven decision-making among teachers. To do so, To this end, a nine-step data-driven decision-learning process was first constructed, consisting of nine steps: D0. Preliminary guidance, D1. Problem definition and hypothesis generation, D2. Data collection, D3. Preprocessing to check data quality, D4. Data analysis using predictive models, D5. Data interpretation and inference, D6. Data Evaluation, D7. Data Visualization, and D8. Instructional Action Plan. Then, dialog-based prompts were designed and trained according to the data-driven decision-making learning process derived earlier. Various prompting strategies were employed, including few-shot, format, seed-word, zero-shot, markdown, chain-of-thinking (CoT), let's think about this, and re-generate (ReAct). These strategies were used to adjust the learning context, emphasize learning keywords, and check the errors. Subsequently, the generative AI chatbot was developed within the GPTs environment. Second, the effectiveness of using a generative AI chatbot for enhancing teachers' data literacy and data-driven decision-making was verified. Data literacy significantly improved, as indicated by descriptive statistics and paired sample t-tests. The sub-components of data literacy—problem identification and definition, data collection and management, data analysis and representation, instructional decision-making, and evaluation and reflection elements—were all statistically significantly improved. These findings were further supported by teachers' reflective responses, which highlighted their recognition of the generative AI chatbots as a valuable tool. According to their responses, teachers reported taking greater ownership of data analysis and developing flexibility and efficiency in applying their data analysis skills. The results from descriptive statistics and paired-sample t-tests indicated significant improvements in teachers' data-driven decision-making efficacy. These findings suggest that enhancing data literacy through the use of generative AI chatbots also boosts decision-making efficacy. Furthermore, these results are also supported by the teachers' reflective responses in that they explored the possibility of data-driven instructional decision-making and intervention through generative AI chatbots. Third, teachers' responses to teachers using the generative AI chatbot were analyzed to identify areas for improvement. Discussions emphasized the need to provide scaffolding to manage their cognitive load, enhance the UX and UI of generative AI chatbots to make them more intuitive and convenient, ensure the chatbots function seamlessly in Korean, and expand the capabilities of generative AI to deliver customized experiences. Based on these findings, the implications of this study are threefold. First, for a theoretical implication, this study empirically verified that teachers' data literacy and data-driven decision-making efficacy improved when they followed a data-driven decision-making learning process using a generative AI chatbot. Second, for a practical implication, this study developed a generative AI chatbot that can support teachers' data-driven decision-making process in schools. Third, as a methodological implication, the study attempted to demonstrate the application of prompt engineering to train generative AI, which was then implemented as a chatbot and applied in facilitating data-driven decision-making. The limitations of this study and suggestions for further research are as follows. First, accessing the developed generative AI chatbot required a ChatGPT membership, which posed a barrier for teachers. Therefore, future efforts should concentrate on enhancing the accessibility of generative AI chatbots to teachers.Second, the diversity of the participants in the study was insufficient to reflect the overall population. Therefore, future research should consider recruiting a larger and more diverse group of teachers, ensuring equal representation across age, teaching experience, school levels, and subjects. Third, this study's exploration of data-driven decision-making was constrained to a limited range of contexts. Future studies should broaden their scope to include various contexts encountered in the educational field and provide enhanced support for data-driven decision-making processes using generative AI chatbots.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017054067&target=NART&cn=DIKO0017054067",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 빅데이터와 인공지능 기술의 비약적인 발전으로 시대가 데이터를 바라보는 관점이 달라졌다. 이제 데이터는 모두의 합리적인 의사결정 과정에 활용될 수 있는 귀중한 자원이다. 이는 교육에서도 마찬가지며 특히 교사는 데이터를 잘 수집, 분석, 해석하는 절차를 통해 교수적 의사결정 능력을 향상할 수 있다. 이러한 추세에 따라 정부에서도 AI 디지털교과서 같은 교육 데이터 기반의 맞춤형 수업 지원 방안을 위한 인프라를 조성하고 있고, 민간 기업 차원에서도 학습 관리 시스템(Learning Management System) 같은 플랫폼에 개별 학습자 데이터 보관 및 활용을 강화하여 이를 기반으로 개별화 교수전략을 지원하는 등의 움직임을 보인다. 이를 바탕으로 학계에서는 교사의 데이터 리터러시를 어떻게 향상할 지에 대한 논 의 또한 끊임없이 진행되고 있다. 교사를 위한 데이터 리터러시 역량에는 단순히 데이터를 잘 활용하는 것만을 의미하지는 않는다. 궁극적으로 목표하는 행동인 데이터 기반 의사결정을 촉진하기 위해 문제 확인 및 목표 설정, 데이터 수집, 데이터 분석, 데이터 해석 그리고 교수적 의사결정의 요소를 고려한다. 이러한 역량을 기반으로 교사들의 맞춤형 수업 진행도, 개별화 교수전략 지원도 효과적으로 이뤄질 수 있는 것이다. 반면, 교사들은 데이터 분석 학습에는 높은 비용과 에너지가 요구된다. 대다수 교사는 데이터 분석에 대한 비전공자일 뿐만 아니라 현업을 병행하는 학습자로서 데이터 리터러시 향상을 위한 교육 프로그램을 장기간 체계적으로 이수하기 어려운 상황에 있다. 더불어, 선행연구를 고찰하였을 때, 교육 프로그램을 수강할지라 도 데이터 분석 과정 중에서 통계, 머신러닝 등의 지식 위주로만 학습되고 있었으며, 현장에서의 데이터 분석 활용에 대한 역량 계발 지원이 미흡한 실정이다. 따라서 본 연구는 교사의 데이터 리터러시 향상을 위해 데이터 기반 의사결정의 단 계에 따라 생성형 AI 챗봇을 개발하고 이를 활용하는 방식을 제안하고자 한다. 이를 위해 우선, 프롬프트 엔지니어링 전략을 통해 생성형 AI를 훈련하여 교사의 데이터 기반 의사결정을 위한 챗봇을 개발하고자 하였다. 프롬프트 엔지니어링은 생성형 AI와 같은 대규모 언어모델이 사용자의 명령을 피드백 삼아서 높은 확률과 명확한 예측값을 생성할 수 있도록 훈련하는 것이다. 이러한 방식은 생성형 AI 챗봇을 교육적으로 활용하는 데에 문제가 될 만한 환각(hallucination) 요소를 줄이는 데 효과적이다. 다음으로, 교사가 1:1로 생성형 AI 챗봇을 주체적으로 활용하도록 촉진하기 위해 의사결정 기반 학습을 지원하고자 한다. 데이터 분석에 관한 초보자인 대다수 교사에게 데이터 기반 의사결정 절차에 따라 생성형 AI를 활용하여 데이터 분석을 하도록 함으로써 데이터 기반 의사결정의 효능감을 촉진할 수 있도록 한다. 따라서, 본 연구의 목적은 교사를 대상으로 데이터 리터러시 향상을 위한 생성형 AI 챗봇을 개발하고, 데이터 리터러시 및 데이터 기반 의사결정의 효과성을 양적으로 검증한 후 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정의 요소, 절차 등에 관해 학습한 학습자의 반응을 질적으로 분석하고자 한다. 이를 위해 본 연구에서 설정한 연구 문제는 다음과 같다. 1. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇은 어떻게 구현할 것인가? 2. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇의 효과는 어떠한가? 2.1. 생성형 AI 챗봇을 활용함으로써 데이터 리터러시가 향상되는가? 2.2. 생성형 AI 챗봇을 활용함으로써 데이터 기반 의사결정 효능감이 향상되는가? 3. 데이터 기반 의사결정을 위한 생성형 AI 챗봇에 대한 학습자 반응은 어떠한가? 위 연구 문제에 따른 결과를 검증하기 위해 본 연구는 Richey와 Klein의 설계· 개발 연구방법에 따라 진행하였다. 설계·개발 연구방법 중에서도 유형I의 산출물 및 도구 개발을 택하여 분석, 설계, 개발 및 평가의 4단계를 따랐다. 분석 단계에서는 프롬프트, 데이터 리터러시, 의사결정 학습 절차에 관한 선행연구를 고찰하여 생성형 AI 챗봇 개발을 위한 데이터 기반 의사결정 학습 절차를 구조화했다. 그리고 현장 교사 31명을 대상으로 요구 분석을 진행하여 교사 대상의 생성형 AI 챗봇 활용 데이터 분석에 적합한 교육 데이터 분석 사례를 탐색하고자 했다. 설계 단계에서는 앞서 진행한 문헌 분석과 요구 분석에 따라 생성형 AI 활용 데이터 기반 의사결정 학습 절차를 확고히 했고, 이에 따라 프롬프트 패턴 및 전략 을 참고하여 생성형 AI를 훈련할 프롬프트를 설계했다. 그리고 개발 및 평가 단계 에서는 다량의 프롬프트 입력을 통해 훈련된 생성형 AI 챗봇을 개발하였다. 이후 5인의 전문가 검토와 4인의 파일럿 테스트를 거쳐서 최종적으로 챗봇을 보완한 뒤 단일집단을 대상으로 효과성 검증을 위한 실험을 진행하였다. 총 25명의 교사를 대상으로 1차, 2차 실험을 대략 2주 동안 ZOOM 실험 환경에서 진행하였다. 이후 데이터 리터러시와 데이터 기반 의사결정 효능감에 관한 사전-사후 효과성 검증을 대응표본 t 검정을 통해 진행하였다. 그리고 학습자 반응 분석을 위해 실험에 참여한 교사들이 응답한 성찰일지를 분석하였다. 이를 바탕으로 도출한 본 연구의 주된 결과와 논의 사항은 다음과 같다. 첫째, 9단계의 데이터 기반 의사결정 학습 절차에 따른 교사의 데이터 기반 의 사결정을 위한 생성형 AI 챗봇을 개발하였다. 이를 위해 우선 D0. 사전 안내, D1. 문제 정의 및 가설 설정, D2. 데이터 수집, D3. 데이터 품질 확인을 위한 전처리, D4. 예측 모델을 통한 데이터 분석, D5. 데이터 해석 및 결론 도출, D6. 데이터 평가, D7. 데이터 시각화, D8. 교수적 처치 계획의 총 9단계 데이터 기반 의사결정 학습 절차를 구성하였다. 그 뒤 각 절차에 따른 생성형 AI 챗봇을 구현하기 위해 대화 기반의 프롬프트를 설계하고 이를 훈련했다. 이때 학습 맥락 조정, 학습 키워드 강조, 오류 점검을 위주로 퓨샷(few-shot), 형식지정(format), 핵심어(seed-word), 제로샷(zero-shot), 마크다운(markdown), 사고의 연쇄 기법(CoT), 다시 생각하기(Let’s think about this), 다시 생성하기(ReAct)의 프롬프트 엔지니어링 전략을 활용하였다. 그렇게 GPTs 환경에서 생성형 AI 챗봇이 개발되었다. 둘째, 교사를 대상으로 데이터 기반 의사결정을 위한 생성형 AI 챗봇을 사용하였을 때, 데이터 리터러시와 데이터 기반 의사결정 효능감의 효과성을 검증하였다. 데이터 리터러시는 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 데이터 리터러시의 하위 요소인 문제 확인 및 정의, 데이터 수집 및 관리, 데이터 분석 및 표현, 교수적 의사결정, 평가 및 성찰 요소 모두 통계적으로 유의미하게 향상되었다. 더불어 위 결과에 관하여 생성형 AI 챗봇을 통해 주체적으로 데이터 분석을 진행하고, 데이터 분석에 관한 지식을 유연하고 효율적으로 학습할 수 있었다는 학습자 응답 결과가 뒷받침될 수 있었다. 데이터 기반 의사결정 효능 감 또한 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 그리고 이러한 결과는 생성형 AI 챗봇을 활용하여 데이터 리터러시가 향상된다면, 데이터 기반 의사결정 효능감 또한 향상된 점을 시사한다. 더불어 위의 결과는 생성형 AI 챗봇을 통해 데이터 기반 교수적 의사결정과 처방의 가능성을 탐색했다는 학습자 응답 결과에서도 뒷받침될 수 있었다. 셋째, 생성형 AI 챗봇을 활용한 교사를 대상으로 학습자 반응을 분석하여 학습자가 인식한 단점, 개선할 점을 통해 챗봇의 보완 방향을 도출하였다. 보완 방향에는 총 4가지가 언급되었으며, 주요 내용은 다음과 같다. 인지 부하 조절을 위한 여러 스캐폴딩 요소 지원, 생성형 AI 챗봇이 더욱 직관적이고 편리한 UX와 UI 지원, 한글 사용에 불편함이 없는 생성형 AI 챗봇 지원, 생성형 AI의 활용범위를 확장하여 사용자에게 맞춤화된 경험 지원에 관해 논할 수 있었다. 이를 바탕으로 본 연구의 이론적, 실천적, 방법적인 시사점은 다음과 같다. 첫째, 이론적 시사점으로써 교사를 대상으로 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정 학습 절차에 따라 진행하였을 때 데이터 리터러시 및 데이터 기반 의사결정 효능감이 향상되었다는 것을 밝혀낸 실증 연구로서 기여한 점이다. 둘째, 실천적 시사점으로써 학교 현장 속 교사들의 데이터 기반 의사결정 과정을 지 원해줄 수 있는 생성형 AI 챗봇을 개발한 것이다. 셋째, 방법적 시사점으로써 프롬프트 엔지니어링을 통해 생성형 AI를 훈련하여 챗봇 형태로 구현하고 이를 교사를 위한 데이터 기반 의사결정 학습 차원에서 적용한 것이다. 마지막으로 본 연구의 제한점과 후속 연구를 위한 제언은 다음과 같다. 첫째, 개발된 생성형 AI 챗봇 사용을 위한 접근성 측면에서 ChatGPT 멤버십에 관한 제약이 있었다. 그렇지만, 최근 GPT-4o 버전이 출시되면서 무료화되었다. 따라서 앞으로 교사들이 더욱 접근성 있게 생성형 AI 챗봇을 활용할 수 있도록 여러 기회 와 자원이 지원되어야 할 것이다. 둘째, 연구 참여자의 다양성 측면에서 교사에 관한 전체 모집단을 고려하기엔 본 연구의 표본은 부족했다. 이에 따라 향후 연구에서는 교사들의 연령대, 교직 경력, 학교급, 담당 과목 등을 균등하게 고려하여 더욱 많은 교사를 모집하는 것이 필요하다. 셋째, 교육현장의 훨씬 다양한 맥락에서 데이터 기반 의사결정을 고려하지 못하였다. 이에 따라 앞으로는 학습자 군집에 따른 맞춤형 교수전략 외에 현장에서 접할 수 있는 다양한 맥락을 고려하여 생성형 AI 챗봇을 통한 데이터 기반 의사결정 과정을 지원할 필요가 있다.Big data and artificial intelligence have revolutionized our approach to data, establishing it as a valuable resource for informed decision-making across various fields, including education. Specifically, teachers can improve their ability to make instructional decisions by learning to collect, analyze, and interpret data effectively. For these reasons, the Korean government is developing an infrastructure to support personalized instruction based on educational data, such as AI digital textbooks. At the same time, companies are integrating individual learner data into platforms like learning management systems to support personalized teaching strategies. In addition, there is ongoing research and discussion on how to improve teachers' data literacy, aiming to equip teachers with the necessary skills to effectively interpret and utilize data in their teaching practices. Teachers' data literacy skills encompass more than mere proficiency with data. They are about facilitating data-driven decision-making, which is the ultimate goal. Subcomponents include problem identification and goal setting, data collection, data analysis, data interpretation, and instructional decision-making. With these competencies, teachers can effectively tailor their instruction to meet individual needs and implement personalized teaching strategies. On the other hand, equipping teachers with data analytics skills to enhance their data literacy has proven to be costly and energy-intensive. Most teachers, being novices in data analytics and learning while on the job, find it challenging to systematically complete data literacy training programs over an extended period. In addition, a review of previous studies shows that data analytics courses tend to focus on imparting knowledge in areas like statistics and machine learning, but they fail to provide adequate support for developing competencies in the use of data analytics in practice. Therefore, this study proposes a method to develop and use a generative AI for data-driven decision-making to effectively and efficiently enhance teachers' data literacy. To do so, this study first aimed to develop a chatbot to improve teachers' data literacy by employing a prompt engineering strategy to train generative AI. Prompt engineering involves training large-scale language models, such as generative AI, to generate high probability and more accurate predictions by using user command prompts as feedback. This approach helps reduce issues such as hallucination, which pose significant challenges in the educational application of generative AI chatbots. Next, this study aims to support teachers in using generative AI chatbots in one-on-one settings, following a decision-learning process, to effectively enhance data literacy. By guiding teachers, many of whom are novices in data analysis, through the steps of a data-driven decision-making process using generative AI, teachers’ competency in data-driven decision-making can be promoted. Therefore, the purpose of this study is to develop a generative AI chatbot to improve teachers' data literacy, quantitatively verify the effectiveness of data literacy and data-driven decision-making, and qualitatively analyze teachers' responses to the generative AI chatbot. For this purpose, the following research questions were derived. RQ1. How can a generative AI chatbot be developed for teachers’ data-driven decision-making? RQ2. Is a generative AI chatbot effective for teachers' data-driven decision-making? RQ2.1. Does utilizing generative AI chatbots improve data literacy? RQ2.2. Does utilizing generative AI chatbots improve data-driven decision-making efficacy? RQ3. How do teachers respond to generative AI chatbots for data-driven decision-making? To address the research questions above, this study adopted Richey and Klein's design and development research method. Specifically, following their Type I method for developing products and tools, the study was conducted across four phases: analysis, design, development, and evaluation. In the analysis phase, previous studies on prompts, data literacy, and decision-learning procedures were reviewed to structure a data-driven decision-learning procedure for developing generative AI chatbots. Then, a needs analysis was conducted with 31 teachers in the field to explore educational data analysis cases suitable for data analysis utilizing generative AI chatbots for teachers. In the design phase, the data-driven decision-learning procedure for generative AI was solidified based on the literature review and needs analysis. Prompts were designed to train generative AI by referring to prompt patterns and strategies. In the development and evaluation phase, a generative AI chatbot trained with a large amount of prompt input was developed. The chatbot was then reviewed by five experts and pilot-tested by four participants. Finally, after refining the chatbot, an experiment was conducted to verify its effectiveness. A one-group pre-post paired sample t-test was conducted with a total of 25 teachers on ZOOM for about two weeks. Afterward, the effectiveness of data literacy and data-driven decision-making efficacy were evaluated using paired-sample t-tests. To further analyze teachers’ responses, reflection journals from the teachers who participated in the experiment were examined using open-coding techniques. The main findings and discussions of this study are as follows. First, a generative AI chatbot was developed based on nine data-driven decision-making learning procedures to enhance and support data-driven decision-making among teachers. To do so, To this end, a nine-step data-driven decision-learning process was first constructed, consisting of nine steps: D0. Preliminary guidance, D1. Problem definition and hypothesis generation, D2. Data collection, D3. Preprocessing to check data quality, D4. Data analysis using predictive models, D5. Data interpretation and inference, D6. Data Evaluation, D7. Data Visualization, and D8. Instructional Action Plan. Then, dialog-based prompts were designed and trained according to the data-driven decision-making learning process derived earlier. Various prompting strategies were employed, including few-shot, format, seed-word, zero-shot, markdown, chain-of-thinking (CoT), let's think about this, and re-generate (ReAct). These strategies were used to adjust the learning context, emphasize learning keywords, and check the errors. Subsequently, the generative AI chatbot was developed within the GPTs environment. Second, the effectiveness of using a generative AI chatbot for enhancing teachers' data literacy and data-driven decision-making was verified. Data literacy significantly improved, as indicated by descriptive statistics and paired sample t-tests. The sub-components of data literacy—problem identification and definition, data collection and management, data analysis and representation, instructional decision-making, and evaluation and reflection elements—were all statistically significantly improved. These findings were further supported by teachers' reflective responses, which highlighted their recognition of the generative AI chatbots as a valuable tool. According to their responses, teachers reported taking greater ownership of data analysis and developing flexibility and efficiency in applying their data analysis skills. The results from descriptive statistics and paired-sample t-tests indicated significant improvements in teachers' data-driven decision-making efficacy. These findings suggest that enhancing data literacy through the use of generative AI chatbots also boosts decision-making efficacy. Furthermore, these results are also supported by the teachers' reflective responses in that they explored the possibility of data-driven instructional decision-making and intervention through generative AI chatbots. Third, teachers' responses to teachers using the generative AI chatbot were analyzed to identify areas for improvement. Discussions emphasized the need to provide scaffolding to manage their cognitive load, enhance the UX and UI of generative AI chatbots to make them more intuitive and convenient, ensure the chatbots function seamlessly in Korean, and expand the capabilities of generative AI to deliver customized experiences. Based on these findings, the implications of this study are threefold. First, for a theoretical implication, this study empirically verified that teachers' data literacy and data-driven decision-making efficacy improved when they followed a data-driven decision-making learning process using a generative AI chatbot. Second, for a practical implication, this study developed a generative AI chatbot that can support teachers' data-driven decision-making process in schools. Third, as a methodological implication, the study attempted to demonstrate the application of prompt engineering to train generative AI, which was then implemented as a chatbot and applied in facilitating data-driven decision-making. The limitations of this study and suggestions for further research are as follows. First, accessing the developed generative AI chatbot required a ChatGPT membership, which posed a barrier for teachers. Therefore, future efforts should concentrate on enhancing the accessibility of generative AI chatbots to teachers.Second, the diversity of the participants in the study was insufficient to reflect the overall population. Therefore, future research should consider recruiting a larger and more diverse group of teachers, ensuring equal representation across age, teaching experience, school levels, and subjects. Third, this study's exploration of data-driven decision-making was constrained to a limited range of contexts. Future studies should broaden their scope to include various contexts encountered in the educational field and provide enhanced support for data-driven decision-making processes using generative AI chatbots."
        },
        {
          "rank": 40,
          "score": 0.6032817363739014,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 41,
          "score": 0.6024547219276428,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 42,
          "score": 0.6023693084716797,
          "doc_id": "JAKO202516964801568",
          "title": "STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계",
          "abstract": "본 연구는 기업의 생성형 AI 도입 과정에서 발생하는 복잡한 리스크를 효과적으로 관리하기 위한 종합적인 평가 프레임워크인 STAGE-AI Metrics를 제안한다. 해당 프레임워크는 사회적 영향(Social impact), 기술적 성능(Technical performance), 조직 내 도입(Adaptation to organization), 지속가능성(Growth in sustainability), 윤리적 고려 사항(Ethical consideration)의 다섯 가지 주요 영역을 포괄하며, 영역별로 세부적인 평가 지표와 관련 벤치마크를 제시한다. 특히 기술적 성능(Technology)을 기반으로 사회적 영향(Social) 및 윤리적 측면(Ethics)을 순차적으로 고려하여 설계되었다. AI 시스템의 기본적인 성능 평가에서 출발, 해당 기술의 도입이 조직과 사회에 미치는 광범위한 파급 효과까지 포괄적으로 평가가 가능하게 하며 추가로 지속가능성(Sustainability)까지 검토할 수 있도록 지원한다. STAGE-AI Metrics는 기존의 단편적인 성능 평가 방식을 넘어, AI 시스템의 기술적 성능뿐만 아니라 사회적 영향과 윤리적 측면까지 고려하는 다면적 접근을 통해 기업이 자사의 특성과 요구사항에 최적화된 AI 모델을 선택하고 도입할 수 있도록 지원한다. 본 연구는 AI 도입의 초기 단계에서 발생할 수 있는 잠재적 문제점들을 사전에 식별하고 대비할 수 있는 실용적인 도구를 제공함으로써, 기업의 AI 도입 성공률을 높이고 장기적인 경쟁력 확보에 기여할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202516964801568&target=NART&cn=JAKO202516964801568",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 본 연구는 기업의 생성형 AI 도입 과정에서 발생하는 복잡한 리스크를 효과적으로 관리하기 위한 종합적인 평가 프레임워크인 STAGE-AI Metrics를 제안한다. 해당 프레임워크는 사회적 영향(Social impact), 기술적 성능(Technical performance), 조직 내 도입(Adaptation to organization), 지속가능성(Growth in sustainability), 윤리적 고려 사항(Ethical consideration)의 다섯 가지 주요 영역을 포괄하며, 영역별로 세부적인 평가 지표와 관련 벤치마크를 제시한다. 특히 기술적 성능(Technology)을 기반으로 사회적 영향(Social) 및 윤리적 측면(Ethics)을 순차적으로 고려하여 설계되었다. AI 시스템의 기본적인 성능 평가에서 출발, 해당 기술의 도입이 조직과 사회에 미치는 광범위한 파급 효과까지 포괄적으로 평가가 가능하게 하며 추가로 지속가능성(Sustainability)까지 검토할 수 있도록 지원한다. STAGE-AI Metrics는 기존의 단편적인 성능 평가 방식을 넘어, AI 시스템의 기술적 성능뿐만 아니라 사회적 영향과 윤리적 측면까지 고려하는 다면적 접근을 통해 기업이 자사의 특성과 요구사항에 최적화된 AI 모델을 선택하고 도입할 수 있도록 지원한다. 본 연구는 AI 도입의 초기 단계에서 발생할 수 있는 잠재적 문제점들을 사전에 식별하고 대비할 수 있는 실용적인 도구를 제공함으로써, 기업의 AI 도입 성공률을 높이고 장기적인 경쟁력 확보에 기여할 것으로 기대된다."
        },
        {
          "rank": 43,
          "score": 0.60146564245224,
          "doc_id": "NART89294359",
          "title": "Disaster Risk Reduction in Agriculture through Geospatial (Big) Data Processing",
          "abstract": "<P>Intensive farming on land represents an increased burden on the environment due to, among other reasons, the usage of agrochemicals. Precision farming can reduce the environmental burden by employing site specific crop management practices which implement advanced geospatial technologies for respecting soil heterogeneity. The objectives of this paper are to present the frontier approaches of geospatial (Big) data processing based on satellite and sensor data which both aim at the prevention and mitigation phases of disaster risk reduction in agriculture. Three techniques are presented in order to demonstrate the possibilities of geospatial (Big) data collection in agriculture: (1) farm machinery telemetry for providing data about machinery operations on fields through the developed MapLogAgri application; (2) agrometeorological observation in the form of a wireless sensor network together with the SensLog solution for storing, analysing, and publishing sensor data; and (3) remote sensing for monitoring field spatial variability and crop status by means of freely-available high resolution satellite imagery. The benefits of re-using the techniques in disaster risk reduction processes are discussed. The conducted tests demonstrated the transferability of agricultural techniques to crisis/emergency management domains.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART89294359&target=NART&cn=NART89294359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Disaster Risk Reduction in Agriculture through Geospatial (Big) Data Processing Disaster Risk Reduction in Agriculture through Geospatial (Big) Data Processing Disaster Risk Reduction in Agriculture through Geospatial (Big) Data Processing <P>Intensive farming on land represents an increased burden on the environment due to, among other reasons, the usage of agrochemicals. Precision farming can reduce the environmental burden by employing site specific crop management practices which implement advanced geospatial technologies for respecting soil heterogeneity. The objectives of this paper are to present the frontier approaches of geospatial (Big) data processing based on satellite and sensor data which both aim at the prevention and mitigation phases of disaster risk reduction in agriculture. Three techniques are presented in order to demonstrate the possibilities of geospatial (Big) data collection in agriculture: (1) farm machinery telemetry for providing data about machinery operations on fields through the developed MapLogAgri application; (2) agrometeorological observation in the form of a wireless sensor network together with the SensLog solution for storing, analysing, and publishing sensor data; and (3) remote sensing for monitoring field spatial variability and crop status by means of freely-available high resolution satellite imagery. The benefits of re-using the techniques in disaster risk reduction processes are discussed. The conducted tests demonstrated the transferability of agricultural techniques to crisis/emergency management domains.</P>"
        },
        {
          "rank": 44,
          "score": 0.6012223958969116,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 45,
          "score": 0.6005941033363342,
          "doc_id": "JAKO202405136180702",
          "title": "자율주행자동차 사고조사 관점에서 주행데이터 관리방안 연구",
          "abstract": "This study aims to evaluate and monitor the overall performance of autonomous driving systems (ADS) and help DSSAD investigate accidents. In the current DSSAD system, only ADS status values are recorded with a timestamp method, and data retrieval methods and data reporting formats considering real accident cases are not reflected, so DSSAD may difficult to identify the cause of the accident quickly. Therefore, current DSSAD-related regulations and risk situations during autonomous driving in Korea were considered. This presented improvements to the DSSAD data management plan to contribute to ADS incident investigation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202405136180702&target=NART&cn=JAKO202405136180702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자율주행자동차 사고조사 관점에서 주행데이터 관리방안 연구 자율주행자동차 사고조사 관점에서 주행데이터 관리방안 연구 자율주행자동차 사고조사 관점에서 주행데이터 관리방안 연구 This study aims to evaluate and monitor the overall performance of autonomous driving systems (ADS) and help DSSAD investigate accidents. In the current DSSAD system, only ADS status values are recorded with a timestamp method, and data retrieval methods and data reporting formats considering real accident cases are not reflected, so DSSAD may difficult to identify the cause of the accident quickly. Therefore, current DSSAD-related regulations and risk situations during autonomous driving in Korea were considered. This presented improvements to the DSSAD data management plan to contribute to ADS incident investigation."
        },
        {
          "rank": 46,
          "score": 0.6005743145942688,
          "doc_id": "JAKO201303537265581",
          "title": "공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 -",
          "abstract": "개방과 공유에 기초한 정부 3.0이라는 새로운 패러다임이 국정전반에 확산되고 있다. 공간정보산업의 발전이라는 장기적인 관점에서 볼 때 항공사진의 공개해상도 등 공간정보 보안규제는 합리적으로 개선되어야 한다. 그러나 공간정보 보안관리체계가 합리적으로 확립되지 않은 상태에서의 규제 철폐는 자칫 국가안보와 같은 또 다른 문제를 야기할 수도 있다. 본 연구의 목적은 현행 국가 공간정보 보안정책과 공간정보산업 등 시대적 여건 변화를 고려하여, 보안규제의 완화를 위해 필요한 공간정보 보안관체계의 개선방안을 제시하는 것이다. 분석의 관점으로써 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면을 종합적으로 검토하였으며, 특히 공간정보 보안관리의 통합적 관점을 유지하였다. 공간정보 보안체계의 문제점과 함께 해외 공간정보 보안규제 정책을 검토한 후, 이를 토대로 합리적인 보안관리 개선 방안을 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면으로 나누어 제시하였으며 장기적인 보안규제의 완화를 위한 3단계 보안관리체계의 개선방안을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303537265581&target=NART&cn=JAKO201303537265581",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 개방과 공유에 기초한 정부 3.0이라는 새로운 패러다임이 국정전반에 확산되고 있다. 공간정보산업의 발전이라는 장기적인 관점에서 볼 때 항공사진의 공개해상도 등 공간정보 보안규제는 합리적으로 개선되어야 한다. 그러나 공간정보 보안관리체계가 합리적으로 확립되지 않은 상태에서의 규제 철폐는 자칫 국가안보와 같은 또 다른 문제를 야기할 수도 있다. 본 연구의 목적은 현행 국가 공간정보 보안정책과 공간정보산업 등 시대적 여건 변화를 고려하여, 보안규제의 완화를 위해 필요한 공간정보 보안관체계의 개선방안을 제시하는 것이다. 분석의 관점으로써 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면을 종합적으로 검토하였으며, 특히 공간정보 보안관리의 통합적 관점을 유지하였다. 공간정보 보안체계의 문제점과 함께 해외 공간정보 보안규제 정책을 검토한 후, 이를 토대로 합리적인 보안관리 개선 방안을 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면으로 나누어 제시하였으며 장기적인 보안규제의 완화를 위한 3단계 보안관리체계의 개선방안을 제시하였다."
        },
        {
          "rank": 47,
          "score": 0.6003814339637756,
          "doc_id": "NART90416077",
          "title": "Cloud parallel spatial&#x2010;temporal data model with intelligent parameter adaptation for spatial&#x2010;temporal big data",
          "abstract": "<P><B>Summary</B></P><P>With the fast development of earth observation technology and internet of things technology, the spatial&#8208;temporal data can be obtained with higher speed and lower cost, and spatial&#8208;temporal big data management with existing spatial&#8208;temporal data model has become one of the bottlenecks of spatial&#8208;temporal applications such as e&#8208;government construction, digital city, and smart city. Cloud parallel spatial&#8208;temporal data model with intelligent parameter adaptation for spatial&#8208;temporal big data provided in this paper is able to divide a spatial&#8208;temporal problem into a lot of subdivided spatial&#8208;temporal problems and to map the subdivided problems onto different cloud parallel computing nodes to process. This paper includes the concept, division methods, and mathematical formulas of cloud parallel spatial&#8208;temporal data model and provides the method to intelligently find the best parameter of cloud parallel spatial&#8208;temporal data model for solving the problem with highest parallel speedup or highest parallel efficiency in cloud parallel computing environment.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART90416077&target=NART&cn=NART90416077",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud parallel spatial&#x2010;temporal data model with intelligent parameter adaptation for spatial&#x2010;temporal big data Cloud parallel spatial&#x2010;temporal data model with intelligent parameter adaptation for spatial&#x2010;temporal big data Cloud parallel spatial&#x2010;temporal data model with intelligent parameter adaptation for spatial&#x2010;temporal big data <P><B>Summary</B></P><P>With the fast development of earth observation technology and internet of things technology, the spatial&#8208;temporal data can be obtained with higher speed and lower cost, and spatial&#8208;temporal big data management with existing spatial&#8208;temporal data model has become one of the bottlenecks of spatial&#8208;temporal applications such as e&#8208;government construction, digital city, and smart city. Cloud parallel spatial&#8208;temporal data model with intelligent parameter adaptation for spatial&#8208;temporal big data provided in this paper is able to divide a spatial&#8208;temporal problem into a lot of subdivided spatial&#8208;temporal problems and to map the subdivided problems onto different cloud parallel computing nodes to process. This paper includes the concept, division methods, and mathematical formulas of cloud parallel spatial&#8208;temporal data model and provides the method to intelligently find the best parameter of cloud parallel spatial&#8208;temporal data model for solving the problem with highest parallel speedup or highest parallel efficiency in cloud parallel computing environment.</P>"
        },
        {
          "rank": 48,
          "score": 0.6002359986305237,
          "doc_id": "ART003238246",
          "title": "Big Data Analysis on Success Factors of Franchise Business",
          "abstract": "This paper intends to analyze the current status of success factors in the domestic franchise business using big data. Franchise businesses that occupy most markets can continue to operate stably using minimal capital, but competition is occurring due to overflowing franchise businesses and the exit rate is also increasing. In this dual situation, the franchise business needs empirical analysis of successful operation strategies, and we intend to derive success factors by utilizing big data for future development. Using TexTom, a big data analysis program, data were collected from May 2022 to May 2025 and text mining was carried out, and based on this, analysis results were derived more easily using the connectivity analysis tool UCinet visualization function. As a result of the study, key factors such as 'improvement of operating system', 'strategic support of member headquarters', 'strengthening brand image', 'sensitive response to consumer trends', and 'strategies for overseas expansion' were derived. Such results will greatly contribute to proposing strategic directions to franchise management practitioners in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003238246&target=NART&cn=ART003238246",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analysis on Success Factors of Franchise Business Big Data Analysis on Success Factors of Franchise Business Big Data Analysis on Success Factors of Franchise Business This paper intends to analyze the current status of success factors in the domestic franchise business using big data. Franchise businesses that occupy most markets can continue to operate stably using minimal capital, but competition is occurring due to overflowing franchise businesses and the exit rate is also increasing. In this dual situation, the franchise business needs empirical analysis of successful operation strategies, and we intend to derive success factors by utilizing big data for future development. Using TexTom, a big data analysis program, data were collected from May 2022 to May 2025 and text mining was carried out, and based on this, analysis results were derived more easily using the connectivity analysis tool UCinet visualization function. As a result of the study, key factors such as 'improvement of operating system', 'strategic support of member headquarters', 'strengthening brand image', 'sensitive response to consumer trends', and 'strategies for overseas expansion' were derived. Such results will greatly contribute to proposing strategic directions to franchise management practitioners in the future."
        },
        {
          "rank": 49,
          "score": 0.6002150774002075,
          "doc_id": "ATN0031724803",
          "title": "CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색",
          "abstract": "This study aimed to explore the ways to develop competencies pursued in the next national-level curriculum through an analysis of the OECD 2030 Learning Framework.To this end, the backgrounds and goals of development of competency frameworks of international organizations and national curricula, and the structures and elements of competency frameworks were examined. In addition, according to the five criteria applied in the development of the CCR framework(Comprehensive, Compact, Uncorrelated, Appropriate Layer of Abstraction, Globally Relevant), the OECD learning framework was mainly analyzed, but compared and analyzed with the competency frameworks of other countries. As a result of the study, it was found that the competencies in the OECD learning framework are presented more relatively comprehensively than the competencies of other national frameworks(Comprehensiveness). In terms of Compactness, they are insufficient compared to the competencies of other national frameworks. Redundancy is high(Uncorrelatedness). The level of abstraction is appropriate but is in need of improvement(Appropriate Layer of Abstraction). The Globally Relevance is high. The study proposed to structuralize a competency framework for developing the next national curriculum based on the CCR development criteria. Furthermore, the emerging competencies and the hierarchical methods to structuralize the competencies applied in the OECD Learning Framework need to be considered.[",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0031724803&target=NART&cn=ATN0031724803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 This study aimed to explore the ways to develop competencies pursued in the next national-level curriculum through an analysis of the OECD 2030 Learning Framework.To this end, the backgrounds and goals of development of competency frameworks of international organizations and national curricula, and the structures and elements of competency frameworks were examined. In addition, according to the five criteria applied in the development of the CCR framework(Comprehensive, Compact, Uncorrelated, Appropriate Layer of Abstraction, Globally Relevant), the OECD learning framework was mainly analyzed, but compared and analyzed with the competency frameworks of other countries. As a result of the study, it was found that the competencies in the OECD learning framework are presented more relatively comprehensively than the competencies of other national frameworks(Comprehensiveness). In terms of Compactness, they are insufficient compared to the competencies of other national frameworks. Redundancy is high(Uncorrelatedness). The level of abstraction is appropriate but is in need of improvement(Appropriate Layer of Abstraction). The Globally Relevance is high. The study proposed to structuralize a competency framework for developing the next national curriculum based on the CCR development criteria. Furthermore, the emerging competencies and the hierarchical methods to structuralize the competencies applied in the OECD Learning Framework need to be considered.["
        },
        {
          "rank": 50,
          "score": 0.5998178720474243,
          "doc_id": "JAKO202405250401713",
          "title": "Analysis of Hallyu research trends based on topic modeling",
          "abstract": "To analyze trends in Hallyu research, this paper collected a total of 1,320 KCI-listed and candidate papers from 1997 to May 2023 and conducted topic modeling. As a result of the analysis, the main research topic of Hallyu 1.0 is the causes and characteristics of the Hallyu phenomenon, and Hallyu 2.0 focuses on the revitalization and expansion of the Hallyu industry through the sustainability of the Hallyu. Hallyu 3.0 recognized the importance of consumer intention and behavior, and Hallyu 4.0 showed the need to develop strategies and platforms to respond to the digital age along with the widespread spread of K-Culture. Based on this, two key tasks for the globalization of the Hallyu are needed: content and localization through understanding consumer behavior, and development of new strategies and platforms to meet the digital age.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202405250401713&target=NART&cn=JAKO202405250401713",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Analysis of Hallyu research trends based on topic modeling Analysis of Hallyu research trends based on topic modeling Analysis of Hallyu research trends based on topic modeling To analyze trends in Hallyu research, this paper collected a total of 1,320 KCI-listed and candidate papers from 1997 to May 2023 and conducted topic modeling. As a result of the analysis, the main research topic of Hallyu 1.0 is the causes and characteristics of the Hallyu phenomenon, and Hallyu 2.0 focuses on the revitalization and expansion of the Hallyu industry through the sustainability of the Hallyu. Hallyu 3.0 recognized the importance of consumer intention and behavior, and Hallyu 4.0 showed the need to develop strategies and platforms to respond to the digital age along with the widespread spread of K-Culture. Based on this, two key tasks for the globalization of the Hallyu are needed: content and localization through understanding consumer behavior, and development of new strategies and platforms to meet the digital age."
        }
      ]
    },
    {
      "query": "What is the proposed enabling framework for achieving the second Sustainable Development Goal?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6387714743614197,
          "doc_id": "ATN0031724803",
          "title": "CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색",
          "abstract": "This study aimed to explore the ways to develop competencies pursued in the next national-level curriculum through an analysis of the OECD 2030 Learning Framework.To this end, the backgrounds and goals of development of competency frameworks of international organizations and national curricula, and the structures and elements of competency frameworks were examined. In addition, according to the five criteria applied in the development of the CCR framework(Comprehensive, Compact, Uncorrelated, Appropriate Layer of Abstraction, Globally Relevant), the OECD learning framework was mainly analyzed, but compared and analyzed with the competency frameworks of other countries. As a result of the study, it was found that the competencies in the OECD learning framework are presented more relatively comprehensively than the competencies of other national frameworks(Comprehensiveness). In terms of Compactness, they are insufficient compared to the competencies of other national frameworks. Redundancy is high(Uncorrelatedness). The level of abstraction is appropriate but is in need of improvement(Appropriate Layer of Abstraction). The Globally Relevance is high. The study proposed to structuralize a competency framework for developing the next national curriculum based on the CCR development criteria. Furthermore, the emerging competencies and the hierarchical methods to structuralize the competencies applied in the OECD Learning Framework need to be considered.[",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0031724803&target=NART&cn=ATN0031724803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 CCR 역량 프레임워크 개발 준거를 활용한 OECD 학습 프레임워크 분석의 시사점 탐색 This study aimed to explore the ways to develop competencies pursued in the next national-level curriculum through an analysis of the OECD 2030 Learning Framework.To this end, the backgrounds and goals of development of competency frameworks of international organizations and national curricula, and the structures and elements of competency frameworks were examined. In addition, according to the five criteria applied in the development of the CCR framework(Comprehensive, Compact, Uncorrelated, Appropriate Layer of Abstraction, Globally Relevant), the OECD learning framework was mainly analyzed, but compared and analyzed with the competency frameworks of other countries. As a result of the study, it was found that the competencies in the OECD learning framework are presented more relatively comprehensively than the competencies of other national frameworks(Comprehensiveness). In terms of Compactness, they are insufficient compared to the competencies of other national frameworks. Redundancy is high(Uncorrelatedness). The level of abstraction is appropriate but is in need of improvement(Appropriate Layer of Abstraction). The Globally Relevance is high. The study proposed to structuralize a competency framework for developing the next national curriculum based on the CCR development criteria. Furthermore, the emerging competencies and the hierarchical methods to structuralize the competencies applied in the OECD Learning Framework need to be considered.["
        },
        {
          "rank": 2,
          "score": 0.630435049533844,
          "doc_id": "NART69871315",
          "title": "국내 기업의 업종별 지속가능성 순위 평가",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;‘지속가능성 보고’ 또는 ‘지속가능경영 보고서’는 지속가능한 발전을 위한 조직의 성과를 측정, 공개하고 이해관계자에게 그에 걸맞은 책임을 약속하는 활동을 의미한다. 지속가능보고서의 경우 제3자 검증을 거치지만, 보고서 간행 국제기준의 부합성 여부와 내용의 충실성을 일반인이 판단하기는 쉽지 않은 편이다. 본 연구는 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위한 목적을 가지고 실시되었다. 국내 15개 업종별 지속가능성 보고서를 기초로 GRI(Global Reporting Initiatives) G3 Guideline 기준 부합도 및 내용의 충실 정도를 비교 평가하였다. 그리고 해당 결과를 통해 지속가능 우수 업종을 판단하여 업종별 수행 미흡 지표분석 및 향후 지속가능성 보고의 발전방향을 제시하고자 하였다. 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위해 2010-2011년에 간행된 각 업종별 기업들의 지속가능성 보고서를 수집한 후 ‘원료’, ‘에너지’, ‘생물다양성’, ‘대기오염 물질과 폐수 및 폐기물’, ‘기타’ 등 GRI G3 가이드라인 환경지표(EN)에 기준한 6개 지표로 평가하였다. 적합성 및 충실도를 5점 척도에 적용 산출한 후 그 결과를 비교 평가하였다. 국내 기업의 환경부문 지속가능 경영 수준을 각 업종별 지속가능성 보고서를 통해 분석한 결과 대형유통업 &amp;gt; 철도운수업 &amp;gt; 금융업 &amp;gt; 생활용품제조업 &amp;gt; 전기전자제품제조업 &amp;gt; 종합건설업 &amp;gt; 정유업 = 자동차제조업 &amp;gt; 공기업A(국토해양부 산하) &amp;gt; 발전업 &amp;gt; 공기업B(지식경제부 산하) &amp;gt; 기계제조업 &amp;gt; 항공운수업 &amp;gt; 보험업 &amp;gt; 제철업 순으로 나타났다. 지속가능보고서 작성 기준의 체계화를 위해 GRI 가이드라인의 보완, 명확한 경계의 설정과 핵심지표와 부가지표의 수정이 필요하다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69871315&target=NART&cn=NART69871315",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국내 기업의 업종별 지속가능성 순위 평가 국내 기업의 업종별 지속가능성 순위 평가 국내 기업의 업종별 지속가능성 순위 평가 <P>&amp;nbsp;&amp;nbsp;‘지속가능성 보고’ 또는 ‘지속가능경영 보고서’는 지속가능한 발전을 위한 조직의 성과를 측정, 공개하고 이해관계자에게 그에 걸맞은 책임을 약속하는 활동을 의미한다. 지속가능보고서의 경우 제3자 검증을 거치지만, 보고서 간행 국제기준의 부합성 여부와 내용의 충실성을 일반인이 판단하기는 쉽지 않은 편이다. 본 연구는 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위한 목적을 가지고 실시되었다. 국내 15개 업종별 지속가능성 보고서를 기초로 GRI(Global Reporting Initiatives) G3 Guideline 기준 부합도 및 내용의 충실 정도를 비교 평가하였다. 그리고 해당 결과를 통해 지속가능 우수 업종을 판단하여 업종별 수행 미흡 지표분석 및 향후 지속가능성 보고의 발전방향을 제시하고자 하였다. 국내 기업의 업종별 지속가능경영 수준을 비교 평가하기 위해 2010-2011년에 간행된 각 업종별 기업들의 지속가능성 보고서를 수집한 후 ‘원료’, ‘에너지’, ‘생물다양성’, ‘대기오염 물질과 폐수 및 폐기물’, ‘기타’ 등 GRI G3 가이드라인 환경지표(EN)에 기준한 6개 지표로 평가하였다. 적합성 및 충실도를 5점 척도에 적용 산출한 후 그 결과를 비교 평가하였다. 국내 기업의 환경부문 지속가능 경영 수준을 각 업종별 지속가능성 보고서를 통해 분석한 결과 대형유통업 &amp;gt; 철도운수업 &amp;gt; 금융업 &amp;gt; 생활용품제조업 &amp;gt; 전기전자제품제조업 &amp;gt; 종합건설업 &amp;gt; 정유업 = 자동차제조업 &amp;gt; 공기업A(국토해양부 산하) &amp;gt; 발전업 &amp;gt; 공기업B(지식경제부 산하) &amp;gt; 기계제조업 &amp;gt; 항공운수업 &amp;gt; 보험업 &amp;gt; 제철업 순으로 나타났다. 지속가능보고서 작성 기준의 체계화를 위해 GRI 가이드라인의 보완, 명확한 경계의 설정과 핵심지표와 부가지표의 수정이 필요하다.</P>"
        },
        {
          "rank": 3,
          "score": 0.6200776100158691,
          "doc_id": "NART69878555",
          "title": "사회적기업의 지속가능성과 공동체 정신",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;The purpose of this study is to provide a theoretical framework which could explain sustainability of social enterprise(SE). For this purpose, after critical reading of existing studies on SE ’ s sustainability, it first suggests reconceptualization of sustainability. After another critical review of existing studies of SE’s sustainability regarding the factors that have been suggested to influence SE’s sustainability, it builds up a theoretical framework based on such concepts as sense of community, organizational identity and organizational identification. And, the study concludes with some practical implications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69878555&target=NART&cn=NART69878555",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "사회적기업의 지속가능성과 공동체 정신 사회적기업의 지속가능성과 공동체 정신 사회적기업의 지속가능성과 공동체 정신 <P>&amp;nbsp;&amp;nbsp;The purpose of this study is to provide a theoretical framework which could explain sustainability of social enterprise(SE). For this purpose, after critical reading of existing studies on SE ’ s sustainability, it first suggests reconceptualization of sustainability. After another critical review of existing studies of SE’s sustainability regarding the factors that have been suggested to influence SE’s sustainability, it builds up a theoretical framework based on such concepts as sense of community, organizational identity and organizational identification. And, the study concludes with some practical implications.</P>"
        },
        {
          "rank": 4,
          "score": 0.6176807284355164,
          "doc_id": "NART112066192",
          "title": "Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics",
          "abstract": "<P><B>Abstract</B></P>  <P>The momentum has been building toward the realisation of the United Nations Development Programme's Sustainable Development Goals (SDGs). In this regard, technological upgrading through the adoption of innovative technologies, as in big data analytics (BDA), can be seen as a key enabler of helping to address societal challenges. While there is some evidence for realising value created from BDA adoption, organisational issues associated with societal challenges, specifically those targeting the SDGs, are yet to be appreciated. This study utilises a technology&ndash;organisation&ndash;environment framework to examine the role of top management support in facilitating value creation from BDA adoption for the realisation SDGs. Based on a survey of 320 UK managers, this study found that the technological driver of BDA coupled with top management support, can significantly help in the adoption process. Therefore, crafting the value needed for effectively supporting the realisation of these goals.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART112066192&target=NART&cn=NART112066192",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics Value creation for realising the sustainable development goals: Fostering organisational adoption of big data analytics <P><B>Abstract</B></P>  <P>The momentum has been building toward the realisation of the United Nations Development Programme's Sustainable Development Goals (SDGs). In this regard, technological upgrading through the adoption of innovative technologies, as in big data analytics (BDA), can be seen as a key enabler of helping to address societal challenges. While there is some evidence for realising value created from BDA adoption, organisational issues associated with societal challenges, specifically those targeting the SDGs, are yet to be appreciated. This study utilises a technology&ndash;organisation&ndash;environment framework to examine the role of top management support in facilitating value creation from BDA adoption for the realisation SDGs. Based on a survey of 320 UK managers, this study found that the technological driver of BDA coupled with top management support, can significantly help in the adoption process. Therefore, crafting the value needed for effectively supporting the realisation of these goals.</P>"
        },
        {
          "rank": 5,
          "score": 0.6125110387802124,
          "doc_id": "JAKO202520650404296",
          "title": "주니어 공학교육을 위한 지속가능발전목표(SDGs) 기반 인공지능 로봇 교육 프로그램 개발 및 적용",
          "abstract": "본 연구는 예비 공학도인 고등학생을 대상으로 17가지 지속가능발전목표(SDGs)를 기반으로 한 인공지능 로봇 교육 프로그램을 개발하고 그 효과를 검증하는 것을 목적으로 하였다. 미래 사회는 기술적 역량과 함께 인간 중심의 가치와 윤리적 소양을 갖춘 인재를 요구하고 있으나 현재 주니어 공학교육에서는 이러한 융합 교육이 부족한 실정이다. Dick & Carey(2001) 모형을 기반으로 체계적으로 교육프로그램을 설계 및 개발한 본 연구는 문헌 고찰, 프로그램 설계, 전문가 타당도 검증, 현장 적용 및 효과 분석의 단계를 거쳐 수행되었다. 개발된 프로그램은 전문가 내용 타당도 검증을 통해 신뢰도를 확보하였으며, 고등 학생을 대상으로 현장 적용 후 사전-사후 설문 분석을 통해 효과를 분석하였다. 연구 결과, 학생들의 프로그램 만족도는 응답자의 94.1%가 긍정적으로 평가하였다. 특히, 프로그램 참여 후 SDGs 17개 모두 '국가/사회적 노력'에 대한 중요성 인식이 통계적으로 유의미하게 상승하였으며(p<.05), 특히 '모두를 위한 저렴하고 깨끗한 에너지'(SDGs 7), '산업, 혁신, 사회기반시설 구축'(SDGs 9), '모든 종류의 불평등 감소'(SDGs 10)와 같은 특정목표는 '시급하게 중요하다.'는 인식이 유의미하게 증가하였다. 이는 본 프로그램이 첨단 기술 교육을 통해 학생들의 사회 문제에 대한 인식과 교육 공동체의 역할에 대한 중요성을 효과적으로 제고했음을 시사한다. 본 연구는 예비 공학 인재들에게 기술적 역량과 사회적 가치를 통합적으로 교육하는 구체적인 융합 교육 모델을 제시하고, 그 교육적 효과를 실증적으로 확인했다는 점에서 의의가 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202520650404296&target=NART&cn=JAKO202520650404296",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "주니어 공학교육을 위한 지속가능발전목표(SDGs) 기반 인공지능 로봇 교육 프로그램 개발 및 적용 주니어 공학교육을 위한 지속가능발전목표(SDGs) 기반 인공지능 로봇 교육 프로그램 개발 및 적용 주니어 공학교육을 위한 지속가능발전목표(SDGs) 기반 인공지능 로봇 교육 프로그램 개발 및 적용 본 연구는 예비 공학도인 고등학생을 대상으로 17가지 지속가능발전목표(SDGs)를 기반으로 한 인공지능 로봇 교육 프로그램을 개발하고 그 효과를 검증하는 것을 목적으로 하였다. 미래 사회는 기술적 역량과 함께 인간 중심의 가치와 윤리적 소양을 갖춘 인재를 요구하고 있으나 현재 주니어 공학교육에서는 이러한 융합 교육이 부족한 실정이다. Dick & Carey(2001) 모형을 기반으로 체계적으로 교육프로그램을 설계 및 개발한 본 연구는 문헌 고찰, 프로그램 설계, 전문가 타당도 검증, 현장 적용 및 효과 분석의 단계를 거쳐 수행되었다. 개발된 프로그램은 전문가 내용 타당도 검증을 통해 신뢰도를 확보하였으며, 고등 학생을 대상으로 현장 적용 후 사전-사후 설문 분석을 통해 효과를 분석하였다. 연구 결과, 학생들의 프로그램 만족도는 응답자의 94.1%가 긍정적으로 평가하였다. 특히, 프로그램 참여 후 SDGs 17개 모두 '국가/사회적 노력'에 대한 중요성 인식이 통계적으로 유의미하게 상승하였으며(p<.05), 특히 '모두를 위한 저렴하고 깨끗한 에너지'(SDGs 7), '산업, 혁신, 사회기반시설 구축'(SDGs 9), '모든 종류의 불평등 감소'(SDGs 10)와 같은 특정목표는 '시급하게 중요하다.'는 인식이 유의미하게 증가하였다. 이는 본 프로그램이 첨단 기술 교육을 통해 학생들의 사회 문제에 대한 인식과 교육 공동체의 역할에 대한 중요성을 효과적으로 제고했음을 시사한다. 본 연구는 예비 공학 인재들에게 기술적 역량과 사회적 가치를 통합적으로 교육하는 구체적인 융합 교육 모델을 제시하고, 그 교육적 효과를 실증적으로 확인했다는 점에서 의의가 있다."
        },
        {
          "rank": 6,
          "score": 0.6113746166229248,
          "doc_id": "DIKO0016086032",
          "title": "저탄소 신유망 산업의 녹색정책금융 성과분석 : 미래차·물관련·신소재 산업의 중소기업을 중심으로",
          "abstract": "탄소 중립이 전 세계적인 뉴노멀로 정착하고 한국도 ‘2050년 탄소 중립 목표’를 선언하면서 기후변화 대응은 국가 산업의 필수 경쟁력으로 부각되고 있다. 더불어 포스트 코로나로 변화하는 경제·사회 구조 전환을 가속화 하기 위한 목적으로 정부는 ‘한국판 뉴딜 2.0’을 발표하며 ‘그린뉴딜’ 분야에 저탄소 경제구조 전환을 위한 세부과제 키워드로 ‘녹색금융’, ‘미래차’, ‘물산업’, ‘신소재’ 등을 제시했다. 한편 정부의 그린뉴딜 정책에 대응하여 국내 중소기업의 자본과 기술력 등 대응 역량은 부족한 상황이다.&amp;#xD; &amp;#xD; 따라서 본 연구에서는 그린뉴딜의 시대에서 중소기업이 소외되지 않고, ‘뉴-플레이어’로서 주도적 역할을 창출하기 위해 녹색정책금융의 유형별 접근과 저탄소 신유망 산업의 특성을 반영하여 효과적인 중소기업 정책 포트폴리오를 제안한다. 이를 위해 특히 한국판 그린뉴딜의 저탄소 신유망 산업별(미래차, 물산업, 신소재) 특성을 확인하고 실증분석을 통해 탄소 중립 및 저탄소 경제 사회로의 이행을 위해 기여하고자 한다. &amp;#xD; &amp;#xD; 연구의 분석 방법 및 단계는 아래와 같다. 우선 정부 정책 및 선행연구 등을 통한 녹색정책금융의 유형화를 시도하였다. 다음으로 저탄소 신유망 산업 국내외 정책 동향 등을 참고하고 업종별 구분을 통해 산업을 정의했다. 또한 정부의 중소기업 정책금융 효과 분석에 필요한 성과지표로서 ‘영업성과(고용, 매출 등)’ 및 ‘기술성과(연구투자, 연구개발집중도 등)’ 변수를 추출하였다. 투입변수인 녹색정책금융은 ‘직·간접투자’, ‘R&amp;amp;D’, ‘인프라’, ‘기타’ 항목으로 분류했고 다중회귀분석을 하였다. 나아가 분석 결과를 기초로 각 산업별 중소기업 녹색정책금융 포트폴리오를 Level 1~4단계로 구분하였으며 단계별 정책 유형과 기대효과를 제시하였다. &amp;#xD; &amp;#xD; 연구분석결과 유망산업 모두 녹색정책금융 유형의 ‘기타’ 항목에서 Level 1 수준이 도출되어 직접·단기적으로 고용 확대의 성과가 예측되었고, ‘직간접 투자’, ‘인프라’ 지원 항목의 경우 Level 2 수준으로 직접·중기 효과가 예상되었다. 한편 ‘R&amp;amp;D’ 지원 유형의 경우 신소재 산업에서는 Level 1 수준으로 고용창출의 직접·단기적 효과가 도출되었으나 미래차 및 물관련 산업에서는 Level 3 수준으로 직간접 및 중장기적 정책효과가 예상된다. &amp;#xD; &amp;#xD; 결론적으로 Level 1~2가 도출된 정책 유형은 직접·단기적 효과를 얻을 수 있어 정책 포트폴리오의 주요 구성으로 검토하며 Level 3~4 수준에서는 정책효과를 제고하기 위한 방안 마련과 장기적 관점에서의 접근을 해야 한다. 특히 중소기업의 고용창출은 전산업 모두 직접·단기적 효과를 얻을 수 있어 관련 업종 종사자수 증가를 통한 시장확대와 전문성 강화를 위한 교육 및 역량 강화, 인재 육성, 산·학연계 등의 정책 프로그램도 활용해야 할 것이다. 나아가 저탄소 유망 산업별 연계를 통한 시너지 효과 창출을 위한 정책 추진과 그린뉴딜의 중장기적 지원 효과 분석을 위한 체계적인 데이터 구축·관리가 요구된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016086032&target=NART&cn=DIKO0016086032",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "저탄소 신유망 산업의 녹색정책금융 성과분석 : 미래차·물관련·신소재 산업의 중소기업을 중심으로 저탄소 신유망 산업의 녹색정책금융 성과분석 : 미래차·물관련·신소재 산업의 중소기업을 중심으로 저탄소 신유망 산업의 녹색정책금융 성과분석 : 미래차·물관련·신소재 산업의 중소기업을 중심으로 탄소 중립이 전 세계적인 뉴노멀로 정착하고 한국도 ‘2050년 탄소 중립 목표’를 선언하면서 기후변화 대응은 국가 산업의 필수 경쟁력으로 부각되고 있다. 더불어 포스트 코로나로 변화하는 경제·사회 구조 전환을 가속화 하기 위한 목적으로 정부는 ‘한국판 뉴딜 2.0’을 발표하며 ‘그린뉴딜’ 분야에 저탄소 경제구조 전환을 위한 세부과제 키워드로 ‘녹색금융’, ‘미래차’, ‘물산업’, ‘신소재’ 등을 제시했다. 한편 정부의 그린뉴딜 정책에 대응하여 국내 중소기업의 자본과 기술력 등 대응 역량은 부족한 상황이다.&amp;#xD; &amp;#xD; 따라서 본 연구에서는 그린뉴딜의 시대에서 중소기업이 소외되지 않고, ‘뉴-플레이어’로서 주도적 역할을 창출하기 위해 녹색정책금융의 유형별 접근과 저탄소 신유망 산업의 특성을 반영하여 효과적인 중소기업 정책 포트폴리오를 제안한다. 이를 위해 특히 한국판 그린뉴딜의 저탄소 신유망 산업별(미래차, 물산업, 신소재) 특성을 확인하고 실증분석을 통해 탄소 중립 및 저탄소 경제 사회로의 이행을 위해 기여하고자 한다. &amp;#xD; &amp;#xD; 연구의 분석 방법 및 단계는 아래와 같다. 우선 정부 정책 및 선행연구 등을 통한 녹색정책금융의 유형화를 시도하였다. 다음으로 저탄소 신유망 산업 국내외 정책 동향 등을 참고하고 업종별 구분을 통해 산업을 정의했다. 또한 정부의 중소기업 정책금융 효과 분석에 필요한 성과지표로서 ‘영업성과(고용, 매출 등)’ 및 ‘기술성과(연구투자, 연구개발집중도 등)’ 변수를 추출하였다. 투입변수인 녹색정책금융은 ‘직·간접투자’, ‘R&amp;amp;D’, ‘인프라’, ‘기타’ 항목으로 분류했고 다중회귀분석을 하였다. 나아가 분석 결과를 기초로 각 산업별 중소기업 녹색정책금융 포트폴리오를 Level 1~4단계로 구분하였으며 단계별 정책 유형과 기대효과를 제시하였다. &amp;#xD; &amp;#xD; 연구분석결과 유망산업 모두 녹색정책금융 유형의 ‘기타’ 항목에서 Level 1 수준이 도출되어 직접·단기적으로 고용 확대의 성과가 예측되었고, ‘직간접 투자’, ‘인프라’ 지원 항목의 경우 Level 2 수준으로 직접·중기 효과가 예상되었다. 한편 ‘R&amp;amp;D’ 지원 유형의 경우 신소재 산업에서는 Level 1 수준으로 고용창출의 직접·단기적 효과가 도출되었으나 미래차 및 물관련 산업에서는 Level 3 수준으로 직간접 및 중장기적 정책효과가 예상된다. &amp;#xD; &amp;#xD; 결론적으로 Level 1~2가 도출된 정책 유형은 직접·단기적 효과를 얻을 수 있어 정책 포트폴리오의 주요 구성으로 검토하며 Level 3~4 수준에서는 정책효과를 제고하기 위한 방안 마련과 장기적 관점에서의 접근을 해야 한다. 특히 중소기업의 고용창출은 전산업 모두 직접·단기적 효과를 얻을 수 있어 관련 업종 종사자수 증가를 통한 시장확대와 전문성 강화를 위한 교육 및 역량 강화, 인재 육성, 산·학연계 등의 정책 프로그램도 활용해야 할 것이다. 나아가 저탄소 유망 산업별 연계를 통한 시너지 효과 창출을 위한 정책 추진과 그린뉴딜의 중장기적 지원 효과 분석을 위한 체계적인 데이터 구축·관리가 요구된다."
        },
        {
          "rank": 7,
          "score": 0.6091933250427246,
          "doc_id": "DIKO0016854880",
          "title": "지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용",
          "abstract": "인류사의 새로운 물결인 제4차 산업혁명에 대응하고 당면한 문제를 해결하기 위해 세계 각국은 인공지능교육에 역량을 집중하는 한편 환경오염, 자원 고갈, 빈부격차, 불평등, 기후변화 등의 다양한 현실 문제를 인식하고, 변화를 위한 행동을 촉구하는 방안으로 지속가능발전교육의 필요성이 강조되고 있다. &amp;#xD; 지속가능발전교육은 지속가능발전 및 지속가능발전목표를 이해하고 삶 속에서 자기주도적으로 현실의 문제를 해결하려는 기능과 태도를 갖춰 지속가능 발전역량을 강화하는 것이 목표이다. 이에 구체적인 실행 방안으로 현실 인식 및 미래 예측을 돕고 지속 가능한 발전을 이끄는 인공지능 교육을 들 수 있다. 인공지능은 이미 직면한 문제를 해결하고 지속 가능한 사회를 만들고 있기 때문이다. &amp;#xD; 따라서 본 연구는 인공지능 교육을 통해 인공지능의 기초·원리를 이해하고 윤리적인 측면을 고려하여 올바르게 활용하는 능력인 인공지능 리터러시 및 전 지구적 문제해결을 위한 지속가능 발전역량 함양을 목적으로 한다. 이를 위해 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램을 개발 및 적용하여 인공지능 리터러시와 지속가능 발전역량에 미치는 효과를 확인하였다. &amp;#xD; 본 연구의 대상은 초등학교 6학년 학생 40명이며 6주간 15차시에 걸쳐 개발된 프로그램이 적용되었다. 교육 프로그램은 ADDIE 수업 모형을 바탕으로 분석, 설계, 개발, 실행 평가의 5단계로 설계되어 사전 및 프로젝트 학습으로 구성되었다. &amp;#xD; 사전학습에서 인공지능의 이해와 윤리를 바탕으로 올바르게 활용하는 방법을 익힌다. 프로젝트 학습은 인공지능과 지속가능 발전의 연관성을 탐구하며 데이터 기반 의사결정으로 지속가능 발전을 위한 인공지능 모델 개발 등 프로젝트를 수행하고 평가하는 활동으로 구성되었다. &amp;#xD; 본 연구는 사전 요구 분석 조사 및 교육 프로그램 적용 전후 인공지능 리터러시와 지속가능 발전역량을 측정하는 검사를 실시하여 그 결과를 분석하였다. &amp;#xD; 연구 결과, 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램은 학생들의 인공지능 리터러시 및 지속가능 발전역량 향상에 통계적으로 유의미한 효과가 있음을 확인하였다(p&amp;lt;.001). &amp;#xD; 본 연구가 2022 개정 교육과정에서 강조되는 인공지능 리터러시 및 지속가능 발전역량 함양과 관련된 연구 확산에 초석이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016854880&target=NART&cn=DIKO0016854880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 지속가능발전교육을 위한 데이터 기반 초등학교 인공지능 교육 프로그램 개발 및 적용 인류사의 새로운 물결인 제4차 산업혁명에 대응하고 당면한 문제를 해결하기 위해 세계 각국은 인공지능교육에 역량을 집중하는 한편 환경오염, 자원 고갈, 빈부격차, 불평등, 기후변화 등의 다양한 현실 문제를 인식하고, 변화를 위한 행동을 촉구하는 방안으로 지속가능발전교육의 필요성이 강조되고 있다. &amp;#xD; 지속가능발전교육은 지속가능발전 및 지속가능발전목표를 이해하고 삶 속에서 자기주도적으로 현실의 문제를 해결하려는 기능과 태도를 갖춰 지속가능 발전역량을 강화하는 것이 목표이다. 이에 구체적인 실행 방안으로 현실 인식 및 미래 예측을 돕고 지속 가능한 발전을 이끄는 인공지능 교육을 들 수 있다. 인공지능은 이미 직면한 문제를 해결하고 지속 가능한 사회를 만들고 있기 때문이다. &amp;#xD; 따라서 본 연구는 인공지능 교육을 통해 인공지능의 기초·원리를 이해하고 윤리적인 측면을 고려하여 올바르게 활용하는 능력인 인공지능 리터러시 및 전 지구적 문제해결을 위한 지속가능 발전역량 함양을 목적으로 한다. 이를 위해 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램을 개발 및 적용하여 인공지능 리터러시와 지속가능 발전역량에 미치는 효과를 확인하였다. &amp;#xD; 본 연구의 대상은 초등학교 6학년 학생 40명이며 6주간 15차시에 걸쳐 개발된 프로그램이 적용되었다. 교육 프로그램은 ADDIE 수업 모형을 바탕으로 분석, 설계, 개발, 실행 평가의 5단계로 설계되어 사전 및 프로젝트 학습으로 구성되었다. &amp;#xD; 사전학습에서 인공지능의 이해와 윤리를 바탕으로 올바르게 활용하는 방법을 익힌다. 프로젝트 학습은 인공지능과 지속가능 발전의 연관성을 탐구하며 데이터 기반 의사결정으로 지속가능 발전을 위한 인공지능 모델 개발 등 프로젝트를 수행하고 평가하는 활동으로 구성되었다. &amp;#xD; 본 연구는 사전 요구 분석 조사 및 교육 프로그램 적용 전후 인공지능 리터러시와 지속가능 발전역량을 측정하는 검사를 실시하여 그 결과를 분석하였다. &amp;#xD; 연구 결과, 지속가능발전교육을 위한 데이터 기반 인공지능 교육 프로그램은 학생들의 인공지능 리터러시 및 지속가능 발전역량 향상에 통계적으로 유의미한 효과가 있음을 확인하였다(p&amp;lt;.001). &amp;#xD; 본 연구가 2022 개정 교육과정에서 강조되는 인공지능 리터러시 및 지속가능 발전역량 함양과 관련된 연구 확산에 초석이 되기를 기대한다."
        },
        {
          "rank": 8,
          "score": 0.6084834337234497,
          "doc_id": "JAKO202208148825854",
          "title": "사회적협동조합의 지속가능성에 관한 연구",
          "abstract": "본 연구는 사회적협동조합에 대한 이론적 검토와 4차에 걸친 실태조사 결과를 바탕으로 사회적협동조합의 지속가능성에 대해 협동조합 7대 원칙을 중심으로 사회적&#x00B7;경제적&#x00B7;환경적 측면에서 논의하고자 하였다. 지속가능성의 문제는 '미래 세대가 그들의 필요를 충족시킬 능력을 저해하지 않으면서 현재 세대의 필요를 충족시키는 발전, 자원의 이용, 투자의 방향, 기술의 발전 그리고 제도변화가 서로 조화를 이루며 현재와 미래의 모든 세대의 필요와 욕구를 증진시키는 변화의 과정'으로 정의되었듯이. 사회적 가치와 환경보전 그리고 경제성장이 상호 대립되는 개념이 아닌 조화와 균형으로 미래 세대에도 지속가능한 사회를 연결하자는 의미를 담고 있다. 지속가능한 발전에 담겨진 사회적&#x00B7;경제적&#x00B7;환경적 지속가능성의 개념과 협동조합 7대 원칙과 연계성을 정리한 결과, 사회적협동조합의 지속가능성에 대해 다음과 같이 제언하고자 한다. 첫째, 지역사회 밀착형 사회공헌에 노력해야 한다. 둘째, 공익과 더불어 수익모델을 창출해야 한다. 셋째, 파트너십을 강화해야 한다. 본연구를 통해 사회적협동조합이 실현하고자 하는 공익적 가치와 목적을 살펴볼 때, 지속가능한 발전의 세 가지 범위는 현 사회적경제 조직이 직면하고 있는 사회적&#x00B7;경제적 가치 추구를 위한 중요한 행위자로서의 역할과 직결된다 하겠다. 따라서 사회적협동조합의 지속가능성 문제는 사회적협동조합이 추구하는 목적과 가치가 환경적&#x00B7;사회적&#x00B7;경제적 측면에서의 조화와 균형발전이라는 개념에 기초하여 사회적협동조합 스스로의 노력뿐만 아니라 정부의 제도적인 뒷받침이 제시되어야 할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202208148825854&target=NART&cn=JAKO202208148825854",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "사회적협동조합의 지속가능성에 관한 연구 사회적협동조합의 지속가능성에 관한 연구 사회적협동조합의 지속가능성에 관한 연구 본 연구는 사회적협동조합에 대한 이론적 검토와 4차에 걸친 실태조사 결과를 바탕으로 사회적협동조합의 지속가능성에 대해 협동조합 7대 원칙을 중심으로 사회적&#x00B7;경제적&#x00B7;환경적 측면에서 논의하고자 하였다. 지속가능성의 문제는 '미래 세대가 그들의 필요를 충족시킬 능력을 저해하지 않으면서 현재 세대의 필요를 충족시키는 발전, 자원의 이용, 투자의 방향, 기술의 발전 그리고 제도변화가 서로 조화를 이루며 현재와 미래의 모든 세대의 필요와 욕구를 증진시키는 변화의 과정'으로 정의되었듯이. 사회적 가치와 환경보전 그리고 경제성장이 상호 대립되는 개념이 아닌 조화와 균형으로 미래 세대에도 지속가능한 사회를 연결하자는 의미를 담고 있다. 지속가능한 발전에 담겨진 사회적&#x00B7;경제적&#x00B7;환경적 지속가능성의 개념과 협동조합 7대 원칙과 연계성을 정리한 결과, 사회적협동조합의 지속가능성에 대해 다음과 같이 제언하고자 한다. 첫째, 지역사회 밀착형 사회공헌에 노력해야 한다. 둘째, 공익과 더불어 수익모델을 창출해야 한다. 셋째, 파트너십을 강화해야 한다. 본연구를 통해 사회적협동조합이 실현하고자 하는 공익적 가치와 목적을 살펴볼 때, 지속가능한 발전의 세 가지 범위는 현 사회적경제 조직이 직면하고 있는 사회적&#x00B7;경제적 가치 추구를 위한 중요한 행위자로서의 역할과 직결된다 하겠다. 따라서 사회적협동조합의 지속가능성 문제는 사회적협동조합이 추구하는 목적과 가치가 환경적&#x00B7;사회적&#x00B7;경제적 측면에서의 조화와 균형발전이라는 개념에 기초하여 사회적협동조합 스스로의 노력뿐만 아니라 정부의 제도적인 뒷받침이 제시되어야 할 것이다."
        },
        {
          "rank": 9,
          "score": 0.6039522886276245,
          "doc_id": "JAKO200951062618667",
          "title": "저탄소 녹색성장을 위한 녹색산업.기술 육성 II",
          "abstract": "최근 세계 경제는 사상 유래를 찾기 힘든 경제위기에 홍역을 앓고 있다. 국제유가를 비롯한 원자재가격은 수급불균형과 정치적 이슈, 그리고 투기자본의 유입이 어우러져 급등락을 거듭하고 있다. 또한, 지구온난화를 막기 위해 국제사회에서 추진하고 있는 기후변화협약도 큰 어려움을 겪고 있다. 선진국들은 배출권 거래제도 시행, 탄소세 도입 등을 통해 본격적인 환경 무역시대가 도래에 대비하고 있으며, 포스트 교토체제에 대한 협상도 본격화 되고 있어 대응이 시급한 실정이다. 자원 환경위기의 시대에 녹색성장은 불가피한 선택이 되었으며 우리나라에서도 온실가스 감축을 위해 많은 노력을 하고 있다. 정부에서는 탄소포인트제도 도입과 10대 녹색기술 산업 육성, 그린 뉴딜을 통한 녹색일자리 4만 3천개 창출 등 기후변화 대응을 위한 정책들을 추진하고 있으며, 또한 저탄소 녹색성장의 한 주축으로 신재생 에너지 기술개발 및 보급의 확대를 통해 세계시장 선점을 위해 매진하고 있다. 환경부에서는 폐기물에너지화, 기후변화대응, 환경산업육성 등 '저탄소 녹색성장'을 이끌 사업과 '경제 살리기'에 역점을 두고 2009년도에는 환경부 소관예산 '08년 예산 3조 5,914억원 대비 5,008억원(13.9%) 증액된 총 4조 922억원을 투자할 계획이다. 이에 본지에서는 지난호에 이어 저탄소 녹색성장을 위한 녹색자원 기술 육성II로 주제를 잡고 '온 국민이 참여하는 기후변화 대응 정책 추진', '녹색성장 정책 추진에 있어 기업체 지원방향', '우리나라 신재생에너지 기술개발현황과 앞으로의 과제', '가정에서 온실 가스 줄인만큼 혜택받는 탄소은행'등에 대하여 살펴보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200951062618667&target=NART&cn=JAKO200951062618667",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "저탄소 녹색성장을 위한 녹색산업.기술 육성 II 저탄소 녹색성장을 위한 녹색산업.기술 육성 II 저탄소 녹색성장을 위한 녹색산업.기술 육성 II 최근 세계 경제는 사상 유래를 찾기 힘든 경제위기에 홍역을 앓고 있다. 국제유가를 비롯한 원자재가격은 수급불균형과 정치적 이슈, 그리고 투기자본의 유입이 어우러져 급등락을 거듭하고 있다. 또한, 지구온난화를 막기 위해 국제사회에서 추진하고 있는 기후변화협약도 큰 어려움을 겪고 있다. 선진국들은 배출권 거래제도 시행, 탄소세 도입 등을 통해 본격적인 환경 무역시대가 도래에 대비하고 있으며, 포스트 교토체제에 대한 협상도 본격화 되고 있어 대응이 시급한 실정이다. 자원 환경위기의 시대에 녹색성장은 불가피한 선택이 되었으며 우리나라에서도 온실가스 감축을 위해 많은 노력을 하고 있다. 정부에서는 탄소포인트제도 도입과 10대 녹색기술 산업 육성, 그린 뉴딜을 통한 녹색일자리 4만 3천개 창출 등 기후변화 대응을 위한 정책들을 추진하고 있으며, 또한 저탄소 녹색성장의 한 주축으로 신재생 에너지 기술개발 및 보급의 확대를 통해 세계시장 선점을 위해 매진하고 있다. 환경부에서는 폐기물에너지화, 기후변화대응, 환경산업육성 등 '저탄소 녹색성장'을 이끌 사업과 '경제 살리기'에 역점을 두고 2009년도에는 환경부 소관예산 '08년 예산 3조 5,914억원 대비 5,008억원(13.9%) 증액된 총 4조 922억원을 투자할 계획이다. 이에 본지에서는 지난호에 이어 저탄소 녹색성장을 위한 녹색자원 기술 육성II로 주제를 잡고 '온 국민이 참여하는 기후변화 대응 정책 추진', '녹색성장 정책 추진에 있어 기업체 지원방향', '우리나라 신재생에너지 기술개발현황과 앞으로의 과제', '가정에서 온실 가스 줄인만큼 혜택받는 탄소은행'등에 대하여 살펴보고자 한다."
        },
        {
          "rank": 10,
          "score": 0.6032509803771973,
          "doc_id": "JAKO200908856862407",
          "title": "지속가능성보고서를 토대로 한 기업 지속가능가치평가",
          "abstract": "본 연구는 지속가능성보고서평가 시 지속가능한 기업을 어떻게 구분할 것인가에 대한 문제를 제기하고, 이에 대한 해결방안을 기업 지속가능가치에서 찾아보며, 이를 지속가능성보고서를 토대로 기업의 지속가능성 평가에 활용할 수 있는 방안을 모색하는 것을 목적으로 한다. 지속가능가치는 기업이 지속가능경영을 위한 현재와 미래에 필요한 자원을 적절히 관리하고 있는가를 파악하기 위해 경제, 사회 그리고 생태적 영역에 걸친 성과를 평가하는 방법론이다. 기존의 지속가능성평가모델들이 기업이 생산활동을 통해 얼마나 많은 외부효과를 발생시켰는지를 평가하는 부하 지향적 방법이었다면 지속가능가치는 한정된 자원을 얼마나 효율적으로 사용하여 비교대상보다 더 많은 가치를 창출하였는가의 관점에서 지속가능경영 성과를 평가하는 가치 지향적 방법이라 할 수 있다. 본 연구의 결과로 제시된 지속가능보고서를 토대로 한 지속가능가치 평가는 지속가능성보고서의 질, 지속가능성보고서 내용의 충실성뿐만 아니라, 지속가능성보고서가 기술하고 있는 기업의 지속가능경영성과를 종합적으로 평가할 수 유용한 수단이 될 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200908856862407&target=NART&cn=JAKO200908856862407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지속가능성보고서를 토대로 한 기업 지속가능가치평가 지속가능성보고서를 토대로 한 기업 지속가능가치평가 지속가능성보고서를 토대로 한 기업 지속가능가치평가 본 연구는 지속가능성보고서평가 시 지속가능한 기업을 어떻게 구분할 것인가에 대한 문제를 제기하고, 이에 대한 해결방안을 기업 지속가능가치에서 찾아보며, 이를 지속가능성보고서를 토대로 기업의 지속가능성 평가에 활용할 수 있는 방안을 모색하는 것을 목적으로 한다. 지속가능가치는 기업이 지속가능경영을 위한 현재와 미래에 필요한 자원을 적절히 관리하고 있는가를 파악하기 위해 경제, 사회 그리고 생태적 영역에 걸친 성과를 평가하는 방법론이다. 기존의 지속가능성평가모델들이 기업이 생산활동을 통해 얼마나 많은 외부효과를 발생시켰는지를 평가하는 부하 지향적 방법이었다면 지속가능가치는 한정된 자원을 얼마나 효율적으로 사용하여 비교대상보다 더 많은 가치를 창출하였는가의 관점에서 지속가능경영 성과를 평가하는 가치 지향적 방법이라 할 수 있다. 본 연구의 결과로 제시된 지속가능보고서를 토대로 한 지속가능가치 평가는 지속가능성보고서의 질, 지속가능성보고서 내용의 충실성뿐만 아니라, 지속가능성보고서가 기술하고 있는 기업의 지속가능경영성과를 종합적으로 평가할 수 유용한 수단이 될 수 있을 것이다."
        },
        {
          "rank": 11,
          "score": 0.5992391109466553,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 12,
          "score": 0.5983140468597412,
          "doc_id": "NART118561572",
          "title": "AHP QFD methodology for a recycled solar collector",
          "abstract": "<P><B>Abstract</B></P><P>As it is presented in literature, the AHP-QFD method is a method applicable to many sectors, namely industry. The article is a part of this framework, applying this method for the design of a recycled solar air heater according to customer&rsquo;s expectations. The methodology is based on the application of QFD to detect consumer requirements, technical characteristics and their relationship matrices. while the AHP method aims to evaluate the weights of each criterion in order to make the right decision.</P><P>In this study, the manufacturing process was projected from upstream to downstream, as well as a market study was established in October 2020, in Khouribga-Morocco, in which 50 people responded favourably to a survey about the most frequently searched requirements which include size, efficiency, design, price and ecology as well as their importance in a solar collector. Besides, relationship matrices and the weight matrices of the technical criteria have been established, by presenting a consistent ratio &ldquo;CR&rdquo; less than 10% showing the consistency of the assessment, and finally a priority given to the characteristics of the recycled solar air heater: cans and thermal insulation more superior to the others characteristics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118561572&target=NART&cn=NART118561572",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP QFD methodology for a recycled solar collector AHP QFD methodology for a recycled solar collector AHP QFD methodology for a recycled solar collector <P><B>Abstract</B></P><P>As it is presented in literature, the AHP-QFD method is a method applicable to many sectors, namely industry. The article is a part of this framework, applying this method for the design of a recycled solar air heater according to customer&rsquo;s expectations. The methodology is based on the application of QFD to detect consumer requirements, technical characteristics and their relationship matrices. while the AHP method aims to evaluate the weights of each criterion in order to make the right decision.</P><P>In this study, the manufacturing process was projected from upstream to downstream, as well as a market study was established in October 2020, in Khouribga-Morocco, in which 50 people responded favourably to a survey about the most frequently searched requirements which include size, efficiency, design, price and ecology as well as their importance in a solar collector. Besides, relationship matrices and the weight matrices of the technical criteria have been established, by presenting a consistent ratio &ldquo;CR&rdquo; less than 10% showing the consistency of the assessment, and finally a priority given to the characteristics of the recycled solar air heater: cans and thermal insulation more superior to the others characteristics.</P>"
        },
        {
          "rank": 13,
          "score": 0.5966374278068542,
          "doc_id": "NART69849180",
          "title": "도시재생 영역의 중요도 분석을 통한 사회적기업의 지속가능성 탐색",
          "abstract": "<P>최근 도시재생은 지역이라는 한정된 공간에서 경제, 사회, 환경, 문화 분야 등을 포괄하는 종합적인 관점에서 접근되고 있으며, 커뮤니티 비즈니스 형태의 사회적기업에 의해 지역 취약계층에 대한 일자리 제공과 복지서비스 등을 제공하는 도시재생 전략을 활용하기도 한다. 이런 관점에서 우리 정부는 각 부처에서 다양한 형태로 진행되고 있는 도시재생 관련 사업을 유기적이고 종합적인 관점에서 추진하고자 물리, 경제, 사회, 문화, 환경적 측면에서 지속적으로 추진 가능한 연계대상사업을 선정하였다. 또한 2007년 이래 법제도의 정비에 기반해 사회적기업이 발굴ㆍ육성되어 양적인 성장을 보이고는 있으나 궁극적으로 사회적기업의 지속가능성에 대한 의문이 다각적 측면에서 제기되고 있다. 이런 시점에서 본 연구는 사회적기업의 지속가능성을 기존의 도시재생(연계사업) 영역의 중요도 분석을 통해 탐색해 보고자 한다. 이를 위해 먼저 지속가능성의 개념적 유형화, 그리고 도시재생사업과 사회적기업과의 연계성에 관해 이론적인 측면에서 논의한다. 이를 바탕으로 도시재생연계사업 영역의 중요성에 대한 전문가 인식을 설문조사하여 사회적기업의 분야별 지속가능성 확보를 위한 분야별 도시재생연계사업과의 연계 가능성을 실증적으로 분석해 보았다.</P><P>&nbsp;AHP 계층구조에 근거하여 분석한 평가영역 간 중요도는 문화재생(.330), 경제재생(.271), 환경재생(.235), 복지재생(.164) 등의 순서로 중요도가 분석되었는바 이러한 결과는 문화를 기반으로 하는 도시재생 전략의 접근법이 우리나라에서도 중요하게 인식되고 있으며, 사회적기업의 지속성 및 도시재생의 성공적 수행을 위한 지역차원의 전략적 계획수립에 있어서 지역의 문화자원을 활용한 사업발굴과 유형화가 구체화되어야 할 것이다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69849180&target=NART&cn=NART69849180",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "도시재생 영역의 중요도 분석을 통한 사회적기업의 지속가능성 탐색 도시재생 영역의 중요도 분석을 통한 사회적기업의 지속가능성 탐색 도시재생 영역의 중요도 분석을 통한 사회적기업의 지속가능성 탐색 <P>최근 도시재생은 지역이라는 한정된 공간에서 경제, 사회, 환경, 문화 분야 등을 포괄하는 종합적인 관점에서 접근되고 있으며, 커뮤니티 비즈니스 형태의 사회적기업에 의해 지역 취약계층에 대한 일자리 제공과 복지서비스 등을 제공하는 도시재생 전략을 활용하기도 한다. 이런 관점에서 우리 정부는 각 부처에서 다양한 형태로 진행되고 있는 도시재생 관련 사업을 유기적이고 종합적인 관점에서 추진하고자 물리, 경제, 사회, 문화, 환경적 측면에서 지속적으로 추진 가능한 연계대상사업을 선정하였다. 또한 2007년 이래 법제도의 정비에 기반해 사회적기업이 발굴ㆍ육성되어 양적인 성장을 보이고는 있으나 궁극적으로 사회적기업의 지속가능성에 대한 의문이 다각적 측면에서 제기되고 있다. 이런 시점에서 본 연구는 사회적기업의 지속가능성을 기존의 도시재생(연계사업) 영역의 중요도 분석을 통해 탐색해 보고자 한다. 이를 위해 먼저 지속가능성의 개념적 유형화, 그리고 도시재생사업과 사회적기업과의 연계성에 관해 이론적인 측면에서 논의한다. 이를 바탕으로 도시재생연계사업 영역의 중요성에 대한 전문가 인식을 설문조사하여 사회적기업의 분야별 지속가능성 확보를 위한 분야별 도시재생연계사업과의 연계 가능성을 실증적으로 분석해 보았다.</P><P>&nbsp;AHP 계층구조에 근거하여 분석한 평가영역 간 중요도는 문화재생(.330), 경제재생(.271), 환경재생(.235), 복지재생(.164) 등의 순서로 중요도가 분석되었는바 이러한 결과는 문화를 기반으로 하는 도시재생 전략의 접근법이 우리나라에서도 중요하게 인식되고 있으며, 사회적기업의 지속성 및 도시재생의 성공적 수행을 위한 지역차원의 전략적 계획수립에 있어서 지역의 문화자원을 활용한 사업발굴과 유형화가 구체화되어야 할 것이다.</P>"
        },
        {
          "rank": 14,
          "score": 0.5963963270187378,
          "doc_id": "JAKO202224143278172",
          "title": "지속가능성을 위한 기독교교육",
          "abstract": "연구 목적 : 본고는 오늘날의 기후환경 및 생태위기를 극복하기 위해 등장한 '지속가능발전'(SD) 개념에 대한 비판적 고찰을 통해 그것이 가진 모순을 드러내고 지속가능성을 위한 기독교교육이 자족과 청빈, 나눔과 정의의 영성을 함양하는 영성교육이 되어야 함을 주장한다. 연구 내용 및 방법 : 이를 위해 먼저 심화되는 환경문제와 이를 타개하기 위한 국제적 공조의 노력과 한계를 고찰한다. 실제로 기후환경과 관련된 국제협약들은 경제적 이익을 포기하지 못하는 강대국들의 탐욕으로 인해 제대로 실현되지 못하고 있다. 또한 '녹색혁명'의 이상과 현실 간의 차이로 인해 지속가능한 사회는 요원해졌다. 이런 상황에 직면해 기독교 신학은 그동안 인간 중심적이고 영과 육의 이원론에 근거한 내세 중심적인 고전 신학의 한계로부터 벗어나 새로운 신학적 패러다임을 구축하려고 노력하고 있다. 이런 신학적 성찰들을 통해 기독교교육은 창조 세계의 회복을 위해 본질적으로 인간의 탐욕 문제를 어떻게 다룰 것인지에 초점을 맞춰 영성교육을 수행해야 할 필요가 있다. 결론 및 제언 : 이에 본고는 자족과 청빈, 나눔과 정의의 영성의 필요성을 주장하며 이를 훈련하기 위해 인간의 탐욕에 대한 깊은 신학적 성찰과 회개, 피해자 목소리의 경청, 소비의 절제, 대안적 사례 연구, 피해자 입장에서 진실을 밝히는 결단력 있는 행동을 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202224143278172&target=NART&cn=JAKO202224143278172",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지속가능성을 위한 기독교교육 지속가능성을 위한 기독교교육 지속가능성을 위한 기독교교육 연구 목적 : 본고는 오늘날의 기후환경 및 생태위기를 극복하기 위해 등장한 '지속가능발전'(SD) 개념에 대한 비판적 고찰을 통해 그것이 가진 모순을 드러내고 지속가능성을 위한 기독교교육이 자족과 청빈, 나눔과 정의의 영성을 함양하는 영성교육이 되어야 함을 주장한다. 연구 내용 및 방법 : 이를 위해 먼저 심화되는 환경문제와 이를 타개하기 위한 국제적 공조의 노력과 한계를 고찰한다. 실제로 기후환경과 관련된 국제협약들은 경제적 이익을 포기하지 못하는 강대국들의 탐욕으로 인해 제대로 실현되지 못하고 있다. 또한 '녹색혁명'의 이상과 현실 간의 차이로 인해 지속가능한 사회는 요원해졌다. 이런 상황에 직면해 기독교 신학은 그동안 인간 중심적이고 영과 육의 이원론에 근거한 내세 중심적인 고전 신학의 한계로부터 벗어나 새로운 신학적 패러다임을 구축하려고 노력하고 있다. 이런 신학적 성찰들을 통해 기독교교육은 창조 세계의 회복을 위해 본질적으로 인간의 탐욕 문제를 어떻게 다룰 것인지에 초점을 맞춰 영성교육을 수행해야 할 필요가 있다. 결론 및 제언 : 이에 본고는 자족과 청빈, 나눔과 정의의 영성의 필요성을 주장하며 이를 훈련하기 위해 인간의 탐욕에 대한 깊은 신학적 성찰과 회개, 피해자 목소리의 경청, 소비의 절제, 대안적 사례 연구, 피해자 입장에서 진실을 밝히는 결단력 있는 행동을 제안한다."
        },
        {
          "rank": 15,
          "score": 0.5927402377128601,
          "doc_id": "JAKO202407845889961",
          "title": "공간정보 표준기반 스마트시티 프레임워크",
          "abstract": "현대 도시는 다양한 도시 문제에 대응하기 위해 적극적으로 스마트시티 서비스를 도입하고 있다. 공간정보는 스마트시티의 기반 인프라로 작용하며, 도시의 지속 가능한 발전을 촉진한다. 공간정보의 표준화와 활용이 증가함에 따라 스마트시티의 효율적인 운영과 지속가능성이 향상되는데, 이를 위해서는 다양한 이해관계자들간의 협력을 통한 최적의 공간정보 기반 스마트시티 서비스 제공이 중요하다. 본 연구에서는 교통 및 건축-에너지 도메인 중심의 스마트시티 서비스를 공간정보 기술의 생애주기 기반으로 정의하고, 이를 공간정보 표준에 적용하고 활용하는 중요성을 강조한다. 또한, 공간정보 표준기반 스마트시티(SCGI, Smart City based on Geospatial Information standards) 프레임워크를 제안하여, 공간정보 표준에 매핑 가능한 스마트시티 서비스의 표준화에 관한 인사이트를 제시하였다. 본 연구는 공간정보 표준을 활용하여 커스터마이징된 솔루션을 제공함으로써 스마트시티 서비스의 표준화를 위한 새로운 패러다임을 제시하며, 스마트시티의 미래 발전 가능성을 논의한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407845889961&target=NART&cn=JAKO202407845889961",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보 표준기반 스마트시티 프레임워크 공간정보 표준기반 스마트시티 프레임워크 공간정보 표준기반 스마트시티 프레임워크 현대 도시는 다양한 도시 문제에 대응하기 위해 적극적으로 스마트시티 서비스를 도입하고 있다. 공간정보는 스마트시티의 기반 인프라로 작용하며, 도시의 지속 가능한 발전을 촉진한다. 공간정보의 표준화와 활용이 증가함에 따라 스마트시티의 효율적인 운영과 지속가능성이 향상되는데, 이를 위해서는 다양한 이해관계자들간의 협력을 통한 최적의 공간정보 기반 스마트시티 서비스 제공이 중요하다. 본 연구에서는 교통 및 건축-에너지 도메인 중심의 스마트시티 서비스를 공간정보 기술의 생애주기 기반으로 정의하고, 이를 공간정보 표준에 적용하고 활용하는 중요성을 강조한다. 또한, 공간정보 표준기반 스마트시티(SCGI, Smart City based on Geospatial Information standards) 프레임워크를 제안하여, 공간정보 표준에 매핑 가능한 스마트시티 서비스의 표준화에 관한 인사이트를 제시하였다. 본 연구는 공간정보 표준을 활용하여 커스터마이징된 솔루션을 제공함으로써 스마트시티 서비스의 표준화를 위한 새로운 패러다임을 제시하며, 스마트시티의 미래 발전 가능성을 논의한다."
        },
        {
          "rank": 16,
          "score": 0.5903714299201965,
          "doc_id": "JAKO201206735658103",
          "title": "그린산업 육성을 위한 농업분야 IT융합기술",
          "abstract": "Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201206735658103&target=NART&cn=JAKO201206735658103",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "그린산업 육성을 위한 농업분야 IT융합기술 그린산업 육성을 위한 농업분야 IT융합기술 그린산업 육성을 위한 농업분야 IT융합기술 Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy."
        },
        {
          "rank": 17,
          "score": 0.5892511010169983,
          "doc_id": "JAKO201415642603283",
          "title": "섬유·패션기업의 지속가능성 실천 평가 연구",
          "abstract": "The practice of sustainability is an important subject to integrate into the management, product planning, manufacturing by textile and fashion companies as well as consumption by end-users. This study shows an evaluation scale designed to assess the practical cases in order to suggest efficient and systematic methods to fulfill the practice of sustainability in textile and fashion companies. First, companies should practice environmental sustainability to use eco-friendly material and cleaner production, protect the environment, and save natural resources. Second, social sustainability is required to fulfill social responsibility and ethical needs. Third, companies should perform various innovative activities, transparency in management, fair competition and economic contribution in the local community in order to maintain economic sustainability to survive in industry. Finally, cultural sustainability should be fulfilled by textile and fashion companies as part of the intellectual-cultural industry in a way that increases the importance of ethnic and cultural diversity. Textile and fashion companies should fulfill four environmental, social, and economic cultural sustainable subjects in a balanced method to accomplish sustainability. The concerns and practices of environmental sustainability are comparatively highly rated due to the analysis of the evaluation scale. However, cultural sustainability (a need of the times) is poorly rated and needs more attention. Therefore, the evaluation scale can be used as a standard tool to fulfill the sustainability of companies and brands from the viewpoint of improving poor and insufficiently sustainable items as well as balancing sustainability management.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642603283&target=NART&cn=JAKO201415642603283",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "섬유·패션기업의 지속가능성 실천 평가 연구 섬유·패션기업의 지속가능성 실천 평가 연구 섬유·패션기업의 지속가능성 실천 평가 연구 The practice of sustainability is an important subject to integrate into the management, product planning, manufacturing by textile and fashion companies as well as consumption by end-users. This study shows an evaluation scale designed to assess the practical cases in order to suggest efficient and systematic methods to fulfill the practice of sustainability in textile and fashion companies. First, companies should practice environmental sustainability to use eco-friendly material and cleaner production, protect the environment, and save natural resources. Second, social sustainability is required to fulfill social responsibility and ethical needs. Third, companies should perform various innovative activities, transparency in management, fair competition and economic contribution in the local community in order to maintain economic sustainability to survive in industry. Finally, cultural sustainability should be fulfilled by textile and fashion companies as part of the intellectual-cultural industry in a way that increases the importance of ethnic and cultural diversity. Textile and fashion companies should fulfill four environmental, social, and economic cultural sustainable subjects in a balanced method to accomplish sustainability. The concerns and practices of environmental sustainability are comparatively highly rated due to the analysis of the evaluation scale. However, cultural sustainability (a need of the times) is poorly rated and needs more attention. Therefore, the evaluation scale can be used as a standard tool to fulfill the sustainability of companies and brands from the viewpoint of improving poor and insufficiently sustainable items as well as balancing sustainability management."
        },
        {
          "rank": 18,
          "score": 0.5883466005325317,
          "doc_id": "NART132462882",
          "title": "Post-lifelong learning and the ontology of learning",
          "abstract": "<P>In the various arguments that talk about the future of education, the six principles platform of the suburban education frame, which is still operating in the way of defining the learning style, is 'who, what, how, when, what, why' learning. It is expressed that the person can use it for the purpose of the indigenous people, is separated in time and space, and the object and method can be unique. The lifelong learning approach that can use concepts such as bearing environment learning, transformative learning, situated learning, and expanded learning is included in the scope of application from the moment of expanding the horizon of learning, and more new approaches are possible. In the view of researchers, it is necessary to understand from an independent and neutral perspective. Researchers attempt the generative ability of learning, that is, the '(object)-becoming' of learning, and unravel the new existential members of learning with Latour's owner network theory (ANT) and Gaia theory, which inherited Deleuze's assemblage theory. Through this, they try to refresh the image of &ldquo;future lifelong education&rdquo; through lifelong learning. The researchers argue that early lifelong education is futuristic, and what the 'abstract machine' is, and how it differs from the current fitness university signal configuration. Second, they analyze the future educational discourse being discused in the future into several turning points, and judge whether the ontological way of understanding learners will not deviate from the state university interpretation method despite the &ldquo;future discussion&rdquo; within it. Finally, the researchers introduce the post-lifelong learning perspective as a new way to replace it, and suggest methods and conditions that can define the existence and function of 'eco-global' learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART132462882&target=NART&cn=NART132462882",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Post-lifelong learning and the ontology of learning Post-lifelong learning and the ontology of learning Post-lifelong learning and the ontology of learning <P>In the various arguments that talk about the future of education, the six principles platform of the suburban education frame, which is still operating in the way of defining the learning style, is 'who, what, how, when, what, why' learning. It is expressed that the person can use it for the purpose of the indigenous people, is separated in time and space, and the object and method can be unique. The lifelong learning approach that can use concepts such as bearing environment learning, transformative learning, situated learning, and expanded learning is included in the scope of application from the moment of expanding the horizon of learning, and more new approaches are possible. In the view of researchers, it is necessary to understand from an independent and neutral perspective. Researchers attempt the generative ability of learning, that is, the '(object)-becoming' of learning, and unravel the new existential members of learning with Latour's owner network theory (ANT) and Gaia theory, which inherited Deleuze's assemblage theory. Through this, they try to refresh the image of &ldquo;future lifelong education&rdquo; through lifelong learning. The researchers argue that early lifelong education is futuristic, and what the 'abstract machine' is, and how it differs from the current fitness university signal configuration. Second, they analyze the future educational discourse being discused in the future into several turning points, and judge whether the ontological way of understanding learners will not deviate from the state university interpretation method despite the &ldquo;future discussion&rdquo; within it. Finally, the researchers introduce the post-lifelong learning perspective as a new way to replace it, and suggest methods and conditions that can define the existence and function of 'eco-global' learning.</P>"
        },
        {
          "rank": 19,
          "score": 0.5857382416725159,
          "doc_id": "JAKO201809538045810",
          "title": "쌀 수급안정과 식량안보를 위한 친환경&#183;저탄소 농업 전환방안",
          "abstract": "국내에서 주곡인 쌀은 재배 면적이 감소되고 있으나, 단위 면적당 생산량이 증가되고 쌀 소비는 급감하고 있는 상황에서 외국 쌀 의무수입량은 연간 409천 톤으로 쌀 생산조정 노력에도 불구하고 재고량이 누적되고 있다. 따라서 비상 시 식량안보를 위하여 현 재배면적을 유지하면서 생산량을 감축해야 할 필요성이 있다. 또한 농촌노동력의 노령화 및 지구온난화에 대응하여 노동력 절감과 생산비를 절감으로 농가 소득을 증대하고 친환경 유기농업으로 토양에 유기탄소의 저장력을 높이며, 온실가스 발생량을 줄이는 저탄소 농업기술을 개발, 지속가능한 농업환경을 조성하여 후손에게 물려주어야 할 책무가 있다. 쌀 수급안정에 대한 대안으로서 현 재배면적을 유지하면서 전국의 친환경재배 면적을 현재의 전남 수준인 17%까지 확대하는 1단계, 점차 확산하여 25%까지 확대하는 2단계, 중점확대로 친환경 면적을 35%까지 확대하는 3단계 시나리오를 설정하였다. 쌀 단가를 동일한 고정단가로 분석한 결과 1단계에서는 쌀 생산량은 6만톤 감축되고 생산비는 592억원 증가되며, 소득은 2,015억원 감소될 것으로 추정되었다. 2단계로 친환경농업을 점차 확산할 경우 쌀 생산량은 9만 톤 감축되고, 생산비는 1,221억원 증가되며, 소득은 3,137억원 감소될 것으로 추정되었다. 그리고 3단계에서는 쌀 생산량이 38만 톤 감축되고, 생산비는 2,220억원 증가되며, 소득은 4,645억원 감소될 것으로 추정되었다. 그리고 변동단가를 적용하면 친환경재배는 관행 일반재배에 비하여 소득은 11.5~14.5% 증가되며, 순소득은 -2.9~27.8% 증가되는 효과가 있다. 그리고 저탄소 벼 부분경운 동시 이앙 시범재배 단지 10 ha 조성 시나리오를 설정하여 분석한 결과, 단지별로 쌀 수량은 1.3~1.5톤이 감소되지만 쌀 생산비 감소로 농가소득은 증가되는 것으로 분석되었다. 따라서 생산조정 면적 8만 ha를 시행하는데 소요되는 정부 재정지출 예산을 감안하면 정부재정 범위 내에서 친환경 및 저탄소 농업 확대에 일정부분 지원이 가능할 것으로 생각되었다. 현재의 쌀 재고량 감축을 위한 재고관리에 일정한 한계가 있는 상황에서, 친환경 및 저탄소 농업으로 인한 생산비 증가나 소득감소를 재정적으로 뒷받침해 타작목에 영향을 최소화하면서 지속가능한 농업 환경 보전은 물론 식량안보와 소비자의 안전에도 기여하는 등, 친환경과 저탄소농업 확대는 적은 비용으로 큰 효과를 거둘 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809538045810&target=NART&cn=JAKO201809538045810",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "쌀 수급안정과 식량안보를 위한 친환경&#183;저탄소 농업 전환방안 쌀 수급안정과 식량안보를 위한 친환경&#183;저탄소 농업 전환방안 쌀 수급안정과 식량안보를 위한 친환경&#183;저탄소 농업 전환방안 국내에서 주곡인 쌀은 재배 면적이 감소되고 있으나, 단위 면적당 생산량이 증가되고 쌀 소비는 급감하고 있는 상황에서 외국 쌀 의무수입량은 연간 409천 톤으로 쌀 생산조정 노력에도 불구하고 재고량이 누적되고 있다. 따라서 비상 시 식량안보를 위하여 현 재배면적을 유지하면서 생산량을 감축해야 할 필요성이 있다. 또한 농촌노동력의 노령화 및 지구온난화에 대응하여 노동력 절감과 생산비를 절감으로 농가 소득을 증대하고 친환경 유기농업으로 토양에 유기탄소의 저장력을 높이며, 온실가스 발생량을 줄이는 저탄소 농업기술을 개발, 지속가능한 농업환경을 조성하여 후손에게 물려주어야 할 책무가 있다. 쌀 수급안정에 대한 대안으로서 현 재배면적을 유지하면서 전국의 친환경재배 면적을 현재의 전남 수준인 17%까지 확대하는 1단계, 점차 확산하여 25%까지 확대하는 2단계, 중점확대로 친환경 면적을 35%까지 확대하는 3단계 시나리오를 설정하였다. 쌀 단가를 동일한 고정단가로 분석한 결과 1단계에서는 쌀 생산량은 6만톤 감축되고 생산비는 592억원 증가되며, 소득은 2,015억원 감소될 것으로 추정되었다. 2단계로 친환경농업을 점차 확산할 경우 쌀 생산량은 9만 톤 감축되고, 생산비는 1,221억원 증가되며, 소득은 3,137억원 감소될 것으로 추정되었다. 그리고 3단계에서는 쌀 생산량이 38만 톤 감축되고, 생산비는 2,220억원 증가되며, 소득은 4,645억원 감소될 것으로 추정되었다. 그리고 변동단가를 적용하면 친환경재배는 관행 일반재배에 비하여 소득은 11.5~14.5% 증가되며, 순소득은 -2.9~27.8% 증가되는 효과가 있다. 그리고 저탄소 벼 부분경운 동시 이앙 시범재배 단지 10 ha 조성 시나리오를 설정하여 분석한 결과, 단지별로 쌀 수량은 1.3~1.5톤이 감소되지만 쌀 생산비 감소로 농가소득은 증가되는 것으로 분석되었다. 따라서 생산조정 면적 8만 ha를 시행하는데 소요되는 정부 재정지출 예산을 감안하면 정부재정 범위 내에서 친환경 및 저탄소 농업 확대에 일정부분 지원이 가능할 것으로 생각되었다. 현재의 쌀 재고량 감축을 위한 재고관리에 일정한 한계가 있는 상황에서, 친환경 및 저탄소 농업으로 인한 생산비 증가나 소득감소를 재정적으로 뒷받침해 타작목에 영향을 최소화하면서 지속가능한 농업 환경 보전은 물론 식량안보와 소비자의 안전에도 기여하는 등, 친환경과 저탄소농업 확대는 적은 비용으로 큰 효과를 거둘 수 있을 것으로 기대된다."
        },
        {
          "rank": 20,
          "score": 0.5836219787597656,
          "doc_id": "JAKO200024136583853",
          "title": "신환경영향평가기술(新環境影響評價技術)의 개발방향(開發方向)",
          "abstract": "The purpose of this study is to identify the problems of environmental impact assessment(EIA) and to suggest new EIA technology. The problems of EIA in Korea can be summarized as follows. First, the EIA does not reflect the impact of policy, plan and program on environment. Second, the project EIA does not consider the cumulative impacts such as additive impacts, synergistic impacts, threshold/saturation impacts, induced and indirect impacts, time-crowded impacts, and space-crowded impacts. Third, the EIA techniques in Korea are not standardized. Finally, the present EIA suggests only alternatives to reduce adverse impacts. To solve above-mentioned problems, the development of new EIA technology is essential. First, the new EIA technology should be developed toward pollution prevention technology and comprehensive and integrated environmental management technology. Second, new fields of EIA for pollution prevention contain strategic environmental assessment, cumulative impacts assessment, socio-economic impact assessment, cyber EIA and EIA technology necessary after the reunification of Korean Peninsula. Third, EIA technology for integrated environmental management contains the development of integated environment assessment system and the development of packaged EIA technology. The EIA technology for integrated environmental assessment system contains (1) development of integrated impact assessment technology combining air/water quality model, GIS and remote sensing, (2) integrated impact assessment of EIA, traffic impact assessment, population impact assessment and disaster impact assessment. (3) development of integrated technology combining risk assessment and EIA (4) development of integrated technology of life cycle assessment and EIA, (5) development of integrated technology of spatial planning and EIA, (6) EIA technology for biodiversity towards sustainable development, (7) mathematical model and GIS based location decision techniques, and (8) environmental monitoring and audit. Furthermore, there are some fields which need packaged EIA technology. In case of dam development, urban or industrial complex development, tourist development, landfill or combustion facilities construction, electric power plant development, development of port, road/rail/air port, is necessary the standardized and packaged EIA technology which considers the common characteristics of the same kind of development project.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200024136583853&target=NART&cn=JAKO200024136583853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신환경영향평가기술(新環境影響評價技術)의 개발방향(開發方向) 신환경영향평가기술(新環境影響評價技術)의 개발방향(開發方向) 신환경영향평가기술(新環境影響評價技術)의 개발방향(開發方向) The purpose of this study is to identify the problems of environmental impact assessment(EIA) and to suggest new EIA technology. The problems of EIA in Korea can be summarized as follows. First, the EIA does not reflect the impact of policy, plan and program on environment. Second, the project EIA does not consider the cumulative impacts such as additive impacts, synergistic impacts, threshold/saturation impacts, induced and indirect impacts, time-crowded impacts, and space-crowded impacts. Third, the EIA techniques in Korea are not standardized. Finally, the present EIA suggests only alternatives to reduce adverse impacts. To solve above-mentioned problems, the development of new EIA technology is essential. First, the new EIA technology should be developed toward pollution prevention technology and comprehensive and integrated environmental management technology. Second, new fields of EIA for pollution prevention contain strategic environmental assessment, cumulative impacts assessment, socio-economic impact assessment, cyber EIA and EIA technology necessary after the reunification of Korean Peninsula. Third, EIA technology for integrated environmental management contains the development of integated environment assessment system and the development of packaged EIA technology. The EIA technology for integrated environmental assessment system contains (1) development of integrated impact assessment technology combining air/water quality model, GIS and remote sensing, (2) integrated impact assessment of EIA, traffic impact assessment, population impact assessment and disaster impact assessment. (3) development of integrated technology combining risk assessment and EIA (4) development of integrated technology of life cycle assessment and EIA, (5) development of integrated technology of spatial planning and EIA, (6) EIA technology for biodiversity towards sustainable development, (7) mathematical model and GIS based location decision techniques, and (8) environmental monitoring and audit. Furthermore, there are some fields which need packaged EIA technology. In case of dam development, urban or industrial complex development, tourist development, landfill or combustion facilities construction, electric power plant development, development of port, road/rail/air port, is necessary the standardized and packaged EIA technology which considers the common characteristics of the same kind of development project."
        },
        {
          "rank": 21,
          "score": 0.582897424697876,
          "doc_id": "JAKO201202950478852",
          "title": "융합 비즈니스 모델링 프레임워크에 관한 연구",
          "abstract": "정부와 산업에서 융합 내지 융합 비즈니스에 대한 정책과 전략이 광범위하게 확산되고 있음에 반해 이를 성공적으로 구현하는데 필요한 이론적 기반과 효과적 방법론은 매우 부족한 상태이다. 특히, 융합 비즈니스 모델(BM)의 '이상적(ideal)유형' 즉, 이론적 유형에 대한 연구는 국내/외를 막론하고 아직까지 주목할 만한 결과가 없는 것으로 파악된다. 본 논문은 BM의 개념적 프레임워크로 '4W1H 모형'을 제안하고 이를 통해 융합 BM의 이론적 유형, BM 유형별 전략과 설계 수순 등을 정의할 수 있음을 보이기 위한 것이다. 4W1H 모형은 BM의 구성요소를 고객가치(why), 가치제안(what), 운영방식(how), 목표시장(whom), 공급역량(who) 등 5개로 정의한 것으로서 이를 통해 가치혁신형, 상품혁신형, 운영혁신형, 시장혁신형, 역량혁신형 등의 융합 BM 유형을 도출하였다. BM 구성요소와 유형(즉, 구조적 특성) 정의에 이어 BM 구성 요소간 상호작용(즉, 행위적 특성)에 대한 정의를 통해 BM이 기업전략과도 연계될 수 있음을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201202950478852&target=NART&cn=JAKO201202950478852",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "융합 비즈니스 모델링 프레임워크에 관한 연구 융합 비즈니스 모델링 프레임워크에 관한 연구 융합 비즈니스 모델링 프레임워크에 관한 연구 정부와 산업에서 융합 내지 융합 비즈니스에 대한 정책과 전략이 광범위하게 확산되고 있음에 반해 이를 성공적으로 구현하는데 필요한 이론적 기반과 효과적 방법론은 매우 부족한 상태이다. 특히, 융합 비즈니스 모델(BM)의 '이상적(ideal)유형' 즉, 이론적 유형에 대한 연구는 국내/외를 막론하고 아직까지 주목할 만한 결과가 없는 것으로 파악된다. 본 논문은 BM의 개념적 프레임워크로 '4W1H 모형'을 제안하고 이를 통해 융합 BM의 이론적 유형, BM 유형별 전략과 설계 수순 등을 정의할 수 있음을 보이기 위한 것이다. 4W1H 모형은 BM의 구성요소를 고객가치(why), 가치제안(what), 운영방식(how), 목표시장(whom), 공급역량(who) 등 5개로 정의한 것으로서 이를 통해 가치혁신형, 상품혁신형, 운영혁신형, 시장혁신형, 역량혁신형 등의 융합 BM 유형을 도출하였다. BM 구성요소와 유형(즉, 구조적 특성) 정의에 이어 BM 구성 요소간 상호작용(즉, 행위적 특성)에 대한 정의를 통해 BM이 기업전략과도 연계될 수 있음을 보였다."
        },
        {
          "rank": 22,
          "score": 0.5818126201629639,
          "doc_id": "JAKO200229741630452",
          "title": "환경영향평가상의 효율성 주민의견 수렴에 관한 연구",
          "abstract": "Procedures to establish well-balanced development and effectiveness of environmental impact assessment need include various stakeholder's participation in writing and reviewing document of environmental impact assessment, collecting public opinion, and post monitoring. Accordingly, to encourage effective and efficient collection of resident's opinion analyze present conditions and problems and suggest institutional and politic alternative proposals of it. This study resulted in following conclusions. In institutional aspects, (1) Proposal for drafting document of environmental impact assessment (2) Composition of committee for collecting and regulating stakeholder's opinion (3) Width of civil participation scale. In politic aspects, (1) Use of local community (2) Guide of local information from local society and environmental specialist (3) Understandable document and data of environmental impact assessment (4) Strength of roles and duties of local government.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200229741630452&target=NART&cn=JAKO200229741630452",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "환경영향평가상의 효율성 주민의견 수렴에 관한 연구 환경영향평가상의 효율성 주민의견 수렴에 관한 연구 환경영향평가상의 효율성 주민의견 수렴에 관한 연구 Procedures to establish well-balanced development and effectiveness of environmental impact assessment need include various stakeholder's participation in writing and reviewing document of environmental impact assessment, collecting public opinion, and post monitoring. Accordingly, to encourage effective and efficient collection of resident's opinion analyze present conditions and problems and suggest institutional and politic alternative proposals of it. This study resulted in following conclusions. In institutional aspects, (1) Proposal for drafting document of environmental impact assessment (2) Composition of committee for collecting and regulating stakeholder's opinion (3) Width of civil participation scale. In politic aspects, (1) Use of local community (2) Guide of local information from local society and environmental specialist (3) Understandable document and data of environmental impact assessment (4) Strength of roles and duties of local government."
        },
        {
          "rank": 23,
          "score": 0.581558346748352,
          "doc_id": "ATN0037490138",
          "title": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크",
          "abstract": "In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037490138&target=NART&cn=ATN0037490138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains."
        },
        {
          "rank": 24,
          "score": 0.5807576775550842,
          "doc_id": "ART002127072",
          "title": "Development of a Big Data Capability Assessment Model",
          "abstract": "Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002127072&target=NART&cn=ART002127072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback."
        },
        {
          "rank": 25,
          "score": 0.579168975353241,
          "doc_id": "JAKO202516964801568",
          "title": "STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계",
          "abstract": "본 연구는 기업의 생성형 AI 도입 과정에서 발생하는 복잡한 리스크를 효과적으로 관리하기 위한 종합적인 평가 프레임워크인 STAGE-AI Metrics를 제안한다. 해당 프레임워크는 사회적 영향(Social impact), 기술적 성능(Technical performance), 조직 내 도입(Adaptation to organization), 지속가능성(Growth in sustainability), 윤리적 고려 사항(Ethical consideration)의 다섯 가지 주요 영역을 포괄하며, 영역별로 세부적인 평가 지표와 관련 벤치마크를 제시한다. 특히 기술적 성능(Technology)을 기반으로 사회적 영향(Social) 및 윤리적 측면(Ethics)을 순차적으로 고려하여 설계되었다. AI 시스템의 기본적인 성능 평가에서 출발, 해당 기술의 도입이 조직과 사회에 미치는 광범위한 파급 효과까지 포괄적으로 평가가 가능하게 하며 추가로 지속가능성(Sustainability)까지 검토할 수 있도록 지원한다. STAGE-AI Metrics는 기존의 단편적인 성능 평가 방식을 넘어, AI 시스템의 기술적 성능뿐만 아니라 사회적 영향과 윤리적 측면까지 고려하는 다면적 접근을 통해 기업이 자사의 특성과 요구사항에 최적화된 AI 모델을 선택하고 도입할 수 있도록 지원한다. 본 연구는 AI 도입의 초기 단계에서 발생할 수 있는 잠재적 문제점들을 사전에 식별하고 대비할 수 있는 실용적인 도구를 제공함으로써, 기업의 AI 도입 성공률을 높이고 장기적인 경쟁력 확보에 기여할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202516964801568&target=NART&cn=JAKO202516964801568",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 STAGE-AI Metrics: 기업을 위한 생성형 AI 평가지표 설계 본 연구는 기업의 생성형 AI 도입 과정에서 발생하는 복잡한 리스크를 효과적으로 관리하기 위한 종합적인 평가 프레임워크인 STAGE-AI Metrics를 제안한다. 해당 프레임워크는 사회적 영향(Social impact), 기술적 성능(Technical performance), 조직 내 도입(Adaptation to organization), 지속가능성(Growth in sustainability), 윤리적 고려 사항(Ethical consideration)의 다섯 가지 주요 영역을 포괄하며, 영역별로 세부적인 평가 지표와 관련 벤치마크를 제시한다. 특히 기술적 성능(Technology)을 기반으로 사회적 영향(Social) 및 윤리적 측면(Ethics)을 순차적으로 고려하여 설계되었다. AI 시스템의 기본적인 성능 평가에서 출발, 해당 기술의 도입이 조직과 사회에 미치는 광범위한 파급 효과까지 포괄적으로 평가가 가능하게 하며 추가로 지속가능성(Sustainability)까지 검토할 수 있도록 지원한다. STAGE-AI Metrics는 기존의 단편적인 성능 평가 방식을 넘어, AI 시스템의 기술적 성능뿐만 아니라 사회적 영향과 윤리적 측면까지 고려하는 다면적 접근을 통해 기업이 자사의 특성과 요구사항에 최적화된 AI 모델을 선택하고 도입할 수 있도록 지원한다. 본 연구는 AI 도입의 초기 단계에서 발생할 수 있는 잠재적 문제점들을 사전에 식별하고 대비할 수 있는 실용적인 도구를 제공함으로써, 기업의 AI 도입 성공률을 높이고 장기적인 경쟁력 확보에 기여할 것으로 기대된다."
        },
        {
          "rank": 26,
          "score": 0.5783601999282837,
          "doc_id": "ATN0049463041",
          "title": "기후변화에 대한 EU의 저탄소 경제정책",
          "abstract": "Preventing dangerous climate change is a strategic priority for the EU. The EU is working hard to cut its greenhouse gas emissions substantially while encouraging other nations and regions to do likewise. EU Member States have committed to transforming Europe into a highly energy-efficient, low carbon economy. The EU has set itself targets for reducing its greenhouse gas emissions progressively up to 2050 and is working successfully towards meeting them. For 2050, EU Member States have endorsed the objective of reducing Europe's greenhouse gas emissions by 80-95% compared to 1990 levels as part of efforts by developed countries as a group to reduce their emissions by a similar degree. And the European Commission has published a roadmap for building the low-carbon European economy that this will require.\nTherefore, this paper aimed to review on the EU’s competitive low carbon economic policy against climate change. For this, this article provides specially an in-depth analysis of the various environment policy through “A Roadmap for moving to a competitive low carbon economy in 2050”. In this roadmap, the EU is committed to reducing its domestic GHG emissions by at least 20 % by 2020; increasing the share of renewables in its energy mix to 20 %; achieving energy efficiency of 20 % by 2020. Moreover, the EU should prepare for reductions in its domestic GHG emissions by 40 % by 2030, and by 80 % by 2050. These emission levels are calculated with respect to 1990 levels. And this roadmap must be accompanied by various sectoral strategies fostering technological innovation. Such sectoral strategies should concern, in particular, the electricity sector, sustainable mobility, the construction sector, industry and agriculture. The development of low carbon energy sources must be based on sustainable and diversified financial investments as well as international cooperation. The EU therefore undertakes to intensify its bilateral and multilateral cooperation to promote the tackling of climate change. Its action should in particular contribute to innovation, energy security and competitiveness in the key sectors of growth and development.\nAfter all the EU is likely to play an increasingly important role in the negotiation concerning climate change in the international society. The Republic of Korea must also strengthen control on emission, as the EU has done, specially in relation to the competitive low carbon economy to prevent climate change in advance.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0049463041&target=NART&cn=ATN0049463041",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기후변화에 대한 EU의 저탄소 경제정책 기후변화에 대한 EU의 저탄소 경제정책 기후변화에 대한 EU의 저탄소 경제정책 Preventing dangerous climate change is a strategic priority for the EU. The EU is working hard to cut its greenhouse gas emissions substantially while encouraging other nations and regions to do likewise. EU Member States have committed to transforming Europe into a highly energy-efficient, low carbon economy. The EU has set itself targets for reducing its greenhouse gas emissions progressively up to 2050 and is working successfully towards meeting them. For 2050, EU Member States have endorsed the objective of reducing Europe's greenhouse gas emissions by 80-95% compared to 1990 levels as part of efforts by developed countries as a group to reduce their emissions by a similar degree. And the European Commission has published a roadmap for building the low-carbon European economy that this will require.\nTherefore, this paper aimed to review on the EU’s competitive low carbon economic policy against climate change. For this, this article provides specially an in-depth analysis of the various environment policy through “A Roadmap for moving to a competitive low carbon economy in 2050”. In this roadmap, the EU is committed to reducing its domestic GHG emissions by at least 20 % by 2020; increasing the share of renewables in its energy mix to 20 %; achieving energy efficiency of 20 % by 2020. Moreover, the EU should prepare for reductions in its domestic GHG emissions by 40 % by 2030, and by 80 % by 2050. These emission levels are calculated with respect to 1990 levels. And this roadmap must be accompanied by various sectoral strategies fostering technological innovation. Such sectoral strategies should concern, in particular, the electricity sector, sustainable mobility, the construction sector, industry and agriculture. The development of low carbon energy sources must be based on sustainable and diversified financial investments as well as international cooperation. The EU therefore undertakes to intensify its bilateral and multilateral cooperation to promote the tackling of climate change. Its action should in particular contribute to innovation, energy security and competitiveness in the key sectors of growth and development.\nAfter all the EU is likely to play an increasingly important role in the negotiation concerning climate change in the international society. The Republic of Korea must also strengthen control on emission, as the EU has done, specially in relation to the competitive low carbon economy to prevent climate change in advance."
        },
        {
          "rank": 27,
          "score": 0.5776506662368774,
          "doc_id": "NPAP12667947",
          "title": "Analysis on Consumer Repeat Purchase Behavior of Buying Green Products",
          "abstract": "<P>The need for green products can vary due to differences in cultural beliefs and consumers' active sharing and participation on green environmental issues in the world. The cultural beliefs toward environmental friendly events also differ through involving social and economic matters. Therefore, this study looks for understanding consumers' green repeat purchase intention based on the theory of perceived value. Concurrently, the purpose of this study also intends to detect variables that affect consumers' intention of buying green products and to verify how store service quality and perceived value simultaneously influence consumer repeat purchase intention of buying green products. A quantitative approach was adopted for data collection. Using a sample of 228 members, a survey was developed and conducted in well-known online shopping website of green products filling out the questionnaires completely, and then evaluated with structural equation modeling, and confirmatory factor analysis was also applied, using SmartPLS 2.0, to test if the empirical data conform to the proposed model. Results indicate that this study find that perceived value and store service quality clearly play important roles in influencing consumer repeat purchase intention of buying green products. To the end, a proposed model is developed to realize green repeat purchase intention of consumers and all the consequences with implications for theory and practice would be further discussed, too.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12667947&target=NART&cn=NPAP12667947",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Analysis on Consumer Repeat Purchase Behavior of Buying Green Products Analysis on Consumer Repeat Purchase Behavior of Buying Green Products Analysis on Consumer Repeat Purchase Behavior of Buying Green Products <P>The need for green products can vary due to differences in cultural beliefs and consumers' active sharing and participation on green environmental issues in the world. The cultural beliefs toward environmental friendly events also differ through involving social and economic matters. Therefore, this study looks for understanding consumers' green repeat purchase intention based on the theory of perceived value. Concurrently, the purpose of this study also intends to detect variables that affect consumers' intention of buying green products and to verify how store service quality and perceived value simultaneously influence consumer repeat purchase intention of buying green products. A quantitative approach was adopted for data collection. Using a sample of 228 members, a survey was developed and conducted in well-known online shopping website of green products filling out the questionnaires completely, and then evaluated with structural equation modeling, and confirmatory factor analysis was also applied, using SmartPLS 2.0, to test if the empirical data conform to the proposed model. Results indicate that this study find that perceived value and store service quality clearly play important roles in influencing consumer repeat purchase intention of buying green products. To the end, a proposed model is developed to realize green repeat purchase intention of consumers and all the consequences with implications for theory and practice would be further discussed, too.</P>"
        },
        {
          "rank": 28,
          "score": 0.5775798559188843,
          "doc_id": "JAKO202413550406983",
          "title": "웰니스&#x00B7;의료관광 융복합 추진과제 도출 및 우선순위 분석: AHP를 활용하여",
          "abstract": "Purpose - This study aims to examine the key factors to consider in promoting the convergence of medical tourism and wellness tourism and to analyze the relative importance of tasks for their integration using the Analytic Hierarchy Process (AHP) method to determine priorities. Design/methodology/approach - An AHP analysis was conducted with 12 stakeholders in medical tourism and wellness tourism in Busan to determine the priorities of strategies and tasks for promoting the convergence of wellness and medical tourism. The goal of &#x003C;Hierarchy 1&#x003E; was set as 'Evaluating the priority of tasks for the integration of wellness and medical tourism.' &#x003C;Hierarchy 2&#x003E; comprised three strategic directions: 'Discovering convergence resources, infrastructure, and 'Strengthening promotion and marketing. &#x003C;Hierarchy 3&#x003E; included specific tasks under each strategic direction. Findings - The priority rankings for the execution strategies in &#x003C;Hierarchy 2&#x003E; were as follows: 'Resource discovery for convergence' (0.394), 'Enhancing promotion and marketing' (0.327), and 'Infrastructure development' (0.278). In &#x003C;Hierarchy 3&#x003E;, the overall importance rankings were: a brand image for wellness and medical tourism' (0.175), 'Creating a dedicated organization' (0.094), and 'Discovering marine wellness resources' (0.092). Research applications or Originality - This study provides practical alternatives by presenting policy priorities for the convergence of wellness tourism and medical tourism, addressing the relative lack of prior research on their integration. It is expected to assist in determining policy priorities and establishing a roadmap for wellness and medical tourism in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202413550406983&target=NART&cn=JAKO202413550406983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "웰니스&#x00B7;의료관광 융복합 추진과제 도출 및 우선순위 분석: AHP를 활용하여 웰니스&#x00B7;의료관광 융복합 추진과제 도출 및 우선순위 분석: AHP를 활용하여 웰니스&#x00B7;의료관광 융복합 추진과제 도출 및 우선순위 분석: AHP를 활용하여 Purpose - This study aims to examine the key factors to consider in promoting the convergence of medical tourism and wellness tourism and to analyze the relative importance of tasks for their integration using the Analytic Hierarchy Process (AHP) method to determine priorities. Design/methodology/approach - An AHP analysis was conducted with 12 stakeholders in medical tourism and wellness tourism in Busan to determine the priorities of strategies and tasks for promoting the convergence of wellness and medical tourism. The goal of &#x003C;Hierarchy 1&#x003E; was set as 'Evaluating the priority of tasks for the integration of wellness and medical tourism.' &#x003C;Hierarchy 2&#x003E; comprised three strategic directions: 'Discovering convergence resources, infrastructure, and 'Strengthening promotion and marketing. &#x003C;Hierarchy 3&#x003E; included specific tasks under each strategic direction. Findings - The priority rankings for the execution strategies in &#x003C;Hierarchy 2&#x003E; were as follows: 'Resource discovery for convergence' (0.394), 'Enhancing promotion and marketing' (0.327), and 'Infrastructure development' (0.278). In &#x003C;Hierarchy 3&#x003E;, the overall importance rankings were: a brand image for wellness and medical tourism' (0.175), 'Creating a dedicated organization' (0.094), and 'Discovering marine wellness resources' (0.092). Research applications or Originality - This study provides practical alternatives by presenting policy priorities for the convergence of wellness tourism and medical tourism, addressing the relative lack of prior research on their integration. It is expected to assist in determining policy priorities and establishing a roadmap for wellness and medical tourism in the future."
        },
        {
          "rank": 29,
          "score": 0.5766726136207581,
          "doc_id": "JAKO201117463449578",
          "title": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크",
          "abstract": "T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201117463449578&target=NART&cn=JAKO201117463449578",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다."
        },
        {
          "rank": 30,
          "score": 0.5760900974273682,
          "doc_id": "JAKO201020439056567",
          "title": "해외 저탄소 녹색수변도시",
          "abstract": "저자는 기후변화에 대응한 저탄소 녹색수변도시 조성을 위한 방향설정을 위해 해외 저탄소 녹색수변도시에 대한 사례를 검토하였다. 해외 저탄소 녹색수변도시 검토 결과 자원순환을 통한 에너지 절감, 시설 및 공간 집약적 토지이용계획, 대중교통 및 보행자 중심의 교통체계, 신재생에너지의 활용을 통한 에너지 저감 및 재활용이라는 시사점을 도출하였다. 이러한 시사점을 바탕으로 우리나라 수변도시에 적용을 위한 방향으로 (1) 교통부문의 에너지 절약을 위한 압축형 도시공간구조, 복합토지이용, 대중교통 중심의 교통제계 계획, (2) 건물 및 일상생활에서의 신재생에너지 활용, (3) 탄소 흡수원 역할과 삶의 질을 높여주는 녹지공간 확보, (4) 물자원의 선순환구조 구축을 제시하였다. 마지막으로 우리나라에서 녹색수변도시 조성을 위해서는 이러한 노력들과 더불어 다양한 해외사례 검토와 기술부문에 대한 조사를 통해 저탄소 녹색수변도시 조성을 위한 기반이 마련되어야 할 것임을 논하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201020439056567&target=NART&cn=JAKO201020439056567",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "해외 저탄소 녹색수변도시 해외 저탄소 녹색수변도시 해외 저탄소 녹색수변도시 저자는 기후변화에 대응한 저탄소 녹색수변도시 조성을 위한 방향설정을 위해 해외 저탄소 녹색수변도시에 대한 사례를 검토하였다. 해외 저탄소 녹색수변도시 검토 결과 자원순환을 통한 에너지 절감, 시설 및 공간 집약적 토지이용계획, 대중교통 및 보행자 중심의 교통체계, 신재생에너지의 활용을 통한 에너지 저감 및 재활용이라는 시사점을 도출하였다. 이러한 시사점을 바탕으로 우리나라 수변도시에 적용을 위한 방향으로 (1) 교통부문의 에너지 절약을 위한 압축형 도시공간구조, 복합토지이용, 대중교통 중심의 교통제계 계획, (2) 건물 및 일상생활에서의 신재생에너지 활용, (3) 탄소 흡수원 역할과 삶의 질을 높여주는 녹지공간 확보, (4) 물자원의 선순환구조 구축을 제시하였다. 마지막으로 우리나라에서 녹색수변도시 조성을 위해서는 이러한 노력들과 더불어 다양한 해외사례 검토와 기술부문에 대한 조사를 통해 저탄소 녹색수변도시 조성을 위한 기반이 마련되어야 할 것임을 논하였다."
        },
        {
          "rank": 31,
          "score": 0.5755360126495361,
          "doc_id": "JAKO202013461500175",
          "title": "토지환경 및 자연생태환경을 고려한 환경영향평가 협의결정 개선방안",
          "abstract": "과거에는 대기오염, 수질오염, 폐기물 등이 환경영향평가에서 주요한 평가항목이었는데 최근에는 토지환경(토지이용, 지형), 자연생태환경(동&#x00B7;식물상, 자연환경자산), 사회&#x00B7;경제 환경 등이 주요한 평가항목으로 다뤄지고 있다. 2012년 이후 전략환경영향평가와 소규모환경영향평가의 협의결과를 보면, 90 %이상이 조건부동의였다. 그러나 환경영향평가의 협의결과는 2012년~2016년 기간 거의 대부분(94.1 %) 동의였으나, 환경정책기조가 바뀌는 2017년 이후부터 대부분(87.4 %) 조건부동의로 결정되었다. 그리고 세 종류 환경영향평가의 부동의 비율이 2013년~2016년 기간 0.3~0.6 % 밖에 되지 않았는데, 2017년~2019년 기간 1.3~3.1 %로 급증하였다. 그 사이 협의 결과에 영향을 미칠만한 제도나 분석기법의 변화가 없었다면, 협의결과의 일관성 및 공정성의 결여가 문제로 제기될 수 있다. 따라서 환경영향평가에서 입지타당성을 결정하는 토지이용, 동&#x00B7;식물상 및 자연환경자산, 사회&#x00B7;경제 등의 평가항목에 대한 지표개발과 적용에 대한 연구가 요구되고 있다. 본 연구는 환경영향평가가 전략환경영향평가, 환경영향평가, 소규모환경영향평가로 구분되어 시행되는 2012년 이후 동의, 조건부동의, 부동의 협의결과를 분석한다. 부동의 사례에 대해 6개 환경분야 중 입지타당성분석에서 중요한 토지환경과 자연생태환경의 평가항목을 중심으로 근거요인을 분석하고, 환경관련 토지이용규제와 환경관련 등급을 중심으로 개발계획이나 개발사업에 대한 환경영향평가에서 협의 결정의 개선방안을 모색한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013461500175&target=NART&cn=JAKO202013461500175",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "토지환경 및 자연생태환경을 고려한 환경영향평가 협의결정 개선방안 토지환경 및 자연생태환경을 고려한 환경영향평가 협의결정 개선방안 토지환경 및 자연생태환경을 고려한 환경영향평가 협의결정 개선방안 과거에는 대기오염, 수질오염, 폐기물 등이 환경영향평가에서 주요한 평가항목이었는데 최근에는 토지환경(토지이용, 지형), 자연생태환경(동&#x00B7;식물상, 자연환경자산), 사회&#x00B7;경제 환경 등이 주요한 평가항목으로 다뤄지고 있다. 2012년 이후 전략환경영향평가와 소규모환경영향평가의 협의결과를 보면, 90 %이상이 조건부동의였다. 그러나 환경영향평가의 협의결과는 2012년~2016년 기간 거의 대부분(94.1 %) 동의였으나, 환경정책기조가 바뀌는 2017년 이후부터 대부분(87.4 %) 조건부동의로 결정되었다. 그리고 세 종류 환경영향평가의 부동의 비율이 2013년~2016년 기간 0.3~0.6 % 밖에 되지 않았는데, 2017년~2019년 기간 1.3~3.1 %로 급증하였다. 그 사이 협의 결과에 영향을 미칠만한 제도나 분석기법의 변화가 없었다면, 협의결과의 일관성 및 공정성의 결여가 문제로 제기될 수 있다. 따라서 환경영향평가에서 입지타당성을 결정하는 토지이용, 동&#x00B7;식물상 및 자연환경자산, 사회&#x00B7;경제 등의 평가항목에 대한 지표개발과 적용에 대한 연구가 요구되고 있다. 본 연구는 환경영향평가가 전략환경영향평가, 환경영향평가, 소규모환경영향평가로 구분되어 시행되는 2012년 이후 동의, 조건부동의, 부동의 협의결과를 분석한다. 부동의 사례에 대해 6개 환경분야 중 입지타당성분석에서 중요한 토지환경과 자연생태환경의 평가항목을 중심으로 근거요인을 분석하고, 환경관련 토지이용규제와 환경관련 등급을 중심으로 개발계획이나 개발사업에 대한 환경영향평가에서 협의 결정의 개선방안을 모색한다."
        },
        {
          "rank": 32,
          "score": 0.5748249292373657,
          "doc_id": "NART54384096",
          "title": "Development of socio-technical disaster model",
          "abstract": "Using a grounded theory approach, six public inquiry reports were utilized to identify the phases associated with the development of socio-technical disasters. Despite the differences of disasters involved and their technologies, the disasters were found to exhibit common features and characteristics. The findings demonstrated that socio-technical disasters are not sudden cataclysmic events but they evolved in phases with long developmental period. A model of the sequential development of socio-technical disaster is proposed as consisting of ten phases namely operation, incubation, forewarning, activation, onset, rescue and recovery, inquiry and reporting, feedback, social justice, and social and legislation reform. This model reaffirms and advances developmental theory of disasters.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART54384096&target=NART&cn=NART54384096",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Development of socio-technical disaster model Development of socio-technical disaster model Development of socio-technical disaster model Using a grounded theory approach, six public inquiry reports were utilized to identify the phases associated with the development of socio-technical disasters. Despite the differences of disasters involved and their technologies, the disasters were found to exhibit common features and characteristics. The findings demonstrated that socio-technical disasters are not sudden cataclysmic events but they evolved in phases with long developmental period. A model of the sequential development of socio-technical disaster is proposed as consisting of ten phases namely operation, incubation, forewarning, activation, onset, rescue and recovery, inquiry and reporting, feedback, social justice, and social and legislation reform. This model reaffirms and advances developmental theory of disasters."
        },
        {
          "rank": 33,
          "score": 0.5735980272293091,
          "doc_id": "NART106300987",
          "title": "An ethical framework for big data and smart cities",
          "abstract": "<P><B>Abstract</B></P>  <P>This paper presents an ethical framework for Big Data and Smart cities, focusing on contemporary ethical and non-ethical issues in big data analytics applications in smart cities and public transportation systems. The framework provides reviews and analysis of ethical and emerging issues and provides a summary of recommendations and discussions for four emerging areas. By reviewing recent studies on both the technological development and emerging ethical problems in the emerging industries, this paper seeks to find and raise public awareness of ethical issues lying in urban big data analytics and public transportation systems. In order to deal with emerging issues, four recommendations have been explained and subsequently, two areas of discussion have been described in detail to support the ethical framework. This paper addresses emerging issues and their ethical concerns for big data and smart cities. Possible recommendations and solutions have been demonstrated to promote the competency of companies and organizations in this big data era. How the ethical framework can be used by six smart cities have been described. Our findings and analysis for big data for high growth, innovation and core competencies and validity of the ethical framework have been justified.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We present an ethical framework for big data and smart cities. </LI> <LI>  We identify four emerging areas, particularly big data analytics and its impacts. </LI> <LI>  We provide detailed recommendations and discussions. </LI> <LI>  We explain how the ethical framework can be used in six smart cities. </LI> <LI>  We explain how framework can be used for countries with lower ethical requirements. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106300987&target=NART&cn=NART106300987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "An ethical framework for big data and smart cities An ethical framework for big data and smart cities An ethical framework for big data and smart cities <P><B>Abstract</B></P>  <P>This paper presents an ethical framework for Big Data and Smart cities, focusing on contemporary ethical and non-ethical issues in big data analytics applications in smart cities and public transportation systems. The framework provides reviews and analysis of ethical and emerging issues and provides a summary of recommendations and discussions for four emerging areas. By reviewing recent studies on both the technological development and emerging ethical problems in the emerging industries, this paper seeks to find and raise public awareness of ethical issues lying in urban big data analytics and public transportation systems. In order to deal with emerging issues, four recommendations have been explained and subsequently, two areas of discussion have been described in detail to support the ethical framework. This paper addresses emerging issues and their ethical concerns for big data and smart cities. Possible recommendations and solutions have been demonstrated to promote the competency of companies and organizations in this big data era. How the ethical framework can be used by six smart cities have been described. Our findings and analysis for big data for high growth, innovation and core competencies and validity of the ethical framework have been justified.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We present an ethical framework for big data and smart cities. </LI> <LI>  We identify four emerging areas, particularly big data analytics and its impacts. </LI> <LI>  We provide detailed recommendations and discussions. </LI> <LI>  We explain how the ethical framework can be used in six smart cities. </LI> <LI>  We explain how framework can be used for countries with lower ethical requirements. </LI> </UL> </P>"
        },
        {
          "rank": 34,
          "score": 0.5729581117630005,
          "doc_id": "JAKO201526650061635",
          "title": "산업융합환경을 위한 보안 거버넌스 프레임워크 설계",
          "abstract": "산업과 ICT 기술간의 융합으로 새로운 부가가치를 창출할 수 있는 융합환경이 도래되어짐에 따라 경제성장과 더불어 우리의 삶의 질이 향상 되고 있지만 이러한 융합환경은 다수의 이익만을 제공하는 것이 아니라 융복합적인 보안 위협이 발생됨에 따라 다양한 보안문제를 발생시켰다. 이러한 보안 문제를 해결하기 위해서는 기존의 기술적인 접근으로 단편적인 보안 문제 해결방식이 아닌 통합적인 관점에서 보안문제를 접근할 필요가 있다. 그래서 본 연구에서는 전략적 관점, 관리적/운영적관점, 기술적 관점 등 다차원적인 관점에서 신뢰성 있는 보안 거버넌스 관리를 할 수 있도록 인적측면이 고려되어진 보안 거버넌스 프레임워크를 개발하였다. 그래서 이 프레임워크를 통해 보안 관리에 대한 단일 기준을 제시함으로서 최고 경영진들의 직접적인 관여가 가능하고 조직구성원들이 스스로 보안활동을 수행하고 책임 질수 있는 신뢰성 있는 보안관리체계를 구축할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201526650061635&target=NART&cn=JAKO201526650061635",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업과 ICT 기술간의 융합으로 새로운 부가가치를 창출할 수 있는 융합환경이 도래되어짐에 따라 경제성장과 더불어 우리의 삶의 질이 향상 되고 있지만 이러한 융합환경은 다수의 이익만을 제공하는 것이 아니라 융복합적인 보안 위협이 발생됨에 따라 다양한 보안문제를 발생시켰다. 이러한 보안 문제를 해결하기 위해서는 기존의 기술적인 접근으로 단편적인 보안 문제 해결방식이 아닌 통합적인 관점에서 보안문제를 접근할 필요가 있다. 그래서 본 연구에서는 전략적 관점, 관리적/운영적관점, 기술적 관점 등 다차원적인 관점에서 신뢰성 있는 보안 거버넌스 관리를 할 수 있도록 인적측면이 고려되어진 보안 거버넌스 프레임워크를 개발하였다. 그래서 이 프레임워크를 통해 보안 관리에 대한 단일 기준을 제시함으로서 최고 경영진들의 직접적인 관여가 가능하고 조직구성원들이 스스로 보안활동을 수행하고 책임 질수 있는 신뢰성 있는 보안관리체계를 구축할 수 있을 것이다."
        },
        {
          "rank": 35,
          "score": 0.5727913975715637,
          "doc_id": "JAKO201228439147521",
          "title": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할",
          "abstract": "현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201228439147521&target=NART&cn=JAKO201228439147521",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다."
        },
        {
          "rank": 36,
          "score": 0.5727896094322205,
          "doc_id": "NART117058201",
          "title": "Prioritization of renewable energy source for electricity generation through AHP-VIKOR integrated methodology",
          "abstract": "<P><B>Abstract</B></P>  <P>As the worldwide energy crisis worsens, renewable energy sources have undeniably opened new horizons for our society. It will offer an efficient solution to this severe energy crisis, environmental issues and fulfilling human energy needs. Therefore, six main criteria, social, economic, quality of energy, political, technical, environmental, and sixteen sub-criteria have been employed, and an assessment model is developed for prioritizing the most pertinent renewable energy sources for electricity generation in developing countries in which four major resources, solar energy, wind energy, hydropower, and biomass energy, are considered and their electricity generation potential. Furthermore, the integrated method with the analytical hierarchy process and VIekriterijumsko KOmpromisno Rangiranje are acquired for a comprehensive assessment. The results demonstrate that the economic criterion had the highest weight of (0.353) compared to the technical criterion, which took place second with a weight of (0.244) followed by environmental (0.205) and quality of energy with a weight (0.098), respectively. The political and social criteria have the lowest weights of (0.057) and (0.043). From the review, renewable resources seem to have sufficient potential to develop a sustainable electricity system. Likewise, the model priorities these resources, revealing that hydropower is the best renewable energy source option, followed by wind energy. Biomass energy and solar energy ranked third and fourth. The assessment performed in this study can help decision-makers in Pakistan to frame long-term energy policy directing for sustainability.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Integrated AHP-VIKOR with weighting method are used to prioritize the renewable energy sources. </LI> <LI>  Assessment of renewable energy resources is based on six criteria and sixteen subcriteria. </LI> <LI>  A criteria system is constructed (social, economic, technical, political, quality of energy and environmental aspects). </LI> <LI>  Economic and technical is determined as most essential criteria. </LI> <LI>  Hydropower is the best option for electricity generation, among the selected alternatives. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART117058201&target=NART&cn=NART117058201",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prioritization of renewable energy source for electricity generation through AHP-VIKOR integrated methodology Prioritization of renewable energy source for electricity generation through AHP-VIKOR integrated methodology Prioritization of renewable energy source for electricity generation through AHP-VIKOR integrated methodology <P><B>Abstract</B></P>  <P>As the worldwide energy crisis worsens, renewable energy sources have undeniably opened new horizons for our society. It will offer an efficient solution to this severe energy crisis, environmental issues and fulfilling human energy needs. Therefore, six main criteria, social, economic, quality of energy, political, technical, environmental, and sixteen sub-criteria have been employed, and an assessment model is developed for prioritizing the most pertinent renewable energy sources for electricity generation in developing countries in which four major resources, solar energy, wind energy, hydropower, and biomass energy, are considered and their electricity generation potential. Furthermore, the integrated method with the analytical hierarchy process and VIekriterijumsko KOmpromisno Rangiranje are acquired for a comprehensive assessment. The results demonstrate that the economic criterion had the highest weight of (0.353) compared to the technical criterion, which took place second with a weight of (0.244) followed by environmental (0.205) and quality of energy with a weight (0.098), respectively. The political and social criteria have the lowest weights of (0.057) and (0.043). From the review, renewable resources seem to have sufficient potential to develop a sustainable electricity system. Likewise, the model priorities these resources, revealing that hydropower is the best renewable energy source option, followed by wind energy. Biomass energy and solar energy ranked third and fourth. The assessment performed in this study can help decision-makers in Pakistan to frame long-term energy policy directing for sustainability.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Integrated AHP-VIKOR with weighting method are used to prioritize the renewable energy sources. </LI> <LI>  Assessment of renewable energy resources is based on six criteria and sixteen subcriteria. </LI> <LI>  A criteria system is constructed (social, economic, technical, political, quality of energy and environmental aspects). </LI> <LI>  Economic and technical is determined as most essential criteria. </LI> <LI>  Hydropower is the best option for electricity generation, among the selected alternatives. </LI> </UL> </P>"
        },
        {
          "rank": 37,
          "score": 0.5725130438804626,
          "doc_id": "JAKO201664750651098",
          "title": "아시아 문화유산의 지속가능성을 위한 ODA 현황과 과제",
          "abstract": "2015년 9월 UN 개발정상회의에서 Post 2015 개발의제로 '지속가능개발목표(SDGs)'가 채택됨에 따라 '지속가능성'을 문화유산과 연계한 다양한 의견과 토의가 활발히 이루어지고 있다. 그러나 굳이 SDGs를 내세우지 않아도 문화유산 보존 자체가 문화유산이 가지는 자국 문화의 독자성, 특성, 다양성 등을 영구히 유지한다는 지속가능성을 바탕으로 하고 있다. 이런 관점에서 정책이나 이론적 접근이 아닌 실제적인 문화유산 ODA 사업을 파악할 필요가 있을 것이다. 본고에서는 아시아 문화유산 ODA와 관련한 국내외 현황을 살펴보고 이를 토대로 문제점과 향후의 방향성, 과제에 대해 언급하였다. 먼저 ODA 사업이 시작된 배경이나 개념을 알아보고, 동남아시아의 대표적인 문화유산 ODA 수행국가인 일본과 중국의 사업 내용을 알아보았다. 한국의 문화유산 ODA는 라오스, 캄보디아 유적 복원을 중심으로 비교적 최근에 시작되어 아직 규모나 내용면에서 미비한 수준이다. 문화유산 ODA의 발전을 위한 과제로 다음 몇 가지 사항을 제안하고자 한다. 첫째로 아시아 문화유산의 지속가능성을 위한 ODA 사업의 장기 마스터플랜 설정이 필요할 것이다. 둘째로 여러 국가를 대상으로 하는 나열식의 단기간 사업 대신 장기적 관점에서의 선택과 집중이 필요할 것이다. 이미 잘 알려진 사업이 아닌 한국만이 할 수 있는 한국형 문화유산 ODA 모델이 필요하다. 다음으로 지속가능성과의 연계인데, 문화유산 보존은 결국 현지 관광 활성화와 같은 경제 활성화의 원동력이 되면서 현지인에게 그 혜택이 주어져야 한다. 이를 위한 가장 좋은 대안으로 현지전문가 양성을 위한 교육과 역량 강화를 제안한다. 자국의 문화유산은 자국 문화의 고유한 독자성과 특성이 반영된 산물로 자국민에 의한 복원이 최상이다. 이런 점에서 국립문화재연구소에서 실시하고 있는 ACPCS 사업은 한국 고유의 특화된 프로그램으로 역할을 담당할 것이다. 마지막으로 문화유산 ODA의 컨트롤 타워 역할을 수행할 수 있는 체계 구축이 필요하다. 정보공유와 협력체계 구축, 중복사업 방지 등을 위한 것으로, 일본의 '문화유산 국제협력 컨소시엄'은 참고할 수 있는 사례가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201664750651098&target=NART&cn=JAKO201664750651098",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "아시아 문화유산의 지속가능성을 위한 ODA 현황과 과제 아시아 문화유산의 지속가능성을 위한 ODA 현황과 과제 아시아 문화유산의 지속가능성을 위한 ODA 현황과 과제 2015년 9월 UN 개발정상회의에서 Post 2015 개발의제로 '지속가능개발목표(SDGs)'가 채택됨에 따라 '지속가능성'을 문화유산과 연계한 다양한 의견과 토의가 활발히 이루어지고 있다. 그러나 굳이 SDGs를 내세우지 않아도 문화유산 보존 자체가 문화유산이 가지는 자국 문화의 독자성, 특성, 다양성 등을 영구히 유지한다는 지속가능성을 바탕으로 하고 있다. 이런 관점에서 정책이나 이론적 접근이 아닌 실제적인 문화유산 ODA 사업을 파악할 필요가 있을 것이다. 본고에서는 아시아 문화유산 ODA와 관련한 국내외 현황을 살펴보고 이를 토대로 문제점과 향후의 방향성, 과제에 대해 언급하였다. 먼저 ODA 사업이 시작된 배경이나 개념을 알아보고, 동남아시아의 대표적인 문화유산 ODA 수행국가인 일본과 중국의 사업 내용을 알아보았다. 한국의 문화유산 ODA는 라오스, 캄보디아 유적 복원을 중심으로 비교적 최근에 시작되어 아직 규모나 내용면에서 미비한 수준이다. 문화유산 ODA의 발전을 위한 과제로 다음 몇 가지 사항을 제안하고자 한다. 첫째로 아시아 문화유산의 지속가능성을 위한 ODA 사업의 장기 마스터플랜 설정이 필요할 것이다. 둘째로 여러 국가를 대상으로 하는 나열식의 단기간 사업 대신 장기적 관점에서의 선택과 집중이 필요할 것이다. 이미 잘 알려진 사업이 아닌 한국만이 할 수 있는 한국형 문화유산 ODA 모델이 필요하다. 다음으로 지속가능성과의 연계인데, 문화유산 보존은 결국 현지 관광 활성화와 같은 경제 활성화의 원동력이 되면서 현지인에게 그 혜택이 주어져야 한다. 이를 위한 가장 좋은 대안으로 현지전문가 양성을 위한 교육과 역량 강화를 제안한다. 자국의 문화유산은 자국 문화의 고유한 독자성과 특성이 반영된 산물로 자국민에 의한 복원이 최상이다. 이런 점에서 국립문화재연구소에서 실시하고 있는 ACPCS 사업은 한국 고유의 특화된 프로그램으로 역할을 담당할 것이다. 마지막으로 문화유산 ODA의 컨트롤 타워 역할을 수행할 수 있는 체계 구축이 필요하다. 정보공유와 협력체계 구축, 중복사업 방지 등을 위한 것으로, 일본의 '문화유산 국제협력 컨소시엄'은 참고할 수 있는 사례가 될 것이다."
        },
        {
          "rank": 38,
          "score": 0.5722059011459351,
          "doc_id": "JAKO201116450098703",
          "title": "AHP와 ANP 방법론을 이용한 그린 ICT 정책의 전략적 우선순위 도출 방안",
          "abstract": "최근, 세계적으로 에너지 소비 증가와 온난화 현상의 진행으로 정치, 경제, 사회 및 환경 부분에 직접적인 영향을 받는 글로벌 환경위기에 직면하고 있다. 이러한 문제를 해결하기 위해 세계 각 국에서는 그린 ICT 정책을 마련하고 있다. 국내에서도 환경 오염 문제를 해결하고, 에너지 효율을 높일 수 있는 그린 ICT 정책 도입을 통한 대책을 마련해야 한다. 따라서 본 연구의 목적은 국내 그린 ICT 정책 도입 후 효율을 최대화 하기 위해 고려해야 할 정책 목표의 우선순위를 전략적으로 도출하는 것이다. 이를 위해 '저탄소 녹색성장 기본법'을 바탕으로 경제성, 효율성, 환경성, 기술성, 안정성 등의 주요 변수를 도출하였고, 각각의 변수 별 세부 변수를 도출하였다. 도출된 변수들의 우선순위 분석을 위해 관련 정책 전문가를 대상으로 AHP 방법과 ANP 방법으로 각각 설문조사를 실시하였다. 설문 결과와 AHP 방법론으로 그린 ICT 정책의 우선순위를 도출한 결과 환경성, 기술성, 경제성, 효율성, 안정성의 순으로 도출되었고, ANP 방법론으로 결과를 도출한 결과 기술성, 효율성, 경제성, 환경성, 안정성의 순으로 도출되었다. 이와 같이 본 논문은 AHP와 ANP 방법론을 이용하여 그린 ICT 정책 목표의 우선순위를 학술적으로 분석하였다. 따라서 향후 관련 정책 수립 시 실용적인 가이드라인이 될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201116450098703&target=NART&cn=JAKO201116450098703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP와 ANP 방법론을 이용한 그린 ICT 정책의 전략적 우선순위 도출 방안 AHP와 ANP 방법론을 이용한 그린 ICT 정책의 전략적 우선순위 도출 방안 AHP와 ANP 방법론을 이용한 그린 ICT 정책의 전략적 우선순위 도출 방안 최근, 세계적으로 에너지 소비 증가와 온난화 현상의 진행으로 정치, 경제, 사회 및 환경 부분에 직접적인 영향을 받는 글로벌 환경위기에 직면하고 있다. 이러한 문제를 해결하기 위해 세계 각 국에서는 그린 ICT 정책을 마련하고 있다. 국내에서도 환경 오염 문제를 해결하고, 에너지 효율을 높일 수 있는 그린 ICT 정책 도입을 통한 대책을 마련해야 한다. 따라서 본 연구의 목적은 국내 그린 ICT 정책 도입 후 효율을 최대화 하기 위해 고려해야 할 정책 목표의 우선순위를 전략적으로 도출하는 것이다. 이를 위해 '저탄소 녹색성장 기본법'을 바탕으로 경제성, 효율성, 환경성, 기술성, 안정성 등의 주요 변수를 도출하였고, 각각의 변수 별 세부 변수를 도출하였다. 도출된 변수들의 우선순위 분석을 위해 관련 정책 전문가를 대상으로 AHP 방법과 ANP 방법으로 각각 설문조사를 실시하였다. 설문 결과와 AHP 방법론으로 그린 ICT 정책의 우선순위를 도출한 결과 환경성, 기술성, 경제성, 효율성, 안정성의 순으로 도출되었고, ANP 방법론으로 결과를 도출한 결과 기술성, 효율성, 경제성, 환경성, 안정성의 순으로 도출되었다. 이와 같이 본 논문은 AHP와 ANP 방법론을 이용하여 그린 ICT 정책 목표의 우선순위를 학술적으로 분석하였다. 따라서 향후 관련 정책 수립 시 실용적인 가이드라인이 될 수 있다."
        },
        {
          "rank": 39,
          "score": 0.5697371363639832,
          "doc_id": "NART108501356",
          "title": "Environmental air pollution management system: Predicting user adoption behavior of big data analytics",
          "abstract": "<P><B>Abstract</B></P>  <P>This study has a dual purpose: to explore the novel phenomenon of a big data analytics-environmental air pollution (BDA-EAP) management system, and to propose a research model of factors influencing adoption of such a system. The research model is based on task-technology fit (TTF) and unified theory of acceptance and use of technology (UTAUT) concepts. A comprehensive BDA-EAP management system is proposed and the potential adoption speed of such a system evaluated by sending structured questionnaires to the employees of relevant environmental agencies, yielding 412 valid responses, using the structural equation modeling approach. The results of the study predict that factors of TTF including task characteristics and technology characteristics are strong influencers of TTF, and TTF is a strong predictor of the behavioral intention of users to adopt a BDA-EAP management system. The results demonstrated that the combination of TTF and UTAUT is a stronger predictor of behavioral intention than either TTF or UTAUT alone. Furthermore, resistance to change negatively moderates and extrinsic motivation positively moderates the significant positive relationship between behavioral intention and adoption of a BDA-EAP management system. Meanwhile, behavioral intention, resistance to change, and extrinsic motivation have a significant three-way interaction impact on adoption of a BDA-EAP management system such that an increase in users&rsquo; extrinsic motivation will decrease the negative impact of resistance to change during the process of adoption. The study findings contribute to the literature regarding the use of BDA to manage EAP, and provide a basis for future research in this area.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Explores the novel big data analytics-environmental air pollutionmanagement system. </LI> <LI>  Proposes a research model of factors influencing adoption of such a system. </LI> <LI>  Model based on <I>task-technology fit</I> and <I>unified theory of acceptance and use of technology</I> concepts. </LI> <LI>  Combination of TTF and UTAUT is a stronger predictor of behavioral intention. </LI> <LI>  Contributes to literature about use of big data analytics to manage environmental air pollution. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108501356&target=NART&cn=NART108501356",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Environmental air pollution management system: Predicting user adoption behavior of big data analytics Environmental air pollution management system: Predicting user adoption behavior of big data analytics Environmental air pollution management system: Predicting user adoption behavior of big data analytics <P><B>Abstract</B></P>  <P>This study has a dual purpose: to explore the novel phenomenon of a big data analytics-environmental air pollution (BDA-EAP) management system, and to propose a research model of factors influencing adoption of such a system. The research model is based on task-technology fit (TTF) and unified theory of acceptance and use of technology (UTAUT) concepts. A comprehensive BDA-EAP management system is proposed and the potential adoption speed of such a system evaluated by sending structured questionnaires to the employees of relevant environmental agencies, yielding 412 valid responses, using the structural equation modeling approach. The results of the study predict that factors of TTF including task characteristics and technology characteristics are strong influencers of TTF, and TTF is a strong predictor of the behavioral intention of users to adopt a BDA-EAP management system. The results demonstrated that the combination of TTF and UTAUT is a stronger predictor of behavioral intention than either TTF or UTAUT alone. Furthermore, resistance to change negatively moderates and extrinsic motivation positively moderates the significant positive relationship between behavioral intention and adoption of a BDA-EAP management system. Meanwhile, behavioral intention, resistance to change, and extrinsic motivation have a significant three-way interaction impact on adoption of a BDA-EAP management system such that an increase in users&rsquo; extrinsic motivation will decrease the negative impact of resistance to change during the process of adoption. The study findings contribute to the literature regarding the use of BDA to manage EAP, and provide a basis for future research in this area.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Explores the novel big data analytics-environmental air pollutionmanagement system. </LI> <LI>  Proposes a research model of factors influencing adoption of such a system. </LI> <LI>  Model based on <I>task-technology fit</I> and <I>unified theory of acceptance and use of technology</I> concepts. </LI> <LI>  Combination of TTF and UTAUT is a stronger predictor of behavioral intention. </LI> <LI>  Contributes to literature about use of big data analytics to manage environmental air pollution. </LI> </UL> </P>"
        },
        {
          "rank": 40,
          "score": 0.5697095394134521,
          "doc_id": "JAKO200909659871357",
          "title": "소규모 프로젝트를 위한 애자일 프레임워크 설계 및 평가",
          "abstract": "본 논문에서는 애자일 방법론을 기반으로 한 소프트웨어 개발 프레임워크(AFSP)를 설계하였다. AFSP는 화장된 스크럼 프로세스와 소규모 프로젝트에 최적화된 애자일 프랙티스로 구성된다. AFSP 프랙티스는 스크럼, XP, FDD, DSDM, 크리스탈 클리어로부터 민첩도가 높은 프랙티스를 접목함으로써 소규모 프로젝트 개발 및 관리에 보다 최적화될 수 있도록 하였으며, 소프트웨어 개발 생명 주기에 따라 6대 애자일 프로젝트 성공요소를 반영하여 효과적인 적용이 가능하도록 했다. 또한, AFSP를 소규모 웹 어플리케이션 프로젝트에 적용하고 종합적인 평가를 수행함으로써 그 효율성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200909659871357&target=NART&cn=JAKO200909659871357",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소규모 프로젝트를 위한 애자일 프레임워크 설계 및 평가 소규모 프로젝트를 위한 애자일 프레임워크 설계 및 평가 소규모 프로젝트를 위한 애자일 프레임워크 설계 및 평가 본 논문에서는 애자일 방법론을 기반으로 한 소프트웨어 개발 프레임워크(AFSP)를 설계하였다. AFSP는 화장된 스크럼 프로세스와 소규모 프로젝트에 최적화된 애자일 프랙티스로 구성된다. AFSP 프랙티스는 스크럼, XP, FDD, DSDM, 크리스탈 클리어로부터 민첩도가 높은 프랙티스를 접목함으로써 소규모 프로젝트 개발 및 관리에 보다 최적화될 수 있도록 하였으며, 소프트웨어 개발 생명 주기에 따라 6대 애자일 프로젝트 성공요소를 반영하여 효과적인 적용이 가능하도록 했다. 또한, AFSP를 소규모 웹 어플리케이션 프로젝트에 적용하고 종합적인 평가를 수행함으로써 그 효율성을 입증하였다."
        },
        {
          "rank": 41,
          "score": 0.5695476531982422,
          "doc_id": "NART69852024",
          "title": "저탄소 녹색성장을 위한 그린 IT 정책 추진 방향",
          "abstract": "<P>온실가스 배출에 따른 기후변화와 에너지 수급 불균형에 의한 고유가 문제가 글로벌 도전과제로 부상하면서 국제사회는 선진국을 중심으로 전 지구적인 공동 대응방안 마련을 촉구하고 있다. 우리나라 역시 지난 8월 15일‘63회 광복절 및 건국 60주년 대통령 경축사’를 통해‘저탄소 녹색성장’을 미래 국가 발전 비전으로 제시하고 관련 기술 개발 및 산업 육성 전략을 추진하고 있다. 저탄소 녹색성장의 핵심은 에너지와 자원을 효율적으로 이용하여 온실가스 배출과 환경오염을 최소화하는 등 지속가능한 경제성장을 추구하는 것이다. 이처럼 기후변화에 대응하기 위한 국내외적 관심이 고조되고 있는 상황에서 IT 부문 역시 저탄소 녹색성장에 기여하기 위한 방안 모색이 한창으로 최근 IT 업계에서는 그린 IT가 새로운 이슈로 떠오르고 있다. 이에 본고는 저탄소 녹색성장을 실현하기 위한 핵심 솔루션으로 그린 IT 개념을 정립하고 선진국의 그린 IT 정책 추진 동향을 살펴봄으로써 우리가 고려해야 할 정책 과제를 짚어 보고자 한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69852024&target=NART&cn=NART69852024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "저탄소 녹색성장을 위한 그린 IT 정책 추진 방향 저탄소 녹색성장을 위한 그린 IT 정책 추진 방향 저탄소 녹색성장을 위한 그린 IT 정책 추진 방향 <P>온실가스 배출에 따른 기후변화와 에너지 수급 불균형에 의한 고유가 문제가 글로벌 도전과제로 부상하면서 국제사회는 선진국을 중심으로 전 지구적인 공동 대응방안 마련을 촉구하고 있다. 우리나라 역시 지난 8월 15일‘63회 광복절 및 건국 60주년 대통령 경축사’를 통해‘저탄소 녹색성장’을 미래 국가 발전 비전으로 제시하고 관련 기술 개발 및 산업 육성 전략을 추진하고 있다. 저탄소 녹색성장의 핵심은 에너지와 자원을 효율적으로 이용하여 온실가스 배출과 환경오염을 최소화하는 등 지속가능한 경제성장을 추구하는 것이다. 이처럼 기후변화에 대응하기 위한 국내외적 관심이 고조되고 있는 상황에서 IT 부문 역시 저탄소 녹색성장에 기여하기 위한 방안 모색이 한창으로 최근 IT 업계에서는 그린 IT가 새로운 이슈로 떠오르고 있다. 이에 본고는 저탄소 녹색성장을 실현하기 위한 핵심 솔루션으로 그린 IT 개념을 정립하고 선진국의 그린 IT 정책 추진 동향을 살펴봄으로써 우리가 고려해야 할 정책 과제를 짚어 보고자 한다.</P>"
        },
        {
          "rank": 42,
          "score": 0.5682209134101868,
          "doc_id": "JAKO201303537265581",
          "title": "공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 -",
          "abstract": "개방과 공유에 기초한 정부 3.0이라는 새로운 패러다임이 국정전반에 확산되고 있다. 공간정보산업의 발전이라는 장기적인 관점에서 볼 때 항공사진의 공개해상도 등 공간정보 보안규제는 합리적으로 개선되어야 한다. 그러나 공간정보 보안관리체계가 합리적으로 확립되지 않은 상태에서의 규제 철폐는 자칫 국가안보와 같은 또 다른 문제를 야기할 수도 있다. 본 연구의 목적은 현행 국가 공간정보 보안정책과 공간정보산업 등 시대적 여건 변화를 고려하여, 보안규제의 완화를 위해 필요한 공간정보 보안관체계의 개선방안을 제시하는 것이다. 분석의 관점으로써 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면을 종합적으로 검토하였으며, 특히 공간정보 보안관리의 통합적 관점을 유지하였다. 공간정보 보안체계의 문제점과 함께 해외 공간정보 보안규제 정책을 검토한 후, 이를 토대로 합리적인 보안관리 개선 방안을 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면으로 나누어 제시하였으며 장기적인 보안규제의 완화를 위한 3단계 보안관리체계의 개선방안을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303537265581&target=NART&cn=JAKO201303537265581",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 공간정보산업 활성화를 위한 공간정보 보안관리체계의 개선전략 - 공간정보의 생산·관리·보급 기관을 중심으로 - 개방과 공유에 기초한 정부 3.0이라는 새로운 패러다임이 국정전반에 확산되고 있다. 공간정보산업의 발전이라는 장기적인 관점에서 볼 때 항공사진의 공개해상도 등 공간정보 보안규제는 합리적으로 개선되어야 한다. 그러나 공간정보 보안관리체계가 합리적으로 확립되지 않은 상태에서의 규제 철폐는 자칫 국가안보와 같은 또 다른 문제를 야기할 수도 있다. 본 연구의 목적은 현행 국가 공간정보 보안정책과 공간정보산업 등 시대적 여건 변화를 고려하여, 보안규제의 완화를 위해 필요한 공간정보 보안관체계의 개선방안을 제시하는 것이다. 분석의 관점으로써 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면을 종합적으로 검토하였으며, 특히 공간정보 보안관리의 통합적 관점을 유지하였다. 공간정보 보안체계의 문제점과 함께 해외 공간정보 보안규제 정책을 검토한 후, 이를 토대로 합리적인 보안관리 개선 방안을 법제도적 측면, 운영 관리적인 측면, 기술 시스템 측면으로 나누어 제시하였으며 장기적인 보안규제의 완화를 위한 3단계 보안관리체계의 개선방안을 제시하였다."
        },
        {
          "rank": 43,
          "score": 0.567157506942749,
          "doc_id": "JAKO201534168451815",
          "title": "강소농사업 참여농가의 역량강화에 영향을 미치는 요인 분석",
          "abstract": "The Strong Small Farm (SSF) is small farm, but strong farm so that the SSF competes with farm of the world. Also, SSF means that farmer brings about management innovation through improvements of continuous competence and individual efforts. Ultimate goals of SSF are to improve competence of farm household by 20 percent and to increase farm household income by 10 percent. The purpose of this paper is to examine the factors affecting the improvement of competence of the Strong Small Farm. The major findings of this study are summarized as follows. First, the results indicated that competence of farm household was improved by 8.5 percent. Second, the findings showed that management plan report, implement report, precision management consulting and whether or not he or she was urban to rural returner had a significant impact on improvement of competence.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201534168451815&target=NART&cn=JAKO201534168451815",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "강소농사업 참여농가의 역량강화에 영향을 미치는 요인 분석 강소농사업 참여농가의 역량강화에 영향을 미치는 요인 분석 강소농사업 참여농가의 역량강화에 영향을 미치는 요인 분석 The Strong Small Farm (SSF) is small farm, but strong farm so that the SSF competes with farm of the world. Also, SSF means that farmer brings about management innovation through improvements of continuous competence and individual efforts. Ultimate goals of SSF are to improve competence of farm household by 20 percent and to increase farm household income by 10 percent. The purpose of this paper is to examine the factors affecting the improvement of competence of the Strong Small Farm. The major findings of this study are summarized as follows. First, the results indicated that competence of farm household was improved by 8.5 percent. Second, the findings showed that management plan report, implement report, precision management consulting and whether or not he or she was urban to rural returner had a significant impact on improvement of competence."
        },
        {
          "rank": 44,
          "score": 0.5669918656349182,
          "doc_id": "JAKO202405955800623",
          "title": "토픽모델링을 활용한 국내 ESG 연구 트렌드 분석",
          "abstract": "Purpose The purpose of this study is to examine trends in domestic ESG research before and after the Paris Climate Change Convention, and to present trends in ESG-related keyword research so that ESG academic research can throw meaningful keywords on enhancing corporate competitiveness and building a sustainable corporate management environment. Design/methodology/approach The study designed a research model by collecting the abstracts of 875 papers on ESG published in 'KCI-registered' journals. It is analyzed through frequency analysis, topic analysis, and CONCOR analysis on a yearly basis from 2017 to 2023. Findings According to the analysis result, ESG research has evolved and been confirmed since the Paris Climate Change Convention in 2021, from the focus of corporate sustainability and financial performance to the ESG research stage that united the environment, social responsibility, and governance. It is also meaningful to suggest the direction of ESG research and the direction of establishing an ESG management strategy.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202405955800623&target=NART&cn=JAKO202405955800623",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "토픽모델링을 활용한 국내 ESG 연구 트렌드 분석 토픽모델링을 활용한 국내 ESG 연구 트렌드 분석 토픽모델링을 활용한 국내 ESG 연구 트렌드 분석 Purpose The purpose of this study is to examine trends in domestic ESG research before and after the Paris Climate Change Convention, and to present trends in ESG-related keyword research so that ESG academic research can throw meaningful keywords on enhancing corporate competitiveness and building a sustainable corporate management environment. Design/methodology/approach The study designed a research model by collecting the abstracts of 875 papers on ESG published in 'KCI-registered' journals. It is analyzed through frequency analysis, topic analysis, and CONCOR analysis on a yearly basis from 2017 to 2023. Findings According to the analysis result, ESG research has evolved and been confirmed since the Paris Climate Change Convention in 2021, from the focus of corporate sustainability and financial performance to the ESG research stage that united the environment, social responsibility, and governance. It is also meaningful to suggest the direction of ESG research and the direction of establishing an ESG management strategy."
        },
        {
          "rank": 45,
          "score": 0.5664248466491699,
          "doc_id": "ART001567787",
          "title": "일본의 저탄소 녹색성장 전략과 그린IT 정책",
          "abstract": "Japan has tried to fulfil greenhouse gas reduction plan and in same time breathing some life into the its economy by investment on environmental industry. Thus, Japan planning to accomplish both economy growth and low carbon society and this policy is fully led by its government. Japan considers that development strategy would be the main measure to reach the goal. Japan as well as other developed nations shows huge increase amount of information and communication as their development of IT technology. Therefore, they are introducing 'Green of IT' and finally 'Green by IT' to reduce power consumption of its own IT equipments and in same time use IT technology to increase efficiency in the field of industry, business, household,transport etc.This paper will analyse Japan's latest policy toward Green IT and its position in the larger frame of Green Growth Plan. It is aims to give implication to future Korea's Green Growth Plan and direction of Green IT policy.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART001567787&target=NART&cn=ART001567787",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "일본의 저탄소 녹색성장 전략과 그린IT 정책 일본의 저탄소 녹색성장 전략과 그린IT 정책 일본의 저탄소 녹색성장 전략과 그린IT 정책 Japan has tried to fulfil greenhouse gas reduction plan and in same time breathing some life into the its economy by investment on environmental industry. Thus, Japan planning to accomplish both economy growth and low carbon society and this policy is fully led by its government. Japan considers that development strategy would be the main measure to reach the goal. Japan as well as other developed nations shows huge increase amount of information and communication as their development of IT technology. Therefore, they are introducing 'Green of IT' and finally 'Green by IT' to reduce power consumption of its own IT equipments and in same time use IT technology to increase efficiency in the field of industry, business, household,transport etc.This paper will analyse Japan's latest policy toward Green IT and its position in the larger frame of Green Growth Plan. It is aims to give implication to future Korea's Green Growth Plan and direction of Green IT policy."
        },
        {
          "rank": 46,
          "score": 0.5661903023719788,
          "doc_id": "JAKO199728062537308",
          "title": "식생지수를 이용한 환경영향평가",
          "abstract": "Vegetation Index(VI) derived from remote sensing data is used to assess ecosystem factor in Environmental Impact Assessment(EIA) process. Ecosystem factor has been prepared by Degree of Green Naturality(DGN) mainly in Environmental Impact Statements. But DGN has room for improvement of assessing actual ecosystem situation. The objectives of this study are to define the relationship between field measure DGN and VI, and to develop methodologies to use VI for assessing the status and conditions of natural ecosystem. For verification of DGN and VI, 35 sites using global positioning system are selected and reviewed. Correlation coefficients of DGN and VI shows highly as 0.69. Also VI in EIA found it can be applied to assess ecosystem. It concluded that VI as well as DGN can be applied to assess ecosystem newly and largescale.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199728062537308&target=NART&cn=JAKO199728062537308",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "식생지수를 이용한 환경영향평가 식생지수를 이용한 환경영향평가 식생지수를 이용한 환경영향평가 Vegetation Index(VI) derived from remote sensing data is used to assess ecosystem factor in Environmental Impact Assessment(EIA) process. Ecosystem factor has been prepared by Degree of Green Naturality(DGN) mainly in Environmental Impact Statements. But DGN has room for improvement of assessing actual ecosystem situation. The objectives of this study are to define the relationship between field measure DGN and VI, and to develop methodologies to use VI for assessing the status and conditions of natural ecosystem. For verification of DGN and VI, 35 sites using global positioning system are selected and reviewed. Correlation coefficients of DGN and VI shows highly as 0.69. Also VI in EIA found it can be applied to assess ecosystem. It concluded that VI as well as DGN can be applied to assess ecosystem newly and largescale."
        },
        {
          "rank": 47,
          "score": 0.5661762356758118,
          "doc_id": "JAKO202207750087253",
          "title": "중소기업의 환경적 지속가능성과 혁신지향성이 사회적통합 및 기술통합을 통해 지속가능성 성과에 미치는 영향 연구",
          "abstract": "본 연구는 지속가능경영을 위한 중소기업의 주요 요인 중 환경적 지속가능성과 혁신지향성 그리고 통합활동을 중심으로 지속가능성 성과에 미치는 영향에 대해 실증분석하고 시사점을 제공하고자 한다. 연구수행을 위해 국내 제조 중소기업의 부서장급 이상 임원과 대표로 전문 리서치회사를 통하여 획득한 366부를 최종분석에 사용하였으며, SmartPLS 3.0과 SPSS 25를 활용하여 연구가설을 검증하였다. 분석결과 환경적 지속가능성이 사회적통합과 기술통합에 유의한 영향을 미치고, 혁신지향성이 사회적통합과 기술통합에 유의한 영향을 미치는 것으로 확인하였다. 또한, 사회적통합과 기술통합 요인이 중소기업의 지속가능성 성과에 유의한 영향을 주는 것으로 확인하였다. 이러한 연구 결과를 바탕으로 이론적 시사점과 실무적 시사점 및 향후 연구 방향을 제시하였다. 본 연구 결과를 참조하면 제조 중소기업들이 지속가능성 성과를 달성하기 위한 혁신지향성, 사회적통합 및 기술통합 관련 전략을 수립하는데 도움을 받을 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202207750087253&target=NART&cn=JAKO202207750087253",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "중소기업의 환경적 지속가능성과 혁신지향성이 사회적통합 및 기술통합을 통해 지속가능성 성과에 미치는 영향 연구 중소기업의 환경적 지속가능성과 혁신지향성이 사회적통합 및 기술통합을 통해 지속가능성 성과에 미치는 영향 연구 중소기업의 환경적 지속가능성과 혁신지향성이 사회적통합 및 기술통합을 통해 지속가능성 성과에 미치는 영향 연구 본 연구는 지속가능경영을 위한 중소기업의 주요 요인 중 환경적 지속가능성과 혁신지향성 그리고 통합활동을 중심으로 지속가능성 성과에 미치는 영향에 대해 실증분석하고 시사점을 제공하고자 한다. 연구수행을 위해 국내 제조 중소기업의 부서장급 이상 임원과 대표로 전문 리서치회사를 통하여 획득한 366부를 최종분석에 사용하였으며, SmartPLS 3.0과 SPSS 25를 활용하여 연구가설을 검증하였다. 분석결과 환경적 지속가능성이 사회적통합과 기술통합에 유의한 영향을 미치고, 혁신지향성이 사회적통합과 기술통합에 유의한 영향을 미치는 것으로 확인하였다. 또한, 사회적통합과 기술통합 요인이 중소기업의 지속가능성 성과에 유의한 영향을 주는 것으로 확인하였다. 이러한 연구 결과를 바탕으로 이론적 시사점과 실무적 시사점 및 향후 연구 방향을 제시하였다. 본 연구 결과를 참조하면 제조 중소기업들이 지속가능성 성과를 달성하기 위한 혁신지향성, 사회적통합 및 기술통합 관련 전략을 수립하는데 도움을 받을 수 있을 것으로 기대한다."
        },
        {
          "rank": 48,
          "score": 0.5639876127243042,
          "doc_id": "JAKO200311922053515",
          "title": "자원인자 기반 스케줄링 프레임워크",
          "abstract": "대규모 환경의 고성능 그리드 구현을 위해서는 기존 그리드 자원 스케줄링 파라다임이 갖 성능 확장성 측면의 제한성을 극복할 수 있는 새로운 자원 스케줄링 프레임워크가 요구된다. 본 연구에서는 자원 스케줄링 성능 최적화를 목표로 자원인자 그래프(Resource Parameter Graph), 자원인자 인덱스 트리(Resource Parameter Index Tree), 그리고 정적 자원 정보 리포지터리로 구성되는 자원인자 스케줄링 프레임워크를 제안한다. 자원인자 그래프는 자원간의 관계 및 자원의 계층적 구성을 나타낼 수 있는 자원표현기법이며 이러한 표현을 기술하기 위한 XML 기반 자원정보 및 자원요청 기술 스키마를 설계하였다. 또한 자원인자 인덱스 트리는 자원 스케줄링의 자원탐색 및 자원할당, 상태정보 공지 등의 알고리즘의 효율적인 지원을 위한 메모리 기반 인덱스의 데이터 구조이다. 본 논문에서는 이러한 자원인자 스케줄링 프레임워크의 구성 내용에 대하여 기술한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922053515&target=NART&cn=JAKO200311922053515",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자원인자 기반 스케줄링 프레임워크 자원인자 기반 스케줄링 프레임워크 자원인자 기반 스케줄링 프레임워크 대규모 환경의 고성능 그리드 구현을 위해서는 기존 그리드 자원 스케줄링 파라다임이 갖 성능 확장성 측면의 제한성을 극복할 수 있는 새로운 자원 스케줄링 프레임워크가 요구된다. 본 연구에서는 자원 스케줄링 성능 최적화를 목표로 자원인자 그래프(Resource Parameter Graph), 자원인자 인덱스 트리(Resource Parameter Index Tree), 그리고 정적 자원 정보 리포지터리로 구성되는 자원인자 스케줄링 프레임워크를 제안한다. 자원인자 그래프는 자원간의 관계 및 자원의 계층적 구성을 나타낼 수 있는 자원표현기법이며 이러한 표현을 기술하기 위한 XML 기반 자원정보 및 자원요청 기술 스키마를 설계하였다. 또한 자원인자 인덱스 트리는 자원 스케줄링의 자원탐색 및 자원할당, 상태정보 공지 등의 알고리즘의 효율적인 지원을 위한 메모리 기반 인덱스의 데이터 구조이다. 본 논문에서는 이러한 자원인자 스케줄링 프레임워크의 구성 내용에 대하여 기술한다."
        },
        {
          "rank": 49,
          "score": 0.5633074045181274,
          "doc_id": "NART135127671",
          "title": "IT/OT-Konvergenz: Status-Quo und Umsetzungsempfehlungen",
          "abstract": "<P><B>Abstract</B><P>This study examines IT/OT Convergence in 31 predominantly large German companies. It presents an &ldquo;IT/OT Governance Framework&rdquo; as a specific model for successful convergence implementation. The analysis reveals a heterogeneous level of convergence maturity across the examined companies, the majority of which are at the beginning or in the implementation phase. Close cooperation between IT and OT is favored, but without IT completely taking over OT. An IT/OT tandem consisting of a CIO and a central OT responsible person is seen as the ideal way to take responsibility. Six specific recommendations were derived from the interviews and included in the IT/OT Governance Framework developed. These include ensuring top management support, using security as a driver, introducing a central OT responsible person, bringing IT and OT teams physically closer together, continuously demonstrating the added value of convergence, and taking a step-by-step approach to implementation.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135127671&target=NART&cn=NART135127671",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "IT/OT-Konvergenz: Status-Quo und Umsetzungsempfehlungen IT/OT-Konvergenz: Status-Quo und Umsetzungsempfehlungen IT/OT-Konvergenz: Status-Quo und Umsetzungsempfehlungen <P><B>Abstract</B><P>This study examines IT/OT Convergence in 31 predominantly large German companies. It presents an &ldquo;IT/OT Governance Framework&rdquo; as a specific model for successful convergence implementation. The analysis reveals a heterogeneous level of convergence maturity across the examined companies, the majority of which are at the beginning or in the implementation phase. Close cooperation between IT and OT is favored, but without IT completely taking over OT. An IT/OT tandem consisting of a CIO and a central OT responsible person is seen as the ideal way to take responsibility. Six specific recommendations were derived from the interviews and included in the IT/OT Governance Framework developed. These include ensuring top management support, using security as a driver, introducing a central OT responsible person, bringing IT and OT teams physically closer together, continuously demonstrating the added value of convergence, and taking a step-by-step approach to implementation.</P></P>"
        },
        {
          "rank": 50,
          "score": 0.5631571412086487,
          "doc_id": "NART72188129",
          "title": "Advancing societal readiness toward renewable energy system adoption with a socio-technical perspective",
          "abstract": "The development of renewable energy systems has put a large emphasis on technical progress rather than examination of ways to foster societal demand to diffuse the new energy technologies. In order to understand demand-side issues that are important to sustainable energy innovation, this research examines key factors of renewable energy systems diffusion from a socio-technological perspective. Based on theory of planned behavior (TPB), a research model was constructed around ''societal'' factors such as social trust and social support alongside ''technology'' issues such as technical facilitating conditions and perceived system quality. This research reveals that attitude, subjective norm and perceived behavioral control impact on consumers' intention to use renewable energy systems. In addition, social trust and social support are influential factors on attitude and subjective norm while facilitating technical condition has influence on perceived behavioral control. The findings of this study suggest that business managers and policy makers should have a strategy to advance societal readiness toward sustainable energy innovation and to balance it with technology development.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART72188129&target=NART&cn=NART72188129",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Advancing societal readiness toward renewable energy system adoption with a socio-technical perspective Advancing societal readiness toward renewable energy system adoption with a socio-technical perspective Advancing societal readiness toward renewable energy system adoption with a socio-technical perspective The development of renewable energy systems has put a large emphasis on technical progress rather than examination of ways to foster societal demand to diffuse the new energy technologies. In order to understand demand-side issues that are important to sustainable energy innovation, this research examines key factors of renewable energy systems diffusion from a socio-technological perspective. Based on theory of planned behavior (TPB), a research model was constructed around ''societal'' factors such as social trust and social support alongside ''technology'' issues such as technical facilitating conditions and perceived system quality. This research reveals that attitude, subjective norm and perceived behavioral control impact on consumers' intention to use renewable energy systems. In addition, social trust and social support are influential factors on attitude and subjective norm while facilitating technical condition has influence on perceived behavioral control. The findings of this study suggest that business managers and policy makers should have a strategy to advance societal readiness toward sustainable energy innovation and to balance it with technology development."
        }
      ]
    },
    {
      "query": "What is the role of data sharing within this framework?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7176532745361328,
          "doc_id": "DIKO0016665439",
          "title": "이기종 장치간 협업을 위한 데이터 공유 프레임워크",
          "abstract": "본 연구는 다중 장치 환경에서 장치 간의 협업을 위한 프레임워크를 제안한다. 응용프로그램 수준에서 직접 데이터를 전송하려면 데이터를 처리할 장치에도 해당 응용프로그램이 설치되어 있어야 한다. 이런 접근 방법은 응용프로그램에 종속적이며 데이터를 전송하고자 하는 응용프로그램마다 이를 위한 코드를 개별적으로 작성해야 한다. 본 논문이 제안하는 데이터 공유 프레임워크는 다중 장치 환경에서 사용자가 응용프로그램의 설치 및 변경 없이 데이터를 전송할 수 있는 환경을 제공한다. 프레임워크에서 데이터 전송을 지원함으로써 특정 기능을 투명하게 원격에서 실행할 수 있다. 실험을 통해 프레임워크의 데이터 원격 전송의 속도를 향상하기 위한 외부 라이브러리의 도입을 검증하였고, 제안하는 프레임워크의 데이터 전송 및 인텐트 원격 실행 속도를 측정하여 실효성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016665439&target=NART&cn=DIKO0016665439",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 장치간 협업을 위한 데이터 공유 프레임워크 이기종 장치간 협업을 위한 데이터 공유 프레임워크 이기종 장치간 협업을 위한 데이터 공유 프레임워크 본 연구는 다중 장치 환경에서 장치 간의 협업을 위한 프레임워크를 제안한다. 응용프로그램 수준에서 직접 데이터를 전송하려면 데이터를 처리할 장치에도 해당 응용프로그램이 설치되어 있어야 한다. 이런 접근 방법은 응용프로그램에 종속적이며 데이터를 전송하고자 하는 응용프로그램마다 이를 위한 코드를 개별적으로 작성해야 한다. 본 논문이 제안하는 데이터 공유 프레임워크는 다중 장치 환경에서 사용자가 응용프로그램의 설치 및 변경 없이 데이터를 전송할 수 있는 환경을 제공한다. 프레임워크에서 데이터 전송을 지원함으로써 특정 기능을 투명하게 원격에서 실행할 수 있다. 실험을 통해 프레임워크의 데이터 원격 전송의 속도를 향상하기 위한 외부 라이브러리의 도입을 검증하였고, 제안하는 프레임워크의 데이터 전송 및 인텐트 원격 실행 속도를 측정하여 실효성을 입증하였다."
        },
        {
          "rank": 2,
          "score": 0.6829636096954346,
          "doc_id": "JAKO201233355899170",
          "title": "신원 인증 공유를 위한 동적 신뢰 프레임워크",
          "abstract": "인터넷 환경에서 신원 인증 서비스를 제공하는 신원 제공자의 신원 인증 결과를 다수의 서비스 제공자가 공유하는 신원 인증 공유는, 반복적인 등록 회피와 싱글 사인온을 통한 사용자 편의성 제고, 신원 제공자로부터의 신원 인증 서비스 아웃소싱을 통한 서비스 제공자의 비용 절감, 그리고 제한된 수의 통제된 신원 제공자에게 한정된 신원 정보 노출을 통한 프라이버시 보호 등의 측면에서 몇 가지 중요한 장점을 제공한다. 그러나 신원 인증 공유 기술이 글로벌 인터넷 차원에서 광범위하게 적용되기 위해서는 신원 제공자, 서비스 제공자, 그리고 사용자간에 신원 인증과 관련된 신뢰 문제가 선결되어야 한다. 본 논문은 신원 인증 공유를 위한 신뢰 프레임워크의 현황을 분석하고, 분석 결과를 바탕으로 신원 인증 공유를 위한 동적인 개방형 신뢰 프레임워크를 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201233355899170&target=NART&cn=JAKO201233355899170",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신원 인증 공유를 위한 동적 신뢰 프레임워크 신원 인증 공유를 위한 동적 신뢰 프레임워크 신원 인증 공유를 위한 동적 신뢰 프레임워크 인터넷 환경에서 신원 인증 서비스를 제공하는 신원 제공자의 신원 인증 결과를 다수의 서비스 제공자가 공유하는 신원 인증 공유는, 반복적인 등록 회피와 싱글 사인온을 통한 사용자 편의성 제고, 신원 제공자로부터의 신원 인증 서비스 아웃소싱을 통한 서비스 제공자의 비용 절감, 그리고 제한된 수의 통제된 신원 제공자에게 한정된 신원 정보 노출을 통한 프라이버시 보호 등의 측면에서 몇 가지 중요한 장점을 제공한다. 그러나 신원 인증 공유 기술이 글로벌 인터넷 차원에서 광범위하게 적용되기 위해서는 신원 제공자, 서비스 제공자, 그리고 사용자간에 신원 인증과 관련된 신뢰 문제가 선결되어야 한다. 본 논문은 신원 인증 공유를 위한 신뢰 프레임워크의 현황을 분석하고, 분석 결과를 바탕으로 신원 인증 공유를 위한 동적인 개방형 신뢰 프레임워크를 제시한다."
        },
        {
          "rank": 3,
          "score": 0.6812036037445068,
          "doc_id": "DIKO0014170353",
          "title": "링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크",
          "abstract": "건설 프로젝트에서 발생하는 하자는 프로젝트의 성과에 심각한 영향을 미치는 요인으로 인식되고 있다. 이에 학계와 실무에서는 하자저감을 위해 과거부터 지속적인 노력을 기울여왔다. 하지만, 현재에도 과거에 발생된 하자가 반복해서 발생되고 있다는 점을 고려볼 때, 지금까지의 하자정보 관리 및 활용 체계가 비효율적이고 비생산적임을 의미한다. &amp;#xD; 이에 본 연구는 프로젝트 수행 시 발생되는 하자를 체계적으로 저장하고, 효율적으로 검색 및 공유하여 하자정보 활용의 선순환 체계를 구축하기 위한 수단으로 최신 정보 통신 기술을 복합적으로 적용하여, 기존 방식을 획기적으로 개선시킬 수 있는 시스템 프레임워크 개발을 목적으로 수행되었다. &amp;#xD; 이를 위해 선행연구와 하자정보 활용현황을 분석하여, 지식관리 프로세스 관점에서 현 하자정보 활용의 한계를 도출하였다. 정보 생성 영역에서는 비체계적인 방식으로 정보가 수집되고 있으며, 정보 저장 영역에서는 문서기반의 비구조적인 방식으로 정보가 저장되고 있으며, 정보 검색 영역에서는 키워드, 카테고리 기반의 검색 방식만을 제공하고 있으며, 정보 공유 및 활용 영역에서는 정보를 제공받아야 할 주체에게 정보가 전달될 수 없는 환경이다. 이러한 기존 하자정보 활용체계를 개선하기 위해서는 각 단계별 요구사항을 만족시킬 수 있을 뿐만 아니라 하자정보의 생성부터 저장 및 활용에 이르는 개별 정보 흐름이 시스템적으로 연계될 필요가 있다. &amp;#xD; 이를 위해 본 연구에서는 정보통신 분야와 건설 분야에서 활용되고 있는 최신 기술을 고찰하여, 기존 하자정보 활용체계를 획기적으로 개선시킬 수 있는 방안을 제시하였다. 먼저 정보 통신 분야에서는 해당 분야의 지식을 체계화하여 컴퓨터가 이해할 수 있도록 하는 새로운 정보표현 기술인 온톨로지와 이를 기반으로 서로 다른 시스템이나 웹상에 분산된 정보를 단일한 플랫폼에서 검색하고 분석할 수 있는 링크드 데이터 기술을 활용하였다. 건설 분야에서는 기존 문서중심의 2D 환경을 3D 객체기반 디지털 환경으로 전환하여 정보의 통합 및 호환성 향상을 위해 개발된 플랫폼인 BIM 기술을 활용하였다. 이에 본 연구에서는 BIM의 디지털 정보와 온톨로지와 링크드 데이터 기술을 융합하여 하자정보 공유 및 활용체계를 획기적으로 개선할 수 있는 시스템 프레임워크를 제안하였으며, 세부 기술 구현을 통해 기술 적용 가능성을 검증하였다. 본 연구에서 구현한 기술과 기능을 요약하면 다음과 같다.&amp;#xD; 먼저 정보 생성 모듈에서는 하자정보 구성체계를 제안하고 이를 구조화된 지시표현 방식으로 전환하기 위해 온톨로지 저작툴인 Protege를 활용하여 하자 온톨로지를 개발하였다. 정보 저장 모듈에서는 RDF 전환 프로그램을 개발하여, BIM 객체로부터 추출된 작업상황 정보를 위 프로그램을 활용하여 RDF 파일을 자동으로 생성할 수 있는 시스템을 구현하였다. 정보 검색 모듈에서는 SPARQL 쿼리를 활용하여 정보의 검색 및 통계가 가능함을 확인하였고, 마지막으로 정보 공유 및 활용 모듈에서는 링크드 데이터 환경을 구현하기 위해 Sesame 프로그램을 활용하여, 실제 웹 사이트에 저장된 정보를 RDF 파일로 변환하고, 이를 RDF store에 업로드 한 후, SPARQL endpoint를 통해 해당 웹사이트로 접근이 가능함을 확인하였다. 또한, 하자사례를 규칙화하여 SWRL룰로 변환하고, 이를 BIM 정보를 활용하여 하자발생 상황을 자동으로 추론할 수 있음을 확인하였다. &amp;#xD; 본 연구는 과거 수십 년간 강조해왔던 하자정보 피드백 환경을 구현하기 위해 최신기술인 링크드 데이터, 온톨로지, BIM의 기능을 융합한 시스템 프레임워크를 제시하였다. 본 연구는 하자정보의 흐름을 지식관리 프로세스 관점에서 바라보았으며, 각 단계별로 요구되는 기능을 규명하여 이를 기술적 방법론을 제시하였다는 것과 하자관리 업무에 참고해야 될 사례로만 여겨졌던 하자정보도 규칙화 될 수 있다는 것을 검증한 측면에서 학술적 기여가 있는 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014170353&target=NART&cn=DIKO0014170353",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 링크드 데이터 기술을 활용한 건설 하자정보 공유 시스템 프레임워크 건설 프로젝트에서 발생하는 하자는 프로젝트의 성과에 심각한 영향을 미치는 요인으로 인식되고 있다. 이에 학계와 실무에서는 하자저감을 위해 과거부터 지속적인 노력을 기울여왔다. 하지만, 현재에도 과거에 발생된 하자가 반복해서 발생되고 있다는 점을 고려볼 때, 지금까지의 하자정보 관리 및 활용 체계가 비효율적이고 비생산적임을 의미한다. &amp;#xD; 이에 본 연구는 프로젝트 수행 시 발생되는 하자를 체계적으로 저장하고, 효율적으로 검색 및 공유하여 하자정보 활용의 선순환 체계를 구축하기 위한 수단으로 최신 정보 통신 기술을 복합적으로 적용하여, 기존 방식을 획기적으로 개선시킬 수 있는 시스템 프레임워크 개발을 목적으로 수행되었다. &amp;#xD; 이를 위해 선행연구와 하자정보 활용현황을 분석하여, 지식관리 프로세스 관점에서 현 하자정보 활용의 한계를 도출하였다. 정보 생성 영역에서는 비체계적인 방식으로 정보가 수집되고 있으며, 정보 저장 영역에서는 문서기반의 비구조적인 방식으로 정보가 저장되고 있으며, 정보 검색 영역에서는 키워드, 카테고리 기반의 검색 방식만을 제공하고 있으며, 정보 공유 및 활용 영역에서는 정보를 제공받아야 할 주체에게 정보가 전달될 수 없는 환경이다. 이러한 기존 하자정보 활용체계를 개선하기 위해서는 각 단계별 요구사항을 만족시킬 수 있을 뿐만 아니라 하자정보의 생성부터 저장 및 활용에 이르는 개별 정보 흐름이 시스템적으로 연계될 필요가 있다. &amp;#xD; 이를 위해 본 연구에서는 정보통신 분야와 건설 분야에서 활용되고 있는 최신 기술을 고찰하여, 기존 하자정보 활용체계를 획기적으로 개선시킬 수 있는 방안을 제시하였다. 먼저 정보 통신 분야에서는 해당 분야의 지식을 체계화하여 컴퓨터가 이해할 수 있도록 하는 새로운 정보표현 기술인 온톨로지와 이를 기반으로 서로 다른 시스템이나 웹상에 분산된 정보를 단일한 플랫폼에서 검색하고 분석할 수 있는 링크드 데이터 기술을 활용하였다. 건설 분야에서는 기존 문서중심의 2D 환경을 3D 객체기반 디지털 환경으로 전환하여 정보의 통합 및 호환성 향상을 위해 개발된 플랫폼인 BIM 기술을 활용하였다. 이에 본 연구에서는 BIM의 디지털 정보와 온톨로지와 링크드 데이터 기술을 융합하여 하자정보 공유 및 활용체계를 획기적으로 개선할 수 있는 시스템 프레임워크를 제안하였으며, 세부 기술 구현을 통해 기술 적용 가능성을 검증하였다. 본 연구에서 구현한 기술과 기능을 요약하면 다음과 같다.&amp;#xD; 먼저 정보 생성 모듈에서는 하자정보 구성체계를 제안하고 이를 구조화된 지시표현 방식으로 전환하기 위해 온톨로지 저작툴인 Protege를 활용하여 하자 온톨로지를 개발하였다. 정보 저장 모듈에서는 RDF 전환 프로그램을 개발하여, BIM 객체로부터 추출된 작업상황 정보를 위 프로그램을 활용하여 RDF 파일을 자동으로 생성할 수 있는 시스템을 구현하였다. 정보 검색 모듈에서는 SPARQL 쿼리를 활용하여 정보의 검색 및 통계가 가능함을 확인하였고, 마지막으로 정보 공유 및 활용 모듈에서는 링크드 데이터 환경을 구현하기 위해 Sesame 프로그램을 활용하여, 실제 웹 사이트에 저장된 정보를 RDF 파일로 변환하고, 이를 RDF store에 업로드 한 후, SPARQL endpoint를 통해 해당 웹사이트로 접근이 가능함을 확인하였다. 또한, 하자사례를 규칙화하여 SWRL룰로 변환하고, 이를 BIM 정보를 활용하여 하자발생 상황을 자동으로 추론할 수 있음을 확인하였다. &amp;#xD; 본 연구는 과거 수십 년간 강조해왔던 하자정보 피드백 환경을 구현하기 위해 최신기술인 링크드 데이터, 온톨로지, BIM의 기능을 융합한 시스템 프레임워크를 제시하였다. 본 연구는 하자정보의 흐름을 지식관리 프로세스 관점에서 바라보았으며, 각 단계별로 요구되는 기능을 규명하여 이를 기술적 방법론을 제시하였다는 것과 하자관리 업무에 참고해야 될 사례로만 여겨졌던 하자정보도 규칙화 될 수 있다는 것을 검증한 측면에서 학술적 기여가 있는 것으로 판단된다."
        },
        {
          "rank": 4,
          "score": 0.6805612444877625,
          "doc_id": "JAKO201811459664238",
          "title": "데이터를 활용한 공동주택 프레임워크 디자인",
          "abstract": "본 연구는 새로운 건축 설계 과정을 설명하는데 있어 특정한 시스템을 이용해서 건축 프레임워크에 대한 수행을 분석하는 것이 가능하다. 또한, 이러한 시스템은 컴퓨터가 설치되어있고 인터넷망이 구축되어 있으면 장소에 구애받지 않은 채로 가동이 가능하며, 사용자가 컴퓨터에 입력한 내용을 기반으로 한 독특한 프레임워크 결과물을 산출해 낼 수 있다. 이러한 시스템을 사용하기 전에, 건축가가 설계를 제대로 했을지라도, 컴퓨터가 잘못 인식할 수도 있으므로 건축 설계자는 원하는 결과를 얻을 수 있도록 사전에 건축 디자인과 설계 과정을 생각해야 한다. 그런데 같은 과정을 입력했는데도 불구하고 건축 계획의 프레임워크 결과가 달라진다면, 그것은 제대로 된 건축 설계라고 볼 수 없다. 그러므로 정확하게 데이터 처리를 할 수 있는 도구가 건축 디자인과 설계를 함에 있어서 필요하다. 따라서 건축을 설계할 때, 건축의 새로운 패러다임으로 각종 데이터를 활용하여 논의의 사안을 찾아 구별해야 한다. 또한 이것을 바탕으로 다양한 정보융합과 공간클라우드를 접목하여 나타낼 수 있는 파라미터정보와 건축디자인을 연관시킨 공동주택계획안을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201811459664238&target=NART&cn=JAKO201811459664238",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터를 활용한 공동주택 프레임워크 디자인 데이터를 활용한 공동주택 프레임워크 디자인 데이터를 활용한 공동주택 프레임워크 디자인 본 연구는 새로운 건축 설계 과정을 설명하는데 있어 특정한 시스템을 이용해서 건축 프레임워크에 대한 수행을 분석하는 것이 가능하다. 또한, 이러한 시스템은 컴퓨터가 설치되어있고 인터넷망이 구축되어 있으면 장소에 구애받지 않은 채로 가동이 가능하며, 사용자가 컴퓨터에 입력한 내용을 기반으로 한 독특한 프레임워크 결과물을 산출해 낼 수 있다. 이러한 시스템을 사용하기 전에, 건축가가 설계를 제대로 했을지라도, 컴퓨터가 잘못 인식할 수도 있으므로 건축 설계자는 원하는 결과를 얻을 수 있도록 사전에 건축 디자인과 설계 과정을 생각해야 한다. 그런데 같은 과정을 입력했는데도 불구하고 건축 계획의 프레임워크 결과가 달라진다면, 그것은 제대로 된 건축 설계라고 볼 수 없다. 그러므로 정확하게 데이터 처리를 할 수 있는 도구가 건축 디자인과 설계를 함에 있어서 필요하다. 따라서 건축을 설계할 때, 건축의 새로운 패러다임으로 각종 데이터를 활용하여 논의의 사안을 찾아 구별해야 한다. 또한 이것을 바탕으로 다양한 정보융합과 공간클라우드를 접목하여 나타낼 수 있는 파라미터정보와 건축디자인을 연관시킨 공동주택계획안을 제시하였다."
        },
        {
          "rank": 5,
          "score": 0.6753146648406982,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 6,
          "score": 0.6689062118530273,
          "doc_id": "ATN0024933735",
          "title": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안",
          "abstract": "Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0024933735&target=NART&cn=ATN0024933735",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner."
        },
        {
          "rank": 7,
          "score": 0.662166953086853,
          "doc_id": "JAKO200835054210184",
          "title": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크",
          "abstract": "본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200835054210184&target=NART&cn=JAKO200835054210184",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다."
        },
        {
          "rank": 8,
          "score": 0.6588495969772339,
          "doc_id": "ATN0037490138",
          "title": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크",
          "abstract": "In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037490138&target=NART&cn=ATN0037490138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains."
        },
        {
          "rank": 9,
          "score": 0.6586199402809143,
          "doc_id": "JAKO201905653788881",
          "title": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안",
          "abstract": "오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905653788881&target=NART&cn=JAKO201905653788881",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다."
        },
        {
          "rank": 10,
          "score": 0.6552140712738037,
          "doc_id": "JAKO200932056735683",
          "title": "마이크로어레이 데이터 공유 시스템",
          "abstract": "최근, 마이크로어레이 실험 데이터의 품질과 재생산성에 대한 신뢰도가 증가하고 있어 마이크로어레이 데이터의 공유 및 활용에 대한 요구가 급속히 증가하고 있다. 그러나 공개되어 있는 국내, 외 마이크로어레이 데이터는 실험 방식, 플랫폼 등에 따라 서로 다른 데이터 항목과 포맷을 가지므로 데이터의 실제적 접근 및 활용이 어려운 상황이다. 본 논문에서는 실험 플랫폼, 데이터 포맷, 정규화 기법, 분석 방식 등이 서로 다른 기존의 마이크로어레이 데이터를 효율적으로 검색, 공유, 통합할 수 있는 마이크로어레이 데이터 공유 시스템을 제안한다. 제안된 시스템은 웹 서비스 기반 기술을 이용하여 분산된 마이크로어레이 데이터를 통합하며, 각 사이트의 사용자는 UDDI를 통하여 검색한 데이터를 표준 MGED 기반의 공통 데이터 구조로 자동 변환하여 다운 받을 수 있다. 정의된 공통 데이터 구조는 IDF,ADF,SDRF,EDF로 구성되어 다양한 구조의 마이크로어레이를 통합할 수 있는 템플릿 역할을 수행하며, MAGE-ML, MAGE-TAB, XML Schema 문서로 저장할 수 있다. 또한 제안된 시스템의 자동 데이터 제출기, 파일 관리자 등은 마이크로어레이 데이터 공유를 위한 다양한 부가 기능을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200932056735683&target=NART&cn=JAKO200932056735683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "마이크로어레이 데이터 공유 시스템 마이크로어레이 데이터 공유 시스템 마이크로어레이 데이터 공유 시스템 최근, 마이크로어레이 실험 데이터의 품질과 재생산성에 대한 신뢰도가 증가하고 있어 마이크로어레이 데이터의 공유 및 활용에 대한 요구가 급속히 증가하고 있다. 그러나 공개되어 있는 국내, 외 마이크로어레이 데이터는 실험 방식, 플랫폼 등에 따라 서로 다른 데이터 항목과 포맷을 가지므로 데이터의 실제적 접근 및 활용이 어려운 상황이다. 본 논문에서는 실험 플랫폼, 데이터 포맷, 정규화 기법, 분석 방식 등이 서로 다른 기존의 마이크로어레이 데이터를 효율적으로 검색, 공유, 통합할 수 있는 마이크로어레이 데이터 공유 시스템을 제안한다. 제안된 시스템은 웹 서비스 기반 기술을 이용하여 분산된 마이크로어레이 데이터를 통합하며, 각 사이트의 사용자는 UDDI를 통하여 검색한 데이터를 표준 MGED 기반의 공통 데이터 구조로 자동 변환하여 다운 받을 수 있다. 정의된 공통 데이터 구조는 IDF,ADF,SDRF,EDF로 구성되어 다양한 구조의 마이크로어레이를 통합할 수 있는 템플릿 역할을 수행하며, MAGE-ML, MAGE-TAB, XML Schema 문서로 저장할 수 있다. 또한 제안된 시스템의 자동 데이터 제출기, 파일 관리자 등은 마이크로어레이 데이터 공유를 위한 다양한 부가 기능을 제공한다."
        },
        {
          "rank": 11,
          "score": 0.6548894643783569,
          "doc_id": "JAKO201306464397174",
          "title": "콘텐츠 공유 프레임워크 기반의 다중 디바이스 간 협업 시스템",
          "abstract": "네트워크 환경에서 한 사용자가 공유 자원을 이용하여 작업을 수행할 때, 주변의 여러 스마트 디바이스를 활용하여 협업함으로써 사용자의 작업 효율을 향상시킬 수 있다. 하지만 각 스마트 디바이스의 해상도, 플랫폼, 브라우저 등의 고유 정보가 서로 다른 경우에는 협업 시스템을 구현하기 어렵다. 따라서 본 논문에서는 협업을 하고자 하는 사용자의 의도를 파악하고, 협업에 필요한 공유자원을 통해 협업을 수행하는 시스템을 제안한다. 제안하는 시스템은 콘텐츠 공유 프레임워크를 기반으로 다중 디바이스 간 콘텐츠를 공유할 수 있으며, 공유 자원을 동시에 처리하는 기능을 포함한다. 이를 통해 사용자는 하나의 작업을 기기 간에 협업을 통해 수행함으로써 단일 디바이스를 이용하는 것보다 작업의 효율을 높일 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201306464397174&target=NART&cn=JAKO201306464397174",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "콘텐츠 공유 프레임워크 기반의 다중 디바이스 간 협업 시스템 콘텐츠 공유 프레임워크 기반의 다중 디바이스 간 협업 시스템 콘텐츠 공유 프레임워크 기반의 다중 디바이스 간 협업 시스템 네트워크 환경에서 한 사용자가 공유 자원을 이용하여 작업을 수행할 때, 주변의 여러 스마트 디바이스를 활용하여 협업함으로써 사용자의 작업 효율을 향상시킬 수 있다. 하지만 각 스마트 디바이스의 해상도, 플랫폼, 브라우저 등의 고유 정보가 서로 다른 경우에는 협업 시스템을 구현하기 어렵다. 따라서 본 논문에서는 협업을 하고자 하는 사용자의 의도를 파악하고, 협업에 필요한 공유자원을 통해 협업을 수행하는 시스템을 제안한다. 제안하는 시스템은 콘텐츠 공유 프레임워크를 기반으로 다중 디바이스 간 콘텐츠를 공유할 수 있으며, 공유 자원을 동시에 처리하는 기능을 포함한다. 이를 통해 사용자는 하나의 작업을 기기 간에 협업을 통해 수행함으로써 단일 디바이스를 이용하는 것보다 작업의 효율을 높일 수 있다."
        },
        {
          "rank": 12,
          "score": 0.6541105508804321,
          "doc_id": "JAKO200914035207851",
          "title": "애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계",
          "abstract": "본 논문에서는 인터넷 상에서 애플리케이션 공유과 데이터 접근을 수행할 수 있는 씬-클라이언트 프레임워크를 설계할 것이며, 관련 기술로 X 윈도우 시스템, 가상 서버, CODA 파일 시스템, MPI(Message Passing Interface)를 활용하고자 한다. 우리는 네트워크 연결이 중단되더라도 서버 상에서 실행되던 애플리케이션을 로컬 상에서 실행할 수 있음은 물론 서버 상의 작업 수행으로 생성된 데이터에 클라이언트가 최적으로 접근할 수 있는 씬-클라이언트 프레임워크를 제안하고자 한다. 또한 네트워크가 복원되었을 때 로컬 상의 작업 내역이 서버에 효과적으로 반영될 수 있어야 할 것이다. 이러한 씬-클라이언트 프레임워크를 설계하기 위하여 본 논문에서는 기존의 시스템에 분산 Pseudo 서버, CODA 파일 시스템 기술을 접목시킬 것이며, 보다 효율적인 작업 수행, 관리를 위해 MPI를 활용할 것이다. 이를 통하여 네트워크 독립적인 씬-클라이언트 작업 환경을 구축할 수 있고 서버의 병목현상을 지양함으로써 다수의 사용자에게 확장성 있는 애플리케이션 서비스를 제공할 수 있다. 본 논문에서는 이를 구현함에 있어 기반이 되는 씬-클라이언트 프레임워크의 설계 방안에 대해 논의하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200914035207851&target=NART&cn=JAKO200914035207851",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 본 논문에서는 인터넷 상에서 애플리케이션 공유과 데이터 접근을 수행할 수 있는 씬-클라이언트 프레임워크를 설계할 것이며, 관련 기술로 X 윈도우 시스템, 가상 서버, CODA 파일 시스템, MPI(Message Passing Interface)를 활용하고자 한다. 우리는 네트워크 연결이 중단되더라도 서버 상에서 실행되던 애플리케이션을 로컬 상에서 실행할 수 있음은 물론 서버 상의 작업 수행으로 생성된 데이터에 클라이언트가 최적으로 접근할 수 있는 씬-클라이언트 프레임워크를 제안하고자 한다. 또한 네트워크가 복원되었을 때 로컬 상의 작업 내역이 서버에 효과적으로 반영될 수 있어야 할 것이다. 이러한 씬-클라이언트 프레임워크를 설계하기 위하여 본 논문에서는 기존의 시스템에 분산 Pseudo 서버, CODA 파일 시스템 기술을 접목시킬 것이며, 보다 효율적인 작업 수행, 관리를 위해 MPI를 활용할 것이다. 이를 통하여 네트워크 독립적인 씬-클라이언트 작업 환경을 구축할 수 있고 서버의 병목현상을 지양함으로써 다수의 사용자에게 확장성 있는 애플리케이션 서비스를 제공할 수 있다. 본 논문에서는 이를 구현함에 있어 기반이 되는 씬-클라이언트 프레임워크의 설계 방안에 대해 논의하고자 한다."
        },
        {
          "rank": 13,
          "score": 0.6524794101715088,
          "doc_id": "NART112054592",
          "title": "Satellite Data and Crowdsourcing",
          "abstract": "<P><B>Abstract</B></P>  <P>Crowdsourcing increases the value of satellite data by supplying human resources for processing them and providing complementary data. This article reviews previous research to clarify the stakeholders and their relationships in business ecosystems where satellite data and crowdsourcing are combined for new products and services. Crowdsourcing has three functions in satellite data businesses: analyzing, monitoring, and collecting data. The functions of collecting and monitoring complementary ground data that are used with satellite data have become increasingly important in recent years. The conclusions indicate that the business ecosystems have evolved from being led by satellite data platforms to being coordinated by third parties.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Crowdsourcing has three functions in satellite data business; analyzing, monitoring, and collecting data. </LI> <LI>  There are direct and indirect crowdsourcing involvement pattern in satellite data. </LI> <LI>  Ground data have increasingly important complimentary roles to satellite data. </LI> <LI>  Business models have evolved from being led by satellite data platforms to being coordinated by third parties. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART112054592&target=NART&cn=NART112054592",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Satellite Data and Crowdsourcing Satellite Data and Crowdsourcing Satellite Data and Crowdsourcing <P><B>Abstract</B></P>  <P>Crowdsourcing increases the value of satellite data by supplying human resources for processing them and providing complementary data. This article reviews previous research to clarify the stakeholders and their relationships in business ecosystems where satellite data and crowdsourcing are combined for new products and services. Crowdsourcing has three functions in satellite data businesses: analyzing, monitoring, and collecting data. The functions of collecting and monitoring complementary ground data that are used with satellite data have become increasingly important in recent years. The conclusions indicate that the business ecosystems have evolved from being led by satellite data platforms to being coordinated by third parties.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Crowdsourcing has three functions in satellite data business; analyzing, monitoring, and collecting data. </LI> <LI>  There are direct and indirect crowdsourcing involvement pattern in satellite data. </LI> <LI>  Ground data have increasingly important complimentary roles to satellite data. </LI> <LI>  Business models have evolved from being led by satellite data platforms to being coordinated by third parties. </LI> </UL> </P>"
        },
        {
          "rank": 14,
          "score": 0.6518160700798035,
          "doc_id": "JAKO201518564243615",
          "title": "공동혁신과 융합을 위한 개념적 프레임워크 및 플랫폼 설계",
          "abstract": "전통적으로 제품이나 서비스의 가치는 생산자에 의해 고객에게 제공되었다. 그러나 현대에 와서는 제품이나 서비스의 개발에 고객들의 참여가 폭 넓게 이루어지고 있다. 공동가치창출과 같은 공동혁신을 통해 고객은 기업의 제품이나 서비스의 설계, 생산, 마케팅, 그리고 판매 등에 참여하여 새로운 가치를 창출하고 있다. 공동가치창출과 같은 공동혁신을 통해 생산자와 고객 간의 벽이 무너지고 있는 것이다. 정보기술의 발전으로 인해 고객의 경험을 공유할 수 있는 기회가 증가하고 있다. 공동혁신은 새로운 경영기법을 적용하는 것이 아니라, 기업 활동과 세부 업무 자체를 변화시키는 패러다임으로 기업 활동에 고객이 참여하여 새로운 가치를 창출하는 것은 기존 업무 프로세스로는 수행하기 어렵고, 업무 프로세스를 공동혁신 활동에 맞추어 새롭게 변화시켜야 한다. 본 연구에서는 공동혁신을 통해 새로운 비즈니스 모델을 개발하기 위한 프레임워크와 이를 위한 서비스 플랫폼의 개념적 모델을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201518564243615&target=NART&cn=JAKO201518564243615",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공동혁신과 융합을 위한 개념적 프레임워크 및 플랫폼 설계 공동혁신과 융합을 위한 개념적 프레임워크 및 플랫폼 설계 공동혁신과 융합을 위한 개념적 프레임워크 및 플랫폼 설계 전통적으로 제품이나 서비스의 가치는 생산자에 의해 고객에게 제공되었다. 그러나 현대에 와서는 제품이나 서비스의 개발에 고객들의 참여가 폭 넓게 이루어지고 있다. 공동가치창출과 같은 공동혁신을 통해 고객은 기업의 제품이나 서비스의 설계, 생산, 마케팅, 그리고 판매 등에 참여하여 새로운 가치를 창출하고 있다. 공동가치창출과 같은 공동혁신을 통해 생산자와 고객 간의 벽이 무너지고 있는 것이다. 정보기술의 발전으로 인해 고객의 경험을 공유할 수 있는 기회가 증가하고 있다. 공동혁신은 새로운 경영기법을 적용하는 것이 아니라, 기업 활동과 세부 업무 자체를 변화시키는 패러다임으로 기업 활동에 고객이 참여하여 새로운 가치를 창출하는 것은 기존 업무 프로세스로는 수행하기 어렵고, 업무 프로세스를 공동혁신 활동에 맞추어 새롭게 변화시켜야 한다. 본 연구에서는 공동혁신을 통해 새로운 비즈니스 모델을 개발하기 위한 프레임워크와 이를 위한 서비스 플랫폼의 개념적 모델을 제시한다."
        },
        {
          "rank": 15,
          "score": 0.6498804092407227,
          "doc_id": "JAKO199811921340072",
          "title": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구",
          "abstract": "CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921340072&target=NART&cn=JAKO199811921340072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies."
        },
        {
          "rank": 16,
          "score": 0.6467865109443665,
          "doc_id": "NART94225864",
          "title": "Hengam a MapReduce-Based Distributed Data Warehouse for Big Data : A MapReduce-Based Distributed Data Warehouse for Big Data",
          "abstract": "<P>When working with a high volume of information that follows an exponential pattern, the authors confront big data. This huge amount of information makes big data retrieval and analytics important issues. There have been many attempts to solve data analytic problems using distributed platforms, but the main problem with the proposed methods is not observing the data locality. In this article, a MapReduce-based method called Hengam is proposed. In this method, data format unification helps nodes to have data independence. The unified format leads to an increase in the information retrieval speed and prevents data exchange betoen nodes. The proposed method was evaluated using data items from an ICT company and the information retrieval time was much better than that of other open-source distributed data warehouse software.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART94225864&target=NART&cn=NART94225864",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hengam a MapReduce-Based Distributed Data Warehouse for Big Data : A MapReduce-Based Distributed Data Warehouse for Big Data Hengam a MapReduce-Based Distributed Data Warehouse for Big Data : A MapReduce-Based Distributed Data Warehouse for Big Data Hengam a MapReduce-Based Distributed Data Warehouse for Big Data : A MapReduce-Based Distributed Data Warehouse for Big Data <P>When working with a high volume of information that follows an exponential pattern, the authors confront big data. This huge amount of information makes big data retrieval and analytics important issues. There have been many attempts to solve data analytic problems using distributed platforms, but the main problem with the proposed methods is not observing the data locality. In this article, a MapReduce-based method called Hengam is proposed. In this method, data format unification helps nodes to have data independence. The unified format leads to an increase in the information retrieval speed and prevents data exchange betoen nodes. The proposed method was evaluated using data items from an ICT company and the information retrieval time was much better than that of other open-source distributed data warehouse software.</P>"
        },
        {
          "rank": 17,
          "score": 0.6410520672798157,
          "doc_id": "JAKO201613360956661",
          "title": "서지프레임워크를 활용한 공공도서관 서지데이터와 서비스 데이터의 연계",
          "abstract": "본 연구에서는 공공도서관의 서비스 프로그램 운영과정에서 생산된 '서비스 데이터'를 서지데이터와 연계하여 도서관 목록을 개선시키고자 하였다. 이를 위해 2015년에 우수 도서관으로 선정된 공공도서관 7곳을 대상으로 서비스 데이터를 수집하고 분석하였다. 이를 바탕으로 서지데이터와 서비스 데이터를 서지프레임워크를 적용하여 시범적으로 연계하고, 활용 가능한 인터페이스를 제안하였다. 본 연구결과는 1) 선별적이고 가치 평가가 포함된 서지데이터를 확보하고, 2) 장서의 생애주기 동안 서지데이터를 지속적으로 업데이트할 수 있게 되며, 3) 체계적으로 관리되기 어려웠던 서지데이터의 보존성과 공유 가능성을 향상시킬 수 있으며, 4) 시맨틱웹 환경에서 외부 링크드 데이터를 추가적으로 연계할 수 있는 서지데이터 개발을 위한 기초자료로 활용될 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201613360956661&target=NART&cn=JAKO201613360956661",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서지프레임워크를 활용한 공공도서관 서지데이터와 서비스 데이터의 연계 서지프레임워크를 활용한 공공도서관 서지데이터와 서비스 데이터의 연계 서지프레임워크를 활용한 공공도서관 서지데이터와 서비스 데이터의 연계 본 연구에서는 공공도서관의 서비스 프로그램 운영과정에서 생산된 '서비스 데이터'를 서지데이터와 연계하여 도서관 목록을 개선시키고자 하였다. 이를 위해 2015년에 우수 도서관으로 선정된 공공도서관 7곳을 대상으로 서비스 데이터를 수집하고 분석하였다. 이를 바탕으로 서지데이터와 서비스 데이터를 서지프레임워크를 적용하여 시범적으로 연계하고, 활용 가능한 인터페이스를 제안하였다. 본 연구결과는 1) 선별적이고 가치 평가가 포함된 서지데이터를 확보하고, 2) 장서의 생애주기 동안 서지데이터를 지속적으로 업데이트할 수 있게 되며, 3) 체계적으로 관리되기 어려웠던 서지데이터의 보존성과 공유 가능성을 향상시킬 수 있으며, 4) 시맨틱웹 환경에서 외부 링크드 데이터를 추가적으로 연계할 수 있는 서지데이터 개발을 위한 기초자료로 활용될 수 있을 것이다."
        },
        {
          "rank": 18,
          "score": 0.6406545042991638,
          "doc_id": "NART93845311",
          "title": "Security Benefits of Little Data From the Socio-Technical Perspective :",
          "abstract": "<P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART93845311&target=NART&cn=NART93845311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : <P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>"
        },
        {
          "rank": 19,
          "score": 0.6365840435028076,
          "doc_id": "JAKO201909258120070",
          "title": "의료 빅 데이터를 활용한 서비스 제공 프레임워크 설계",
          "abstract": "본 논문에서는 의료용 빅 데이터를 활용하여 비즈니스와 연계하여 새로운 서비스를 창출하기 위한 프레임 워크를 설계하였다. 단순한 데이터 분석 단계를 나타내는 것이 아니라 데이터의 활용 목적을 명확히 하고, 이에 대한 분석을 수행하여 그 속에서 가치를 추출하고 실제 사업이나 서비스를 운용할 때까지의 과정을 설계한다. 설계된 프레임워크는 기본 아키텍처, 사회 시스템 모델까지 커버할 수 있도록 하였다. 설계된 프레임 워크를 참조하여 사회 시스템에 적용될 수 있도록 디자인하였으며, 기본 데이터로는 의료용 빅 데이터를 중심으로 하였다. 의료용 기본 데이터를 적용한 프레임 워크 설계로 여러 의료용 사업 제휴 및 서비스 창출을 실현할 수 있을 것으로 기대하고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909258120070&target=NART&cn=JAKO201909258120070",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 빅 데이터를 활용한 서비스 제공 프레임워크 설계 의료 빅 데이터를 활용한 서비스 제공 프레임워크 설계 의료 빅 데이터를 활용한 서비스 제공 프레임워크 설계 본 논문에서는 의료용 빅 데이터를 활용하여 비즈니스와 연계하여 새로운 서비스를 창출하기 위한 프레임 워크를 설계하였다. 단순한 데이터 분석 단계를 나타내는 것이 아니라 데이터의 활용 목적을 명확히 하고, 이에 대한 분석을 수행하여 그 속에서 가치를 추출하고 실제 사업이나 서비스를 운용할 때까지의 과정을 설계한다. 설계된 프레임워크는 기본 아키텍처, 사회 시스템 모델까지 커버할 수 있도록 하였다. 설계된 프레임 워크를 참조하여 사회 시스템에 적용될 수 있도록 디자인하였으며, 기본 데이터로는 의료용 빅 데이터를 중심으로 하였다. 의료용 기본 데이터를 적용한 프레임 워크 설계로 여러 의료용 사업 제휴 및 서비스 창출을 실현할 수 있을 것으로 기대하고 있다."
        },
        {
          "rank": 20,
          "score": 0.6342815160751343,
          "doc_id": "JAKO201117463449578",
          "title": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크",
          "abstract": "T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201117463449578&target=NART&cn=JAKO201117463449578",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스 Part 2: 하이브리드 서비스 저작 프레임워크 T-DMB 하이브리드 데이터 서비스는 서비스를 구성하는 장면 기술 정보와 객체 기술 정보를 방송망 이외의 전송 경로를 통해 분산 전송할 수 있도록 구성하는 하이브리드 BIFS 기술을 이용하여 기존 T-DMB 수신기와의 역호환성을 보장하면서 새로운 데이터 서비스를 제공한다. 본 논문에서는 하이브리드 BIFS 기술을 이용하여 분산 전송이 가능한 BIFS를 구성하기 위한 하이브리드 서비스 저작 프레임워크의 구현 결과와 이를 이용한 실험 결과를 소개한다. 하이브리드 서비스 저작 프레임워크는 서비스 생성 시스템, 서비스 관리 시스템, 콘텐츠 제공 시스템 등으로 구성되며, 통합된 하이브리드 서비스를 저작하는 것은 물론 이를 방송망으로 전송되는 데이터와 무선 통신망을 통해 전송되는 개인맞춤형 데이터로 분할하여 생성하고 관리하는 기능을 제공한다. 이 서비스 프레임워크를 통해 구현된 콘텐츠는 기존 수신기와의 역호환성을 보장하면서 새로운 개인맞춤형 데이터 서비스 구현이 가능함을 검증하였다."
        },
        {
          "rank": 21,
          "score": 0.6326359510421753,
          "doc_id": "JAKO201306366998119",
          "title": "클라우드 컴퓨팅 정보보호 프레임워크에 관한 연구",
          "abstract": "탄력성(elasticity), 빠른 적용과 릴리즈, 광대역 네트워크 접속, 다중 접속(multi-tenancy), 활용에 제한이 없는(ubiquity) 유연성 등 클라우드 컴퓨팅의 고유한 속성들은 클라우드를 선택한 기업과 기관에게 획기적인 효율성을 제공하지만 원천적으로 내재된 보안 위협을 제거해야 하는 대책수립이 필요하다. 이를 위해 본 논문에서는 전략적 연계 모델을 참조하여 클라우드 컴퓨팅 정보보호 프레임워크를 제시하였다. 클라우드 컴퓨팅 정보보호 프레임워크는 클라우드 위협, 보안통제 활동, 클라우드 이해관계자를 중심 축으로 합목적성, 책임성, 투명한 책임소재의 벽면으로 구성된다. 중심 축은 클라우드 환경에서 정보보호 활동을 수행하는 주요 목적인 위협 최소화목표와 이해관계자를 지정하고 그들이 해야 할 정보보호 활동을 정의하고 있다. 또한, 3개 벽면은 클라우드 환경에서 정보보호 활동을 수행하기 위한 원칙이며 중심 축 간의 접점에서 7개 서비스 패키지 도출을 위한 방향을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201306366998119&target=NART&cn=JAKO201306366998119",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "클라우드 컴퓨팅 정보보호 프레임워크에 관한 연구 클라우드 컴퓨팅 정보보호 프레임워크에 관한 연구 클라우드 컴퓨팅 정보보호 프레임워크에 관한 연구 탄력성(elasticity), 빠른 적용과 릴리즈, 광대역 네트워크 접속, 다중 접속(multi-tenancy), 활용에 제한이 없는(ubiquity) 유연성 등 클라우드 컴퓨팅의 고유한 속성들은 클라우드를 선택한 기업과 기관에게 획기적인 효율성을 제공하지만 원천적으로 내재된 보안 위협을 제거해야 하는 대책수립이 필요하다. 이를 위해 본 논문에서는 전략적 연계 모델을 참조하여 클라우드 컴퓨팅 정보보호 프레임워크를 제시하였다. 클라우드 컴퓨팅 정보보호 프레임워크는 클라우드 위협, 보안통제 활동, 클라우드 이해관계자를 중심 축으로 합목적성, 책임성, 투명한 책임소재의 벽면으로 구성된다. 중심 축은 클라우드 환경에서 정보보호 활동을 수행하는 주요 목적인 위협 최소화목표와 이해관계자를 지정하고 그들이 해야 할 정보보호 활동을 정의하고 있다. 또한, 3개 벽면은 클라우드 환경에서 정보보호 활동을 수행하기 위한 원칙이며 중심 축 간의 접점에서 7개 서비스 패키지 도출을 위한 방향을 제공한다."
        },
        {
          "rank": 22,
          "score": 0.6316465139389038,
          "doc_id": "DIKO0012543052",
          "title": "국방 IT 거버넌스 프레임워크 구축을 위한 핵심 추진전략 연구",
          "abstract": "1990년대 중반 이후 인터넷이나 휴대전화와 같은 정보기술의 보급에 따라, 정보가 사회 및 경제의 중심이 되는 정보화 사회로 변화하였다. 기업과 공공기관에 IT(정보기술)이 도입되면서 경영목표와 IT의 연계 필요성이 증대되었다. 또한 IT 전반에 대한 관리의 필요성이 대두되었다. 더불어 IT 투자의 중복을 방지하는 등의 ROI( Return On Investment : 투자수익)을 추구하는 조직이 늘어났다. 결과적으로 IT 거버넌스에 대해 학계와 산업계에서 다양한 정의와 설명들이 제시되고 있으며, 이미 선진기업에서는 IT 거버넌스라는 개념을 경영에 적용하고 있다. IT 거버넌스는 기업의 비즈니스와 IT에 영향을 미치는 구조적 결정인자들의 구조 및 동적양상을 나타내며, 비즈니스와 IT 관련 사내외 위원회 및 부서, 그리고 그들의 활동범위 및 연관관계를 나타내는 프레임워크, 조직도 및 프로세스 구성으로 표현이 된다. 이러한 외부적인 요인과 맞물려 현재 우리 군의 국방 비전과 목표를 달성하기 위한 국방 IT 거버넌스의 재확립은 필수적인 사항이 되었다. 본 논문에서는 국방 IT 거버넌스의 프레임워크를 구축하기 위한 핵심 추진전략에 대해서 기술하였다. 이러한 주장에 뒷받침하기 위해서 IT 거버넌스의 전반적인 내용을 기술하고 국내&amp;#8729;외와 해외의 군 사례를 분석하여 보고 국방 IT 거버넌스의 프레임워크 구축을 위한 핵심 추진전략을 연구하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012543052&target=NART&cn=DIKO0012543052",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 IT 거버넌스 프레임워크 구축을 위한 핵심 추진전략 연구 국방 IT 거버넌스 프레임워크 구축을 위한 핵심 추진전략 연구 국방 IT 거버넌스 프레임워크 구축을 위한 핵심 추진전략 연구 1990년대 중반 이후 인터넷이나 휴대전화와 같은 정보기술의 보급에 따라, 정보가 사회 및 경제의 중심이 되는 정보화 사회로 변화하였다. 기업과 공공기관에 IT(정보기술)이 도입되면서 경영목표와 IT의 연계 필요성이 증대되었다. 또한 IT 전반에 대한 관리의 필요성이 대두되었다. 더불어 IT 투자의 중복을 방지하는 등의 ROI( Return On Investment : 투자수익)을 추구하는 조직이 늘어났다. 결과적으로 IT 거버넌스에 대해 학계와 산업계에서 다양한 정의와 설명들이 제시되고 있으며, 이미 선진기업에서는 IT 거버넌스라는 개념을 경영에 적용하고 있다. IT 거버넌스는 기업의 비즈니스와 IT에 영향을 미치는 구조적 결정인자들의 구조 및 동적양상을 나타내며, 비즈니스와 IT 관련 사내외 위원회 및 부서, 그리고 그들의 활동범위 및 연관관계를 나타내는 프레임워크, 조직도 및 프로세스 구성으로 표현이 된다. 이러한 외부적인 요인과 맞물려 현재 우리 군의 국방 비전과 목표를 달성하기 위한 국방 IT 거버넌스의 재확립은 필수적인 사항이 되었다. 본 논문에서는 국방 IT 거버넌스의 프레임워크를 구축하기 위한 핵심 추진전략에 대해서 기술하였다. 이러한 주장에 뒷받침하기 위해서 IT 거버넌스의 전반적인 내용을 기술하고 국내&amp;#8729;외와 해외의 군 사례를 분석하여 보고 국방 IT 거버넌스의 프레임워크 구축을 위한 핵심 추진전략을 연구하였다."
        },
        {
          "rank": 23,
          "score": 0.6315321922302246,
          "doc_id": "JAKO201228439147521",
          "title": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할",
          "abstract": "현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201228439147521&target=NART&cn=JAKO201228439147521",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 공간정보 소셜플랫폼의 개념과 플랫포머로서 정부의 역할 현재의 공간정보서비스는 스마트 사회의 도래에 따라 정보화 사회에서 축적된 공간정보의 콘텐츠 및 기술적 자산을 기반으로 스마트 사회에 걸맞은 모습으로 새롭게 전환되어야 할 필요가 있다. 본 연구는 공간정보 오픈플랫폼이 보다 경쟁력 있고 지속적인 자생력을 갖추기 위하여 공간정보 소셜플랫폼으로 전환해야 하는 필요성을 제시하였다. 공간정보 오픈플랫폼이 공간정보 소셜플랫폼으로 점진적으로 진화하기 위한 소셜화의 요구조건들을 P. Savalle가 제시한 소셜플랫폼이 갖추어야 할 주요 개념을 기준으로 검토하였다. 이를 기반으로 스마트 사회에 대응한 공간정보 서비스의 구현기반으로서 공간정보 소셜플랫폼의 개념과 플랫포머로서의 정부의 역할을 제시하였다."
        },
        {
          "rank": 24,
          "score": 0.6284776926040649,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        },
        {
          "rank": 25,
          "score": 0.6281185746192932,
          "doc_id": "NART118817514",
          "title": "Ensuring the ethical use of big data: lessons from secure data access",
          "abstract": "<▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118817514&target=NART&cn=NART118817514",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access <▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>"
        },
        {
          "rank": 26,
          "score": 0.6239267587661743,
          "doc_id": "JAKO201134036350760",
          "title": "지속적인 실시간 공동 편집을 위한 프레임워크 개발",
          "abstract": "스마트폰의 보급과 소셜 네트워크 서비스의 활성화로 인해 문서 편집 분야에서도 여러 사용자가 하나의 문서를 동시에 편집하는 실시간 공동 편집에 대한 연구가 활발하게 진행되고 있다 실시간 공동 편집에서는 문서의 변경 사항에 대한 동기화를 위해서 참가자 간의 공동 편집 세션을 유지해야 한다. 공동 편집 중에 세션이 종료된다면 연결되어 있던 참가자들은 더 이상 공동 편집을 진행할 수 없게 된다 본 연구의 목적은 의도하지 않은 상황에서 편집 중인 세션이 종료되지 않는 지속적인 실시간 공동 편집을 위한 프레임워크를 개발하는 것이다. 본 논문에 제안된 공동 편집 프레임워크에서 공옹 편집 세션의 참가자는 언제든지 편집을 종료할 수 있고, 불안정한 네트워크로 인해 특정 참가자의 연결이 끊어지는 경우에도 공동 편집 세션은 지속적으로 유지될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201134036350760&target=NART&cn=JAKO201134036350760",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지속적인 실시간 공동 편집을 위한 프레임워크 개발 지속적인 실시간 공동 편집을 위한 프레임워크 개발 지속적인 실시간 공동 편집을 위한 프레임워크 개발 스마트폰의 보급과 소셜 네트워크 서비스의 활성화로 인해 문서 편집 분야에서도 여러 사용자가 하나의 문서를 동시에 편집하는 실시간 공동 편집에 대한 연구가 활발하게 진행되고 있다 실시간 공동 편집에서는 문서의 변경 사항에 대한 동기화를 위해서 참가자 간의 공동 편집 세션을 유지해야 한다. 공동 편집 중에 세션이 종료된다면 연결되어 있던 참가자들은 더 이상 공동 편집을 진행할 수 없게 된다 본 연구의 목적은 의도하지 않은 상황에서 편집 중인 세션이 종료되지 않는 지속적인 실시간 공동 편집을 위한 프레임워크를 개발하는 것이다. 본 논문에 제안된 공동 편집 프레임워크에서 공옹 편집 세션의 참가자는 언제든지 편집을 종료할 수 있고, 불안정한 네트워크로 인해 특정 참가자의 연결이 끊어지는 경우에도 공동 편집 세션은 지속적으로 유지될 수 있다."
        },
        {
          "rank": 27,
          "score": 0.6235964298248291,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 28,
          "score": 0.6234092116355896,
          "doc_id": "ATN0030056083",
          "title": "공공 빅데이터 플랫폼 참조모델 개발에 관한 연구",
          "abstract": "This paper presents a big data reference model for satisfying user requirements of publicdata providing and analyzing. In this paper extracted components analyzing the big data platformcomponents with Hadoop and standard activities such as NIST, ISO/IEC JTC 1 SC32. Andpresents structured public big data reference model, which is composed of big data platform, datashare channel, and user portal.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030056083&target=NART&cn=ATN0030056083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공공 빅데이터 플랫폼 참조모델 개발에 관한 연구 공공 빅데이터 플랫폼 참조모델 개발에 관한 연구 공공 빅데이터 플랫폼 참조모델 개발에 관한 연구 This paper presents a big data reference model for satisfying user requirements of publicdata providing and analyzing. In this paper extracted components analyzing the big data platformcomponents with Hadoop and standard activities such as NIST, ISO/IEC JTC 1 SC32. Andpresents structured public big data reference model, which is composed of big data platform, datashare channel, and user portal."
        },
        {
          "rank": 29,
          "score": 0.6209592223167419,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 30,
          "score": 0.6208739876747131,
          "doc_id": "JAKO201919163740628",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "초연결, 초지능을 특징으로 하는 4차 산업혁명이 태동하면서 사이버 물리 시스템이 눈앞에 다가온 가운데 사이버공간에서는 인간 생활에 대한 활동기록과 컴퓨터, 정보통신기기 뿐만아니라 사물인터넷과의 통신기록까지 막대한 양의 데이터가 매일 쏟아지고 있다. 3Vs로 대변되는 빅데이터는 국방분야에서도 적극적으로 활용되고 있는데 본 논문에서는 사이버공간에서의 군사작전을 효과적으로 수행될 수 있도록 하기 위한 빅데이터 거버넌스 모델을 제안하였다. 우리의 사이버공간 작전 임무를 구분하고 사이버공간에서 수집될 수 있는 빅데이터 유형을 분류한 후 빅데이터 거버넌스 이슈와 통합하여 빅데이터 거버넌스 프레임워크 모델을 구축하였다. 구축된 모델은 사례를 통하여 그 효용성을 증명하였으며 이를 통하여 국방분야에서 추진되는 빅데이터 활용방안에 기여한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201919163740628&target=NART&cn=JAKO201919163740628",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 초연결, 초지능을 특징으로 하는 4차 산업혁명이 태동하면서 사이버 물리 시스템이 눈앞에 다가온 가운데 사이버공간에서는 인간 생활에 대한 활동기록과 컴퓨터, 정보통신기기 뿐만아니라 사물인터넷과의 통신기록까지 막대한 양의 데이터가 매일 쏟아지고 있다. 3Vs로 대변되는 빅데이터는 국방분야에서도 적극적으로 활용되고 있는데 본 논문에서는 사이버공간에서의 군사작전을 효과적으로 수행될 수 있도록 하기 위한 빅데이터 거버넌스 모델을 제안하였다. 우리의 사이버공간 작전 임무를 구분하고 사이버공간에서 수집될 수 있는 빅데이터 유형을 분류한 후 빅데이터 거버넌스 이슈와 통합하여 빅데이터 거버넌스 프레임워크 모델을 구축하였다. 구축된 모델은 사례를 통하여 그 효용성을 증명하였으며 이를 통하여 국방분야에서 추진되는 빅데이터 활용방안에 기여한다."
        },
        {
          "rank": 31,
          "score": 0.6205025911331177,
          "doc_id": "JAKO202104753781061",
          "title": "마이데이터 비즈니스 생태계 모델 연구",
          "abstract": "본 연구는 마이데이터 개념 태동에 따라, 기존과 상이한 양상을 보이는 마이데이터 비즈니스 생태계의 프레임워크와 해당 생태계에 참여하는 행위자의 특징을 정의하는 것을 목적으로 한다. 마이데이터는 개인이 자신의 데이터의 주권을 행사하는 것이기에, 개인이 비즈니스의 핵심 행위자로 참여한다는 특성이 존재한다. 마이데이터 소유자인 개인, 마이데이터 생성자 및 활용 서비스 제공자와 더불어 개인의 데이터 관리를 지원하는 마이데이터 오퍼레이터가 비즈니스 생태계에 참여한다. 이에, 마이데이터 산업 생태계는 기존의 디지털 비즈니스 생태계와 상이하다. 그러나, 이러한 차별적인 특성에도 불구하고, 그간 마이데이터 생태계를 세밀히 분석한 연구들은 아직 진행되지 못하고 있다. 이에, 본 연구는 국내 마이데이터 산업 활성화를 위하여 국내&#x00B7;외 마이데이터 비즈니스의 사례연구를 수행하여, 마이데이터 비즈니스 생태계 모델을 제안하고자 한다. 이를 위하여, 45개의 해외 마이데이터 오퍼레이터 사례의 비즈니스 모델을 분석하여 4개 그룹 7개 유형으로 분류하였으며, 마이데이터 산업 생태계에서 마이데이터 오퍼레이터 역할의 중요성을 확인하고 발전적 생태계 모델을 제안하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202104753781061&target=NART&cn=JAKO202104753781061",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "마이데이터 비즈니스 생태계 모델 연구 마이데이터 비즈니스 생태계 모델 연구 마이데이터 비즈니스 생태계 모델 연구 본 연구는 마이데이터 개념 태동에 따라, 기존과 상이한 양상을 보이는 마이데이터 비즈니스 생태계의 프레임워크와 해당 생태계에 참여하는 행위자의 특징을 정의하는 것을 목적으로 한다. 마이데이터는 개인이 자신의 데이터의 주권을 행사하는 것이기에, 개인이 비즈니스의 핵심 행위자로 참여한다는 특성이 존재한다. 마이데이터 소유자인 개인, 마이데이터 생성자 및 활용 서비스 제공자와 더불어 개인의 데이터 관리를 지원하는 마이데이터 오퍼레이터가 비즈니스 생태계에 참여한다. 이에, 마이데이터 산업 생태계는 기존의 디지털 비즈니스 생태계와 상이하다. 그러나, 이러한 차별적인 특성에도 불구하고, 그간 마이데이터 생태계를 세밀히 분석한 연구들은 아직 진행되지 못하고 있다. 이에, 본 연구는 국내 마이데이터 산업 활성화를 위하여 국내&#x00B7;외 마이데이터 비즈니스의 사례연구를 수행하여, 마이데이터 비즈니스 생태계 모델을 제안하고자 한다. 이를 위하여, 45개의 해외 마이데이터 오퍼레이터 사례의 비즈니스 모델을 분석하여 4개 그룹 7개 유형으로 분류하였으며, 마이데이터 산업 생태계에서 마이데이터 오퍼레이터 역할의 중요성을 확인하고 발전적 생태계 모델을 제안하였다."
        },
        {
          "rank": 32,
          "score": 0.6202787756919861,
          "doc_id": "JAKO200211921093731",
          "title": "시간 데이타마이닝 프레임워크",
          "abstract": "시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921093731&target=NART&cn=JAKO200211921093731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다."
        },
        {
          "rank": 33,
          "score": 0.6199153661727905,
          "doc_id": "ATN0037504188",
          "title": "오픈소스 기반 서버리스 프레임워크에서의 서비스 메시 구조 및 서비스 성능 평가",
          "abstract": "Service mesh is a technology that enables service calls between internal services in a micro service architecture, and is widely used in a serverless framework that implements the functions of a micro service architecture in a cloud environment. However, the increase in service calls between internal services has a problem of delaying the overall service response speed, so frequent service calls within the framework should be avoided. Therefore, in this paper, a method of using service mesh without deteriorating the overall performance of the serverless framework was proposed, and for this purpose, the performance and function of the implemented service mesh was verified using OpenFx, an open source based serverless framework applying gRPC. This will be helpful to service developers for service distribution and management targeting serverless frameworks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037504188&target=NART&cn=ATN0037504188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "오픈소스 기반 서버리스 프레임워크에서의 서비스 메시 구조 및 서비스 성능 평가 오픈소스 기반 서버리스 프레임워크에서의 서비스 메시 구조 및 서비스 성능 평가 오픈소스 기반 서버리스 프레임워크에서의 서비스 메시 구조 및 서비스 성능 평가 Service mesh is a technology that enables service calls between internal services in a micro service architecture, and is widely used in a serverless framework that implements the functions of a micro service architecture in a cloud environment. However, the increase in service calls between internal services has a problem of delaying the overall service response speed, so frequent service calls within the framework should be avoided. Therefore, in this paper, a method of using service mesh without deteriorating the overall performance of the serverless framework was proposed, and for this purpose, the performance and function of the implemented service mesh was verified using OpenFx, an open source based serverless framework applying gRPC. This will be helpful to service developers for service distribution and management targeting serverless frameworks."
        },
        {
          "rank": 34,
          "score": 0.6190608143806458,
          "doc_id": "JAKO201607564005851",
          "title": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시",
          "abstract": "본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201607564005851&target=NART&cn=JAKO201607564005851",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다."
        },
        {
          "rank": 35,
          "score": 0.6187542676925659,
          "doc_id": "JAKO201336448942825",
          "title": "AHP를 이용한 NAS 연동형 망분리 시스템에 관한 연구",
          "abstract": "국가 공공기관이나 기업에서는 질 높은 서비스를 제공하기 위하여 인테넷 망을 통해 정보 및 자료를 제공하고 있다. 하지만 자료의 송수신간에 악성코드 감염에 노출되어 각종 보안위협에 노출되게 된다. 이러한 이유로 2008년부터 국가 기관의 망 분리 사업이 진행되고 있고, 망 분리 기술로 망 연계 스토리지를 이용하여 물리적 망 분리와 더불어 데이터 연동을 하게 된다. 하지만 망 연계 스토리지는 동일 데이터가 내부 망 스토리지와 외부 망 스토리지에 각각 존재하게 되어 자원의 낭비와 더불어 데이터 관리에 문제점을 가지게 된다. 따라서, 본 연구는 물리적 망 분리의 한계점을 극복하기 위한 방안으로, NAS 스토리지를 이용한 내외부망 데이터 연계 방안을 제안하고, 망 분리 최적화를 위한 항목의 우선순위를 AHP기법을 통하여 검증하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201336448942825&target=NART&cn=JAKO201336448942825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 이용한 NAS 연동형 망분리 시스템에 관한 연구 AHP를 이용한 NAS 연동형 망분리 시스템에 관한 연구 AHP를 이용한 NAS 연동형 망분리 시스템에 관한 연구 국가 공공기관이나 기업에서는 질 높은 서비스를 제공하기 위하여 인테넷 망을 통해 정보 및 자료를 제공하고 있다. 하지만 자료의 송수신간에 악성코드 감염에 노출되어 각종 보안위협에 노출되게 된다. 이러한 이유로 2008년부터 국가 기관의 망 분리 사업이 진행되고 있고, 망 분리 기술로 망 연계 스토리지를 이용하여 물리적 망 분리와 더불어 데이터 연동을 하게 된다. 하지만 망 연계 스토리지는 동일 데이터가 내부 망 스토리지와 외부 망 스토리지에 각각 존재하게 되어 자원의 낭비와 더불어 데이터 관리에 문제점을 가지게 된다. 따라서, 본 연구는 물리적 망 분리의 한계점을 극복하기 위한 방안으로, NAS 스토리지를 이용한 내외부망 데이터 연계 방안을 제안하고, 망 분리 최적화를 위한 항목의 우선순위를 AHP기법을 통하여 검증하고자 한다."
        },
        {
          "rank": 36,
          "score": 0.6173020601272583,
          "doc_id": "NPAP12116569",
          "title": "Big data analytics on large-scale socio-technical software engineering archives",
          "abstract": "<P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12116569&target=NART&cn=NPAP12116569",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives <P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>"
        },
        {
          "rank": 37,
          "score": 0.6171285510063171,
          "doc_id": "DIKO0012654277",
          "title": "클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구",
          "abstract": "디지털 포렌식이란 과학적이거나 기술적인 기법을 사용하여 범죄수사 또는 증거를 수집하는 행위이이다. 이를 위한 도구로 디지털 포렌식 도구가 존재한다. 이 도구는 법과 기술 간의 매개체가 될 수 있는 핵심 요소라 할 수 있다[1]. 디지털 포렌식은 증거 이미징, 분석, 검색, 보고서 작성 등의 일련의 절차를 요구한다. 기존의 디지털 포렌식 도구는 이러한 절차적 기능을 제공하는 것을 목적으로 개발되었다. 현존하는 대부분의 포렌식 도구들은 단일 플랫폼 상의 윈도우 운영체제에서 운용되는 통합 도구로 제공된다. 이동성을 위해 휴대형 하드디스크 드라이브에 저장되며 해당 매체 내에서 실행된다. 목적에 따라 전용 기능을 제공하는 하드웨어 형태의 도구로도 제작 된다. 추가적으로 압수한 데스크탑을 포렌식 연구실로 이동하기 위해서 특수한 장치가 필요할 수 있다. 현재 단일 플랫폼 형태의 포렌식 도구에서 2TB의 데이터를 이미징 하는데 7시간이 걸리며 비트와이즈 검색을 20MB/s 정도의 속도로 처리해 1TB 이미지를 검색 했을 때에는 14시간이 소요된다[2]. 이는 양적으로 증가하는 디지털 증거의 추세에 미루어 볼 때 향후 도구의 증거 처리 속도 문제를 야기 시킬 것이다. 또, 증거물을 포렌식 연구실로 이송을 하거나 고속 처리를 하기위해서는 기타 하드웨어 장치를 이용해야 하고, 이는 도구 사용에 있어 불필요한 번거로움을 초래한다. 따라서 기존의 도구를 아우를 수 있는 새로운 도구 개발이 시급하다. 프로세싱 속도 향상을 위해 단일 플랫폼의 한계를 극복해야하고, 이용의 번거로움을 피하기 위해 모든 장비들을 하나의 도구로 합쳐야 한다. 기존의 도구를 기능을 아우를 수 있고, 단점을 제거하기위해 클라우드 컴퓨팅 개념을 적용해 해결 방안을 모색하였다. 본 논문에서는 클라우드 컴퓨팅[3]을 이용하여 디지털 포렌식 절차에 따라 어디에서든 포렌식을 수행 할 수 있는 DFSaaS(Digital Forensic Software as a Service) 구조와 이에 대한 시나리오를 제시하고, 이들에 대한 프레임워크를 연구한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012654277&target=NART&cn=DIKO0012654277",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 디지털 포렌식이란 과학적이거나 기술적인 기법을 사용하여 범죄수사 또는 증거를 수집하는 행위이이다. 이를 위한 도구로 디지털 포렌식 도구가 존재한다. 이 도구는 법과 기술 간의 매개체가 될 수 있는 핵심 요소라 할 수 있다[1]. 디지털 포렌식은 증거 이미징, 분석, 검색, 보고서 작성 등의 일련의 절차를 요구한다. 기존의 디지털 포렌식 도구는 이러한 절차적 기능을 제공하는 것을 목적으로 개발되었다. 현존하는 대부분의 포렌식 도구들은 단일 플랫폼 상의 윈도우 운영체제에서 운용되는 통합 도구로 제공된다. 이동성을 위해 휴대형 하드디스크 드라이브에 저장되며 해당 매체 내에서 실행된다. 목적에 따라 전용 기능을 제공하는 하드웨어 형태의 도구로도 제작 된다. 추가적으로 압수한 데스크탑을 포렌식 연구실로 이동하기 위해서 특수한 장치가 필요할 수 있다. 현재 단일 플랫폼 형태의 포렌식 도구에서 2TB의 데이터를 이미징 하는데 7시간이 걸리며 비트와이즈 검색을 20MB/s 정도의 속도로 처리해 1TB 이미지를 검색 했을 때에는 14시간이 소요된다[2]. 이는 양적으로 증가하는 디지털 증거의 추세에 미루어 볼 때 향후 도구의 증거 처리 속도 문제를 야기 시킬 것이다. 또, 증거물을 포렌식 연구실로 이송을 하거나 고속 처리를 하기위해서는 기타 하드웨어 장치를 이용해야 하고, 이는 도구 사용에 있어 불필요한 번거로움을 초래한다. 따라서 기존의 도구를 아우를 수 있는 새로운 도구 개발이 시급하다. 프로세싱 속도 향상을 위해 단일 플랫폼의 한계를 극복해야하고, 이용의 번거로움을 피하기 위해 모든 장비들을 하나의 도구로 합쳐야 한다. 기존의 도구를 기능을 아우를 수 있고, 단점을 제거하기위해 클라우드 컴퓨팅 개념을 적용해 해결 방안을 모색하였다. 본 논문에서는 클라우드 컴퓨팅[3]을 이용하여 디지털 포렌식 절차에 따라 어디에서든 포렌식을 수행 할 수 있는 DFSaaS(Digital Forensic Software as a Service) 구조와 이에 대한 시나리오를 제시하고, 이들에 대한 프레임워크를 연구한다."
        },
        {
          "rank": 38,
          "score": 0.6161819100379944,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 39,
          "score": 0.6154969334602356,
          "doc_id": "JAKO201526650061635",
          "title": "산업융합환경을 위한 보안 거버넌스 프레임워크 설계",
          "abstract": "산업과 ICT 기술간의 융합으로 새로운 부가가치를 창출할 수 있는 융합환경이 도래되어짐에 따라 경제성장과 더불어 우리의 삶의 질이 향상 되고 있지만 이러한 융합환경은 다수의 이익만을 제공하는 것이 아니라 융복합적인 보안 위협이 발생됨에 따라 다양한 보안문제를 발생시켰다. 이러한 보안 문제를 해결하기 위해서는 기존의 기술적인 접근으로 단편적인 보안 문제 해결방식이 아닌 통합적인 관점에서 보안문제를 접근할 필요가 있다. 그래서 본 연구에서는 전략적 관점, 관리적/운영적관점, 기술적 관점 등 다차원적인 관점에서 신뢰성 있는 보안 거버넌스 관리를 할 수 있도록 인적측면이 고려되어진 보안 거버넌스 프레임워크를 개발하였다. 그래서 이 프레임워크를 통해 보안 관리에 대한 단일 기준을 제시함으로서 최고 경영진들의 직접적인 관여가 가능하고 조직구성원들이 스스로 보안활동을 수행하고 책임 질수 있는 신뢰성 있는 보안관리체계를 구축할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201526650061635&target=NART&cn=JAKO201526650061635",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업융합환경을 위한 보안 거버넌스 프레임워크 설계 산업과 ICT 기술간의 융합으로 새로운 부가가치를 창출할 수 있는 융합환경이 도래되어짐에 따라 경제성장과 더불어 우리의 삶의 질이 향상 되고 있지만 이러한 융합환경은 다수의 이익만을 제공하는 것이 아니라 융복합적인 보안 위협이 발생됨에 따라 다양한 보안문제를 발생시켰다. 이러한 보안 문제를 해결하기 위해서는 기존의 기술적인 접근으로 단편적인 보안 문제 해결방식이 아닌 통합적인 관점에서 보안문제를 접근할 필요가 있다. 그래서 본 연구에서는 전략적 관점, 관리적/운영적관점, 기술적 관점 등 다차원적인 관점에서 신뢰성 있는 보안 거버넌스 관리를 할 수 있도록 인적측면이 고려되어진 보안 거버넌스 프레임워크를 개발하였다. 그래서 이 프레임워크를 통해 보안 관리에 대한 단일 기준을 제시함으로서 최고 경영진들의 직접적인 관여가 가능하고 조직구성원들이 스스로 보안활동을 수행하고 책임 질수 있는 신뢰성 있는 보안관리체계를 구축할 수 있을 것이다."
        },
        {
          "rank": 40,
          "score": 0.6153264045715332,
          "doc_id": "ATN0025420772",
          "title": "빅데이터, 오픈데이터, 마이데이터의 비교 연구",
          "abstract": "With the advent of the fourth industrial revolution, data becomes very important resource. Now is called as ‘Data Revolution Age.’ It is said that Data Revolution Age started with Big Data, then accelerated with Open Data, finally completed with My Data. In this paper, we compared Big Data, Open Data, and suggested roles and effects of My Data as a digital resource.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420772&target=NART&cn=ATN0025420772",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 With the advent of the fourth industrial revolution, data becomes very important resource. Now is called as ‘Data Revolution Age.’ It is said that Data Revolution Age started with Big Data, then accelerated with Open Data, finally completed with My Data. In this paper, we compared Big Data, Open Data, and suggested roles and effects of My Data as a digital resource."
        },
        {
          "rank": 41,
          "score": 0.6150942444801331,
          "doc_id": "JAKO201908559987020",
          "title": "스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계",
          "abstract": "엔터프라이즈 환경의 표준화 경쟁은 백엔드의 데이터 티어로 시작하여 대표적인 엔터프라이즈 미들 티어가 스프링 프레임워크로 받아들여짐으로써 표준화로 안정화되고 있는 실정이다. 또한 점차 빠른 주기로 새로운 디바이스의 출현으로 웹과 모바일 서비스에 대한 호환성 확보가 웹 서비스 기업들의 중요한 경쟁력이 되고 있다. 그러나 국내 기업들은 이러한 정보화 시대의 격변한 환경 변화에 적절한 역량있는 기술 인력을 확보하지 못하고 있으며, 교육중심 대학들의 교육과정에서도 새로운 역량중심의 교육과정의 요구를 반영하지 못하고 있는 실정이다. 따라서 본 연구에서는 이러한 엔터프라이즈 시스템 플랫폼 환경에서 필요한 역량중심의 기술을 습득과 교육과정을 개발하기 위하여 스프링 프레임워크 환경에서 스프링 데이터 JPA를 활용한 시스템을 분석 및 설계 단계별로 문서화 작성을 통하여 구현하였다. 향후 엔터프라이즈 환경에서의 바로 적용할 수 있는 풀 스택 역량중심의 교육과정 및 캡스톤 디자인 교육과정의 참조 모델을 제공하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201908559987020&target=NART&cn=JAKO201908559987020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 엔터프라이즈 환경의 표준화 경쟁은 백엔드의 데이터 티어로 시작하여 대표적인 엔터프라이즈 미들 티어가 스프링 프레임워크로 받아들여짐으로써 표준화로 안정화되고 있는 실정이다. 또한 점차 빠른 주기로 새로운 디바이스의 출현으로 웹과 모바일 서비스에 대한 호환성 확보가 웹 서비스 기업들의 중요한 경쟁력이 되고 있다. 그러나 국내 기업들은 이러한 정보화 시대의 격변한 환경 변화에 적절한 역량있는 기술 인력을 확보하지 못하고 있으며, 교육중심 대학들의 교육과정에서도 새로운 역량중심의 교육과정의 요구를 반영하지 못하고 있는 실정이다. 따라서 본 연구에서는 이러한 엔터프라이즈 시스템 플랫폼 환경에서 필요한 역량중심의 기술을 습득과 교육과정을 개발하기 위하여 스프링 프레임워크 환경에서 스프링 데이터 JPA를 활용한 시스템을 분석 및 설계 단계별로 문서화 작성을 통하여 구현하였다. 향후 엔터프라이즈 환경에서의 바로 적용할 수 있는 풀 스택 역량중심의 교육과정 및 캡스톤 디자인 교육과정의 참조 모델을 제공하고자 한다."
        },
        {
          "rank": 42,
          "score": 0.6131340265274048,
          "doc_id": "JAKO201110264496611",
          "title": "침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크",
          "abstract": "이 논문에서는 침입 탐지시스템의 체계적인 경보데이터관리 및 경보데이터 상관관계 분석을 위하여 데이터 마이닝 기법을 적용한 경보 데이터 마이닝 프레임워크를 제안한다. 적용된 마이닝 기법은 속성기반 연관규칙, 속성기반 빈발에피소드, 오경보 분류, 그리고 순서기반 클러스터링이다. 이들 구성요소들은 각각 대량의 경보 데이터들로부터 알려지지 않은 패턴을 탐사하여 공격시나리오를 유추하거나, 공격 순서를 예측하는 것이 가능하며, 데이터의 그룹화를 통해 고수준의 의미를 추출할 수 있게 해준다. 실험 및 평가를 위하여 제안된 경보데이터 마이닝 프레임워크의 프로토타입을 구축하였으며 프레임워크의 기능을 검증하였다. 이 논문에서 제안한 경보 데이터 마이닝 프레임워크는 기존의 경보데이터 상관관계분석에서는 해결하지 못했던 통합적인 경보 상관관계 분석 기능을 수행할 뿐만 아니라 대량의 경보데이터에 대한 필터링을 수행하는 장점을 가진다. 또한 추출된 규칙 및 공격시나리오는 침입탐지시스템의 실시간 대응에 활용될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201110264496611&target=NART&cn=JAKO201110264496611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 이 논문에서는 침입 탐지시스템의 체계적인 경보데이터관리 및 경보데이터 상관관계 분석을 위하여 데이터 마이닝 기법을 적용한 경보 데이터 마이닝 프레임워크를 제안한다. 적용된 마이닝 기법은 속성기반 연관규칙, 속성기반 빈발에피소드, 오경보 분류, 그리고 순서기반 클러스터링이다. 이들 구성요소들은 각각 대량의 경보 데이터들로부터 알려지지 않은 패턴을 탐사하여 공격시나리오를 유추하거나, 공격 순서를 예측하는 것이 가능하며, 데이터의 그룹화를 통해 고수준의 의미를 추출할 수 있게 해준다. 실험 및 평가를 위하여 제안된 경보데이터 마이닝 프레임워크의 프로토타입을 구축하였으며 프레임워크의 기능을 검증하였다. 이 논문에서 제안한 경보 데이터 마이닝 프레임워크는 기존의 경보데이터 상관관계분석에서는 해결하지 못했던 통합적인 경보 상관관계 분석 기능을 수행할 뿐만 아니라 대량의 경보데이터에 대한 필터링을 수행하는 장점을 가진다. 또한 추출된 규칙 및 공격시나리오는 침입탐지시스템의 실시간 대응에 활용될 수 있다."
        },
        {
          "rank": 43,
          "score": 0.6125534772872925,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 44,
          "score": 0.612069845199585,
          "doc_id": "JAKO200311922053515",
          "title": "자원인자 기반 스케줄링 프레임워크",
          "abstract": "대규모 환경의 고성능 그리드 구현을 위해서는 기존 그리드 자원 스케줄링 파라다임이 갖 성능 확장성 측면의 제한성을 극복할 수 있는 새로운 자원 스케줄링 프레임워크가 요구된다. 본 연구에서는 자원 스케줄링 성능 최적화를 목표로 자원인자 그래프(Resource Parameter Graph), 자원인자 인덱스 트리(Resource Parameter Index Tree), 그리고 정적 자원 정보 리포지터리로 구성되는 자원인자 스케줄링 프레임워크를 제안한다. 자원인자 그래프는 자원간의 관계 및 자원의 계층적 구성을 나타낼 수 있는 자원표현기법이며 이러한 표현을 기술하기 위한 XML 기반 자원정보 및 자원요청 기술 스키마를 설계하였다. 또한 자원인자 인덱스 트리는 자원 스케줄링의 자원탐색 및 자원할당, 상태정보 공지 등의 알고리즘의 효율적인 지원을 위한 메모리 기반 인덱스의 데이터 구조이다. 본 논문에서는 이러한 자원인자 스케줄링 프레임워크의 구성 내용에 대하여 기술한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922053515&target=NART&cn=JAKO200311922053515",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자원인자 기반 스케줄링 프레임워크 자원인자 기반 스케줄링 프레임워크 자원인자 기반 스케줄링 프레임워크 대규모 환경의 고성능 그리드 구현을 위해서는 기존 그리드 자원 스케줄링 파라다임이 갖 성능 확장성 측면의 제한성을 극복할 수 있는 새로운 자원 스케줄링 프레임워크가 요구된다. 본 연구에서는 자원 스케줄링 성능 최적화를 목표로 자원인자 그래프(Resource Parameter Graph), 자원인자 인덱스 트리(Resource Parameter Index Tree), 그리고 정적 자원 정보 리포지터리로 구성되는 자원인자 스케줄링 프레임워크를 제안한다. 자원인자 그래프는 자원간의 관계 및 자원의 계층적 구성을 나타낼 수 있는 자원표현기법이며 이러한 표현을 기술하기 위한 XML 기반 자원정보 및 자원요청 기술 스키마를 설계하였다. 또한 자원인자 인덱스 트리는 자원 스케줄링의 자원탐색 및 자원할당, 상태정보 공지 등의 알고리즘의 효율적인 지원을 위한 메모리 기반 인덱스의 데이터 구조이다. 본 논문에서는 이러한 자원인자 스케줄링 프레임워크의 구성 내용에 대하여 기술한다."
        },
        {
          "rank": 45,
          "score": 0.6111043691635132,
          "doc_id": "NART87199447",
          "title": "HDM: A Composable Framework for Big Data Processing",
          "abstract": "<P>Over the past years, frameworks such as MapReduce and Spark have been introduced to ease the task of developing big data programs and applications. However, the jobs in these frameworks are roughly defined and packaged as executable jars without any functionality being exposed or described. This means that deployed jobs are not natively composable and reusable for subsequent development. Besides, it also hampers the ability for applying optimizations on the data flow of job sequences and pipelines. In this paper, we present the Hierarchically Distributed Data Matrix (HDM) which is a functional, strongly-typed data representation for writing composable big data applications. Along with HDM, a runtime framework is provided to support the execution, integration and management of HDM applications on distributed infrastructures. Based on the functional data dependency graph of HDM, multiple optimizations are applied to improve the performance of executing HDM jobs. The experimental results show that our optimizations can achieve improvements between 10 to 40 percent of the Job-Completion-Time for different types of applications when compared with the current state of art, Apache Spark.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART87199447&target=NART&cn=NART87199447",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "HDM: A Composable Framework for Big Data Processing HDM: A Composable Framework for Big Data Processing HDM: A Composable Framework for Big Data Processing <P>Over the past years, frameworks such as MapReduce and Spark have been introduced to ease the task of developing big data programs and applications. However, the jobs in these frameworks are roughly defined and packaged as executable jars without any functionality being exposed or described. This means that deployed jobs are not natively composable and reusable for subsequent development. Besides, it also hampers the ability for applying optimizations on the data flow of job sequences and pipelines. In this paper, we present the Hierarchically Distributed Data Matrix (HDM) which is a functional, strongly-typed data representation for writing composable big data applications. Along with HDM, a runtime framework is provided to support the execution, integration and management of HDM applications on distributed infrastructures. Based on the functional data dependency graph of HDM, multiple optimizations are applied to improve the performance of executing HDM jobs. The experimental results show that our optimizations can achieve improvements between 10 to 40 percent of the Job-Completion-Time for different types of applications when compared with the current state of art, Apache Spark.</P>"
        },
        {
          "rank": 46,
          "score": 0.6108593344688416,
          "doc_id": "ATN0030123575",
          "title": "빅데이터는 누구의 소유인가?: 빅데이터의 저작권법에 의한 보호와 공공부문의 빅데이터 활용 문제",
          "abstract": "For a last few years, the “Big data” has become one of the trendiest keywords of the ever-changing world. Big data has been exploited increasingly and considered as an indispensable tool for the proper decision-making not only in the private business branch but also in the public sector. In the course of the modern governance, lots of information can be collected rapidly.\nIt is disputed amongst writers how to regulate the misuse of the personal data when bringing the data into the big data practice. However, it remains not properly discussed who owns the big data that is already collected and organized electronically to be used in analyzing. The Korean Copyright Act has introduced the regime of the database protection, which shall also apply to the big data(bases). As the technology of big data as well as database of the ordinary art are concerned, we can find a large amount of the similarities so far. The Act guarantees the investor thereof an exclusive right to extract and re-use the “substantial” part of data.\nThe big data governed by the public agencies can also claim the protection under the Korean copyright law. Protecting the data from the public’s use might produce some negative effects. Its ownership itself could be, however, the key to enable the efficient management of the big data and to guarantee the quality of the data therein. It is, therefore, necessary to build an appropriate legal basis to promote the use of big data on the one side and to regulate its abuse on the other.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123575&target=NART&cn=ATN0030123575",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터는 누구의 소유인가?: 빅데이터의 저작권법에 의한 보호와 공공부문의 빅데이터 활용 문제 빅데이터는 누구의 소유인가?: 빅데이터의 저작권법에 의한 보호와 공공부문의 빅데이터 활용 문제 빅데이터는 누구의 소유인가?: 빅데이터의 저작권법에 의한 보호와 공공부문의 빅데이터 활용 문제 For a last few years, the “Big data” has become one of the trendiest keywords of the ever-changing world. Big data has been exploited increasingly and considered as an indispensable tool for the proper decision-making not only in the private business branch but also in the public sector. In the course of the modern governance, lots of information can be collected rapidly.\nIt is disputed amongst writers how to regulate the misuse of the personal data when bringing the data into the big data practice. However, it remains not properly discussed who owns the big data that is already collected and organized electronically to be used in analyzing. The Korean Copyright Act has introduced the regime of the database protection, which shall also apply to the big data(bases). As the technology of big data as well as database of the ordinary art are concerned, we can find a large amount of the similarities so far. The Act guarantees the investor thereof an exclusive right to extract and re-use the “substantial” part of data.\nThe big data governed by the public agencies can also claim the protection under the Korean copyright law. Protecting the data from the public’s use might produce some negative effects. Its ownership itself could be, however, the key to enable the efficient management of the big data and to guarantee the quality of the data therein. It is, therefore, necessary to build an appropriate legal basis to promote the use of big data on the one side and to regulate its abuse on the other."
        },
        {
          "rank": 47,
          "score": 0.6104296445846558,
          "doc_id": "JAKO201216349186631",
          "title": "조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크",
          "abstract": "최근 서비스 기반의 소프트웨어 개발이 사용자의 다양한 요구를 충족시킬 수 있는 하나의 솔루션으로 부각되면서, 안정적인 서비스의 조합을 통하여 보다 큰 서비스를 제공하려는 시도가 증가하고 있다. 그러나 조합된 서비스의 개발시 고려되어야 하는 사항중의 하나는 사용자의 입장에서 서비스의 정확성과 함께 신속성을 제공해야 한다는 것이다. 왜냐하면 사용자가 서비스의 요청 과정에서 늦은 응답으로 인하여 실행 버튼을 중복적으로 클릭하는 행동을 보이기 때문이다. 본 논문에서는 조합된 서비스의 성능을 측정하기 위한 테스팅 프레임워크를 제시한다. 즉, 조합된 서비스의 실행 시간을 측정함으로써, 개발자에게 서비스의 성능을 분석할 수 있는 도구를 제공한다. 이러한 실행시간 측정을 위하여 본 연구에서는 Aspect 컴포넌트를 이용하는 타이머 서비스를 개발하여 기존 웹 서비스들과 연동할 수 있도록 하였다. 또한 몇 실험을 통하여 조합된 서비스의 성능 테스트가 가능함을 확인하였다. 제시한 프레임워크는 조합된 서비스를 구성하는 단위 서비스 중에서 가장 많은 시간이 소요되는 서비스를 식별하고 필요에 따라 다른 서비스로 대체할 수 있는 서비스 개발을 가능하게 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201216349186631&target=NART&cn=JAKO201216349186631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 최근 서비스 기반의 소프트웨어 개발이 사용자의 다양한 요구를 충족시킬 수 있는 하나의 솔루션으로 부각되면서, 안정적인 서비스의 조합을 통하여 보다 큰 서비스를 제공하려는 시도가 증가하고 있다. 그러나 조합된 서비스의 개발시 고려되어야 하는 사항중의 하나는 사용자의 입장에서 서비스의 정확성과 함께 신속성을 제공해야 한다는 것이다. 왜냐하면 사용자가 서비스의 요청 과정에서 늦은 응답으로 인하여 실행 버튼을 중복적으로 클릭하는 행동을 보이기 때문이다. 본 논문에서는 조합된 서비스의 성능을 측정하기 위한 테스팅 프레임워크를 제시한다. 즉, 조합된 서비스의 실행 시간을 측정함으로써, 개발자에게 서비스의 성능을 분석할 수 있는 도구를 제공한다. 이러한 실행시간 측정을 위하여 본 연구에서는 Aspect 컴포넌트를 이용하는 타이머 서비스를 개발하여 기존 웹 서비스들과 연동할 수 있도록 하였다. 또한 몇 실험을 통하여 조합된 서비스의 성능 테스트가 가능함을 확인하였다. 제시한 프레임워크는 조합된 서비스를 구성하는 단위 서비스 중에서 가장 많은 시간이 소요되는 서비스를 식별하고 필요에 따라 다른 서비스로 대체할 수 있는 서비스 개발을 가능하게 한다."
        },
        {
          "rank": 48,
          "score": 0.6101201772689819,
          "doc_id": "JAKO201012259057254",
          "title": "데이터 품질관리 프레임워크와 비즈니스 시나리오",
          "abstract": "e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201012259057254&target=NART&cn=JAKO201012259057254",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다."
        },
        {
          "rank": 49,
          "score": 0.6097428202629089,
          "doc_id": "JAKO202009252092311",
          "title": "공공 빅데이터 플랫폼 성과평가 모형",
          "abstract": "본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009252092311&target=NART&cn=JAKO202009252092311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 공공 빅데이터 플랫폼 성과평가 모형 본 연구는 공공데이터 개방에 있어 공공데이터 제공자의 데이터 기여 측면과 공공데이터 사용자의 데이터 활용 측면을 고려하여 공공데이터 플랫폼 성과측정을 위한 프레임워크를 개발하였다. 본 연구는 NIST(2018)의 빅데이터 참조 아키텍처와 Neely et al.(2001)의 성과 프리즘을 기반으로 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역을 제시하였다. 구체적으로, 공공데이터 플랫폼 성과평가 영역은 이해관계자 기여, 빅데이터 거버넌스 역량, 빅데이터 서비스 역량, 빅데이터 정보기술(IT) 역량, 그리고 이해관계자 만족으로 구성된다. 본 연구에서 제시한 공공 빅데이터 플랫폼 성과평가 모형의 5개 영역과 24개 평가지표에 대한 측정 문항은 총 75개 항목으로 구성되었다."
        },
        {
          "rank": 50,
          "score": 0.6091549396514893,
          "doc_id": "NART56283057",
          "title": "참조무결성을 활용한 데이터베이스로 부터 독립적인 데이터웨어하우스 뷰 관리",
          "abstract": "<P>데이터웨어하우스(DW) 뷰는 기존의 DB로부터 저장뷰(materialized view)의 형태로 만들어지는 것이 일반적이다. DW와 DB는 기술적으로나 활용 측면에서 현격한 차이가 있어서 실제로 이들은 별개의 시스템에 구축되는 것이 일반적이나, 내용상 DW는 기존DB에 크게 의존적이다. 본 연구에서는 그 근본적인 한계가 현행 DB와 DW의 철저하지 못한 분리에 있다는 것에 착안하여 이를 대수적으로 보이고, 그 철저한 분리를 위한 새로운 대안을 제시했다. 이는 기존의 DB에서 데이터의 무결성을 위해 사용하는 참조무결성을 활용하여 DW뷰의 갱신에 적용한 것으로 실험을 통해 그 효과를 입증했다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56283057&target=NART&cn=NART56283057",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "참조무결성을 활용한 데이터베이스로 부터 독립적인 데이터웨어하우스 뷰 관리 참조무결성을 활용한 데이터베이스로 부터 독립적인 데이터웨어하우스 뷰 관리 참조무결성을 활용한 데이터베이스로 부터 독립적인 데이터웨어하우스 뷰 관리 <P>데이터웨어하우스(DW) 뷰는 기존의 DB로부터 저장뷰(materialized view)의 형태로 만들어지는 것이 일반적이다. DW와 DB는 기술적으로나 활용 측면에서 현격한 차이가 있어서 실제로 이들은 별개의 시스템에 구축되는 것이 일반적이나, 내용상 DW는 기존DB에 크게 의존적이다. 본 연구에서는 그 근본적인 한계가 현행 DB와 DW의 철저하지 못한 분리에 있다는 것에 착안하여 이를 대수적으로 보이고, 그 철저한 분리를 위한 새로운 대안을 제시했다. 이는 기존의 DB에서 데이터의 무결성을 위해 사용하는 참조무결성을 활용하여 DW뷰의 갱신에 적용한 것으로 실험을 통해 그 효과를 입증했다.</P>"
        }
      ]
    },
    {
      "query": "What is the role of near real-time analytics within this framework?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6657903790473938,
          "doc_id": "JAKO201905653788881",
          "title": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안",
          "abstract": "오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905653788881&target=NART&cn=JAKO201905653788881",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다."
        },
        {
          "rank": 2,
          "score": 0.6428700685501099,
          "doc_id": "JAKO202018955008139",
          "title": "준 실시간 뉴스 이슈 분석을 위한 계층적&#183;점증적 군집화",
          "abstract": "실시간으로 발생하는 뉴스 기사로부터 이슈를 분석하기 위한 다양한 연구가 진행되어 왔다. 하지만 범주에 따라 계층적으로 이슈를 분석하는 연구는 많이 진행되지 않았고, 계층적 이슈 분석을 위한 기존의 연구에서 제안하는 방식 또한 뉴스 기사 증가에 따라 군집화 속도가 느려지는 문제점이 있다. 따라서 본 논문에서는 준 실시간으로 뉴스 기사의 이슈를 분석하는 계층적&#x00B7;점증적 군집화 방식을 제안한다. 제안하는 군집화 방식은 샴 신경망을 이용한 가중 코사인 유사도 측정 모델 기반의 k-평균 알고리즘을 이용한 단어 군집 기반 문서 표현 방식을 통해 뉴스 기사를 문서 벡터로 표현한다. 그리고 문서 벡터로부터 초기 이슈 군집 트리를 생성하고, 새로 발생한 뉴스 기사를 해당 이슈 군집 트리에 추가하는 점증적 군집화 방식을 제안함으로써 뉴스 기사의 계층적 이슈를 준 실시간으로 분석한다. 마지막으로, 본 논문에서 제안하는 방식과 기존 방식들과의 성능평가를 통해 제안하는 군집화 방식이 정확도 측면에서 기존 방식 대비 NMI 지표 기준 0.26 정도 성능이 향상되었고, 속도 측면에서 약 10배 이상의 성능이 향상됨을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202018955008139&target=NART&cn=JAKO202018955008139",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "준 실시간 뉴스 이슈 분석을 위한 계층적&#183;점증적 군집화 준 실시간 뉴스 이슈 분석을 위한 계층적&#183;점증적 군집화 준 실시간 뉴스 이슈 분석을 위한 계층적&#183;점증적 군집화 실시간으로 발생하는 뉴스 기사로부터 이슈를 분석하기 위한 다양한 연구가 진행되어 왔다. 하지만 범주에 따라 계층적으로 이슈를 분석하는 연구는 많이 진행되지 않았고, 계층적 이슈 분석을 위한 기존의 연구에서 제안하는 방식 또한 뉴스 기사 증가에 따라 군집화 속도가 느려지는 문제점이 있다. 따라서 본 논문에서는 준 실시간으로 뉴스 기사의 이슈를 분석하는 계층적&#x00B7;점증적 군집화 방식을 제안한다. 제안하는 군집화 방식은 샴 신경망을 이용한 가중 코사인 유사도 측정 모델 기반의 k-평균 알고리즘을 이용한 단어 군집 기반 문서 표현 방식을 통해 뉴스 기사를 문서 벡터로 표현한다. 그리고 문서 벡터로부터 초기 이슈 군집 트리를 생성하고, 새로 발생한 뉴스 기사를 해당 이슈 군집 트리에 추가하는 점증적 군집화 방식을 제안함으로써 뉴스 기사의 계층적 이슈를 준 실시간으로 분석한다. 마지막으로, 본 논문에서 제안하는 방식과 기존 방식들과의 성능평가를 통해 제안하는 군집화 방식이 정확도 측면에서 기존 방식 대비 NMI 지표 기준 0.26 정도 성능이 향상되었고, 속도 측면에서 약 10배 이상의 성능이 향상됨을 입증하였다."
        },
        {
          "rank": 3,
          "score": 0.6423677206039429,
          "doc_id": "JAKO201216349186631",
          "title": "조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크",
          "abstract": "최근 서비스 기반의 소프트웨어 개발이 사용자의 다양한 요구를 충족시킬 수 있는 하나의 솔루션으로 부각되면서, 안정적인 서비스의 조합을 통하여 보다 큰 서비스를 제공하려는 시도가 증가하고 있다. 그러나 조합된 서비스의 개발시 고려되어야 하는 사항중의 하나는 사용자의 입장에서 서비스의 정확성과 함께 신속성을 제공해야 한다는 것이다. 왜냐하면 사용자가 서비스의 요청 과정에서 늦은 응답으로 인하여 실행 버튼을 중복적으로 클릭하는 행동을 보이기 때문이다. 본 논문에서는 조합된 서비스의 성능을 측정하기 위한 테스팅 프레임워크를 제시한다. 즉, 조합된 서비스의 실행 시간을 측정함으로써, 개발자에게 서비스의 성능을 분석할 수 있는 도구를 제공한다. 이러한 실행시간 측정을 위하여 본 연구에서는 Aspect 컴포넌트를 이용하는 타이머 서비스를 개발하여 기존 웹 서비스들과 연동할 수 있도록 하였다. 또한 몇 실험을 통하여 조합된 서비스의 성능 테스트가 가능함을 확인하였다. 제시한 프레임워크는 조합된 서비스를 구성하는 단위 서비스 중에서 가장 많은 시간이 소요되는 서비스를 식별하고 필요에 따라 다른 서비스로 대체할 수 있는 서비스 개발을 가능하게 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201216349186631&target=NART&cn=JAKO201216349186631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 조합된 서비스의 성능 평가를 위한 Aspect 기반 테스팅 프레임워크 최근 서비스 기반의 소프트웨어 개발이 사용자의 다양한 요구를 충족시킬 수 있는 하나의 솔루션으로 부각되면서, 안정적인 서비스의 조합을 통하여 보다 큰 서비스를 제공하려는 시도가 증가하고 있다. 그러나 조합된 서비스의 개발시 고려되어야 하는 사항중의 하나는 사용자의 입장에서 서비스의 정확성과 함께 신속성을 제공해야 한다는 것이다. 왜냐하면 사용자가 서비스의 요청 과정에서 늦은 응답으로 인하여 실행 버튼을 중복적으로 클릭하는 행동을 보이기 때문이다. 본 논문에서는 조합된 서비스의 성능을 측정하기 위한 테스팅 프레임워크를 제시한다. 즉, 조합된 서비스의 실행 시간을 측정함으로써, 개발자에게 서비스의 성능을 분석할 수 있는 도구를 제공한다. 이러한 실행시간 측정을 위하여 본 연구에서는 Aspect 컴포넌트를 이용하는 타이머 서비스를 개발하여 기존 웹 서비스들과 연동할 수 있도록 하였다. 또한 몇 실험을 통하여 조합된 서비스의 성능 테스트가 가능함을 확인하였다. 제시한 프레임워크는 조합된 서비스를 구성하는 단위 서비스 중에서 가장 많은 시간이 소요되는 서비스를 식별하고 필요에 따라 다른 서비스로 대체할 수 있는 서비스 개발을 가능하게 한다."
        },
        {
          "rank": 4,
          "score": 0.6394791007041931,
          "doc_id": "JAKO201722163435084",
          "title": "원심압축기 공력성능 해석 프레임워크 구축",
          "abstract": "A framework for the aerodynamic performance analysis of a centrifugal compressor was constructed using the non-dimensional performance. Because of the much time and efforts for the new design of centrifugal compressors, it is widely used in the industry to assess the performance of the compressor under the new operating conditions based on the existing performance results and to apply some design changes to the existing compressors. When checking the performance of centrifugal compressors for different operating conditions by using the existing results, it is easy to utilize the non-dimensional performance head coefficient. If the framework of the non-dimensional performance coefficient is utilized, it is convenient to input design variables and performance curve data. Also it is easy to perform the non-dimensional analysis and performance review for off-design points. The accuracy of the framework was verified by comparison with the results of two 1-stage centrifugal compressors at off-design conditions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201722163435084&target=NART&cn=JAKO201722163435084",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "원심압축기 공력성능 해석 프레임워크 구축 원심압축기 공력성능 해석 프레임워크 구축 원심압축기 공력성능 해석 프레임워크 구축 A framework for the aerodynamic performance analysis of a centrifugal compressor was constructed using the non-dimensional performance. Because of the much time and efforts for the new design of centrifugal compressors, it is widely used in the industry to assess the performance of the compressor under the new operating conditions based on the existing performance results and to apply some design changes to the existing compressors. When checking the performance of centrifugal compressors for different operating conditions by using the existing results, it is easy to utilize the non-dimensional performance head coefficient. If the framework of the non-dimensional performance coefficient is utilized, it is convenient to input design variables and performance curve data. Also it is easy to perform the non-dimensional analysis and performance review for off-design points. The accuracy of the framework was verified by comparison with the results of two 1-stage centrifugal compressors at off-design conditions."
        },
        {
          "rank": 5,
          "score": 0.6356474161148071,
          "doc_id": "JAKO200708508458599",
          "title": "시간 결정성을 보장하는 실시간 태스크 스케줄링",
          "abstract": "오늘날의 내장형 시스템은 군사 무기체계, 로봇, 인공위성 등과 같이 전통적인 내장형 시스템에서 휴대폰, 디지털 캠코더, PMP, MP3플레이어와 같은 보다 복잡한 응용프로그램 구동을 필요로 하는 휴대용 시스템으로 그 영역을 넓혀가고 있다. 이런 내장형 실시간 시스템은 내장형 시스템의 한정된 자원을 효율적으로 관리하고 시간적 논리적 정확성을 보장하기 위해 실시간 운영체제를 사용한다. 실시간 운영체제의 서비스를 통해 응용프로그래머는 응용프로그램을 구성하는 각 태스크가 시간 결정성에 위배되지 않도록 응용프로그램을 구현할 수 있다. 더욱이, 실시간 운영체제는 시간 결정성 보장을 위해 스케줄링과 문맥교환에 사용되는 시간을 예측할 수 있어야 한다. 본 논문에서는 추가적인 메모리 오버헤드 없이 22r 레벨의 우선순위를 갖는 시스템에서 고정 상수 시간 내에 가장 높은 우선순위를 갖는 태스크를 결정할 수 있는 알고리즘에 대해 기술한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200708508458599&target=NART&cn=JAKO200708508458599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 결정성을 보장하는 실시간 태스크 스케줄링 시간 결정성을 보장하는 실시간 태스크 스케줄링 시간 결정성을 보장하는 실시간 태스크 스케줄링 오늘날의 내장형 시스템은 군사 무기체계, 로봇, 인공위성 등과 같이 전통적인 내장형 시스템에서 휴대폰, 디지털 캠코더, PMP, MP3플레이어와 같은 보다 복잡한 응용프로그램 구동을 필요로 하는 휴대용 시스템으로 그 영역을 넓혀가고 있다. 이런 내장형 실시간 시스템은 내장형 시스템의 한정된 자원을 효율적으로 관리하고 시간적 논리적 정확성을 보장하기 위해 실시간 운영체제를 사용한다. 실시간 운영체제의 서비스를 통해 응용프로그래머는 응용프로그램을 구성하는 각 태스크가 시간 결정성에 위배되지 않도록 응용프로그램을 구현할 수 있다. 더욱이, 실시간 운영체제는 시간 결정성 보장을 위해 스케줄링과 문맥교환에 사용되는 시간을 예측할 수 있어야 한다. 본 논문에서는 추가적인 메모리 오버헤드 없이 22r 레벨의 우선순위를 갖는 시스템에서 고정 상수 시간 내에 가장 높은 우선순위를 갖는 태스크를 결정할 수 있는 알고리즘에 대해 기술한다."
        },
        {
          "rank": 6,
          "score": 0.6347630620002747,
          "doc_id": "JAKO200310912304785",
          "title": "위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구",
          "abstract": "차세대 무선 인터넷의 킬러 어플리케이션으로 주목받고 있는 위치기반서비스는 시간에 따른 시공간 객체의 위치 및 영역 변화에 대한 분석 기능이 필수적이다. 시공간 데이터베이스 시스템은 대용량 시공간객체의 실시간 위치 정보를 효과적으로 저장하고 빠른 검색을 제공하는 시스템으로 그 필요성이 증가하고 있다. 또한, 시공간 데이터베이스 시스템에서는 시공간 객체의 비공간정보와 공간정보 및 시간정보를 통합 관리할 수 있고, 시간 정보와 관련된 연산을 효율적으로 처리할 수 있는 시공간 데이터모델에 대한 연구가 활발히 진행중이다. 본 논문에서는 시간 흐름에 따라 동적으로 변화하는 시공간 객체 정보들을 현재 시점의 상태와 과거의 변화 과정에 대한 정보를 효과적으로 관리할 수 있는 시공간 데이터 모델을 제안한다. 또한 제안하는 시공간 데이터 모델을 위한 다양한 시공간 연산을 설계하며, 시공간 데이터와 시공간 객체 연산의 무결성을 유지하기 위한 제약조건을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200310912304785&target=NART&cn=JAKO200310912304785",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 위치 기반 서비스를 위한 시공간 데이터모델에 관한 연구 차세대 무선 인터넷의 킬러 어플리케이션으로 주목받고 있는 위치기반서비스는 시간에 따른 시공간 객체의 위치 및 영역 변화에 대한 분석 기능이 필수적이다. 시공간 데이터베이스 시스템은 대용량 시공간객체의 실시간 위치 정보를 효과적으로 저장하고 빠른 검색을 제공하는 시스템으로 그 필요성이 증가하고 있다. 또한, 시공간 데이터베이스 시스템에서는 시공간 객체의 비공간정보와 공간정보 및 시간정보를 통합 관리할 수 있고, 시간 정보와 관련된 연산을 효율적으로 처리할 수 있는 시공간 데이터모델에 대한 연구가 활발히 진행중이다. 본 논문에서는 시간 흐름에 따라 동적으로 변화하는 시공간 객체 정보들을 현재 시점의 상태와 과거의 변화 과정에 대한 정보를 효과적으로 관리할 수 있는 시공간 데이터 모델을 제안한다. 또한 제안하는 시공간 데이터 모델을 위한 다양한 시공간 연산을 설계하며, 시공간 데이터와 시공간 객체 연산의 무결성을 유지하기 위한 제약조건을 제시한다."
        },
        {
          "rank": 7,
          "score": 0.633903980255127,
          "doc_id": "ATN0040736710",
          "title": "Edge TPU에서의 실시간성 보장을 위한 실시간 DNN 프레임워크",
          "abstract": "As deep neural networks (DNNs) have been recently deployed in many safety-critical real-time embedded systems, it has become essential to meet timing requirements that DNN inference tasks must complete their execution within given deadlines. To this end, most previous studies focus on utilizing GPU or CPU in edge computing environments to support real-time DNN tasks. Meanwhile, although Edge TPU is regarded as a next-generation AI processor for edge computing, there is a lack of studies on real-time guarantee for Edge TPU. Thus, this paper presents a novel real-time DNN framework that can satisfy the timing requirements of multiple DNN inference tasks in edge TPU environments. This framework provides 1) a cache memory allocation technique that considers the deadline of each task and 2) a scheduling technique based on model segmentation to reduce priority inversion phenomena. We evaluated the performance of our framework by using Google Coral dev board, an embedded board equipped with Edge TPU, and several image classification models. The experiment result shows that our framework can provide higher schedulability by 37% than the existing Edge TPU system.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0040736710&target=NART&cn=ATN0040736710",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Edge TPU에서의 실시간성 보장을 위한 실시간 DNN 프레임워크 Edge TPU에서의 실시간성 보장을 위한 실시간 DNN 프레임워크 Edge TPU에서의 실시간성 보장을 위한 실시간 DNN 프레임워크 As deep neural networks (DNNs) have been recently deployed in many safety-critical real-time embedded systems, it has become essential to meet timing requirements that DNN inference tasks must complete their execution within given deadlines. To this end, most previous studies focus on utilizing GPU or CPU in edge computing environments to support real-time DNN tasks. Meanwhile, although Edge TPU is regarded as a next-generation AI processor for edge computing, there is a lack of studies on real-time guarantee for Edge TPU. Thus, this paper presents a novel real-time DNN framework that can satisfy the timing requirements of multiple DNN inference tasks in edge TPU environments. This framework provides 1) a cache memory allocation technique that considers the deadline of each task and 2) a scheduling technique based on model segmentation to reduce priority inversion phenomena. We evaluated the performance of our framework by using Google Coral dev board, an embedded board equipped with Edge TPU, and several image classification models. The experiment result shows that our framework can provide higher schedulability by 37% than the existing Edge TPU system."
        },
        {
          "rank": 8,
          "score": 0.6298365592956543,
          "doc_id": "NART97302075",
          "title": "Big data processing framework for manufacturing",
          "abstract": "<P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97302075&target=NART&cn=NART97302075",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data processing framework for manufacturing Big data processing framework for manufacturing Big data processing framework for manufacturing <P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>"
        },
        {
          "rank": 9,
          "score": 0.629365086555481,
          "doc_id": "NART107094279",
          "title": "A practical guide to IT OT convergence - getting value from your business analytics",
          "abstract": "<P> A lot of time, effort and money has been and is being spent by operating companies and service companies in collecting data from many different sources, agglomerating that data, carrying out analytics on that data with the intention of turning that data into actionable insights that positively impact safety, environment, operations and profitability. This has been done with varying levels of success by approaching the problem from either an information technology (IT) or an operational technology (OT) point of view. What we are finding is that the best outcomes are achieved by having IT and OT domain experience with operational industry expertise within the same team. This has proven to be the case in other industries. There is also a need to understand edge and cloud actionable insights delivery in order to determine the optimal balance of edge and cloud delivery in a hybrid solution model. There is a continuum of analytics from high speed analytics at the edge, for such things as assisting regulatory control and real-time safety system diagnostics, to data lake analysis in the cloud, for planning, supply chain and business prioritisation and optimisation. Some analytics are best done at the edge; some are better done in the cloud. It&rsquo;s a &lsquo;horses for courses&rsquo; approach. The nature of the desired outcome, the required actionable insight and the nature of the data gathering are critical in determining the most effective approach. This paper discusses several examples of how this integrated IT OT approach took a desired outcome and turned it into an analytics platform that delivered significant value to the business. This paper cites examples of edge and cloud analytics that are enabled by integrating clever and sufficient industrial internet of things (IIoT) connectivity, which lead to actionable insights. These, in turn, ensured the correct action was effectively applied to the correct part(s) of the business operation, resulting in effective achievement of the desired outcome. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART107094279&target=NART&cn=NART107094279",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A practical guide to IT OT convergence - getting value from your business analytics A practical guide to IT OT convergence - getting value from your business analytics A practical guide to IT OT convergence - getting value from your business analytics <P> A lot of time, effort and money has been and is being spent by operating companies and service companies in collecting data from many different sources, agglomerating that data, carrying out analytics on that data with the intention of turning that data into actionable insights that positively impact safety, environment, operations and profitability. This has been done with varying levels of success by approaching the problem from either an information technology (IT) or an operational technology (OT) point of view. What we are finding is that the best outcomes are achieved by having IT and OT domain experience with operational industry expertise within the same team. This has proven to be the case in other industries. There is also a need to understand edge and cloud actionable insights delivery in order to determine the optimal balance of edge and cloud delivery in a hybrid solution model. There is a continuum of analytics from high speed analytics at the edge, for such things as assisting regulatory control and real-time safety system diagnostics, to data lake analysis in the cloud, for planning, supply chain and business prioritisation and optimisation. Some analytics are best done at the edge; some are better done in the cloud. It&rsquo;s a &lsquo;horses for courses&rsquo; approach. The nature of the desired outcome, the required actionable insight and the nature of the data gathering are critical in determining the most effective approach. This paper discusses several examples of how this integrated IT OT approach took a desired outcome and turned it into an analytics platform that delivered significant value to the business. This paper cites examples of edge and cloud analytics that are enabled by integrating clever and sufficient industrial internet of things (IIoT) connectivity, which lead to actionable insights. These, in turn, ensured the correct action was effectively applied to the correct part(s) of the business operation, resulting in effective achievement of the desired outcome. </P>"
        },
        {
          "rank": 10,
          "score": 0.6286351680755615,
          "doc_id": "JAKO200211921093731",
          "title": "시간 데이타마이닝 프레임워크",
          "abstract": "시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921093731&target=NART&cn=JAKO200211921093731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝 프레임워크 시간 데이타마이닝은 기존 데이타마이닝에 시간 개념을 추가하여 '시간값을 가진 대용량 데이타로부터 이전에 잘 알려지지는 않았지만, 묵시적이고 잠재적으로 유용한 시간 지식을 탐사하는 기술'로 정의된다. 시간 지식이란 주기적 패턴, 캘린더 패턴, 경향 등과 같이 시간 의미와 시간 관계를 가진 지식을 말한다. 실세계에서는 환자의 병력, 상품 구매 이력, 웹 로그 등과 같은 다양한 시간 데이타가 존재하며 이로부터 여러 형태의 유용한 시간 지식을 찾아낼 수 있다. 데이타마이닝에 대한 연구가 진행되면서 순차 패턴, 유사 시계열 탐사, 주기적 연관규칙 탐사 등과 같이 시간 지식을 탐사하고자 하는 시간 데이타마이닝에 대한 부분적인 연구가 수행되었다. 그러나 기존 연구는 단순히 데이타의 발생 순서 및 유사한 패턴을 찾아내는데 중점을 두고 있어 데이타가 포함하고 있는 시간 의미와 시간 관계를 탐사하는데 부족하며, 시간 지식의 전체적인 측면보다는 연관 규칙과 같은 일부분만을 다루고 있다는 문제점을 가지고 있다. 따라서 이 논문에서는 시간 데이타마이닝에 대한 체계적인 연구를 위하여 시간 데이타마이닝에 대한 기존 연구 내용과 해결해야 할 문제점을 분석하고 이를 바탕으로 전체적인 프레임워크를 제시하였다. 또한 그 구현 방안 및 적용평가를 수행하였다. 프레임워크에서는 시간 데이타마이닝 모델을 제안하고, 이를 바탕으로 시간 데이타마이닝 질의어와 시간 지식을 탐사할 수 있는 시간 데이타마이닝 시스템을 설계하였다."
        },
        {
          "rank": 11,
          "score": 0.6262527704238892,
          "doc_id": "NART73533144",
          "title": "A Deep Awareness Framework for Pervasive Video Cloud",
          "abstract": "<P>Context-awareness for big data applications is different from that of traditional applications in that it is getting challenging to obtain the contexts from big data due to the complexity, velocity, variety, and other aspects of big data, especially big video data. The awareness of contexts in big data is more difficult, and should be more in-depth than that of classical applications. Therefore, in this paper, we propose an in-depth context-awareness framework for a pervasive video cloud in order to obtain underlying contexts in big video data. In this framework, we propose an approach that combines the historical view with the current view to obtain meaningful in-depth contexts, where deep learning techniques are used to obtain raw context data. We have conducted initial evaluations to show the effectiveness of the proposed approach in terms of performance and also the accuracy of obtaining the contexts. The evaluation results show that the proposed approach is effective for real-time context-awareness in a pervasive video cloud.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73533144&target=NART&cn=NART73533144",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Deep Awareness Framework for Pervasive Video Cloud A Deep Awareness Framework for Pervasive Video Cloud A Deep Awareness Framework for Pervasive Video Cloud <P>Context-awareness for big data applications is different from that of traditional applications in that it is getting challenging to obtain the contexts from big data due to the complexity, velocity, variety, and other aspects of big data, especially big video data. The awareness of contexts in big data is more difficult, and should be more in-depth than that of classical applications. Therefore, in this paper, we propose an in-depth context-awareness framework for a pervasive video cloud in order to obtain underlying contexts in big video data. In this framework, we propose an approach that combines the historical view with the current view to obtain meaningful in-depth contexts, where deep learning techniques are used to obtain raw context data. We have conducted initial evaluations to show the effectiveness of the proposed approach in terms of performance and also the accuracy of obtaining the contexts. The evaluation results show that the proposed approach is effective for real-time context-awareness in a pervasive video cloud.</P>"
        },
        {
          "rank": 12,
          "score": 0.6213531494140625,
          "doc_id": "NART111547998",
          "title": "Big Data Processing-Beyond Batch Processing",
          "abstract": "<P>This paper mainly focus on analysis of large sets of students data with one of the batch processing analysis techniques Beyond batch process, analysis of data streaming is done based on program of word counting program which executes data with HDFS along with dynamic created data. To compute similar coherent strategies one can implement a schema named batch and streaming process which dynamically creates data. The architecture is reduced to serve as X-Platform which uses ample number of tools for batch and stream analysis on this proposed frame work. Here we use spark-sql, a query language which acts as interface for interactive process to have iterative processes. Real time streaming data processing involves spark streaming works. Here we focus on preliminary evaluation of results and analysis report which compares data sets performance and also achieve low latency rate with usage of RDD.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111547998&target=NART&cn=NART111547998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing-Beyond Batch Processing Big Data Processing-Beyond Batch Processing Big Data Processing-Beyond Batch Processing <P>This paper mainly focus on analysis of large sets of students data with one of the batch processing analysis techniques Beyond batch process, analysis of data streaming is done based on program of word counting program which executes data with HDFS along with dynamic created data. To compute similar coherent strategies one can implement a schema named batch and streaming process which dynamically creates data. The architecture is reduced to serve as X-Platform which uses ample number of tools for batch and stream analysis on this proposed frame work. Here we use spark-sql, a query language which acts as interface for interactive process to have iterative processes. Real time streaming data processing involves spark streaming works. Here we focus on preliminary evaluation of results and analysis report which compares data sets performance and also achieve low latency rate with usage of RDD.</P>"
        },
        {
          "rank": 13,
          "score": 0.6210994124412537,
          "doc_id": "NPAP12116569",
          "title": "Big data analytics on large-scale socio-technical software engineering archives",
          "abstract": "<P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12116569&target=NART&cn=NPAP12116569",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives <P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>"
        },
        {
          "rank": 14,
          "score": 0.619090735912323,
          "doc_id": "JAKO199811919559635",
          "title": "실시간 스케줄링",
          "abstract": "실시간 시스템은 범용 시스템과는 달리 계산 결과의 정확성뿐만 아니라 계산이 종료되는 시점에 의해 그 가치가 결정되는 시스템을 말한다. 따라서 실시간 태스크는 시간적 제한 조건으로서 마감 시한(deadline)을 가지고 있으며 실시간 스케줄링 방법은 범용 시스템에서 사용되는 스케줄링 방법과는 달리 태스크가 마감 시한 내에 종료될수 있음을 보장해 주어야 한다 또한 실시간 스케줄링 방법은 새로운 태스크의 실행을 허가하기 전에 새로운 태스크 집합의 스케줄 가능성을 분석함으로써 시스템 전체의 안전을 유지할 수 있어야 한다. 실시간 스케줄링 방법은 크게 시간 구동형 방식과 우선 순위 기반의 이벤트 구동형 방식으로 우선 순위 기반의 이벤트 구동형 방식으로 나누어지는데 본 논문에서는 주로 우선 순위 기반의 이벤트 구동형 방식으로 나누어지는데 본 논문에서는 주로 우선순위 기반의 스케줄링 방법에 대해서 살펴본다 또한 비주기적인 태스크를 우선 순위기반 스케줄링 방법에 적용하기 위한 여러 가지 기법들에 대해서도 살펴본다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811919559635&target=NART&cn=JAKO199811919559635",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 스케줄링 실시간 스케줄링 실시간 스케줄링 실시간 시스템은 범용 시스템과는 달리 계산 결과의 정확성뿐만 아니라 계산이 종료되는 시점에 의해 그 가치가 결정되는 시스템을 말한다. 따라서 실시간 태스크는 시간적 제한 조건으로서 마감 시한(deadline)을 가지고 있으며 실시간 스케줄링 방법은 범용 시스템에서 사용되는 스케줄링 방법과는 달리 태스크가 마감 시한 내에 종료될수 있음을 보장해 주어야 한다 또한 실시간 스케줄링 방법은 새로운 태스크의 실행을 허가하기 전에 새로운 태스크 집합의 스케줄 가능성을 분석함으로써 시스템 전체의 안전을 유지할 수 있어야 한다. 실시간 스케줄링 방법은 크게 시간 구동형 방식과 우선 순위 기반의 이벤트 구동형 방식으로 우선 순위 기반의 이벤트 구동형 방식으로 나누어지는데 본 논문에서는 주로 우선 순위 기반의 이벤트 구동형 방식으로 나누어지는데 본 논문에서는 주로 우선순위 기반의 스케줄링 방법에 대해서 살펴본다 또한 비주기적인 태스크를 우선 순위기반 스케줄링 방법에 적용하기 위한 여러 가지 기법들에 대해서도 살펴본다."
        },
        {
          "rank": 15,
          "score": 0.6187347173690796,
          "doc_id": "JAKO201436438764787",
          "title": "안드로이드 플랫폼을 기반으로 한 실시간 프레임워크 설계",
          "abstract": "본 논문에서는 오픈 모바일 플랫폼인 안드로이드를 리눅스 커널을 기반으로 하는 ARM Cortex-A8 Core를 사용한 SAMSUNG의 S5PV210 CPU를 장착한 MPU 모듈, Base 보드 모듈 및 센서 모듈을 제작하여 실시간 프레임워크를 설계함으로서 효율적인 산업용 제어를 가능하게 하였다. 센서 모듈에서 획득한 온도 및 습도 데이터는 하이브리드 어플리케이션을 개발함으로서 Web Server를 통하여 데이터베이스에 저장된 후 클라이언트 User가 온도 및 습도 데이터를 스마트 폰에서 확인 함으로서 실시간 프레임워크 설계의 적합성 및 타당성을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201436438764787&target=NART&cn=JAKO201436438764787",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "안드로이드 플랫폼을 기반으로 한 실시간 프레임워크 설계 안드로이드 플랫폼을 기반으로 한 실시간 프레임워크 설계 안드로이드 플랫폼을 기반으로 한 실시간 프레임워크 설계 본 논문에서는 오픈 모바일 플랫폼인 안드로이드를 리눅스 커널을 기반으로 하는 ARM Cortex-A8 Core를 사용한 SAMSUNG의 S5PV210 CPU를 장착한 MPU 모듈, Base 보드 모듈 및 센서 모듈을 제작하여 실시간 프레임워크를 설계함으로서 효율적인 산업용 제어를 가능하게 하였다. 센서 모듈에서 획득한 온도 및 습도 데이터는 하이브리드 어플리케이션을 개발함으로서 Web Server를 통하여 데이터베이스에 저장된 후 클라이언트 User가 온도 및 습도 데이터를 스마트 폰에서 확인 함으로서 실시간 프레임워크 설계의 적합성 및 타당성을 검증한다."
        },
        {
          "rank": 16,
          "score": 0.61008220911026,
          "doc_id": "DIKO0009828582",
          "title": "오픈 소스 자바 퍼시스턴스 프레임워크 비교 분석",
          "abstract": "객체 지향 기술과 관계형 기술은 대부분의 기업에서 어플리케이션을 개발할 때 공통적으로 사용되는 기술이다. 객체 지향 기술은 데이터와 행위를 가진 객체를 통해 어플리케이션 구축을 지원하며, 관계형 기술은 데이터 저장과 프로시저나 SQL를 통한 데이터 조작을 지원한다. 하지만 명확하게 두 기술은 서로 다르다. 이처럼 객체 기술과 관계형 기술을 같이 사용했을 매 발생하는 두 기술간의 불일치를 'object-relational impedance mismatch'라고 한다. 이러한 문제를 해결하기 위해 등장한 기술중의 하나가 바로 ORM(Object/Relational Mapping)이다. 본 논문에서는 ORM 기술을 지원하는 ORM 툴로서의 오픈 소스 자바 프레임 워크를 성능이나 코드 복잡성, 관리 용이성 등 다양한 측면에서 비교 분석하였다. 현재 30여가지가 넘는 다양한 오픈 소스 자바 프레임워크가 개발되어 배포되고 있지만, 본 논문에서는 Hibernate, iBatis SqlMaps, Apache OJB 이렇게 새 개의 프래임워크를 현재 객체 지속성을 위해 가장 많이 사용되는 JDBC 기술을 기준으로 비교 분석하였다. 데이터에 대한 CRUD(저장,추출,수정,삭제)를 수행하는 시간을 통해 성능 분석을 실시하였으며, 사례 어플리케이션 구현을 통해 각 프레임워크 별로 CRUD를 수행하는 메소드 구현 시 코드량 분석을 통해 코드 복잡성을, 요구 사항 변경 시 어떻게 각 프레임워크가 이를 반영하는지를 통해 관리 용이성을 분석하였다. 이러한 분석을 통해 각 프레임워크가 어떠한 서비스를 제공하는지, 각 프레임워크의 성능은 어떠한지 쉽게 알 수 있다. 따라서 기업은 좀더 명확한 근거를 통해 어플리케이션 개발에 적절한 퍼시스턴스 프레임워크를 선택할 수 있을 것이다. 또한 상용과 오픈 소스 기반의 프레임워크 중 어떠한 것을 도입해야 할지 결정해야 할 경우 중요한 참고 자료로 활용할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0009828582&target=NART&cn=DIKO0009828582",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "오픈 소스 자바 퍼시스턴스 프레임워크 비교 분석 오픈 소스 자바 퍼시스턴스 프레임워크 비교 분석 오픈 소스 자바 퍼시스턴스 프레임워크 비교 분석 객체 지향 기술과 관계형 기술은 대부분의 기업에서 어플리케이션을 개발할 때 공통적으로 사용되는 기술이다. 객체 지향 기술은 데이터와 행위를 가진 객체를 통해 어플리케이션 구축을 지원하며, 관계형 기술은 데이터 저장과 프로시저나 SQL를 통한 데이터 조작을 지원한다. 하지만 명확하게 두 기술은 서로 다르다. 이처럼 객체 기술과 관계형 기술을 같이 사용했을 매 발생하는 두 기술간의 불일치를 'object-relational impedance mismatch'라고 한다. 이러한 문제를 해결하기 위해 등장한 기술중의 하나가 바로 ORM(Object/Relational Mapping)이다. 본 논문에서는 ORM 기술을 지원하는 ORM 툴로서의 오픈 소스 자바 프레임 워크를 성능이나 코드 복잡성, 관리 용이성 등 다양한 측면에서 비교 분석하였다. 현재 30여가지가 넘는 다양한 오픈 소스 자바 프레임워크가 개발되어 배포되고 있지만, 본 논문에서는 Hibernate, iBatis SqlMaps, Apache OJB 이렇게 새 개의 프래임워크를 현재 객체 지속성을 위해 가장 많이 사용되는 JDBC 기술을 기준으로 비교 분석하였다. 데이터에 대한 CRUD(저장,추출,수정,삭제)를 수행하는 시간을 통해 성능 분석을 실시하였으며, 사례 어플리케이션 구현을 통해 각 프레임워크 별로 CRUD를 수행하는 메소드 구현 시 코드량 분석을 통해 코드 복잡성을, 요구 사항 변경 시 어떻게 각 프레임워크가 이를 반영하는지를 통해 관리 용이성을 분석하였다. 이러한 분석을 통해 각 프레임워크가 어떠한 서비스를 제공하는지, 각 프레임워크의 성능은 어떠한지 쉽게 알 수 있다. 따라서 기업은 좀더 명확한 근거를 통해 어플리케이션 개발에 적절한 퍼시스턴스 프레임워크를 선택할 수 있을 것이다. 또한 상용과 오픈 소스 기반의 프레임워크 중 어떠한 것을 도입해야 할지 결정해야 할 경우 중요한 참고 자료로 활용할 수 있을 것이다."
        },
        {
          "rank": 17,
          "score": 0.6090413331985474,
          "doc_id": "NART119053407",
          "title": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review",
          "abstract": "<P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119053407&target=NART&cn=NART119053407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review <P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>"
        },
        {
          "rank": 18,
          "score": 0.6079955697059631,
          "doc_id": "DIKO0015889140",
          "title": "딥 러닝 프레임워크 성능 비교 및 개선 방안",
          "abstract": "현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015889140&target=NART&cn=DIKO0015889140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다."
        },
        {
          "rank": 19,
          "score": 0.6076986193656921,
          "doc_id": "NART56158516",
          "title": "실시간 분산 시스템에서의 적응력있는 복합서비스 스케줄링",
          "abstract": "<P> 데드라인 (deadline) - 제한시간 - 까지는 수행종료 되야 하는 한개 이상의 타스크 들로 구성된 비주기적 복합서비스는 임의 시간에 수행요구되므로 그 수행을 위한 스케줄링이 성공적으로 되지 않을 수도 있다. 이러한 서비스에 대한 관리 목표 중의 하나는 성공률 - 수행요구된 총 서비스 수와 성공적으로 스케줄 된 서비스 수 간의 비율 - 을 극대화 하는 것이다. 본 논문은 실시간 분산 시스템에서 수행요구되는 비주기적 복합서비스의 성공률을 향상시키기 위한 적응력있는 런-타임 (run-time) 스케줄링 방법을 제시한다. 모의실험을 통한 성능평가에서 상당한 성공률 개선이 관찰되었다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158516&target=NART&cn=NART56158516",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 분산 시스템에서의 적응력있는 복합서비스 스케줄링 실시간 분산 시스템에서의 적응력있는 복합서비스 스케줄링 실시간 분산 시스템에서의 적응력있는 복합서비스 스케줄링 <P> 데드라인 (deadline) - 제한시간 - 까지는 수행종료 되야 하는 한개 이상의 타스크 들로 구성된 비주기적 복합서비스는 임의 시간에 수행요구되므로 그 수행을 위한 스케줄링이 성공적으로 되지 않을 수도 있다. 이러한 서비스에 대한 관리 목표 중의 하나는 성공률 - 수행요구된 총 서비스 수와 성공적으로 스케줄 된 서비스 수 간의 비율 - 을 극대화 하는 것이다. 본 논문은 실시간 분산 시스템에서 수행요구되는 비주기적 복합서비스의 성공률을 향상시키기 위한 적응력있는 런-타임 (run-time) 스케줄링 방법을 제시한다. 모의실험을 통한 성능평가에서 상당한 성공률 개선이 관찰되었다.</P>"
        },
        {
          "rank": 20,
          "score": 0.6076931953430176,
          "doc_id": "JAKO200211921046697",
          "title": "고신뢰 실시간 시스템을 위한 체크포인팅 프레임워크",
          "abstract": "본 논문은 고신뢰 실시간 시스템에 체크포인팅을 적용할 수 있도록 실시간성과 신뢰성을 모두 고려하는 체크포인팅 프레임워크를 제공한다. 실시간 태스크의 시간 예측성은 할당된 체크포인트의 수와 태스크가 실행 중에 감내 해야하는 고장의 수를 기반으로 태스크의 최악 실행 시간(WCET: Worst Case Execution Time)을 산출함으로써 보장된다. 태스크가 실행 중에 극복해야하는 고장의 수는 태스크의 신뢰성 요구조건을 기반으로 산출됨으로써 태스크의 신뢰성이 보장되도록 한다. 이렇게 얻어진 태스크들의 WCET와 태스크가 극복해야 하는 고장의 수를 이용하여, 각 태스크의 스케줄 가능성을 보장하기 위해 요구되는 최소의 체크포인트 수를 유도하는 알고리즘을 제안한다. 본 논문에서 제안하는 프레임워크는 체크포인팅의 시간 중복량을 기반으로 하므로, 다른 시간 중복 기법에 대해서도 확장이 용이하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921046697&target=NART&cn=JAKO200211921046697",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "고신뢰 실시간 시스템을 위한 체크포인팅 프레임워크 고신뢰 실시간 시스템을 위한 체크포인팅 프레임워크 고신뢰 실시간 시스템을 위한 체크포인팅 프레임워크 본 논문은 고신뢰 실시간 시스템에 체크포인팅을 적용할 수 있도록 실시간성과 신뢰성을 모두 고려하는 체크포인팅 프레임워크를 제공한다. 실시간 태스크의 시간 예측성은 할당된 체크포인트의 수와 태스크가 실행 중에 감내 해야하는 고장의 수를 기반으로 태스크의 최악 실행 시간(WCET: Worst Case Execution Time)을 산출함으로써 보장된다. 태스크가 실행 중에 극복해야하는 고장의 수는 태스크의 신뢰성 요구조건을 기반으로 산출됨으로써 태스크의 신뢰성이 보장되도록 한다. 이렇게 얻어진 태스크들의 WCET와 태스크가 극복해야 하는 고장의 수를 이용하여, 각 태스크의 스케줄 가능성을 보장하기 위해 요구되는 최소의 체크포인트 수를 유도하는 알고리즘을 제안한다. 본 논문에서 제안하는 프레임워크는 체크포인팅의 시간 중복량을 기반으로 하므로, 다른 시간 중복 기법에 대해서도 확장이 용이하다."
        },
        {
          "rank": 21,
          "score": 0.6054105758666992,
          "doc_id": "ATN0037470211",
          "title": "빅데이터 분석 도구 개발기술 동향",
          "abstract": "Due to the advances in device technology such as smartphones and tablet PCs and mobiletechnology, the amount of the generated data is increasing rapidly. In order to analyze such ahuge amount of data, big data-related technology has become an enthusiastic area and is desiredin many applications. Big data analysis tools provide the ability to identify trends, detectpatterns and glean other valuable findings from the sea of data available. In this study, toprovide an overall view of the currently available big data analytics and their utilization, wepresented a detailed survey on state-of-the-art big data analysis techniques and their futureprospects.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037470211&target=NART&cn=ATN0037470211",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석 도구 개발기술 동향 빅데이터 분석 도구 개발기술 동향 빅데이터 분석 도구 개발기술 동향 Due to the advances in device technology such as smartphones and tablet PCs and mobiletechnology, the amount of the generated data is increasing rapidly. In order to analyze such ahuge amount of data, big data-related technology has become an enthusiastic area and is desiredin many applications. Big data analysis tools provide the ability to identify trends, detectpatterns and glean other valuable findings from the sea of data available. In this study, toprovide an overall view of the currently available big data analytics and their utilization, wepresented a detailed survey on state-of-the-art big data analysis techniques and their futureprospects."
        },
        {
          "rank": 22,
          "score": 0.6041289567947388,
          "doc_id": "JAKO201710748277717",
          "title": "제조 공정 빅데이터 분석을 위한 플랫폼 연구",
          "abstract": "IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201710748277717&target=NART&cn=JAKO201710748277717",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다."
        },
        {
          "rank": 23,
          "score": 0.6017096042633057,
          "doc_id": "JAKO201814446221611",
          "title": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현",
          "abstract": "본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201814446221611&target=NART&cn=JAKO201814446221611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다."
        },
        {
          "rank": 24,
          "score": 0.601218581199646,
          "doc_id": "NART87199447",
          "title": "HDM: A Composable Framework for Big Data Processing",
          "abstract": "<P>Over the past years, frameworks such as MapReduce and Spark have been introduced to ease the task of developing big data programs and applications. However, the jobs in these frameworks are roughly defined and packaged as executable jars without any functionality being exposed or described. This means that deployed jobs are not natively composable and reusable for subsequent development. Besides, it also hampers the ability for applying optimizations on the data flow of job sequences and pipelines. In this paper, we present the Hierarchically Distributed Data Matrix (HDM) which is a functional, strongly-typed data representation for writing composable big data applications. Along with HDM, a runtime framework is provided to support the execution, integration and management of HDM applications on distributed infrastructures. Based on the functional data dependency graph of HDM, multiple optimizations are applied to improve the performance of executing HDM jobs. The experimental results show that our optimizations can achieve improvements between 10 to 40 percent of the Job-Completion-Time for different types of applications when compared with the current state of art, Apache Spark.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART87199447&target=NART&cn=NART87199447",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "HDM: A Composable Framework for Big Data Processing HDM: A Composable Framework for Big Data Processing HDM: A Composable Framework for Big Data Processing <P>Over the past years, frameworks such as MapReduce and Spark have been introduced to ease the task of developing big data programs and applications. However, the jobs in these frameworks are roughly defined and packaged as executable jars without any functionality being exposed or described. This means that deployed jobs are not natively composable and reusable for subsequent development. Besides, it also hampers the ability for applying optimizations on the data flow of job sequences and pipelines. In this paper, we present the Hierarchically Distributed Data Matrix (HDM) which is a functional, strongly-typed data representation for writing composable big data applications. Along with HDM, a runtime framework is provided to support the execution, integration and management of HDM applications on distributed infrastructures. Based on the functional data dependency graph of HDM, multiple optimizations are applied to improve the performance of executing HDM jobs. The experimental results show that our optimizations can achieve improvements between 10 to 40 percent of the Job-Completion-Time for different types of applications when compared with the current state of art, Apache Spark.</P>"
        },
        {
          "rank": 25,
          "score": 0.6009854078292847,
          "doc_id": "JAKO201325358306386",
          "title": "SAFE: 확장 가능한 JavaScript 분석 프레임워크",
          "abstract": "JavaScript의 활용이 웹 개발을 넘어 내장형 기기 내부의 응용 애플리케이션까지 확장되고 있는 가운데, 이를 지원하기 위한 웹 브라우저 및 JavaScript 엔진 등의 개발에 산학의 다양한 노력이 이어지고 있다. 하지만 이러한 도구들의 대다수가 체계적으로 문서화되어 있지 않기 때문에 이를 응용한 개발 혹은 연구가 힘들고, 소스코드가 공개되어 있지 않은 경우도 많아 사용 자체가 불가능하기도 하다. 한편, JavaScript가 차세대 언어로 각광을 받고 있는 반면 언어 자체의 보안 취약성에 대한 문제 또한 끊임없이 불거짐에 따라 신뢰도 높은 응용 애플리케이션 개발에 대한 개발자들의 욕구가 점점 거세지고 있다. 본 논문에서는 이러한 한계점들의 대안으로써 개발한 확장 가능한 JavaScript 분석 프레임워크인 SAFE(Scalable Analysis Framework for ECMAScript)에 대해 소개하고, 이에 기반한 산학연구의 사례로 JavaScript 분석기의 정확도를 높이는 기법을 기술함으로써 다양한 분석기를 지원하는 SAFE의 확장성을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201325358306386&target=NART&cn=JAKO201325358306386",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SAFE: 확장 가능한 JavaScript 분석 프레임워크 SAFE: 확장 가능한 JavaScript 분석 프레임워크 SAFE: 확장 가능한 JavaScript 분석 프레임워크 JavaScript의 활용이 웹 개발을 넘어 내장형 기기 내부의 응용 애플리케이션까지 확장되고 있는 가운데, 이를 지원하기 위한 웹 브라우저 및 JavaScript 엔진 등의 개발에 산학의 다양한 노력이 이어지고 있다. 하지만 이러한 도구들의 대다수가 체계적으로 문서화되어 있지 않기 때문에 이를 응용한 개발 혹은 연구가 힘들고, 소스코드가 공개되어 있지 않은 경우도 많아 사용 자체가 불가능하기도 하다. 한편, JavaScript가 차세대 언어로 각광을 받고 있는 반면 언어 자체의 보안 취약성에 대한 문제 또한 끊임없이 불거짐에 따라 신뢰도 높은 응용 애플리케이션 개발에 대한 개발자들의 욕구가 점점 거세지고 있다. 본 논문에서는 이러한 한계점들의 대안으로써 개발한 확장 가능한 JavaScript 분석 프레임워크인 SAFE(Scalable Analysis Framework for ECMAScript)에 대해 소개하고, 이에 기반한 산학연구의 사례로 JavaScript 분석기의 정확도를 높이는 기법을 기술함으로써 다양한 분석기를 지원하는 SAFE의 확장성을 보인다."
        },
        {
          "rank": 26,
          "score": 0.6000102758407593,
          "doc_id": "DIKO0012654277",
          "title": "클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구",
          "abstract": "디지털 포렌식이란 과학적이거나 기술적인 기법을 사용하여 범죄수사 또는 증거를 수집하는 행위이이다. 이를 위한 도구로 디지털 포렌식 도구가 존재한다. 이 도구는 법과 기술 간의 매개체가 될 수 있는 핵심 요소라 할 수 있다[1]. 디지털 포렌식은 증거 이미징, 분석, 검색, 보고서 작성 등의 일련의 절차를 요구한다. 기존의 디지털 포렌식 도구는 이러한 절차적 기능을 제공하는 것을 목적으로 개발되었다. 현존하는 대부분의 포렌식 도구들은 단일 플랫폼 상의 윈도우 운영체제에서 운용되는 통합 도구로 제공된다. 이동성을 위해 휴대형 하드디스크 드라이브에 저장되며 해당 매체 내에서 실행된다. 목적에 따라 전용 기능을 제공하는 하드웨어 형태의 도구로도 제작 된다. 추가적으로 압수한 데스크탑을 포렌식 연구실로 이동하기 위해서 특수한 장치가 필요할 수 있다. 현재 단일 플랫폼 형태의 포렌식 도구에서 2TB의 데이터를 이미징 하는데 7시간이 걸리며 비트와이즈 검색을 20MB/s 정도의 속도로 처리해 1TB 이미지를 검색 했을 때에는 14시간이 소요된다[2]. 이는 양적으로 증가하는 디지털 증거의 추세에 미루어 볼 때 향후 도구의 증거 처리 속도 문제를 야기 시킬 것이다. 또, 증거물을 포렌식 연구실로 이송을 하거나 고속 처리를 하기위해서는 기타 하드웨어 장치를 이용해야 하고, 이는 도구 사용에 있어 불필요한 번거로움을 초래한다. 따라서 기존의 도구를 아우를 수 있는 새로운 도구 개발이 시급하다. 프로세싱 속도 향상을 위해 단일 플랫폼의 한계를 극복해야하고, 이용의 번거로움을 피하기 위해 모든 장비들을 하나의 도구로 합쳐야 한다. 기존의 도구를 기능을 아우를 수 있고, 단점을 제거하기위해 클라우드 컴퓨팅 개념을 적용해 해결 방안을 모색하였다. 본 논문에서는 클라우드 컴퓨팅[3]을 이용하여 디지털 포렌식 절차에 따라 어디에서든 포렌식을 수행 할 수 있는 DFSaaS(Digital Forensic Software as a Service) 구조와 이에 대한 시나리오를 제시하고, 이들에 대한 프레임워크를 연구한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012654277&target=NART&cn=DIKO0012654277",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 클라우드 컴퓨팅을 이용한 DFSaaS 프레임워크 연구 디지털 포렌식이란 과학적이거나 기술적인 기법을 사용하여 범죄수사 또는 증거를 수집하는 행위이이다. 이를 위한 도구로 디지털 포렌식 도구가 존재한다. 이 도구는 법과 기술 간의 매개체가 될 수 있는 핵심 요소라 할 수 있다[1]. 디지털 포렌식은 증거 이미징, 분석, 검색, 보고서 작성 등의 일련의 절차를 요구한다. 기존의 디지털 포렌식 도구는 이러한 절차적 기능을 제공하는 것을 목적으로 개발되었다. 현존하는 대부분의 포렌식 도구들은 단일 플랫폼 상의 윈도우 운영체제에서 운용되는 통합 도구로 제공된다. 이동성을 위해 휴대형 하드디스크 드라이브에 저장되며 해당 매체 내에서 실행된다. 목적에 따라 전용 기능을 제공하는 하드웨어 형태의 도구로도 제작 된다. 추가적으로 압수한 데스크탑을 포렌식 연구실로 이동하기 위해서 특수한 장치가 필요할 수 있다. 현재 단일 플랫폼 형태의 포렌식 도구에서 2TB의 데이터를 이미징 하는데 7시간이 걸리며 비트와이즈 검색을 20MB/s 정도의 속도로 처리해 1TB 이미지를 검색 했을 때에는 14시간이 소요된다[2]. 이는 양적으로 증가하는 디지털 증거의 추세에 미루어 볼 때 향후 도구의 증거 처리 속도 문제를 야기 시킬 것이다. 또, 증거물을 포렌식 연구실로 이송을 하거나 고속 처리를 하기위해서는 기타 하드웨어 장치를 이용해야 하고, 이는 도구 사용에 있어 불필요한 번거로움을 초래한다. 따라서 기존의 도구를 아우를 수 있는 새로운 도구 개발이 시급하다. 프로세싱 속도 향상을 위해 단일 플랫폼의 한계를 극복해야하고, 이용의 번거로움을 피하기 위해 모든 장비들을 하나의 도구로 합쳐야 한다. 기존의 도구를 기능을 아우를 수 있고, 단점을 제거하기위해 클라우드 컴퓨팅 개념을 적용해 해결 방안을 모색하였다. 본 논문에서는 클라우드 컴퓨팅[3]을 이용하여 디지털 포렌식 절차에 따라 어디에서든 포렌식을 수행 할 수 있는 DFSaaS(Digital Forensic Software as a Service) 구조와 이에 대한 시나리오를 제시하고, 이들에 대한 프레임워크를 연구한다."
        },
        {
          "rank": 27,
          "score": 0.5995057821273804,
          "doc_id": "JAKO201110264496611",
          "title": "침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크",
          "abstract": "이 논문에서는 침입 탐지시스템의 체계적인 경보데이터관리 및 경보데이터 상관관계 분석을 위하여 데이터 마이닝 기법을 적용한 경보 데이터 마이닝 프레임워크를 제안한다. 적용된 마이닝 기법은 속성기반 연관규칙, 속성기반 빈발에피소드, 오경보 분류, 그리고 순서기반 클러스터링이다. 이들 구성요소들은 각각 대량의 경보 데이터들로부터 알려지지 않은 패턴을 탐사하여 공격시나리오를 유추하거나, 공격 순서를 예측하는 것이 가능하며, 데이터의 그룹화를 통해 고수준의 의미를 추출할 수 있게 해준다. 실험 및 평가를 위하여 제안된 경보데이터 마이닝 프레임워크의 프로토타입을 구축하였으며 프레임워크의 기능을 검증하였다. 이 논문에서 제안한 경보 데이터 마이닝 프레임워크는 기존의 경보데이터 상관관계분석에서는 해결하지 못했던 통합적인 경보 상관관계 분석 기능을 수행할 뿐만 아니라 대량의 경보데이터에 대한 필터링을 수행하는 장점을 가진다. 또한 추출된 규칙 및 공격시나리오는 침입탐지시스템의 실시간 대응에 활용될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201110264496611&target=NART&cn=JAKO201110264496611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 침입탐지시스템의 경보데이터 분석을 위한 데이터 마이닝 프레임워크 이 논문에서는 침입 탐지시스템의 체계적인 경보데이터관리 및 경보데이터 상관관계 분석을 위하여 데이터 마이닝 기법을 적용한 경보 데이터 마이닝 프레임워크를 제안한다. 적용된 마이닝 기법은 속성기반 연관규칙, 속성기반 빈발에피소드, 오경보 분류, 그리고 순서기반 클러스터링이다. 이들 구성요소들은 각각 대량의 경보 데이터들로부터 알려지지 않은 패턴을 탐사하여 공격시나리오를 유추하거나, 공격 순서를 예측하는 것이 가능하며, 데이터의 그룹화를 통해 고수준의 의미를 추출할 수 있게 해준다. 실험 및 평가를 위하여 제안된 경보데이터 마이닝 프레임워크의 프로토타입을 구축하였으며 프레임워크의 기능을 검증하였다. 이 논문에서 제안한 경보 데이터 마이닝 프레임워크는 기존의 경보데이터 상관관계분석에서는 해결하지 못했던 통합적인 경보 상관관계 분석 기능을 수행할 뿐만 아니라 대량의 경보데이터에 대한 필터링을 수행하는 장점을 가진다. 또한 추출된 규칙 및 공격시나리오는 침입탐지시스템의 실시간 대응에 활용될 수 있다."
        },
        {
          "rank": 28,
          "score": 0.5992631912231445,
          "doc_id": "JAKO202032860595382",
          "title": "제어 네트워크 경계에 대한 OT-IT 책임 역할 연구",
          "abstract": "In recent years, due to the demand for operating efficiency and cost reduction of industrial facilities, remote access via the Internet is expanding. the control network accelerates from network separation to network connection due to the development of IIoT (Industrial Internet of Things) technology. Transition of control network is a new opportunity, but concerns about cybersecurity are also growing. Therefore, manufacturers must reflect security compliance and standards in consideration of the Internet connection environment, and enterprises must newly recognize the connection area of the control network as a security management target. In this study, the core target of the control system security threat is defined as the network boundary, and issues regarding the security architecture configuration for the boundary and the role & responsibility of the working organization are covered. Enterprises do not integrate the design organization with the operation organization after go-live, and are not consistently reflecting security considerations from design to operation. At this point, the expansion of the control network is a big transition that calls for the establishment of a responsible organization and reinforcement of the role of the network boundary area where there is a concern about lack of management. Thus, through the organization of the facility network and the analysis of the roles between each organization, an static perspective and difference in perception were derived. In addition, standards and guidelines required for reinforcing network boundary security were studied to address essential operational standards that required the Internet connection of the control network. This study will help establish a network boundary management system that should be considered at the enterprise level in the future.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032860595382&target=NART&cn=JAKO202032860595382",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제어 네트워크 경계에 대한 OT-IT 책임 역할 연구 제어 네트워크 경계에 대한 OT-IT 책임 역할 연구 제어 네트워크 경계에 대한 OT-IT 책임 역할 연구 In recent years, due to the demand for operating efficiency and cost reduction of industrial facilities, remote access via the Internet is expanding. the control network accelerates from network separation to network connection due to the development of IIoT (Industrial Internet of Things) technology. Transition of control network is a new opportunity, but concerns about cybersecurity are also growing. Therefore, manufacturers must reflect security compliance and standards in consideration of the Internet connection environment, and enterprises must newly recognize the connection area of the control network as a security management target. In this study, the core target of the control system security threat is defined as the network boundary, and issues regarding the security architecture configuration for the boundary and the role & responsibility of the working organization are covered. Enterprises do not integrate the design organization with the operation organization after go-live, and are not consistently reflecting security considerations from design to operation. At this point, the expansion of the control network is a big transition that calls for the establishment of a responsible organization and reinforcement of the role of the network boundary area where there is a concern about lack of management. Thus, through the organization of the facility network and the analysis of the roles between each organization, an static perspective and difference in perception were derived. In addition, standards and guidelines required for reinforcing network boundary security were studied to address essential operational standards that required the Internet connection of the control network. This study will help establish a network boundary management system that should be considered at the enterprise level in the future."
        },
        {
          "rank": 29,
          "score": 0.5992582440376282,
          "doc_id": "JAKO200907559763042",
          "title": "u-Farm 투자성과평가를 위한 프레임워크 개발 및 실증연구",
          "abstract": "As technology develops, more advanced technologies involving GPS, GIS, RFID and sensor networks have been adopted in agriculture sector for u-Farm. However, technology adoptions have been evaluated as ineffective. Farmers and agri-business have low level of understanding on technology so it is not efficiently utilized. This study introduces a case of RFID/sensor networks of mushroom farm as a u-Farm case study, focusing on developing a framework for analysis of u-Farm investment returns. RFID and sensor networks improve real-time production control, processing management, and traceability. Integration of RFID and sensor networks leads to innovation into the mushroom farm, reducing labor cost, increasing productivity, and improving quality of the mushroom. The ROI which is used as an indicator of performance indicator is 413%.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200907559763042&target=NART&cn=JAKO200907559763042",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "u-Farm 투자성과평가를 위한 프레임워크 개발 및 실증연구 u-Farm 투자성과평가를 위한 프레임워크 개발 및 실증연구 u-Farm 투자성과평가를 위한 프레임워크 개발 및 실증연구 As technology develops, more advanced technologies involving GPS, GIS, RFID and sensor networks have been adopted in agriculture sector for u-Farm. However, technology adoptions have been evaluated as ineffective. Farmers and agri-business have low level of understanding on technology so it is not efficiently utilized. This study introduces a case of RFID/sensor networks of mushroom farm as a u-Farm case study, focusing on developing a framework for analysis of u-Farm investment returns. RFID and sensor networks improve real-time production control, processing management, and traceability. Integration of RFID and sensor networks leads to innovation into the mushroom farm, reducing labor cost, increasing productivity, and improving quality of the mushroom. The ROI which is used as an indicator of performance indicator is 413%."
        },
        {
          "rank": 30,
          "score": 0.5992527008056641,
          "doc_id": "JAKO200831852745082",
          "title": "비즈니스 프로세스 패밀리 모델을 위한 가변성 분석 방법",
          "abstract": "오늘날 대부분의 기업들은 외부상황에 신속하게 비즈니스를 바꿀 수 있도록 하는 온디맨드 비즈니스 (On-demand business)를 구현하기 위해 IT 시스템의 유연성을 필요로 한다. 서비스 지향 아키텍처(Service Oriented Architecture: SOA)는 온디맨드 운영환경에서의 비즈니스 유연성을 가능하게 하는 인프라스트럭처 (infrastructure)를 제공한다. 오늘날의 이러한 요구사항을 충족시키기 위하여 SOA 애플리케이션 개발에 맞게 비즈니스 프로세스의 유연성을 확보하고 재사용을 증진시키기 위한 접근법이 필요하다. 그러므로 본 논문에서는 소프트웨어 프로덕트 라인 방법의 가변성 분석 기법을 사용하여 비즈니스 프로세스 패밀리 (family)에서 나타날 수 있는 가변성을 분석하고 이를 명시적으로 비즈니스 프로세스 패밀리 모델 (Business Process Family Model: BPFM)로 표현하는 방법을 제시한다. 또한 이 방법의 사용을 지원하기 위해 개발한 도구에 대해 설명한다. 이는 BPFM을 모델링하고 BPFM으로부터 가변성 결정과 가지치기 과정을 거쳐 자동 비즈니스 프로세스 모델 (Business Process Model: BPM)을 생성하는 기능들을 가지고 있다. 본 논문에서 제시하는 비즈니스 프로세스 패밀리의 가변성 분석을 통하여 비즈니스와 이를 지원하는 IT 시스템은 비즈니스 환경의 변화에 신속하게 대응할 수 있게 된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200831852745082&target=NART&cn=JAKO200831852745082",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비즈니스 프로세스 패밀리 모델을 위한 가변성 분석 방법 비즈니스 프로세스 패밀리 모델을 위한 가변성 분석 방법 비즈니스 프로세스 패밀리 모델을 위한 가변성 분석 방법 오늘날 대부분의 기업들은 외부상황에 신속하게 비즈니스를 바꿀 수 있도록 하는 온디맨드 비즈니스 (On-demand business)를 구현하기 위해 IT 시스템의 유연성을 필요로 한다. 서비스 지향 아키텍처(Service Oriented Architecture: SOA)는 온디맨드 운영환경에서의 비즈니스 유연성을 가능하게 하는 인프라스트럭처 (infrastructure)를 제공한다. 오늘날의 이러한 요구사항을 충족시키기 위하여 SOA 애플리케이션 개발에 맞게 비즈니스 프로세스의 유연성을 확보하고 재사용을 증진시키기 위한 접근법이 필요하다. 그러므로 본 논문에서는 소프트웨어 프로덕트 라인 방법의 가변성 분석 기법을 사용하여 비즈니스 프로세스 패밀리 (family)에서 나타날 수 있는 가변성을 분석하고 이를 명시적으로 비즈니스 프로세스 패밀리 모델 (Business Process Family Model: BPFM)로 표현하는 방법을 제시한다. 또한 이 방법의 사용을 지원하기 위해 개발한 도구에 대해 설명한다. 이는 BPFM을 모델링하고 BPFM으로부터 가변성 결정과 가지치기 과정을 거쳐 자동 비즈니스 프로세스 모델 (Business Process Model: BPM)을 생성하는 기능들을 가지고 있다. 본 논문에서 제시하는 비즈니스 프로세스 패밀리의 가변성 분석을 통하여 비즈니스와 이를 지원하는 IT 시스템은 비즈니스 환경의 변화에 신속하게 대응할 수 있게 된다."
        },
        {
          "rank": 31,
          "score": 0.5983576774597168,
          "doc_id": "NART108328574",
          "title": "A fully open-source framework for deep learning protein real-valued distances",
          "abstract": "<P>As deep learning algorithms drive the progress in protein structure prediction, a lot remains to be studied at this merging superhighway of deep learning and protein structure prediction. Recent findings show that inter-residue distance prediction, a more granular version of the well-known contact prediction problem, is a key to predicting accurate models. However, deep learning methods that predict these distances are still in the early stages of their development. To advance these methods and develop other novel methods, a need exists for a small and representative dataset packaged for faster development and testing. In this work, we introduce protein distance net (PDNET), a framework that consists of one such representative dataset along with the scripts for training and testing deep learning methods. The framework also includes all the scripts that were used to curate the dataset, and generate the input features and distance maps. Deep learning models can also be trained and tested in a web browser using free platforms such as Google Colab. We discuss how PDNET can be used to predict contacts, distance intervals, and real-valued distances.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108328574&target=NART&cn=NART108328574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A fully open-source framework for deep learning protein real-valued distances A fully open-source framework for deep learning protein real-valued distances A fully open-source framework for deep learning protein real-valued distances <P>As deep learning algorithms drive the progress in protein structure prediction, a lot remains to be studied at this merging superhighway of deep learning and protein structure prediction. Recent findings show that inter-residue distance prediction, a more granular version of the well-known contact prediction problem, is a key to predicting accurate models. However, deep learning methods that predict these distances are still in the early stages of their development. To advance these methods and develop other novel methods, a need exists for a small and representative dataset packaged for faster development and testing. In this work, we introduce protein distance net (PDNET), a framework that consists of one such representative dataset along with the scripts for training and testing deep learning methods. The framework also includes all the scripts that were used to curate the dataset, and generate the input features and distance maps. Deep learning models can also be trained and tested in a web browser using free platforms such as Google Colab. We discuss how PDNET can be used to predict contacts, distance intervals, and real-valued distances.</P>"
        },
        {
          "rank": 32,
          "score": 0.5979486703872681,
          "doc_id": "JAKO201908559987020",
          "title": "스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계",
          "abstract": "엔터프라이즈 환경의 표준화 경쟁은 백엔드의 데이터 티어로 시작하여 대표적인 엔터프라이즈 미들 티어가 스프링 프레임워크로 받아들여짐으로써 표준화로 안정화되고 있는 실정이다. 또한 점차 빠른 주기로 새로운 디바이스의 출현으로 웹과 모바일 서비스에 대한 호환성 확보가 웹 서비스 기업들의 중요한 경쟁력이 되고 있다. 그러나 국내 기업들은 이러한 정보화 시대의 격변한 환경 변화에 적절한 역량있는 기술 인력을 확보하지 못하고 있으며, 교육중심 대학들의 교육과정에서도 새로운 역량중심의 교육과정의 요구를 반영하지 못하고 있는 실정이다. 따라서 본 연구에서는 이러한 엔터프라이즈 시스템 플랫폼 환경에서 필요한 역량중심의 기술을 습득과 교육과정을 개발하기 위하여 스프링 프레임워크 환경에서 스프링 데이터 JPA를 활용한 시스템을 분석 및 설계 단계별로 문서화 작성을 통하여 구현하였다. 향후 엔터프라이즈 환경에서의 바로 적용할 수 있는 풀 스택 역량중심의 교육과정 및 캡스톤 디자인 교육과정의 참조 모델을 제공하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201908559987020&target=NART&cn=JAKO201908559987020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 스프링 프레임워크 환경에서 스프링 데이터 JPA기반의 엔터프라이즈 시스템 플랫폼의 설계 엔터프라이즈 환경의 표준화 경쟁은 백엔드의 데이터 티어로 시작하여 대표적인 엔터프라이즈 미들 티어가 스프링 프레임워크로 받아들여짐으로써 표준화로 안정화되고 있는 실정이다. 또한 점차 빠른 주기로 새로운 디바이스의 출현으로 웹과 모바일 서비스에 대한 호환성 확보가 웹 서비스 기업들의 중요한 경쟁력이 되고 있다. 그러나 국내 기업들은 이러한 정보화 시대의 격변한 환경 변화에 적절한 역량있는 기술 인력을 확보하지 못하고 있으며, 교육중심 대학들의 교육과정에서도 새로운 역량중심의 교육과정의 요구를 반영하지 못하고 있는 실정이다. 따라서 본 연구에서는 이러한 엔터프라이즈 시스템 플랫폼 환경에서 필요한 역량중심의 기술을 습득과 교육과정을 개발하기 위하여 스프링 프레임워크 환경에서 스프링 데이터 JPA를 활용한 시스템을 분석 및 설계 단계별로 문서화 작성을 통하여 구현하였다. 향후 엔터프라이즈 환경에서의 바로 적용할 수 있는 풀 스택 역량중심의 교육과정 및 캡스톤 디자인 교육과정의 참조 모델을 제공하고자 한다."
        },
        {
          "rank": 33,
          "score": 0.5973544120788574,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 34,
          "score": 0.5972396731376648,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        },
        {
          "rank": 35,
          "score": 0.597111701965332,
          "doc_id": "NART93845311",
          "title": "Security Benefits of Little Data From the Socio-Technical Perspective :",
          "abstract": "<P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART93845311&target=NART&cn=NART93845311",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : Security Benefits of Little Data From the Socio-Technical Perspective : <P>As organisations are further developing ways to extract value from big data, the amount of personal data being stored in centralised systems is rising. These large data sets are becoming prime targets for hackers as well as raising concerns about end user privacy with how the data is handled. Virtual Personal Assistants (VPA) that use the Little Data approach of keeping data within the control of the end user have the potential to mitigate these risks due to its decentralised nature. Within this article the authors discuss the potential security benefits from the Socio-Technical Perspective of utilising a VPA as a supporting technology for controlling an individual's personal data.</P>"
        },
        {
          "rank": 36,
          "score": 0.5970968008041382,
          "doc_id": "DIKO0012113511",
          "title": "인공신경망을 이용한 판매처 평가 프레임워크",
          "abstract": "인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012113511&target=NART&cn=DIKO0012113511",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다."
        },
        {
          "rank": 37,
          "score": 0.5963914394378662,
          "doc_id": "DIKO0016837574",
          "title": "Research on Deep Spatio-Temporal Prediction Model for Traffic Prediction에 대한 연구",
          "abstract": "최근 차량의 급격한 증가는 다양한 도시 교통 문제를 야기하고 있으며 이를 해결하기 위해 많은 연구가 진행되고 있다. 도시 교통 상황은 시시각각 변화하므로 공간 및 시간적 측면에서 복잡하고 불규칙하며 비선형적인 시공간 관계를 갖는 데이터이다. 따라서 복잡한 시공간 의존성을 효율적으로 포착하고 적시에 정확한 교통 예측을 통한 교통 활용률을 개선하는 것은 매우 어려운 문제이다.&amp;#xD; 교통 예측 문제에 대한 연구는 전통적인 선형 방법, 기계 학습 방법, 딥 러닝을 활용하는 방법으로 발전하고 있지만 기존 방법에는 여전히 많은 문제가 있다. 예를 들어, 시공간 데이터에서 의존성을 획득하는 것만으로는 교통 상황의 급격한 시공간 변화를 반영할 수 없고, 시공간 멀티모달 (multimodal) 융합은 시공간의 복잡성에 적응할 수 없다. 또한 얕은 시공간 모델은 더 풍부한 교통 데이터 특징을 추출하는 데 어려움이 있고, 고정 교통 그래프 구조는 유연성이 부족하다.&amp;#xD; 이 논문은 시공간 교통 데이터를 대상으로 딥 러닝 이론과 방법에 기반한 일련의 혁신적인 시공간 시퀀스 예측 모델을 제시한다. 이를 위해 시공간 다중 연관 그래프 구축, 시공간 멀티모달 융합, 교통 그래프 네트워크 심화, 적응적인 시공간 그래프 등의 방법을 제안한다.&amp;#xD; 논문의 주요 혁신적 연구는 다음과 같습니다.&amp;#xD; 1. 교통망의 공간적 및 시간적, 동적 및 정적 특성을 얻기 위한 시공간적 다중 연관 그래프를 생성하는 새로운 방법을 제안한다. 이는 시공간 차원의 연관관계를 기반으로 여러 시공간 그래프를 생성하여 특징(feature)을 향상시키며 인접 시공간 그래프와 인접하지 않은 시공간 그래프 간의 의존 관계를 학습할 수 있다.&amp;#xD; 2. 시공간 멀티모달 데이터 융합 문제를 해결하기 위한 다단계 혼합 시공간 융합 방법을 제안한다. 이는 멀티헤드 주의(multi-headed attention) 메커니즘과 결합된 적응형 게이팅(adaptive gating) 메커니즘을 사용하여 보다 장기적이고 심층적인 복잡한 시공간 정보를 획득할 수 있다.&amp;#xD; 3. 시공간 그래프의 네트워크 계층의 심화로 인한 과도한 평활화 문제를 해결하기 위한 적응형 은닉층 연결 방법을 제안한다. 이는 특징 표현을 변환 및 분리한 후, 초기 및 은닉층 연결에 추가하고 파라미터를 통해 은닉층의 가중치를 적응적으로 조정한다. 이를 통해 노드의 수용성을 확장하고 더 깊은 교통 인접 노드의 특징을 종합적으로 획득할 수 있다.&amp;#xD; 4. 시공간 그래프의 유연성과 적응성을 향상시키기 위한 교통망의 복잡한 시공간 관계를 분석하기 위해 교통 예측을 위한 파라미터 공유 및 적응적 그래프 컨볼루션 방법을 제안한다. 이는 파라미터 공유를 위한 적응적 행렬을 구성하여 교통망 내의 공간 의존성 및 구조를 적응적으로 학습하고 조정한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016837574&target=NART&cn=DIKO0016837574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Research on Deep Spatio-Temporal Prediction Model for Traffic Prediction에 대한 연구 Research on Deep Spatio-Temporal Prediction Model for Traffic Prediction에 대한 연구 Research on Deep Spatio-Temporal Prediction Model for Traffic Prediction에 대한 연구 최근 차량의 급격한 증가는 다양한 도시 교통 문제를 야기하고 있으며 이를 해결하기 위해 많은 연구가 진행되고 있다. 도시 교통 상황은 시시각각 변화하므로 공간 및 시간적 측면에서 복잡하고 불규칙하며 비선형적인 시공간 관계를 갖는 데이터이다. 따라서 복잡한 시공간 의존성을 효율적으로 포착하고 적시에 정확한 교통 예측을 통한 교통 활용률을 개선하는 것은 매우 어려운 문제이다.&amp;#xD; 교통 예측 문제에 대한 연구는 전통적인 선형 방법, 기계 학습 방법, 딥 러닝을 활용하는 방법으로 발전하고 있지만 기존 방법에는 여전히 많은 문제가 있다. 예를 들어, 시공간 데이터에서 의존성을 획득하는 것만으로는 교통 상황의 급격한 시공간 변화를 반영할 수 없고, 시공간 멀티모달 (multimodal) 융합은 시공간의 복잡성에 적응할 수 없다. 또한 얕은 시공간 모델은 더 풍부한 교통 데이터 특징을 추출하는 데 어려움이 있고, 고정 교통 그래프 구조는 유연성이 부족하다.&amp;#xD; 이 논문은 시공간 교통 데이터를 대상으로 딥 러닝 이론과 방법에 기반한 일련의 혁신적인 시공간 시퀀스 예측 모델을 제시한다. 이를 위해 시공간 다중 연관 그래프 구축, 시공간 멀티모달 융합, 교통 그래프 네트워크 심화, 적응적인 시공간 그래프 등의 방법을 제안한다.&amp;#xD; 논문의 주요 혁신적 연구는 다음과 같습니다.&amp;#xD; 1. 교통망의 공간적 및 시간적, 동적 및 정적 특성을 얻기 위한 시공간적 다중 연관 그래프를 생성하는 새로운 방법을 제안한다. 이는 시공간 차원의 연관관계를 기반으로 여러 시공간 그래프를 생성하여 특징(feature)을 향상시키며 인접 시공간 그래프와 인접하지 않은 시공간 그래프 간의 의존 관계를 학습할 수 있다.&amp;#xD; 2. 시공간 멀티모달 데이터 융합 문제를 해결하기 위한 다단계 혼합 시공간 융합 방법을 제안한다. 이는 멀티헤드 주의(multi-headed attention) 메커니즘과 결합된 적응형 게이팅(adaptive gating) 메커니즘을 사용하여 보다 장기적이고 심층적인 복잡한 시공간 정보를 획득할 수 있다.&amp;#xD; 3. 시공간 그래프의 네트워크 계층의 심화로 인한 과도한 평활화 문제를 해결하기 위한 적응형 은닉층 연결 방법을 제안한다. 이는 특징 표현을 변환 및 분리한 후, 초기 및 은닉층 연결에 추가하고 파라미터를 통해 은닉층의 가중치를 적응적으로 조정한다. 이를 통해 노드의 수용성을 확장하고 더 깊은 교통 인접 노드의 특징을 종합적으로 획득할 수 있다.&amp;#xD; 4. 시공간 그래프의 유연성과 적응성을 향상시키기 위한 교통망의 복잡한 시공간 관계를 분석하기 위해 교통 예측을 위한 파라미터 공유 및 적응적 그래프 컨볼루션 방법을 제안한다. 이는 파라미터 공유를 위한 적응적 행렬을 구성하여 교통망 내의 공간 의존성 및 구조를 적응적으로 학습하고 조정한다."
        },
        {
          "rank": 38,
          "score": 0.5962263941764832,
          "doc_id": "JAKO202029062617674",
          "title": "위성영상-AI 기반 재난모니터링과 실현 가능한 준실시간 통합 재난모니터링 시스템",
          "abstract": "원격탐사 기술의 발전과 활용 가능한 위성의 증가로 재난의 예방, 대비, 대응, 복구 등에서 위성영상자료의 활용에 대한 요구가 높아지고 있다. 위성영상은 센서의 특성에 따라 적용 가능한 재난의 모니터링을 위해 활용되고 있지만, 통합된 모니터링 시스템의 구축을 위해 기존 시스템을 평가하고 이를 바탕으로 실현 가능한 준실시간 통합 재난모니터링 시스템 구축을 위한 구체적인 청사진을 제시한 연구는 국내뿐만 아니라 국외에서도 그 사례가 확인되지 않는다. 본 연구는 원격탐사를 통한 재난모니터링의 개념화를 통해 준실시간 재난모니터링 시스템 구축의 장애요인들을 확인하고, 실제로 활용 가능한 영상자료와 실현 가능한 재난모니터링 시스템을 제시하였다. 원격탐사를 통한 준실시간 재난모니터링은 다양한 요인들에 의해 통합시스템의 구축이 제한되며, 시스템 구축을 위한 기술적, 경제적 요인과 함께 위성영상 확보의 적시성을 가로막는 정책적 요인과 일관성 있는 정보생산을 위한 영상분석에 대한 제도적 요인에도 크게 영향을 받는 것으로 나타났다. 이러한 제약들은 AWS(Amazon Web Services)와 같은 위성영상의 저장, 취득, 분석에 활용되는 컴퓨팅 플랫폼과 같은 통합서버의 확보와, 재난의 종류와 상황에 부합하는 활용 가능 위성의 궤도분석을 가능하게 하는 분석도구의 개발에 의해 극복될 수 있을 것으로 판단된다. 본 연구는 이러한 제도적, 경제적, 기술적, 정책적 제약들을 극복할 수 있는 위성영상 기반 통합 재난모니터링 시스템 구축을 위한 프레임워크를 제시하였으며, 재난의 종류와 단계에 따른 AI 기반 위성영상 분석 방법론을 제안하였다. 이러한 결과는 원격탐사와 재난관리 분야에 학술적 시사점을 제공하고, 재난모니터링 분야에 실무적 기여를 할 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029062617674&target=NART&cn=JAKO202029062617674",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "위성영상-AI 기반 재난모니터링과 실현 가능한 준실시간 통합 재난모니터링 시스템 위성영상-AI 기반 재난모니터링과 실현 가능한 준실시간 통합 재난모니터링 시스템 위성영상-AI 기반 재난모니터링과 실현 가능한 준실시간 통합 재난모니터링 시스템 원격탐사 기술의 발전과 활용 가능한 위성의 증가로 재난의 예방, 대비, 대응, 복구 등에서 위성영상자료의 활용에 대한 요구가 높아지고 있다. 위성영상은 센서의 특성에 따라 적용 가능한 재난의 모니터링을 위해 활용되고 있지만, 통합된 모니터링 시스템의 구축을 위해 기존 시스템을 평가하고 이를 바탕으로 실현 가능한 준실시간 통합 재난모니터링 시스템 구축을 위한 구체적인 청사진을 제시한 연구는 국내뿐만 아니라 국외에서도 그 사례가 확인되지 않는다. 본 연구는 원격탐사를 통한 재난모니터링의 개념화를 통해 준실시간 재난모니터링 시스템 구축의 장애요인들을 확인하고, 실제로 활용 가능한 영상자료와 실현 가능한 재난모니터링 시스템을 제시하였다. 원격탐사를 통한 준실시간 재난모니터링은 다양한 요인들에 의해 통합시스템의 구축이 제한되며, 시스템 구축을 위한 기술적, 경제적 요인과 함께 위성영상 확보의 적시성을 가로막는 정책적 요인과 일관성 있는 정보생산을 위한 영상분석에 대한 제도적 요인에도 크게 영향을 받는 것으로 나타났다. 이러한 제약들은 AWS(Amazon Web Services)와 같은 위성영상의 저장, 취득, 분석에 활용되는 컴퓨팅 플랫폼과 같은 통합서버의 확보와, 재난의 종류와 상황에 부합하는 활용 가능 위성의 궤도분석을 가능하게 하는 분석도구의 개발에 의해 극복될 수 있을 것으로 판단된다. 본 연구는 이러한 제도적, 경제적, 기술적, 정책적 제약들을 극복할 수 있는 위성영상 기반 통합 재난모니터링 시스템 구축을 위한 프레임워크를 제시하였으며, 재난의 종류와 단계에 따른 AI 기반 위성영상 분석 방법론을 제안하였다. 이러한 결과는 원격탐사와 재난관리 분야에 학술적 시사점을 제공하고, 재난모니터링 분야에 실무적 기여를 할 것으로 판단된다."
        },
        {
          "rank": 39,
          "score": 0.5943973660469055,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 40,
          "score": 0.5928555130958557,
          "doc_id": "JAKO201419640882293",
          "title": "텍스트 데이터 시각화를 위한 MVC 프레임워크",
          "abstract": "빅데이터의 중요성에 대한 인식이 확산되고, 관련한 기술이 발전됨에 따라, 최근에는 빅데이터의 처리와 분석의 결과를 어떻게 시각화할 것인지가 매우 관심 받는 주제로 부각되고 있다. 이는 분석된 결과를 보다 명확하고 효과적으로 전달하는 데에 있어서 데이터의 시각화가 매우 효과적인 방법이기 때문이다. 시각화는 분석 시스템과 사용자가 소통하기 위한 하나의 그래픽 사용자 인터페이스(GUI)를 담당하는 역할을 한다. 통상적으로 이러한 GUI 부분은 데이터의 처리나 분석의 결과와 독립될 수록 시스템의 개발과 유지보수가 용이하며, MVC(Model-View-Controller)와 같은 디자인 패턴의 적용을 통해 GUI와 데이터 처리 및 관리 부분 간의 결합도를 최소화하는 것이 중요하다. 한편 빅데이터는 크게 정형 데이터와 비정형 데이터로 구분할 수 있는데 정형 데이터는 시각화가 상대적으로 용이한 반면, 비정형 데이터는 시각화를 구현하기가 복잡하고 다양하다. 그럼에도 불구하고 비정형 데이터에 대한 분석과 활용이 점점 더 확산됨에 따라, 기존의 전통적인 정형 데이터를 위한 시각화 도구들의 한계를 벗어나기 위해 각각의 시스템들의 목적에 따라 고유의 방식으로 시각화 시스템이 구축되는 현실에 직면해 있다. 더욱이나 현재 비정형 데이터 분석의 대상 중 대부분을 차지하고 있는 텍스트 데이터의 경우 언어 분석, 텍스트 마이닝, 소셜 네트워크 분석 등 적용 기술이 매우 다양하여 하나의 시스템에 적용된 시각화 기술을 다른 시스템에 적용하는 것이 용이하지 않다. 이는 현재의 텍스트 분석 결과에 대한 정보 모델이 서로 다른 시스템에 적용될 수 있도록 설계되지 못하는 경우가 많기 때문이다. 본 연구에서는 이러한 문제를 해결하기 위하여 다양한 텍스트 데이터 분석 사례와 시각화 사례들의 공통적 구성 요소들을 식별하여 표준화된 정보 모델인 텍스트 데이터 시각화 모델을 제시하고, 이를 통해 시각화의 GUI 부분과 연결할 수 있는 시스템 모델로서의 시각화 프레임워크인 TexVizu를 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201419640882293&target=NART&cn=JAKO201419640882293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "텍스트 데이터 시각화를 위한 MVC 프레임워크 텍스트 데이터 시각화를 위한 MVC 프레임워크 텍스트 데이터 시각화를 위한 MVC 프레임워크 빅데이터의 중요성에 대한 인식이 확산되고, 관련한 기술이 발전됨에 따라, 최근에는 빅데이터의 처리와 분석의 결과를 어떻게 시각화할 것인지가 매우 관심 받는 주제로 부각되고 있다. 이는 분석된 결과를 보다 명확하고 효과적으로 전달하는 데에 있어서 데이터의 시각화가 매우 효과적인 방법이기 때문이다. 시각화는 분석 시스템과 사용자가 소통하기 위한 하나의 그래픽 사용자 인터페이스(GUI)를 담당하는 역할을 한다. 통상적으로 이러한 GUI 부분은 데이터의 처리나 분석의 결과와 독립될 수록 시스템의 개발과 유지보수가 용이하며, MVC(Model-View-Controller)와 같은 디자인 패턴의 적용을 통해 GUI와 데이터 처리 및 관리 부분 간의 결합도를 최소화하는 것이 중요하다. 한편 빅데이터는 크게 정형 데이터와 비정형 데이터로 구분할 수 있는데 정형 데이터는 시각화가 상대적으로 용이한 반면, 비정형 데이터는 시각화를 구현하기가 복잡하고 다양하다. 그럼에도 불구하고 비정형 데이터에 대한 분석과 활용이 점점 더 확산됨에 따라, 기존의 전통적인 정형 데이터를 위한 시각화 도구들의 한계를 벗어나기 위해 각각의 시스템들의 목적에 따라 고유의 방식으로 시각화 시스템이 구축되는 현실에 직면해 있다. 더욱이나 현재 비정형 데이터 분석의 대상 중 대부분을 차지하고 있는 텍스트 데이터의 경우 언어 분석, 텍스트 마이닝, 소셜 네트워크 분석 등 적용 기술이 매우 다양하여 하나의 시스템에 적용된 시각화 기술을 다른 시스템에 적용하는 것이 용이하지 않다. 이는 현재의 텍스트 분석 결과에 대한 정보 모델이 서로 다른 시스템에 적용될 수 있도록 설계되지 못하는 경우가 많기 때문이다. 본 연구에서는 이러한 문제를 해결하기 위하여 다양한 텍스트 데이터 분석 사례와 시각화 사례들의 공통적 구성 요소들을 식별하여 표준화된 정보 모델인 텍스트 데이터 시각화 모델을 제시하고, 이를 통해 시각화의 GUI 부분과 연결할 수 있는 시스템 모델로서의 시각화 프레임워크인 TexVizu를 제안하고자 한다."
        },
        {
          "rank": 41,
          "score": 0.592785120010376,
          "doc_id": "NPAP13485077",
          "title": "Deep Interpretable Learning for a Rapid Response System",
          "abstract": "In-hospital cardiac arrest is a significant problem for medical systems. Although the traditional early warning systems have been widely applied, they still contain many drawbacks, such as the high false warning rate and low sensitivity. This paper proposed a strategy that involves a deep learning approach based on a novel interpretable deep tabular data learning architecture, named TabNet, for the Rapid Response System. This study has been processed and validated on a dataset collected from two hospitals of Chonnam National University, Korea, in over 10 years. The learning metrics used for the experiment are the area under the receiver operating characteristic curve score (AUROC) and the area under the precision-recall curve score (AUPRC). The experiment on a large real-time dataset shows that our method improves compared to other machine learning-based approaches.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13485077&target=NART&cn=NPAP13485077",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Interpretable Learning for a Rapid Response System Deep Interpretable Learning for a Rapid Response System Deep Interpretable Learning for a Rapid Response System In-hospital cardiac arrest is a significant problem for medical systems. Although the traditional early warning systems have been widely applied, they still contain many drawbacks, such as the high false warning rate and low sensitivity. This paper proposed a strategy that involves a deep learning approach based on a novel interpretable deep tabular data learning architecture, named TabNet, for the Rapid Response System. This study has been processed and validated on a dataset collected from two hospitals of Chonnam National University, Korea, in over 10 years. The learning metrics used for the experiment are the area under the receiver operating characteristic curve score (AUROC) and the area under the precision-recall curve score (AUPRC). The experiment on a large real-time dataset shows that our method improves compared to other machine learning-based approaches."
        },
        {
          "rank": 42,
          "score": 0.5923583507537842,
          "doc_id": "NPAP13648627",
          "title": "Detection of Research Trends using Dynamic Topic Modeling",
          "abstract": "<P>Discovering trends in research areas is helpful for researchers in finding the recent advances in a field or area of research. In addition, policy makers in universities can utilize this information in decision making. Different factors have direct influence on the growth and evolution of research topics. These include the funding, community interest and national needs. In this paper, we propose an unsupervised Dynamic Topic Modeling approach to discover and analyze the most trending research topics in a set of research areas using a collection of publications from the corresponding research areas. Furthermore, we study the correlation between emerging research trends and the different influencing factors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13648627&target=NART&cn=NPAP13648627",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Detection of Research Trends using Dynamic Topic Modeling Detection of Research Trends using Dynamic Topic Modeling Detection of Research Trends using Dynamic Topic Modeling <P>Discovering trends in research areas is helpful for researchers in finding the recent advances in a field or area of research. In addition, policy makers in universities can utilize this information in decision making. Different factors have direct influence on the growth and evolution of research topics. These include the funding, community interest and national needs. In this paper, we propose an unsupervised Dynamic Topic Modeling approach to discover and analyze the most trending research topics in a set of research areas using a collection of publications from the corresponding research areas. Furthermore, we study the correlation between emerging research trends and the different influencing factors.</P>"
        },
        {
          "rank": 43,
          "score": 0.5922635197639465,
          "doc_id": "NART98292774",
          "title": "Deliberate storytelling in big data analytics adoption",
          "abstract": "<P><B>Abstract</B></P><P>The emergence of big data analytics (BDA) has posed opportunities as well as multiple challenges to business practitioners, who have called for research on the behavioural factors underlying BDA adoption at the individual level. The purpose of this study is to extend the information systems (IS) research on storytelling and to explore the role and characteristics of deliberate storytelling in individual&#8208;level BDA adoption. This case study used the grounded theory approach to extract qualitative data from 24 interviews, field notes, and documentary data. The explicit contributions of the study to the literature include (a) increasing our understanding of the facilitating role of deliberate storytelling in individual&#8208;level BDA adoption, (b) identifying four deliberate storytelling patterns and seven underlying corporate stories disseminated by organizations to influence individual behaviour, and (c) defining the core characteristics of effective deliberate storytelling. This study has multiple implications for business practitioners and demonstrates how deliberate storytelling can be used as a facilitating mechanism in daily business practice.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98292774&target=NART&cn=NART98292774",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deliberate storytelling in big data analytics adoption Deliberate storytelling in big data analytics adoption Deliberate storytelling in big data analytics adoption <P><B>Abstract</B></P><P>The emergence of big data analytics (BDA) has posed opportunities as well as multiple challenges to business practitioners, who have called for research on the behavioural factors underlying BDA adoption at the individual level. The purpose of this study is to extend the information systems (IS) research on storytelling and to explore the role and characteristics of deliberate storytelling in individual&#8208;level BDA adoption. This case study used the grounded theory approach to extract qualitative data from 24 interviews, field notes, and documentary data. The explicit contributions of the study to the literature include (a) increasing our understanding of the facilitating role of deliberate storytelling in individual&#8208;level BDA adoption, (b) identifying four deliberate storytelling patterns and seven underlying corporate stories disseminated by organizations to influence individual behaviour, and (c) defining the core characteristics of effective deliberate storytelling. This study has multiple implications for business practitioners and demonstrates how deliberate storytelling can be used as a facilitating mechanism in daily business practice.</P>"
        },
        {
          "rank": 44,
          "score": 0.5915963053703308,
          "doc_id": "NART71734652",
          "title": "Big data analytics in healthcare: promise and potential",
          "abstract": "<P><B>Objective</B></P><P>To describe the promise and potential of big data analytics in healthcare.</P><P><B>Methods</B></P><P>The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions.</P><P><B>Results</B></P><P>The paper provides a broad overview of big data analytics for healthcare researchers and practitioners.</P><P><B>Conclusions</B></P><P>Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART71734652&target=NART&cn=NART71734652",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics in healthcare: promise and potential Big data analytics in healthcare: promise and potential Big data analytics in healthcare: promise and potential <P><B>Objective</B></P><P>To describe the promise and potential of big data analytics in healthcare.</P><P><B>Methods</B></P><P>The paper describes the nascent field of big data analytics in healthcare, discusses the benefits, outlines an architectural framework and methodology, describes examples reported in the literature, briefly discusses the challenges, and offers conclusions.</P><P><B>Results</B></P><P>The paper provides a broad overview of big data analytics for healthcare researchers and practitioners.</P><P><B>Conclusions</B></P><P>Big data analytics in healthcare is evolving into a promising field for providing insight from very large data sets and improving outcomes while reducing costs. Its potential is great; however there remain challenges to overcome.</P>"
        },
        {
          "rank": 45,
          "score": 0.5914261937141418,
          "doc_id": "JAKO200914035207851",
          "title": "애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계",
          "abstract": "본 논문에서는 인터넷 상에서 애플리케이션 공유과 데이터 접근을 수행할 수 있는 씬-클라이언트 프레임워크를 설계할 것이며, 관련 기술로 X 윈도우 시스템, 가상 서버, CODA 파일 시스템, MPI(Message Passing Interface)를 활용하고자 한다. 우리는 네트워크 연결이 중단되더라도 서버 상에서 실행되던 애플리케이션을 로컬 상에서 실행할 수 있음은 물론 서버 상의 작업 수행으로 생성된 데이터에 클라이언트가 최적으로 접근할 수 있는 씬-클라이언트 프레임워크를 제안하고자 한다. 또한 네트워크가 복원되었을 때 로컬 상의 작업 내역이 서버에 효과적으로 반영될 수 있어야 할 것이다. 이러한 씬-클라이언트 프레임워크를 설계하기 위하여 본 논문에서는 기존의 시스템에 분산 Pseudo 서버, CODA 파일 시스템 기술을 접목시킬 것이며, 보다 효율적인 작업 수행, 관리를 위해 MPI를 활용할 것이다. 이를 통하여 네트워크 독립적인 씬-클라이언트 작업 환경을 구축할 수 있고 서버의 병목현상을 지양함으로써 다수의 사용자에게 확장성 있는 애플리케이션 서비스를 제공할 수 있다. 본 논문에서는 이를 구현함에 있어 기반이 되는 씬-클라이언트 프레임워크의 설계 방안에 대해 논의하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200914035207851&target=NART&cn=JAKO200914035207851",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 애플리케이션 공유 및 데이터 접근 최적화를 위한 씬-클라이언트 프레임워크 설계 본 논문에서는 인터넷 상에서 애플리케이션 공유과 데이터 접근을 수행할 수 있는 씬-클라이언트 프레임워크를 설계할 것이며, 관련 기술로 X 윈도우 시스템, 가상 서버, CODA 파일 시스템, MPI(Message Passing Interface)를 활용하고자 한다. 우리는 네트워크 연결이 중단되더라도 서버 상에서 실행되던 애플리케이션을 로컬 상에서 실행할 수 있음은 물론 서버 상의 작업 수행으로 생성된 데이터에 클라이언트가 최적으로 접근할 수 있는 씬-클라이언트 프레임워크를 제안하고자 한다. 또한 네트워크가 복원되었을 때 로컬 상의 작업 내역이 서버에 효과적으로 반영될 수 있어야 할 것이다. 이러한 씬-클라이언트 프레임워크를 설계하기 위하여 본 논문에서는 기존의 시스템에 분산 Pseudo 서버, CODA 파일 시스템 기술을 접목시킬 것이며, 보다 효율적인 작업 수행, 관리를 위해 MPI를 활용할 것이다. 이를 통하여 네트워크 독립적인 씬-클라이언트 작업 환경을 구축할 수 있고 서버의 병목현상을 지양함으로써 다수의 사용자에게 확장성 있는 애플리케이션 서비스를 제공할 수 있다. 본 논문에서는 이를 구현함에 있어 기반이 되는 씬-클라이언트 프레임워크의 설계 방안에 대해 논의하고자 한다."
        },
        {
          "rank": 46,
          "score": 0.590061604976654,
          "doc_id": "NART106379474",
          "title": "구조적 토픽 모델링 기반 스마트 시티 연구 동향 분석",
          "abstract": "본 연구에서는 구조적 토픽 모델링을 활용하여 Scopus에 게재된 스마트 시티 관련 연구논문 12,400들의 데이터들을 수집하여 동향 분석을 수행하였다. 총 15개의 스마트 시티 주요 연구 토픽들은 &quot;Machine Learning&quot;, &quot;Network Performance&quot;, &quot;Waste Disposal&quot;, &quot;Air Quality&quot;, &quot;Energy Management&quot;, &quot;Intelligent Context Recognition&quot;, &quot;Big Data Analytics&quot;, &quot;Cloud Computing&quot;, &quot;IoT & Security&quot;, &quot;Social Media&quot;, &quot;Sustainable Urban Planning&quot;, &quot;Intelligent Traffic System&quot;, &quot;Healthcare&quot;, &quot;GIS&quot;, &quot;Disaster Management&quot;로 나타났으며, 추가적으로 토픽 발현률에 따라 Hot/Cold 토픽으로 분류한 결과로 기계학습 및 IoT와 같은 연구 분야들이 핫토픽으로 분류되었고, 이에 반해 소셜미디어 및 GIS와 같은 연구 분야는 상대적으로 감소추세를 보이므로 콜드토픽으로 분류되었다. 본 연구의 결과를 통해 현재까지의 스마트시티 관련 연구 동향을 파악하고, 향후 연구 및 정책에 대한 방향성을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106379474&target=NART&cn=NART106379474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "구조적 토픽 모델링 기반 스마트 시티 연구 동향 분석 구조적 토픽 모델링 기반 스마트 시티 연구 동향 분석 구조적 토픽 모델링 기반 스마트 시티 연구 동향 분석 본 연구에서는 구조적 토픽 모델링을 활용하여 Scopus에 게재된 스마트 시티 관련 연구논문 12,400들의 데이터들을 수집하여 동향 분석을 수행하였다. 총 15개의 스마트 시티 주요 연구 토픽들은 &quot;Machine Learning&quot;, &quot;Network Performance&quot;, &quot;Waste Disposal&quot;, &quot;Air Quality&quot;, &quot;Energy Management&quot;, &quot;Intelligent Context Recognition&quot;, &quot;Big Data Analytics&quot;, &quot;Cloud Computing&quot;, &quot;IoT & Security&quot;, &quot;Social Media&quot;, &quot;Sustainable Urban Planning&quot;, &quot;Intelligent Traffic System&quot;, &quot;Healthcare&quot;, &quot;GIS&quot;, &quot;Disaster Management&quot;로 나타났으며, 추가적으로 토픽 발현률에 따라 Hot/Cold 토픽으로 분류한 결과로 기계학습 및 IoT와 같은 연구 분야들이 핫토픽으로 분류되었고, 이에 반해 소셜미디어 및 GIS와 같은 연구 분야는 상대적으로 감소추세를 보이므로 콜드토픽으로 분류되었다. 본 연구의 결과를 통해 현재까지의 스마트시티 관련 연구 동향을 파악하고, 향후 연구 및 정책에 대한 방향성을 제시하고자 한다."
        },
        {
          "rank": 47,
          "score": 0.5891209840774536,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 48,
          "score": 0.589103102684021,
          "doc_id": "NART129438421",
          "title": "Big Data Analytics in Higher Education: A New Adaptive Learning Analytics Model Integrating Traditional Approaches",
          "abstract": "<P>Despite the explosion of interest in adaptive learning and learning analytics (LA) for higher education (HE), there has been relatively little research integrating educational approaches&rsquo; indicators to build an adaptive learning analytics model. Adaptive learning analytics (ALA) models have grown in favor of HE due to their claims of enhancing student learning outcomes, providing personalized learning paths, and allowing students to interact with course material at their own pace. With focus on using data to personalize the learning experience and the environment in which the experience of learning occurs, LA centers on enhancing education through meticulous data analysis, while big data (BD) in education addresses the overarching challenges and opportunities arising from extensive and varied datasets. These concepts are interconnected, where LA and ALA specifically apply BD principles within the educational context. In this paper, we explain some BD concepts used in HE, define the essential perceptions related to LA, and analyze educational approaches to define the fundamental implications. Besides, we try to connect some LA model with educational approaches based on the big educational data collected in order to establish an efficient educational model. We include all steps cited before we try to build an ALA model in HE that resolves the limitations of the oldest models, thus improving the learner&rsquo;s learning process by adding and treating additional indicators. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART129438421&target=NART&cn=NART129438421",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analytics in Higher Education: A New Adaptive Learning Analytics Model Integrating Traditional Approaches Big Data Analytics in Higher Education: A New Adaptive Learning Analytics Model Integrating Traditional Approaches Big Data Analytics in Higher Education: A New Adaptive Learning Analytics Model Integrating Traditional Approaches <P>Despite the explosion of interest in adaptive learning and learning analytics (LA) for higher education (HE), there has been relatively little research integrating educational approaches&rsquo; indicators to build an adaptive learning analytics model. Adaptive learning analytics (ALA) models have grown in favor of HE due to their claims of enhancing student learning outcomes, providing personalized learning paths, and allowing students to interact with course material at their own pace. With focus on using data to personalize the learning experience and the environment in which the experience of learning occurs, LA centers on enhancing education through meticulous data analysis, while big data (BD) in education addresses the overarching challenges and opportunities arising from extensive and varied datasets. These concepts are interconnected, where LA and ALA specifically apply BD principles within the educational context. In this paper, we explain some BD concepts used in HE, define the essential perceptions related to LA, and analyze educational approaches to define the fundamental implications. Besides, we try to connect some LA model with educational approaches based on the big educational data collected in order to establish an efficient educational model. We include all steps cited before we try to build an ALA model in HE that resolves the limitations of the oldest models, thus improving the learner&rsquo;s learning process by adding and treating additional indicators. </P>"
        },
        {
          "rank": 49,
          "score": 0.5886712074279785,
          "doc_id": "NART99544525",
          "title": "Healthcare informatics and analytics in big data",
          "abstract": "<P><B>Abstract</B></P>  <P>Healthcare informatics and analytics (HCI&amp;A), also known as healthcare information technology (HIT), healthcare IS (HIS), and so on, has rapidly evolved with the emerge of advanced data analytics technologies applied to the medical domain. Currently, HCI&amp;A has emerged as an important area of study for both practitioners and academic researchers. Accordingly, this emerging field has prompted for an inquiry of the opportunities and challenges related to management of healthcare data, and the application of advanced data analytics to the contemporary healthcare industry. In order to contribute to the literature of healthcare informatics and analytics, this study proposes an HCI&amp;A framework under the context of big data, which covers four important segments such as the underlying technologies, system applications, system evaluations, and emerging research areas. Based on the key features and capabilities of underpinning technologies, the evolution of HCI&amp;A are conceptualized by three stages, namely HCI&amp;A 1.0, HCI&amp;A 2.0, and HCI&amp;A 3.0. By analyzing the technological growth and current research trends, this study outlines the trend map of HCI&amp;A for education and knowledge transfer. We also contributed to conduct a bibliographic study on healthcare informatics and healthcare information systems. To the best of our knowledge, our study is among the very few comprehensive bibliographic studies about HCI&amp;A. We hope that our study can contribute to supplement contemporary thoughts on HCI&amp;A research, and facilitate the related knowledge transfer to the healthcare industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposed a framework for healthcare informatics in Big data context. </LI> <LI>  Presented an overall Synopsis of healthcare informatics and analytics. </LI> <LI>  Reported a bibliographic study on health informatics and information system. </LI> <LI>  Presented some problems and prospects of healthcare education &amp; development. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99544525&target=NART&cn=NART99544525",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Healthcare informatics and analytics in big data Healthcare informatics and analytics in big data Healthcare informatics and analytics in big data <P><B>Abstract</B></P>  <P>Healthcare informatics and analytics (HCI&amp;A), also known as healthcare information technology (HIT), healthcare IS (HIS), and so on, has rapidly evolved with the emerge of advanced data analytics technologies applied to the medical domain. Currently, HCI&amp;A has emerged as an important area of study for both practitioners and academic researchers. Accordingly, this emerging field has prompted for an inquiry of the opportunities and challenges related to management of healthcare data, and the application of advanced data analytics to the contemporary healthcare industry. In order to contribute to the literature of healthcare informatics and analytics, this study proposes an HCI&amp;A framework under the context of big data, which covers four important segments such as the underlying technologies, system applications, system evaluations, and emerging research areas. Based on the key features and capabilities of underpinning technologies, the evolution of HCI&amp;A are conceptualized by three stages, namely HCI&amp;A 1.0, HCI&amp;A 2.0, and HCI&amp;A 3.0. By analyzing the technological growth and current research trends, this study outlines the trend map of HCI&amp;A for education and knowledge transfer. We also contributed to conduct a bibliographic study on healthcare informatics and healthcare information systems. To the best of our knowledge, our study is among the very few comprehensive bibliographic studies about HCI&amp;A. We hope that our study can contribute to supplement contemporary thoughts on HCI&amp;A research, and facilitate the related knowledge transfer to the healthcare industry.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Proposed a framework for healthcare informatics in Big data context. </LI> <LI>  Presented an overall Synopsis of healthcare informatics and analytics. </LI> <LI>  Reported a bibliographic study on health informatics and information system. </LI> <LI>  Presented some problems and prospects of healthcare education &amp; development. </LI> </UL> </P>"
        },
        {
          "rank": 50,
          "score": 0.588431179523468,
          "doc_id": "JAKO201631642279380",
          "title": "Spark SQL 기반 고도 분석 지원 프레임워크 설계",
          "abstract": "기업의 신속한 의사결정 및 전략적 정책 결정을 위해 빅데이터에 대한 고도 분석이 필수적으로 요구됨에 따라 대량의 데이터를 복수의 노드에 분산하여 처리하는 하둡 또는 스파크와 같은 분산 처리 플랫폼이 주목을 받고 있다. 최근 공개된 Spark SQL은 Spark 환경에서 SQL 기반의 분산 처리 기법을 지원하고 있으나, 기계학습이나 그래프 처리와 같은 반복적 처리가 요구되는 고도 분석 분야에서는 효율적 처리가 불가능한 문제가 있다. 따라서 본 논문은 이러한 문제점을 바탕으로 Spark 환경에서 고도 분석 지원을 위한 SQL 기반의 빅데이터 최적처리 엔진설계와 처리 프레임워크를 제안한다. 복수의 조건과 다수의 조인, 집계, 소팅 연산이 필요한 복합 SQL 질의를 분산/병행적으로 처리할 수 있는 최적화 엔진과 관계형 연산을 지원하는 기계학습 최적화하기 위한 프레임워크를 설계한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201631642279380&target=NART&cn=JAKO201631642279380",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Spark SQL 기반 고도 분석 지원 프레임워크 설계 Spark SQL 기반 고도 분석 지원 프레임워크 설계 Spark SQL 기반 고도 분석 지원 프레임워크 설계 기업의 신속한 의사결정 및 전략적 정책 결정을 위해 빅데이터에 대한 고도 분석이 필수적으로 요구됨에 따라 대량의 데이터를 복수의 노드에 분산하여 처리하는 하둡 또는 스파크와 같은 분산 처리 플랫폼이 주목을 받고 있다. 최근 공개된 Spark SQL은 Spark 환경에서 SQL 기반의 분산 처리 기법을 지원하고 있으나, 기계학습이나 그래프 처리와 같은 반복적 처리가 요구되는 고도 분석 분야에서는 효율적 처리가 불가능한 문제가 있다. 따라서 본 논문은 이러한 문제점을 바탕으로 Spark 환경에서 고도 분석 지원을 위한 SQL 기반의 빅데이터 최적처리 엔진설계와 처리 프레임워크를 제안한다. 복수의 조건과 다수의 조인, 집계, 소팅 연산이 필요한 복합 SQL 질의를 분산/병행적으로 처리할 수 있는 최적화 엔진과 관계형 연산을 지원하는 기계학습 최적화하기 위한 프레임워크를 설계한다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}