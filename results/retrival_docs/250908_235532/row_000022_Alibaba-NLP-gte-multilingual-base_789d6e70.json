{
  "id": "row_000022",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:35.153398+09:00",
  "trial_id": "789d6e70",
  "queries": [
    {
      "query": "Can you provide a concise overview of the comparison between deep learning and deep reinforcement learning for complex image analysis, highlighting their strengths and weaknesses?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7948895692825317,
          "doc_id": "ART002574280",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002574280&target=NART&cn=ART002574280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 2,
          "score": 0.7948895692825317,
          "doc_id": "JAKO202009863559871",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009863559871&target=NART&cn=JAKO202009863559871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 3,
          "score": 0.6969382166862488,
          "doc_id": "JAKO202223540366088",
          "title": "이미지 학습을 위한 딥러닝 프레임워크 비교분석",
          "abstract": "딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202223540366088&target=NART&cn=JAKO202223540366088",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다."
        },
        {
          "rank": 4,
          "score": 0.6921593546867371,
          "doc_id": "JAKO201713056893580",
          "title": "딥 러닝 프레임워크의 비교 및 분석",
          "abstract": "딥 러닝은 사람이 가르치지 않아도 컴퓨터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 딥 러닝은 세상을 이해하고 감지하는 인공지능을 개발하는데 가장 촉망받는 기술이 되고 있으며, 구글, 바이두, 페이스북 등이 가장 앞서서 개발을 하고 있다. 본 논문에서는 딥 러닝을 구현하는 딥 러닝 프레임워크의 종류에 대해 논의하고, 딥 러닝 프레임워크의 영상과 음성 인식 분야의 효율성에 대해 비교, 분석하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713056893580&target=NART&cn=JAKO201713056893580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 프레임워크의 비교 및 분석 딥 러닝 프레임워크의 비교 및 분석 딥 러닝 프레임워크의 비교 및 분석 딥 러닝은 사람이 가르치지 않아도 컴퓨터가 스스로 사람처럼 학습할 수 있는 인공지능 기술이다. 딥 러닝은 세상을 이해하고 감지하는 인공지능을 개발하는데 가장 촉망받는 기술이 되고 있으며, 구글, 바이두, 페이스북 등이 가장 앞서서 개발을 하고 있다. 본 논문에서는 딥 러닝을 구현하는 딥 러닝 프레임워크의 종류에 대해 논의하고, 딥 러닝 프레임워크의 영상과 음성 인식 분야의 효율성에 대해 비교, 분석하고자 한다."
        },
        {
          "rank": 5,
          "score": 0.6847774982452393,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 6,
          "score": 0.6842399835586548,
          "doc_id": "NART105497078",
          "title": "Deep Reinforcement Learning for Image Hashing",
          "abstract": "<P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART105497078&target=NART&cn=NART105497078",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing <P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>"
        },
        {
          "rank": 7,
          "score": 0.6807682514190674,
          "doc_id": "JAKO202218262151224",
          "title": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석",
          "abstract": "생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202218262151224&target=NART&cn=JAKO202218262151224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다."
        },
        {
          "rank": 8,
          "score": 0.6627019643783569,
          "doc_id": "JAKO202210351407855",
          "title": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적",
          "abstract": "Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202210351407855&target=NART&cn=JAKO202210351407855",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them."
        },
        {
          "rank": 9,
          "score": 0.660831093788147,
          "doc_id": "JAKO201962652079504",
          "title": "심층 강화학습 기술 동향",
          "abstract": "Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201962652079504&target=NART&cn=JAKO201962652079504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기술 동향 심층 강화학습 기술 동향 심층 강화학습 기술 동향 Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions."
        },
        {
          "rank": 10,
          "score": 0.6590358018875122,
          "doc_id": "NART95036368",
          "title": "Deep Reinforcement Learning in Medicine",
          "abstract": "<P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95036368&target=NART&cn=NART95036368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine <P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>"
        },
        {
          "rank": 11,
          "score": 0.6574050784111023,
          "doc_id": "NART118990104",
          "title": "Hierarchical Image Object Search Based on Deep Reinforcement Learning",
          "abstract": "<P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118990104&target=NART&cn=NART118990104",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning <P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>"
        },
        {
          "rank": 12,
          "score": 0.6573758125305176,
          "doc_id": "NART96288640",
          "title": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms",
          "abstract": "<P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96288640&target=NART&cn=NART96288640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms <P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>"
        },
        {
          "rank": 13,
          "score": 0.6546927690505981,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 14,
          "score": 0.6534938812255859,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 15,
          "score": 0.6470968127250671,
          "doc_id": "JAKO201974757494930",
          "title": "심층강화학습 라이브러리 기술동향",
          "abstract": "Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201974757494930&target=NART&cn=JAKO201974757494930",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective."
        },
        {
          "rank": 16,
          "score": 0.6467992067337036,
          "doc_id": "ART002367528",
          "title": "Recognition of Human Motion with Deep Reinforcement Learning",
          "abstract": "Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002367528&target=NART&cn=ART002367528",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data."
        },
        {
          "rank": 17,
          "score": 0.6466917991638184,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 18,
          "score": 0.6463732719421387,
          "doc_id": "NART121556950",
          "title": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement",
          "abstract": "<P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121556950&target=NART&cn=NART121556950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement <P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>"
        },
        {
          "rank": 19,
          "score": 0.6435012817382812,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 20,
          "score": 0.6432315111160278,
          "doc_id": "JAKO202433861648179",
          "title": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교",
          "abstract": "본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202433861648179&target=NART&cn=JAKO202433861648179",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다."
        },
        {
          "rank": 21,
          "score": 0.6429077982902527,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 22,
          "score": 0.640784502029419,
          "doc_id": "NART119629224",
          "title": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging",
          "abstract": "<P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119629224&target=NART&cn=NART119629224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging <P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>"
        },
        {
          "rank": 23,
          "score": 0.6405501365661621,
          "doc_id": "JAKO201718054814596",
          "title": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석",
          "abstract": "딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201718054814596&target=NART&cn=JAKO201718054814596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다."
        },
        {
          "rank": 24,
          "score": 0.6361116170883179,
          "doc_id": "NPAP12898051",
          "title": "딥러닝 프레임워크 비교 및 분석",
          "abstract": "딥러닝(Deep Learning)을 효과적으로 연구하고 개발할 수 있도록 도와주는 다양한 딥러닝 프레임워크(Deep Learning Framework)가 있다. 딥러닝 프레임워크는 현재 100 가지도 넘는 종류가 있다. 그렇기 때문에 개발의 목적에 가장 적합한 딥러닝 프레임워크를 선택하는 것은 쉽지 않다. 본고에서는 5가지 대표적인 딥러닝 프레임워크에 대해서 각각의 특징을 분석하고 비교한다. 이를 통하여 딥러닝을 개발하기 전에 개발 목적에 적합한 프레임워크를 선택할 수 있는 간단한 안목을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12898051&target=NART&cn=NPAP12898051",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 프레임워크 비교 및 분석 딥러닝 프레임워크 비교 및 분석 딥러닝 프레임워크 비교 및 분석 딥러닝(Deep Learning)을 효과적으로 연구하고 개발할 수 있도록 도와주는 다양한 딥러닝 프레임워크(Deep Learning Framework)가 있다. 딥러닝 프레임워크는 현재 100 가지도 넘는 종류가 있다. 그렇기 때문에 개발의 목적에 가장 적합한 딥러닝 프레임워크를 선택하는 것은 쉽지 않다. 본고에서는 5가지 대표적인 딥러닝 프레임워크에 대해서 각각의 특징을 분석하고 비교한다. 이를 통하여 딥러닝을 개발하기 전에 개발 목적에 적합한 프레임워크를 선택할 수 있는 간단한 안목을 제시한다."
        },
        {
          "rank": 25,
          "score": 0.6333978176116943,
          "doc_id": "NART136112293",
          "title": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning",
          "abstract": "<P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART136112293&target=NART&cn=NART136112293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning <P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>"
        },
        {
          "rank": 26,
          "score": 0.6302131414413452,
          "doc_id": "NART126940867",
          "title": "Developments in Image Processing Using Deep Learning and Reinforcement Learning",
          "abstract": "<P>The growth in the volume of data generated, consumed, and stored, which is estimated to exceed 180 zettabytes in 2025, represents a major challenge both for organizations and for society in general. In addition to being larger, datasets are increasingly complex, bringing new theoretical and computational challenges. Alongside this evolution, data science tools have exploded in popularity over the past two decades due to their myriad of applications when dealing with complex data, their high accuracy, flexible customization, and excellent adaptability. When it comes to images, data analysis presents additional challenges because as the quality of an image increases, which is desirable, so does the volume of data to be processed. Although classic machine learning (ML) techniques are still widely used in different research fields and industries, there has been great interest from the scientific community in the development of new artificial intelligence (AI) techniques. The resurgence of neural networks has boosted remarkable advances in areas such as the understanding and processing of images. In this study, we conducted a comprehensive survey regarding advances in AI design and the optimization solutions proposed to deal with image processing challenges. Despite the good results that have been achieved, there are still many challenges to face in this field of study. In this work, we discuss the main and more recent improvements, applications, and developments when targeting image processing applications, and we propose future research directions in this field of constant and fast evolution.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART126940867&target=NART&cn=NART126940867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Developments in Image Processing Using Deep Learning and Reinforcement Learning Developments in Image Processing Using Deep Learning and Reinforcement Learning Developments in Image Processing Using Deep Learning and Reinforcement Learning <P>The growth in the volume of data generated, consumed, and stored, which is estimated to exceed 180 zettabytes in 2025, represents a major challenge both for organizations and for society in general. In addition to being larger, datasets are increasingly complex, bringing new theoretical and computational challenges. Alongside this evolution, data science tools have exploded in popularity over the past two decades due to their myriad of applications when dealing with complex data, their high accuracy, flexible customization, and excellent adaptability. When it comes to images, data analysis presents additional challenges because as the quality of an image increases, which is desirable, so does the volume of data to be processed. Although classic machine learning (ML) techniques are still widely used in different research fields and industries, there has been great interest from the scientific community in the development of new artificial intelligence (AI) techniques. The resurgence of neural networks has boosted remarkable advances in areas such as the understanding and processing of images. In this study, we conducted a comprehensive survey regarding advances in AI design and the optimization solutions proposed to deal with image processing challenges. Despite the good results that have been achieved, there are still many challenges to face in this field of study. In this work, we discuss the main and more recent improvements, applications, and developments when targeting image processing applications, and we propose future research directions in this field of constant and fast evolution.</P>"
        },
        {
          "rank": 27,
          "score": 0.6294362545013428,
          "doc_id": "JAKO202106153187643",
          "title": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론",
          "abstract": "빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153187643&target=NART&cn=JAKO202106153187643",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다."
        },
        {
          "rank": 28,
          "score": 0.6290249824523926,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 29,
          "score": 0.6287461519241333,
          "doc_id": "NART134008954",
          "title": "The advancements and applications of deep reinforcement learning in Go",
          "abstract": "<P>Combining Deep Learning's perceptual skills with Reinforcement Learning's decision-making abilities, Deep Reinforcement Learning (DRL) represents a significant breakthrough in Artificial Intelligence (AI). This paper examines the evolution and uses of Deep Reinforcement Learning (DRL), emphasizing both the theoretical underpinnings and the noteworthy real-world applications-like AlphaGo's triumph over elite Go players-of the technology. DRL systems learn optimal policies through interactions with their environment, maximizing long-term cumulative rewards. DRL has achieved remarkable results in complex decision-making tasks through the combination of deep learning models like Convolutional Neural Networks (CNN) and reinforcement learning techniques. DRL's potential to transform AI applications is demonstrated by its success in a number of industries, including robotics, autonomous driving, and video games. AlphaGo's success, leveraging DRL and Monte Carlo Tree Search (MCTS), exemplifies the impact of this method on game theory and strategic decision-making. This paper aims to explore the key concepts of DRL, its historical evolution, and its future prospects in advanced AI research.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART134008954&target=NART&cn=NART134008954",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The advancements and applications of deep reinforcement learning in Go The advancements and applications of deep reinforcement learning in Go The advancements and applications of deep reinforcement learning in Go <P>Combining Deep Learning's perceptual skills with Reinforcement Learning's decision-making abilities, Deep Reinforcement Learning (DRL) represents a significant breakthrough in Artificial Intelligence (AI). This paper examines the evolution and uses of Deep Reinforcement Learning (DRL), emphasizing both the theoretical underpinnings and the noteworthy real-world applications-like AlphaGo's triumph over elite Go players-of the technology. DRL systems learn optimal policies through interactions with their environment, maximizing long-term cumulative rewards. DRL has achieved remarkable results in complex decision-making tasks through the combination of deep learning models like Convolutional Neural Networks (CNN) and reinforcement learning techniques. DRL's potential to transform AI applications is demonstrated by its success in a number of industries, including robotics, autonomous driving, and video games. AlphaGo's success, leveraging DRL and Monte Carlo Tree Search (MCTS), exemplifies the impact of this method on game theory and strategic decision-making. This paper aims to explore the key concepts of DRL, its historical evolution, and its future prospects in advanced AI research.</P>"
        },
        {
          "rank": 30,
          "score": 0.6237884759902954,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 31,
          "score": 0.620552122592926,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 32,
          "score": 0.6200940608978271,
          "doc_id": "NART113995599",
          "title": "Deep image enhancement for ill light imaging",
          "abstract": "<P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113995599&target=NART&cn=NART113995599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging <P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>"
        },
        {
          "rank": 33,
          "score": 0.6195369958877563,
          "doc_id": "DIKO0015391154",
          "title": "심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현",
          "abstract": "딥 러닝과 강화학습을 접목한 딥 강화학습은 다양한 분야에 활용 가능성을 보이며 실생활에 적용되고 있다. 또한 성공한 몇몇 사례들의 커다란 가능성을 통해 여러 분야에 걸쳐 폭 넓은 연구들이 이루어지고 있다.&amp;#xD; 본 논문은 오델로, 바둑, 체스 등과 같은 지능적 사고를 필요로 하는 보드게임에서 복잡한 상태와 형세판단 사이의 상관관계를 찾기 위해 실제 프로기사들의 대국을 답습한 CNN을 설계하고, 판단한 형세를 근거 삼아 최소최대탐색을 이용해 최적의 수를 찾는 의사 결정을 한다. 또한 형세 판단의 근거를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안한다.&amp;#xD; 지도학습 과정의 성능을 비교하기 위해 본 연구자가 선행연구 했었던 비교적 간단한 구조를 가진 지도학습 기반의 ANN 가치평가 네트워크[1]와 본 논문에서 제안하는 지도학습 기반 CNN 가치평가 네트워크와의 대국을 실행하여, 흑일 때 69.7%, 백일 때 72.1%의 승률을 보였다. 또한 지도학습 네트워크를 자가대국으로 policy-iteration기반의 강화 학습을 적용하여 발전시킨 네트워크와 앞서 말한 두 네트워크(ANN, CNN)와의 성능 비교도 실시하였으며 최종적인 승률은 흑일 때 ANN을 상대로100%, CNN을 상대로76%의 승률을 보였으며, 백일 때 ANN을 상대로100%, CNN을 상대로 78%의 승률을 보였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015391154&target=NART&cn=DIKO0015391154",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 딥 러닝과 강화학습을 접목한 딥 강화학습은 다양한 분야에 활용 가능성을 보이며 실생활에 적용되고 있다. 또한 성공한 몇몇 사례들의 커다란 가능성을 통해 여러 분야에 걸쳐 폭 넓은 연구들이 이루어지고 있다.&amp;#xD; 본 논문은 오델로, 바둑, 체스 등과 같은 지능적 사고를 필요로 하는 보드게임에서 복잡한 상태와 형세판단 사이의 상관관계를 찾기 위해 실제 프로기사들의 대국을 답습한 CNN을 설계하고, 판단한 형세를 근거 삼아 최소최대탐색을 이용해 최적의 수를 찾는 의사 결정을 한다. 또한 형세 판단의 근거를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안한다.&amp;#xD; 지도학습 과정의 성능을 비교하기 위해 본 연구자가 선행연구 했었던 비교적 간단한 구조를 가진 지도학습 기반의 ANN 가치평가 네트워크[1]와 본 논문에서 제안하는 지도학습 기반 CNN 가치평가 네트워크와의 대국을 실행하여, 흑일 때 69.7%, 백일 때 72.1%의 승률을 보였다. 또한 지도학습 네트워크를 자가대국으로 policy-iteration기반의 강화 학습을 적용하여 발전시킨 네트워크와 앞서 말한 두 네트워크(ANN, CNN)와의 성능 비교도 실시하였으며 최종적인 승률은 흑일 때 ANN을 상대로100%, CNN을 상대로76%의 승률을 보였으며, 백일 때 ANN을 상대로100%, CNN을 상대로 78%의 승률을 보였다.&amp;#xD;"
        },
        {
          "rank": 34,
          "score": 0.6188706159591675,
          "doc_id": "NART101975410",
          "title": "Learning Mobile Manipulation through Deep Reinforcement Learning",
          "abstract": "<P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART101975410&target=NART&cn=NART101975410",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning <P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>"
        },
        {
          "rank": 35,
          "score": 0.6186106204986572,
          "doc_id": "NART119879737",
          "title": "Image Enhancement Method Based on Deep Learning",
          "abstract": "<P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119879737&target=NART&cn=NART119879737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning <P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>"
        },
        {
          "rank": 36,
          "score": 0.6182718873023987,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 37,
          "score": 0.6179240942001343,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 38,
          "score": 0.6174263954162598,
          "doc_id": "JAKO202013562119985",
          "title": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석",
          "abstract": "Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013562119985&target=NART&cn=JAKO202013562119985",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
        },
        {
          "rank": 39,
          "score": 0.6169393062591553,
          "doc_id": "NART115326214",
          "title": "Deep learning-based single image face depth data enhancement",
          "abstract": "<P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART115326214&target=NART&cn=NART115326214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement <P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>"
        },
        {
          "rank": 40,
          "score": 0.6166502237319946,
          "doc_id": "DIKO0014373092",
          "title": "Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서",
          "abstract": "통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014373092&target=NART&cn=DIKO0014373092",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서 Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서 Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다."
        },
        {
          "rank": 41,
          "score": 0.6166480779647827,
          "doc_id": "JAKO202318552746049",
          "title": "그라운드-롤 제거를 위한 CNN과 GAN 기반 딥러닝 모델 비교 분석",
          "abstract": "그라운드-롤(ground roll)은 육상 탄성파 탐사 자료에서 가장 흔하게 나타나는 일관성 잡음(coherent noise)이며 탐사를 통해 얻고자 하는 반사 이벤트 신호보다 훨씬 큰 진폭을 가지고 있다. 따라서 탄성파 자료 처리에서 그라운드-롤 제거는 매우 중요하고 필수적인 과정이다. 그라운드-롤 제거를 위해 주파수-파수 필터링, 커브릿(curvelet) 변환 등 여러 제거 기술이 개발되어 왔으나 제거 성능과 효율성을 개선하기 위한 방법에 대한 수요는 여전히 존재한다. 최근에는 영상처리 분야에서 개발된 딥러닝 기법들을 활용하여 탄성파 자료의 그라운드-롤을 제거하고자 하는 연구도 다양하게 수행되고 있다. 이 논문에서는 그라운드-롤 제거를 위해 CNN (convolutional neural network) 또는 cGAN (conditional generative adversarial network)을 기반으로 하는 세가지 모델(DnCNN (De-noiseCNN), pix2pix, CycleGAN)을 적용한 연구들을 소개하고 수치 예제를 통해 상세히 설명하였다. 알고리듬 비교를 위해 동일한 현장에서 취득한 송신원 모음을 훈련 자료와 테스트 자료로 나누어 모델을 학습하고, 모델 성능을 평가하였다. 이러한 딥러닝 모델은 현장자료를 사용하여 훈련할 때, 그라운드-롤이 제거된 자료가 필요하므로 주파수-파수 필터링으로 그라운드-롤을 제거하여 정답자료로 사용하였다. 딥러닝 모델의 성능 평가 및 훈련 결과 비교는 정답 자료와의 유사성을 기본으로 상관계수와 SSIM (structural similarity index measure)과 같은 정량적 지표를 활용하였다. 결과적으로 DnCNN 모델이 가장 좋은 성능을 보였으며, 다른 모델들도 그라운드-롤 제거에 활용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318552746049&target=NART&cn=JAKO202318552746049",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "그라운드-롤 제거를 위한 CNN과 GAN 기반 딥러닝 모델 비교 분석 그라운드-롤 제거를 위한 CNN과 GAN 기반 딥러닝 모델 비교 분석 그라운드-롤 제거를 위한 CNN과 GAN 기반 딥러닝 모델 비교 분석 그라운드-롤(ground roll)은 육상 탄성파 탐사 자료에서 가장 흔하게 나타나는 일관성 잡음(coherent noise)이며 탐사를 통해 얻고자 하는 반사 이벤트 신호보다 훨씬 큰 진폭을 가지고 있다. 따라서 탄성파 자료 처리에서 그라운드-롤 제거는 매우 중요하고 필수적인 과정이다. 그라운드-롤 제거를 위해 주파수-파수 필터링, 커브릿(curvelet) 변환 등 여러 제거 기술이 개발되어 왔으나 제거 성능과 효율성을 개선하기 위한 방법에 대한 수요는 여전히 존재한다. 최근에는 영상처리 분야에서 개발된 딥러닝 기법들을 활용하여 탄성파 자료의 그라운드-롤을 제거하고자 하는 연구도 다양하게 수행되고 있다. 이 논문에서는 그라운드-롤 제거를 위해 CNN (convolutional neural network) 또는 cGAN (conditional generative adversarial network)을 기반으로 하는 세가지 모델(DnCNN (De-noiseCNN), pix2pix, CycleGAN)을 적용한 연구들을 소개하고 수치 예제를 통해 상세히 설명하였다. 알고리듬 비교를 위해 동일한 현장에서 취득한 송신원 모음을 훈련 자료와 테스트 자료로 나누어 모델을 학습하고, 모델 성능을 평가하였다. 이러한 딥러닝 모델은 현장자료를 사용하여 훈련할 때, 그라운드-롤이 제거된 자료가 필요하므로 주파수-파수 필터링으로 그라운드-롤을 제거하여 정답자료로 사용하였다. 딥러닝 모델의 성능 평가 및 훈련 결과 비교는 정답 자료와의 유사성을 기본으로 상관계수와 SSIM (structural similarity index measure)과 같은 정량적 지표를 활용하였다. 결과적으로 DnCNN 모델이 가장 좋은 성능을 보였으며, 다른 모델들도 그라운드-롤 제거에 활용될 수 있음을 확인하였다."
        },
        {
          "rank": 42,
          "score": 0.6165459156036377,
          "doc_id": "JAKO202109835990951",
          "title": "분해 심층 학습을 이용한 저조도 영상 개선 방식",
          "abstract": "본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109835990951&target=NART&cn=JAKO202109835990951",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다."
        },
        {
          "rank": 43,
          "score": 0.6151126623153687,
          "doc_id": "NART98464294",
          "title": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging",
          "abstract": "<P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98464294&target=NART&cn=NART98464294",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging <P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>"
        },
        {
          "rank": 44,
          "score": 0.6148922443389893,
          "doc_id": "NART110796699",
          "title": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network",
          "abstract": "<P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110796699&target=NART&cn=NART110796699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network <P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>"
        },
        {
          "rank": 45,
          "score": 0.6136350631713867,
          "doc_id": "NART107287464",
          "title": "Benchmarking open source deep learning frameworks",
          "abstract": "<P>Deep Learning (DL) is one of the hottest fields. To foster the growth of DL, several open source frameworks appeared providing implementations of the most common DL algorithms. These frameworks vary in the algorithms they support and in the quality of their implementations. The purpose of this work is to provide a qualitative and quantitative comparison among three such frameworks: TensorFlow, Theano and CNTK. To ensure that our study is as comprehensive as possible, we consider multiple benchmark datasets from different fields (image processing, NLP, etc.) and measure the performance of the frameworks' implementations of different DL algorithms. For most of our experiments, we find out that CNTK's implementations are superior to the other ones under consideration.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART107287464&target=NART&cn=NART107287464",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Benchmarking open source deep learning frameworks Benchmarking open source deep learning frameworks Benchmarking open source deep learning frameworks <P>Deep Learning (DL) is one of the hottest fields. To foster the growth of DL, several open source frameworks appeared providing implementations of the most common DL algorithms. These frameworks vary in the algorithms they support and in the quality of their implementations. The purpose of this work is to provide a qualitative and quantitative comparison among three such frameworks: TensorFlow, Theano and CNTK. To ensure that our study is as comprehensive as possible, we consider multiple benchmark datasets from different fields (image processing, NLP, etc.) and measure the performance of the frameworks' implementations of different DL algorithms. For most of our experiments, we find out that CNTK's implementations are superior to the other ones under consideration.</P>"
        },
        {
          "rank": 46,
          "score": 0.6133102178573608,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 47,
          "score": 0.6118474006652832,
          "doc_id": "JAKO202011161035249",
          "title": "객체 검출을 위한 CNN과 YOLO 성능 비교 실험",
          "abstract": "Object detection plays a critical role in the field of computer vision, and various researches have rapidly increased along with applying convolutional neural network and its modified structures since 2012. There are representative object detection algorithms, which are convolutional neural networks and YOLO. This paper presents two representative algorithm series, based on CNN and YOLO which solves the problem of CNN bounding box. We compare the performance of algorithm series in terms of accuracy, speed and cost. Compared with the latest advanced solution, YOLO v3 achieves a good trade-off between speed and accuracy.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202011161035249&target=NART&cn=JAKO202011161035249",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "객체 검출을 위한 CNN과 YOLO 성능 비교 실험 객체 검출을 위한 CNN과 YOLO 성능 비교 실험 객체 검출을 위한 CNN과 YOLO 성능 비교 실험 Object detection plays a critical role in the field of computer vision, and various researches have rapidly increased along with applying convolutional neural network and its modified structures since 2012. There are representative object detection algorithms, which are convolutional neural networks and YOLO. This paper presents two representative algorithm series, based on CNN and YOLO which solves the problem of CNN bounding box. We compare the performance of algorithm series in terms of accuracy, speed and cost. Compared with the latest advanced solution, YOLO v3 achieves a good trade-off between speed and accuracy."
        },
        {
          "rank": 48,
          "score": 0.6091805696487427,
          "doc_id": "NART131717213",
          "title": "Deep Learning Based Cystoscopy Image Enhancement",
          "abstract": "<P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131717213&target=NART&cn=NART131717213",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement <P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>"
        },
        {
          "rank": 49,
          "score": 0.6089781522750854,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 50,
          "score": 0.6080301403999329,
          "doc_id": "DIKO0015889140",
          "title": "딥 러닝 프레임워크 성능 비교 및 개선 방안",
          "abstract": "현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015889140&target=NART&cn=DIKO0015889140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 딥 러닝 프레임워크 성능 비교 및 개선 방안 현 시대는 4차 산업혁명이 대두되는 시대로 요소 기술들 중 인공지능의 중 요성은 아무리 강조하더라도 지나치지 않으며, 기업들 경쟁력의 척도라고 불 릴만큼 모든 산업에서 활용되고있다. 2016년 경 DeepMind 의 AlphaGo 와 이 세돌 선수의 경기로 국내에서는 처음으로 인공지능의 위력과 Deep Learning 이라는 단어가 대중들에게 알려지게 되었다.&amp;#xD; 특정 IT 산업이 발전하게 되면 해당 분야의 개발자들의 생산성과 접근성을 높이기 위해 Framework 들이 등장, 발전하게 된다. 통신기술과 스마트폰의 출현으로 WEB 붐이 이르렀을 때, Server-side 에서는 Spring, django, Ruby on Rails 등이 출현하였고, Client-side 에서는 Angular, React, jQuery 와 같이 다양한 Framework 들이 등장 발전하였다. 컴퓨터 성능의 발전과 다양 한 컴퓨팅 기술의 발전으로 현 시대는 인공지능 3차 붐으로 Machine Learning 과 Deep Learning 의 시대로 불리고있다.&amp;#xD; 이와 같이 Deep Learning 분야에서도 다양한 Framework 들이 개발되었다. 이런 다양한 Framework 제품들의 목적은 개발자들의 생산성을 향상시키기 위 해 내부 알고리즘이나 메커니즘을 Black Box 형식으로 감추고 High Level API 를 제공하기 때문에, 내부적인 구현 방식은 Framework 별로 다르다. 본 논문에서는 현 시대에 가장 많이 사용하는 대표적인 Framework 들을 선정한 다. 그리고 선정된 Framework 들을 이용하여 Convolutional Neural Network 알고리즘을 구현, 동일한 Training Data 를 이용하여 학습 Model 을 만들어 낸다. 그리고 동일한 Cloud 환경에서 각 Framework 별 학습을 수행하여 성 능을 비교한다. 성능 비교 환경은 총 3가지로 CPU, GPU 1 Core, Multi GPU Core 환경에서 각 Framework 별 성능 지표를 추출한다."
        }
      ]
    },
    {
      "query": "What are the strengths of deep learning for complex image analysis?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.716731607913971,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 2,
          "score": 0.702203631401062,
          "doc_id": "ART002574280",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002574280&target=NART&cn=ART002574280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 3,
          "score": 0.702203631401062,
          "doc_id": "JAKO202009863559871",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009863559871&target=NART&cn=JAKO202009863559871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 4,
          "score": 0.696759819984436,
          "doc_id": "NART136112293",
          "title": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning",
          "abstract": "<P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART136112293&target=NART&cn=NART136112293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning <P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>"
        },
        {
          "rank": 5,
          "score": 0.6945849657058716,
          "doc_id": "NART110796699",
          "title": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network",
          "abstract": "<P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110796699&target=NART&cn=NART110796699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network <P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>"
        },
        {
          "rank": 6,
          "score": 0.6872358322143555,
          "doc_id": "JAKO202223540366088",
          "title": "이미지 학습을 위한 딥러닝 프레임워크 비교분석",
          "abstract": "딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202223540366088&target=NART&cn=JAKO202223540366088",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다."
        },
        {
          "rank": 7,
          "score": 0.6855177879333496,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 8,
          "score": 0.682822048664093,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 9,
          "score": 0.6825244426727295,
          "doc_id": "JAKO201809863000185",
          "title": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구",
          "abstract": "본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809863000185&target=NART&cn=JAKO201809863000185",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다."
        },
        {
          "rank": 10,
          "score": 0.6819021701812744,
          "doc_id": "NART121556950",
          "title": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement",
          "abstract": "<P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121556950&target=NART&cn=NART121556950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement <P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>"
        },
        {
          "rank": 11,
          "score": 0.6813607215881348,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 12,
          "score": 0.680694580078125,
          "doc_id": "JAKO202218262151224",
          "title": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석",
          "abstract": "생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202218262151224&target=NART&cn=JAKO202218262151224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다."
        },
        {
          "rank": 13,
          "score": 0.6791421175003052,
          "doc_id": "JAKO202106153187643",
          "title": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론",
          "abstract": "빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153187643&target=NART&cn=JAKO202106153187643",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다."
        },
        {
          "rank": 14,
          "score": 0.6790497303009033,
          "doc_id": "NART119629224",
          "title": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging",
          "abstract": "<P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119629224&target=NART&cn=NART119629224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging <P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>"
        },
        {
          "rank": 15,
          "score": 0.6767432689666748,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 16,
          "score": 0.6740951538085938,
          "doc_id": "DIKO0017114224",
          "title": "딥러닝을 활용한 초음파 영상 개선",
          "abstract": "의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017114224&target=NART&cn=DIKO0017114224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다."
        },
        {
          "rank": 17,
          "score": 0.6732735633850098,
          "doc_id": "JAKO202109835990951",
          "title": "분해 심층 학습을 이용한 저조도 영상 개선 방식",
          "abstract": "본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109835990951&target=NART&cn=JAKO202109835990951",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다."
        },
        {
          "rank": 18,
          "score": 0.6705180406570435,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 19,
          "score": 0.6691809892654419,
          "doc_id": "NART115326214",
          "title": "Deep learning-based single image face depth data enhancement",
          "abstract": "<P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART115326214&target=NART&cn=NART115326214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement <P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>"
        },
        {
          "rank": 20,
          "score": 0.6680816411972046,
          "doc_id": "JAKO202221359246132",
          "title": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정",
          "abstract": "영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202221359246132&target=NART&cn=JAKO202221359246132",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다."
        },
        {
          "rank": 21,
          "score": 0.6659179329872131,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 22,
          "score": 0.6628118753433228,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 23,
          "score": 0.6624398231506348,
          "doc_id": "JAKO202126048601456",
          "title": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구",
          "abstract": "딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202126048601456&target=NART&cn=JAKO202126048601456",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다."
        },
        {
          "rank": 24,
          "score": 0.6610480546951294,
          "doc_id": "JAKO202013562119985",
          "title": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석",
          "abstract": "Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013562119985&target=NART&cn=JAKO202013562119985",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
        },
        {
          "rank": 25,
          "score": 0.6606168746948242,
          "doc_id": "NART119879737",
          "title": "Image Enhancement Method Based on Deep Learning",
          "abstract": "<P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119879737&target=NART&cn=NART119879737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning <P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>"
        },
        {
          "rank": 26,
          "score": 0.6561802625656128,
          "doc_id": "JAKO202128837709024",
          "title": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법",
          "abstract": "딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128837709024&target=NART&cn=JAKO202128837709024",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 영상 데이터 특징 커버리지 기반 딥러닝 모델 검증 기법 딥러닝 기법은 영상 처리 분야에서 높은 성능을 입증 받아 다양한 분야에서 적용되고 있다. 이러한 딥러닝 모델의 검증에 가장 널리 사용되는 방법으로는 홀드아웃 검증 방법, k-겹 교차 검증 방법, 부트스트랩 방법 등이 있다. 이러한 기존의 기법들은 데이터 셋을 분할하는 과정에서 클래스 간의 비율에 대한 균형을 고려하지만, 같은 클래스 내에서도 존재하는 다양한 특징들의 비율은 고려하지 않고 있다. 이러한 특징들을 고려하지 않을 경우, 일부 특징에 편향된 검증 결과를 얻게 될 수 있다. 따라서 본 논문에서는 기존 검증 방법들을 개선하여 영상 분류를 위한 데이터 특징 커버리지 기반의 딥러닝 모델 검증 기법을 제안한다. 제안하는 기법은 딥러닝 모델의 학습과 검증을 위한 훈련 데이터 셋과 평가 데이터 셋이 전체 데이터 셋의 특징을 얼마나 반영하고 있는지 수치로 측정할 수 있는 데이터 특징 커버리지를 제안한다. 이러한 방식은 전체 데이터 셋의 특징을 모두 포함하도록 커버리지를 보장하여 데이터 셋을 분할할 수 있고, 모델의 평가 결과를 생성한 특징 군집 단위로 분석할 수 있다. 검증결과, 훈련 데이터 셋의 데이터 특징 커버리지가 낮아질 경우, 모델이 특정 특징에 편향되게 학습하여 모델의 성능이 낮아지며, Fashion-MNIST의 경우 정확도가 8.9%까지 차이나는 것을 확인하였다."
        },
        {
          "rank": 27,
          "score": 0.6561777591705322,
          "doc_id": "NART98464294",
          "title": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging",
          "abstract": "<P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98464294&target=NART&cn=NART98464294",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging <P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>"
        },
        {
          "rank": 28,
          "score": 0.6546459197998047,
          "doc_id": "JAKO202513936004376",
          "title": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구",
          "abstract": "본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202513936004376&target=NART&cn=JAKO202513936004376",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다."
        },
        {
          "rank": 29,
          "score": 0.652370810508728,
          "doc_id": "JAKO202300957609703",
          "title": "딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합",
          "abstract": "위성 시계열 데이터가 증가함에 따라 원격탐사 자료의 활용도가 높아지고 있다. 시계열 자료를 통한 분석에 있어 영상 간의 상대적인 위치 정확도는 결과에 큰 영향을 미치기 때문에 이를 보정하기 위한 영상 정합 과정은 필수적으로 선행되어야 한다. 최근에는 기존 알고리즘의 성능을 상회하는 딥러닝 기반 영상 정합 연구의 사례가 증가하고 있다. 딥러닝 기반 정합 모델을 학습하기 위해서는 수 많은 영상 쌍이 필요하다. 또한, 기존 딥러닝 모델의 데이터 간의 상관도 map을 제작하고, 이에 추가적인 연산을 적용하여 정합점을 추출는데 이는 비효율적이다. 이러한 문제를 해결하기 위해 본 연구에서는 영상 정합 모델 학습을 위한 데이터 증강 기법을 구축하여 데이터셋을 제작하였고, 이를 오프셋(offset) 양 자체를 예측하는 정합 모델인 OffsetNet에 적용하여 KOMSAT-2, -3, -3A 영상 정합을 수행하였다. 모델 학습 결과, OffsetNet은 평가 데이터에 대해 높은 정확도로 오프셋 양을 예측하였고, 이를 통해 주영상과 부영상을 효과적으로 정합하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202300957609703&target=NART&cn=JAKO202300957609703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 위성 시계열 데이터가 증가함에 따라 원격탐사 자료의 활용도가 높아지고 있다. 시계열 자료를 통한 분석에 있어 영상 간의 상대적인 위치 정확도는 결과에 큰 영향을 미치기 때문에 이를 보정하기 위한 영상 정합 과정은 필수적으로 선행되어야 한다. 최근에는 기존 알고리즘의 성능을 상회하는 딥러닝 기반 영상 정합 연구의 사례가 증가하고 있다. 딥러닝 기반 정합 모델을 학습하기 위해서는 수 많은 영상 쌍이 필요하다. 또한, 기존 딥러닝 모델의 데이터 간의 상관도 map을 제작하고, 이에 추가적인 연산을 적용하여 정합점을 추출는데 이는 비효율적이다. 이러한 문제를 해결하기 위해 본 연구에서는 영상 정합 모델 학습을 위한 데이터 증강 기법을 구축하여 데이터셋을 제작하였고, 이를 오프셋(offset) 양 자체를 예측하는 정합 모델인 OffsetNet에 적용하여 KOMSAT-2, -3, -3A 영상 정합을 수행하였다. 모델 학습 결과, OffsetNet은 평가 데이터에 대해 높은 정확도로 오프셋 양을 예측하였고, 이를 통해 주영상과 부영상을 효과적으로 정합하였다."
        },
        {
          "rank": 30,
          "score": 0.6522197723388672,
          "doc_id": "NART111939444",
          "title": "Review of deep learning for photoacoustic imaging",
          "abstract": "<P>Machine learning has been developed dramatically and witnessed a lot of applications in various fields over the past few years. This boom originated in 2009, when a new model emerged, that is, the deep artificial neural network, which began to surpass other established mature models on some important benchmarks. Later, it was widely used in academia and industry. Ranging from image analysis to natural language processing, it fully exerted its magic and now become the state-of-the-art machine learning models. Deep neural networks have great potential in medical imaging technology, medical data analysis, medical diagnosis and other healthcare issues, and is promoted in both pre-clinical and even clinical stages. In this review, we performed an overview of some new developments and challenges in the application of machine learning to medical image analysis, with a special focus on deep learning in photoacoustic imaging.</P><P>The aim of this review is threefold: (i) introducing deep learning with some important basics, (ii) reviewing recent works that apply deep learning in the entire ecological chain of photoacoustic imaging, from image reconstruction to disease diagnosis, (iii) providing some open source materials and other resources for researchers interested in applying deep learning to photoacoustic imaging.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111939444&target=NART&cn=NART111939444",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Review of deep learning for photoacoustic imaging Review of deep learning for photoacoustic imaging Review of deep learning for photoacoustic imaging <P>Machine learning has been developed dramatically and witnessed a lot of applications in various fields over the past few years. This boom originated in 2009, when a new model emerged, that is, the deep artificial neural network, which began to surpass other established mature models on some important benchmarks. Later, it was widely used in academia and industry. Ranging from image analysis to natural language processing, it fully exerted its magic and now become the state-of-the-art machine learning models. Deep neural networks have great potential in medical imaging technology, medical data analysis, medical diagnosis and other healthcare issues, and is promoted in both pre-clinical and even clinical stages. In this review, we performed an overview of some new developments and challenges in the application of machine learning to medical image analysis, with a special focus on deep learning in photoacoustic imaging.</P><P>The aim of this review is threefold: (i) introducing deep learning with some important basics, (ii) reviewing recent works that apply deep learning in the entire ecological chain of photoacoustic imaging, from image reconstruction to disease diagnosis, (iii) providing some open source materials and other resources for researchers interested in applying deep learning to photoacoustic imaging.</P>"
        },
        {
          "rank": 31,
          "score": 0.6520252823829651,
          "doc_id": "NART105497078",
          "title": "Deep Reinforcement Learning for Image Hashing",
          "abstract": "<P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART105497078&target=NART&cn=NART105497078",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing <P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>"
        },
        {
          "rank": 32,
          "score": 0.6518994569778442,
          "doc_id": "JAKO202201253146351",
          "title": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가",
          "abstract": "본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202201253146351&target=NART&cn=JAKO202201253146351",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다."
        },
        {
          "rank": 33,
          "score": 0.6511832475662231,
          "doc_id": "ART003167534",
          "title": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior",
          "abstract": "Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003167534&target=NART&cn=ART003167534",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified."
        },
        {
          "rank": 34,
          "score": 0.6484533548355103,
          "doc_id": "NART120416967",
          "title": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement",
          "abstract": "<P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120416967&target=NART&cn=NART120416967",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement <P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>"
        },
        {
          "rank": 35,
          "score": 0.6468303203582764,
          "doc_id": "NART113995599",
          "title": "Deep image enhancement for ill light imaging",
          "abstract": "<P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113995599&target=NART&cn=NART113995599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging <P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>"
        },
        {
          "rank": 36,
          "score": 0.6464868783950806,
          "doc_id": "JAKO202314857616824",
          "title": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석",
          "abstract": "클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202314857616824&target=NART&cn=JAKO202314857616824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 딥러닝 기반의 딥 클러스터링 방법에 대한 분석 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다."
        },
        {
          "rank": 37,
          "score": 0.6464752554893494,
          "doc_id": "NART131717213",
          "title": "Deep Learning Based Cystoscopy Image Enhancement",
          "abstract": "<P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131717213&target=NART&cn=NART131717213",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement <P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>"
        },
        {
          "rank": 38,
          "score": 0.646468997001648,
          "doc_id": "JAKO202026061058152",
          "title": "상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구",
          "abstract": "인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서 큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에 인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는 인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과 테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를 검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반 아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장 좋은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202026061058152&target=NART&cn=JAKO202026061058152",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구 상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구 상처와 주름이 있는 지문 판별에 효율적인 심층 학습 비교연구 인간의 특성과 관련된 측정 항목을 나타내는 생체정보는 도난이나 분실의 염려가 없으므로 높은 신뢰성을 가진 보안 기술로서 큰 주목을 받고 있다. 이러한 생체정보 중 지문은 본인 인증, 신원 파악 등의 분야에 주로 사용된다. 신원을 파악할 때 지문 이미지에 인증을 수행하기 어려운 상처, 주름, 습기 등의 문제가 있을 경우, 지문 전문가가 전처리단계를 통해 직접 지문에 어떠한 문제가 있는지 파악하고 문제에 맞는 영상처리 알고리즘을 적용해 문제를 해결한다. 이때 지문에 상처와 주름이 있는 지문 영상을 판별해주는 인공지능 소프트웨어를 구현하면 손쉽게 상처나 주름의 여부를 확인할 수 있고, 알맞은 알고리즘을 선정해 쉽게 지문 이미지를 개선할 수 있다. 본 연구에서는 이러한 인공지능 소프트웨어의 개발을 위해 캄보디아 왕립대학교의 학생 1,010명, Sokoto 오픈 데이터셋 600명, 국내 학생 98명의 모든 손가락 지문을 취득해 총 17,080개의 지문 데이터베이스를 구축했다. 구축한 데이터베이스에서 상처나 주름이 있는 경우를 판별하기 위해 기준을 확립하고 전문가의 검증을 거쳐 데이터 어노테이션을 진행했다. 트레이닝 데이터셋과 테스트 데이터셋은 캄보디아의 데이터, Sokoto 데이터로 구성하였으며 비율을 8:2로 설정했다. 그리고 국내 학생 98명의 데이터를 검증 데이터 셋으로 설정했다, 구성된 데이터셋을 사용해 Classic CNN, AlexNet, VGG-16, Resnet50, Yolo v3 등의 다섯 가지 CNN 기반 아키텍처를 구현해 학습을 진행했으며 지문의 상처와 주름 판독에서 가장 좋은 성능을 보이는 모델을 찾는 연구를 수행했다. 다섯가지 아키텍처 중 지문 영상에서 상처와 주름 여부를 가장 잘 판별할 수 있는 아키텍처는 ResNet50으로 검증 결과 81.51%로 가장 좋은 성능을 보였다."
        },
        {
          "rank": 39,
          "score": 0.646068811416626,
          "doc_id": "JAKO202226461575702",
          "title": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰",
          "abstract": "Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202226461575702&target=NART&cn=JAKO202226461575702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies."
        },
        {
          "rank": 40,
          "score": 0.6448671221733093,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 41,
          "score": 0.644440770149231,
          "doc_id": "JAKO202408557654430",
          "title": "회전된 객체 분류를 위한 CNN 기법들의 성능 비교 분석",
          "abstract": "이미지 공간에서 무작위로 회전된 객체에 대한 분류 성능이 우수한 기법으로는 군 등변 CNN과 steerable 필터를 이용한 CNN 등이 있다. 본 논문에서는 이들의 수학적 구조를 설명하고 구현 방법을 소개한다. 기존의 CNN을 포함한 세 개의 모델에 대하여 동일한 필터 수를 갖도록 구현한 다음, 무작위로 회전된 MNIST를 이용하여 실험하고 이들의 성능을 비교분석한다. 실험 결과에 의하면 steerable CNN은 CNN보다 6.5% 이상의 인식률 향상을 보여준다. 특히, steerable CNN은 학습할 파라미터의 수가 상대적으로 적어서 훈련 데이터셋의 크기를 줄여도 성능 열화가 비교적 크지 않음을 실험 결과로 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202408557654430&target=NART&cn=JAKO202408557654430",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회전된 객체 분류를 위한 CNN 기법들의 성능 비교 분석 회전된 객체 분류를 위한 CNN 기법들의 성능 비교 분석 회전된 객체 분류를 위한 CNN 기법들의 성능 비교 분석 이미지 공간에서 무작위로 회전된 객체에 대한 분류 성능이 우수한 기법으로는 군 등변 CNN과 steerable 필터를 이용한 CNN 등이 있다. 본 논문에서는 이들의 수학적 구조를 설명하고 구현 방법을 소개한다. 기존의 CNN을 포함한 세 개의 모델에 대하여 동일한 필터 수를 갖도록 구현한 다음, 무작위로 회전된 MNIST를 이용하여 실험하고 이들의 성능을 비교분석한다. 실험 결과에 의하면 steerable CNN은 CNN보다 6.5% 이상의 인식률 향상을 보여준다. 특히, steerable CNN은 학습할 파라미터의 수가 상대적으로 적어서 훈련 데이터셋의 크기를 줄여도 성능 열화가 비교적 크지 않음을 실험 결과로 확인한다."
        },
        {
          "rank": 42,
          "score": 0.6442122459411621,
          "doc_id": "DIKO0015644673",
          "title": "M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지",
          "abstract": "해상 교통량의 증가로 인해 해상 선박관리의 필요성이 늘어남에 따라 선박을 탐지하기 위한 연구들이 꾸준히 수행되어왔다. 특히 위성레이더 영상은 시간과 기후에 영향을 받지 않고 촬영할 수 있다는 장점으로 인해 선박탐지를 위한 많은 연구에서 활용되어왔다. 최근에는 딥러닝 기법의 발전으로 인해 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구들이 꾸준히 수행되고 있다. 그런데 위성레이더 영상은 값의 분포범위가 매우 넓고, 많은 스펙클 노이즈가 존재한다. 이러한 요소들은 딥러닝 모델의 학습에 부정적인 영향을 끼칠 수 있으므로 전처리를 통해 해당 요소들을 저감해줄 필요가 있다. 본 연구에서는 전처리된 위성레이더 영상으로부터 딥러닝 선박탐지를 수행하고, 영상의 전처리가 딥러닝 선박탐지에 미치는 요소를 비교분석 하고자 한다.&amp;#xD; 본 연구를 위해 TerraSAR-X와 COSMO-SkyMed 위성레이더 영상을 이용했다. 영상을 딥러닝 학습에 이용하기 전에 먼저 총 세 가지 다른 방법으로 전처리를 수행했다. 첫 번째는 위성레이더 영상에서 강도 값만을 추출한 강도 영상을 생성하는 방법이다. 강도 영상은 값의 범위가 매우 넓을 뿐만 아니라 많은 스펙클 노이즈를 가지고 있다. 두 번째는 강도영상에서 값의 단위를 데시벨로 변환한 데시벨 영상을 생성하는 방법이다. 데시벨 영상은 강도영상과 마찬가지로 많은 스펙클 노이즈를 가지고 있으나 값의 범위가 줄어들어, 더 안정적인 학습을 할 수 있다. 세 번째는 본 연구에서 제안하는 위성레이더 전처리방법으로써, 강도차분과 거칠기영상을 생성하는 방법이다. 두 영상은 중간값 필터링을 이용해 스펙클 노이즈를 줄이고, 값의 분포 대역을 좁힘으로써 빠른 학습이 가능하다.&amp;#xD; 각 전처리된 위성레이더 영상을 이용해 딥러닝 학습을 하기 위해 본 연구에서는 M2Det 객체탐지 모델을 사용했다. 객체탐지 모델을 학습시킨 뒤 테스트 영상을 이용해 선박탐지를 수행했으며, 테스트 결과는 정밀도(Precision), 재현율(Recall)을 이용해 나타냈으며, 두 지수를 하나의 값으로 표현하기 위해 AP(Average Precision)와 F1 점수(F1-score)를 이용해 나타냈다. 각 영상의 정밀도, 재현율, AP, F1 점수는 강도 영상 93.18%, 91.11%, 89.78%, 92.13%, 데시벨 영상 94.16%, 94.16%, 92.34%, 94.16%, 강도차분과 거칠기 영상 97.40%, 94.94%, 95.55%, 96.15%로 계산되었다. 강도 영상을 이용한 경우 미탐지와 오탐지 선박이 많았으며, 전처리된 영상을 이용한 경우 강도 영상에 비해 미탐지와 오탐지 선박이 줄어든 것을 확인할 수 있었다. 데시벨 영상과 강도차분, 거칠기 영상의 결과를 비교했을 때, 두 영상의 오탐지율은 유사했다. 하지만 강도차분, 거칠기 영상을 이용했을 때 강도 영상에 비해 미탐지 선박의 비율이 4% 줄어든 것을 확인할 수 있었다. 이 결과를 통해 위성레이더 영상을 전처리함으로써 딥러닝 학습을 돕고 선박탐지 결과를 향상시킬 수 있다는 것을 알 수 있다. 본 연구결과는 향후 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구의 발전에 이바지할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015644673&target=NART&cn=DIKO0015644673",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 해상 교통량의 증가로 인해 해상 선박관리의 필요성이 늘어남에 따라 선박을 탐지하기 위한 연구들이 꾸준히 수행되어왔다. 특히 위성레이더 영상은 시간과 기후에 영향을 받지 않고 촬영할 수 있다는 장점으로 인해 선박탐지를 위한 많은 연구에서 활용되어왔다. 최근에는 딥러닝 기법의 발전으로 인해 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구들이 꾸준히 수행되고 있다. 그런데 위성레이더 영상은 값의 분포범위가 매우 넓고, 많은 스펙클 노이즈가 존재한다. 이러한 요소들은 딥러닝 모델의 학습에 부정적인 영향을 끼칠 수 있으므로 전처리를 통해 해당 요소들을 저감해줄 필요가 있다. 본 연구에서는 전처리된 위성레이더 영상으로부터 딥러닝 선박탐지를 수행하고, 영상의 전처리가 딥러닝 선박탐지에 미치는 요소를 비교분석 하고자 한다.&amp;#xD; 본 연구를 위해 TerraSAR-X와 COSMO-SkyMed 위성레이더 영상을 이용했다. 영상을 딥러닝 학습에 이용하기 전에 먼저 총 세 가지 다른 방법으로 전처리를 수행했다. 첫 번째는 위성레이더 영상에서 강도 값만을 추출한 강도 영상을 생성하는 방법이다. 강도 영상은 값의 범위가 매우 넓을 뿐만 아니라 많은 스펙클 노이즈를 가지고 있다. 두 번째는 강도영상에서 값의 단위를 데시벨로 변환한 데시벨 영상을 생성하는 방법이다. 데시벨 영상은 강도영상과 마찬가지로 많은 스펙클 노이즈를 가지고 있으나 값의 범위가 줄어들어, 더 안정적인 학습을 할 수 있다. 세 번째는 본 연구에서 제안하는 위성레이더 전처리방법으로써, 강도차분과 거칠기영상을 생성하는 방법이다. 두 영상은 중간값 필터링을 이용해 스펙클 노이즈를 줄이고, 값의 분포 대역을 좁힘으로써 빠른 학습이 가능하다.&amp;#xD; 각 전처리된 위성레이더 영상을 이용해 딥러닝 학습을 하기 위해 본 연구에서는 M2Det 객체탐지 모델을 사용했다. 객체탐지 모델을 학습시킨 뒤 테스트 영상을 이용해 선박탐지를 수행했으며, 테스트 결과는 정밀도(Precision), 재현율(Recall)을 이용해 나타냈으며, 두 지수를 하나의 값으로 표현하기 위해 AP(Average Precision)와 F1 점수(F1-score)를 이용해 나타냈다. 각 영상의 정밀도, 재현율, AP, F1 점수는 강도 영상 93.18%, 91.11%, 89.78%, 92.13%, 데시벨 영상 94.16%, 94.16%, 92.34%, 94.16%, 강도차분과 거칠기 영상 97.40%, 94.94%, 95.55%, 96.15%로 계산되었다. 강도 영상을 이용한 경우 미탐지와 오탐지 선박이 많았으며, 전처리된 영상을 이용한 경우 강도 영상에 비해 미탐지와 오탐지 선박이 줄어든 것을 확인할 수 있었다. 데시벨 영상과 강도차분, 거칠기 영상의 결과를 비교했을 때, 두 영상의 오탐지율은 유사했다. 하지만 강도차분, 거칠기 영상을 이용했을 때 강도 영상에 비해 미탐지 선박의 비율이 4% 줄어든 것을 확인할 수 있었다. 이 결과를 통해 위성레이더 영상을 전처리함으로써 딥러닝 학습을 돕고 선박탐지 결과를 향상시킬 수 있다는 것을 알 수 있다. 본 연구결과는 향후 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구의 발전에 이바지할 수 있을 것으로 기대된다."
        },
        {
          "rank": 43,
          "score": 0.6417798399925232,
          "doc_id": "JAKO202034965760115",
          "title": "심층 신경망 병렬 학습 방법 연구 동향",
          "abstract": "심층 신경망(Deep Neural Network, DNN) 모델을 대량의 학습 데이터로 학습시키기 위해서는 많은 시간이 소요되기 때문에 병렬 학습 방법이 필요하다. DNN의 학습에는 일반적으로 Stochastic Gradient Descent(SGD) 방법이 사용되는데, SGD는 근본적으로 순차적인 처리가 필요하므로 병렬화하기 위해서는 다양한 근사(approximation) 방법을 적용하게 된다. 본 논문에서는 기존의 DNN 병렬 학습 알고리즘들을 소개하고 연산량, 통신량, 근사 방법 등을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202034965760115&target=NART&cn=JAKO202034965760115",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 신경망 병렬 학습 방법 연구 동향 심층 신경망 병렬 학습 방법 연구 동향 심층 신경망 병렬 학습 방법 연구 동향 심층 신경망(Deep Neural Network, DNN) 모델을 대량의 학습 데이터로 학습시키기 위해서는 많은 시간이 소요되기 때문에 병렬 학습 방법이 필요하다. DNN의 학습에는 일반적으로 Stochastic Gradient Descent(SGD) 방법이 사용되는데, SGD는 근본적으로 순차적인 처리가 필요하므로 병렬화하기 위해서는 다양한 근사(approximation) 방법을 적용하게 된다. 본 논문에서는 기존의 DNN 병렬 학습 알고리즘들을 소개하고 연산량, 통신량, 근사 방법 등을 분석한다."
        },
        {
          "rank": 44,
          "score": 0.6409198045730591,
          "doc_id": "JAKO202431343317630",
          "title": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능",
          "abstract": "인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202431343317630&target=NART&cn=JAKO202431343317630",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다."
        },
        {
          "rank": 45,
          "score": 0.6407008171081543,
          "doc_id": "JAKO201926358474432",
          "title": "CNN의 깊은 특징과 전이학습을 사용한 보행자 분류",
          "abstract": "자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는 HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고 있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여 보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning)을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한 결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61%로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다. 그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금 낮았지만 고정특징추출 기법보다는 높았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201926358474432&target=NART&cn=JAKO201926358474432",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는 HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고 있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여 보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning)을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한 결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61%로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다. 그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금 낮았지만 고정특징추출 기법보다는 높았다."
        },
        {
          "rank": 46,
          "score": 0.6406205892562866,
          "doc_id": "JAKO201817241625699",
          "title": "딥 러닝 기반의 이미지와 비디오 압축 기술 분석",
          "abstract": "본 논문에서는 최근 활발히 연구되고 있는 딥 러닝 기반의 이미지와 비디오 압축 기술에 대해 살펴본다. 딥 러닝 기반의 이미지 압축 기술은 심층 신경망에 압축 대상 이미지를 입력하고 반복적 또는 일괄적 방식으로 은닉 벡터를 추출하여 부호화한다. 이미지 압축 효율을 높이기 위해 심층 신경망은 복원 이미지의 화질은 높이면서 부호화된 은닉 벡터가 보다 적은 비트로 표현될 수 있도록 학습된다. 이러한 기술들은 특히 저 비트율에서 기존의 이미지 압축 기술에 비해 뛰어난 화질의 이미지를 생성할 수 있다. 한편, 딥 러닝 기반의 비디오 압축 기술은 압축 대상 비디오를 직접 입력하여 처리하기 보다는 기존 비디오 코덱의 압축 툴 성능을 개선하는 접근법을 취하고 있다. 본 논문에서 소개하는 심층 신경망 기술들은 최신 비디오 코덱의 인루프 필터를 대체하거나 추가적인 후처리 필터로 사용되어 복원 영상의 화질 개선을 통해 압축 효율을 향상시킨다. 마찬가지로, 화면 내 예측 및 부호화에 적용된 심층 신경망 기술들은 기존 화면 내 예측 툴과 함께 사용되어 예측 정확도를 높이거나 새로운 화면 내 부호화 과정을 추가함으로써 압축 효율을 향상 시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201817241625699&target=NART&cn=JAKO201817241625699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 이미지와 비디오 압축 기술 분석 딥 러닝 기반의 이미지와 비디오 압축 기술 분석 딥 러닝 기반의 이미지와 비디오 압축 기술 분석 본 논문에서는 최근 활발히 연구되고 있는 딥 러닝 기반의 이미지와 비디오 압축 기술에 대해 살펴본다. 딥 러닝 기반의 이미지 압축 기술은 심층 신경망에 압축 대상 이미지를 입력하고 반복적 또는 일괄적 방식으로 은닉 벡터를 추출하여 부호화한다. 이미지 압축 효율을 높이기 위해 심층 신경망은 복원 이미지의 화질은 높이면서 부호화된 은닉 벡터가 보다 적은 비트로 표현될 수 있도록 학습된다. 이러한 기술들은 특히 저 비트율에서 기존의 이미지 압축 기술에 비해 뛰어난 화질의 이미지를 생성할 수 있다. 한편, 딥 러닝 기반의 비디오 압축 기술은 압축 대상 비디오를 직접 입력하여 처리하기 보다는 기존 비디오 코덱의 압축 툴 성능을 개선하는 접근법을 취하고 있다. 본 논문에서 소개하는 심층 신경망 기술들은 최신 비디오 코덱의 인루프 필터를 대체하거나 추가적인 후처리 필터로 사용되어 복원 영상의 화질 개선을 통해 압축 효율을 향상시킨다. 마찬가지로, 화면 내 예측 및 부호화에 적용된 심층 신경망 기술들은 기존 화면 내 예측 툴과 함께 사용되어 예측 정확도를 높이거나 새로운 화면 내 부호화 과정을 추가함으로써 압축 효율을 향상 시킨다."
        },
        {
          "rank": 47,
          "score": 0.6406094431877136,
          "doc_id": "NART121030945",
          "title": "MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning",
          "abstract": "<P>Transmitting orthogonal waveforms are the basis for giving full play to the advantages of MIMO radar imaging technology, but the commonly used waveforms with the same frequency cannot meet the orthogonality requirement, resulting in serious coupling noise in traditional imaging methods and affecting the imaging effect. In order to effectively suppress the mutual coupling interference caused by non-orthogonal waveforms, a new non-orthogonal waveform MIMO radar imaging method based on deep learning is proposed in this paper: with the powerful nonlinear fitting ability of deep learning, the mapping relationship between the non-orthogonal waveform MIMO radar echo and ideal target image is automatically learned by constructing a deep imaging network and training on a large number of simulated training data. The learned imaging network can effectively suppress the coupling interference between non-ideal orthogonal waveforms and improve the imaging quality of MIMO radar. Finally, the effectiveness of the proposed method is verified by experiments with point scattering model data and electromagnetic scattering calculation data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121030945&target=NART&cn=NART121030945",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning <P>Transmitting orthogonal waveforms are the basis for giving full play to the advantages of MIMO radar imaging technology, but the commonly used waveforms with the same frequency cannot meet the orthogonality requirement, resulting in serious coupling noise in traditional imaging methods and affecting the imaging effect. In order to effectively suppress the mutual coupling interference caused by non-orthogonal waveforms, a new non-orthogonal waveform MIMO radar imaging method based on deep learning is proposed in this paper: with the powerful nonlinear fitting ability of deep learning, the mapping relationship between the non-orthogonal waveform MIMO radar echo and ideal target image is automatically learned by constructing a deep imaging network and training on a large number of simulated training data. The learned imaging network can effectively suppress the coupling interference between non-ideal orthogonal waveforms and improve the imaging quality of MIMO radar. Finally, the effectiveness of the proposed method is verified by experiments with point scattering model data and electromagnetic scattering calculation data.</P>"
        },
        {
          "rank": 48,
          "score": 0.6392772197723389,
          "doc_id": "JAKO201718054814596",
          "title": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석",
          "abstract": "딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201718054814596&target=NART&cn=JAKO201718054814596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 스파크 기반 딥 러닝 분산 프레임워크 성능 비교 분석 딥 러닝(Deep learning)은 기존 인공 신경망 내 계층 수를 증가시킴과 동시에 효과적인 학습 방법론을 제시함으로써 객체/음성 인식 및 자연어 처리 등 고수준 문제 해결에 있어 괄목할만한 성과를 보이고 있다. 그러나 학습에 필요한 시간과 리소스가 크다는 한계를 지니고 있어, 이를 줄이기 위한 연구가 활발히 진행되고 있다. 본 연구에서는 아파치 스파크 기반 클러스터 컴퓨팅 프레임워크 상에서 딥 러닝을 분산화하는 두 가지 툴(DeepSpark, SparkNet)의 성능을 학습 정확도와 속도 측면에서 측정하고 분석하였다. CIFAR-10/CIFAR-100 데이터를 사용한 실험에서 SparkNet은 학습 과정의 정확도 변동 폭이 적은 반면 DeepSpark는 학습 초기 정확도는 변동 폭이 크지만 점차 변동 폭이 줄어들면서 SparkNet 대비 약 15% 높은 정확도를 보였고, 조건에 따라 단일 머신보다도 높은 정확도로 보다 빠르게 수렴하는 양상을 확인할 수 있었다."
        },
        {
          "rank": 49,
          "score": 0.6386018991470337,
          "doc_id": "NART90207156",
          "title": "A Mathematical Framework for Deep Learning in Elastic Source Imaging",
          "abstract": "<P>An inverse elastic source problem with sparse measurements is our concern. A generic mathematical framework is proposed which extends a low-dimensional manifold regularization in the conventional source reconstruction algorithms thereby enhancing their performance with sparse data-sets. It is rigorously established that the proposed framework is equivalent to the so-called <italic toggle='yes'>deep convolutional framelet expansion</I> in machine learning literature for inverse problems. Apposite numerical examples are furnished to substantiate the efficacy of the proposed framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART90207156&target=NART&cn=NART90207156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Mathematical Framework for Deep Learning in Elastic Source Imaging A Mathematical Framework for Deep Learning in Elastic Source Imaging A Mathematical Framework for Deep Learning in Elastic Source Imaging <P>An inverse elastic source problem with sparse measurements is our concern. A generic mathematical framework is proposed which extends a low-dimensional manifold regularization in the conventional source reconstruction algorithms thereby enhancing their performance with sparse data-sets. It is rigorously established that the proposed framework is equivalent to the so-called <italic toggle='yes'>deep convolutional framelet expansion</I> in machine learning literature for inverse problems. Apposite numerical examples are furnished to substantiate the efficacy of the proposed framework.</P>"
        },
        {
          "rank": 50,
          "score": 0.6375812888145447,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        }
      ]
    },
    {
      "query": "What are the weaknesses of deep learning for complex image analysis?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.727863073348999,
          "doc_id": "JAKO202009863559871",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009863559871&target=NART&cn=JAKO202009863559871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 2,
          "score": 0.727863073348999,
          "doc_id": "ART002574280",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002574280&target=NART&cn=ART002574280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 3,
          "score": 0.680069088935852,
          "doc_id": "JAKO202218262151224",
          "title": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석",
          "abstract": "생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202218262151224&target=NART&cn=JAKO202218262151224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다."
        },
        {
          "rank": 4,
          "score": 0.6650869250297546,
          "doc_id": "JAKO202106153187643",
          "title": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론",
          "abstract": "빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153187643&target=NART&cn=JAKO202106153187643",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다."
        },
        {
          "rank": 5,
          "score": 0.6638975739479065,
          "doc_id": "JAKO202226461575702",
          "title": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰",
          "abstract": "Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202226461575702&target=NART&cn=JAKO202226461575702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies."
        },
        {
          "rank": 6,
          "score": 0.6614809632301331,
          "doc_id": "NART121556950",
          "title": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement",
          "abstract": "<P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121556950&target=NART&cn=NART121556950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement <P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>"
        },
        {
          "rank": 7,
          "score": 0.6565790176391602,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 8,
          "score": 0.656282901763916,
          "doc_id": "NART136112293",
          "title": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning",
          "abstract": "<P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART136112293&target=NART&cn=NART136112293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning <P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>"
        },
        {
          "rank": 9,
          "score": 0.6545543074607849,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 10,
          "score": 0.6537030339241028,
          "doc_id": "NART110796699",
          "title": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network",
          "abstract": "<P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110796699&target=NART&cn=NART110796699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network <P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>"
        },
        {
          "rank": 11,
          "score": 0.6530071496963501,
          "doc_id": "JAKO202431343317630",
          "title": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능",
          "abstract": "인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202431343317630&target=NART&cn=JAKO202431343317630",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다."
        },
        {
          "rank": 12,
          "score": 0.6503982543945312,
          "doc_id": "NART113995599",
          "title": "Deep image enhancement for ill light imaging",
          "abstract": "<P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113995599&target=NART&cn=NART113995599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging <P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>"
        },
        {
          "rank": 13,
          "score": 0.6503506898880005,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 14,
          "score": 0.6485897302627563,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 15,
          "score": 0.6484405398368835,
          "doc_id": "JAKO202013562119985",
          "title": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석",
          "abstract": "Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013562119985&target=NART&cn=JAKO202013562119985",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
        },
        {
          "rank": 16,
          "score": 0.6463993191719055,
          "doc_id": "JAKO202221359246132",
          "title": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정",
          "abstract": "영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202221359246132&target=NART&cn=JAKO202221359246132",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다."
        },
        {
          "rank": 17,
          "score": 0.6417354941368103,
          "doc_id": "NART115326214",
          "title": "Deep learning-based single image face depth data enhancement",
          "abstract": "<P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART115326214&target=NART&cn=NART115326214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement <P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>"
        },
        {
          "rank": 18,
          "score": 0.6414834260940552,
          "doc_id": "JAKO202109835990951",
          "title": "분해 심층 학습을 이용한 저조도 영상 개선 방식",
          "abstract": "본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109835990951&target=NART&cn=JAKO202109835990951",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다."
        },
        {
          "rank": 19,
          "score": 0.6393477916717529,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 20,
          "score": 0.6390501260757446,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 21,
          "score": 0.6388964653015137,
          "doc_id": "DIKO0017114224",
          "title": "딥러닝을 활용한 초음파 영상 개선",
          "abstract": "의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017114224&target=NART&cn=DIKO0017114224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다."
        },
        {
          "rank": 22,
          "score": 0.6388625502586365,
          "doc_id": "NART120416967",
          "title": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement",
          "abstract": "<P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120416967&target=NART&cn=NART120416967",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement <P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>"
        },
        {
          "rank": 23,
          "score": 0.6386233568191528,
          "doc_id": "NPAP12546494",
          "title": "Deep learning for radar",
          "abstract": "<P>Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12546494&target=NART&cn=NPAP12546494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning for radar Deep learning for radar Deep learning for radar <P>Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem.</P>"
        },
        {
          "rank": 24,
          "score": 0.6320618391036987,
          "doc_id": "NART119629224",
          "title": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging",
          "abstract": "<P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119629224&target=NART&cn=NART119629224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging <P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>"
        },
        {
          "rank": 25,
          "score": 0.6316908597946167,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 26,
          "score": 0.6298223733901978,
          "doc_id": "NART119879737",
          "title": "Image Enhancement Method Based on Deep Learning",
          "abstract": "<P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119879737&target=NART&cn=NART119879737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning <P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>"
        },
        {
          "rank": 27,
          "score": 0.6291849613189697,
          "doc_id": "JAKO202201253146351",
          "title": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가",
          "abstract": "본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202201253146351&target=NART&cn=JAKO202201253146351",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 딥러닝 모델 기반 위성영상 데이터세트 공간 해상도에 따른 수종분류 정확도 평가 본 연구는 분류(classification)기반 딥러닝 모델(deep learning model)인 Inception과 SENet을 결합한 SE-Inception을 활용하여 수종분류를 수행하고 분류정확도를 평가하였다. 데이터세트의 입력 이미지는 Worldview-3와 GeoEye-1 영상을 활용하였으며, 입력 이미지의 크기는 10 &#x00D7; 10 m, 30 &#x00D7; 30 m, 50 &#x00D7; 50 m로 분할하여 수종 분류정확도를 비교&#x00B7;평가하였다. 라벨(label)자료는 분할된 영상을 시각적으로 해석하여 5개의 수종(소나무, 잣나무, 낙엽송, 전나무, 참나무류)으로 구분한 후, 수동으로 라벨링 작업을 수행하였다. 데이터세트는 총 2,429개의 이미지를 구축하였으며, 그중약 85%는 학습자료로, 약 15%는 검증자료로 활용하였다. 딥러닝 모델을 활용한 수종분류 결과, Worldview-3 영상을 활용하였을 때 최대 약 78%의 전체 정확도를 달성하였으며, GeoEye-1영상을 활용할 때 최대 약 84%의 정확도를 보여 수종분류에 우수한 성능을 보였다. 특히, 참나무류는 입력 이미지크기에 관계없이 F<sub>1</sub>은 약 85% 이상의 높은 정확도를 보였으나, 소나무, 잣나무와 같이 분광특성이 유사한 수종은 오분류가 다수 발생하였다. 특정 수종에서 위성영상의 분광정보 만으로는 특징량 추출에 한계가 있을 수 있으며, 식생지수, Gray-Level Co-occurrence Matrix (GLCM) 등 다양한 패턴정보가 포함된 이미지를 활용한다면 분류 정확도를 개선할 수 있을 것으로 판단된다."
        },
        {
          "rank": 28,
          "score": 0.6289952993392944,
          "doc_id": "NART111939444",
          "title": "Review of deep learning for photoacoustic imaging",
          "abstract": "<P>Machine learning has been developed dramatically and witnessed a lot of applications in various fields over the past few years. This boom originated in 2009, when a new model emerged, that is, the deep artificial neural network, which began to surpass other established mature models on some important benchmarks. Later, it was widely used in academia and industry. Ranging from image analysis to natural language processing, it fully exerted its magic and now become the state-of-the-art machine learning models. Deep neural networks have great potential in medical imaging technology, medical data analysis, medical diagnosis and other healthcare issues, and is promoted in both pre-clinical and even clinical stages. In this review, we performed an overview of some new developments and challenges in the application of machine learning to medical image analysis, with a special focus on deep learning in photoacoustic imaging.</P><P>The aim of this review is threefold: (i) introducing deep learning with some important basics, (ii) reviewing recent works that apply deep learning in the entire ecological chain of photoacoustic imaging, from image reconstruction to disease diagnosis, (iii) providing some open source materials and other resources for researchers interested in applying deep learning to photoacoustic imaging.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111939444&target=NART&cn=NART111939444",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Review of deep learning for photoacoustic imaging Review of deep learning for photoacoustic imaging Review of deep learning for photoacoustic imaging <P>Machine learning has been developed dramatically and witnessed a lot of applications in various fields over the past few years. This boom originated in 2009, when a new model emerged, that is, the deep artificial neural network, which began to surpass other established mature models on some important benchmarks. Later, it was widely used in academia and industry. Ranging from image analysis to natural language processing, it fully exerted its magic and now become the state-of-the-art machine learning models. Deep neural networks have great potential in medical imaging technology, medical data analysis, medical diagnosis and other healthcare issues, and is promoted in both pre-clinical and even clinical stages. In this review, we performed an overview of some new developments and challenges in the application of machine learning to medical image analysis, with a special focus on deep learning in photoacoustic imaging.</P><P>The aim of this review is threefold: (i) introducing deep learning with some important basics, (ii) reviewing recent works that apply deep learning in the entire ecological chain of photoacoustic imaging, from image reconstruction to disease diagnosis, (iii) providing some open source materials and other resources for researchers interested in applying deep learning to photoacoustic imaging.</P>"
        },
        {
          "rank": 29,
          "score": 0.6285073757171631,
          "doc_id": "NART121030945",
          "title": "MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning",
          "abstract": "<P>Transmitting orthogonal waveforms are the basis for giving full play to the advantages of MIMO radar imaging technology, but the commonly used waveforms with the same frequency cannot meet the orthogonality requirement, resulting in serious coupling noise in traditional imaging methods and affecting the imaging effect. In order to effectively suppress the mutual coupling interference caused by non-orthogonal waveforms, a new non-orthogonal waveform MIMO radar imaging method based on deep learning is proposed in this paper: with the powerful nonlinear fitting ability of deep learning, the mapping relationship between the non-orthogonal waveform MIMO radar echo and ideal target image is automatically learned by constructing a deep imaging network and training on a large number of simulated training data. The learned imaging network can effectively suppress the coupling interference between non-ideal orthogonal waveforms and improve the imaging quality of MIMO radar. Finally, the effectiveness of the proposed method is verified by experiments with point scattering model data and electromagnetic scattering calculation data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121030945&target=NART&cn=NART121030945",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning MIMO Radar Imaging Method with Non-Orthogonal Waveforms Based on Deep Learning <P>Transmitting orthogonal waveforms are the basis for giving full play to the advantages of MIMO radar imaging technology, but the commonly used waveforms with the same frequency cannot meet the orthogonality requirement, resulting in serious coupling noise in traditional imaging methods and affecting the imaging effect. In order to effectively suppress the mutual coupling interference caused by non-orthogonal waveforms, a new non-orthogonal waveform MIMO radar imaging method based on deep learning is proposed in this paper: with the powerful nonlinear fitting ability of deep learning, the mapping relationship between the non-orthogonal waveform MIMO radar echo and ideal target image is automatically learned by constructing a deep imaging network and training on a large number of simulated training data. The learned imaging network can effectively suppress the coupling interference between non-ideal orthogonal waveforms and improve the imaging quality of MIMO radar. Finally, the effectiveness of the proposed method is verified by experiments with point scattering model data and electromagnetic scattering calculation data.</P>"
        },
        {
          "rank": 30,
          "score": 0.6281247138977051,
          "doc_id": "NART116403822",
          "title": "Deep-Learning for Radar: A Survey",
          "abstract": "<P>A comprehensive and well-structured review on the application of deep learning (DL) based algorithms, such as convolutional neural networks (CNN) and long-short term memory (LSTM), in radar signal processing is given. The following DL application areas are covered: i) radar waveform and antenna array design; ii) passive or low probability of interception (LPI) radar waveform recognition; iii) automatic target recognition (ATR) based on high range resolution profiles (HRRPs), Doppler signatures, and synthetic aperture radar (SAR) images; and iv) radar jamming/clutter recognition and suppression. Although DL is unanimously praised as the ultimate solution to many bottleneck problems in most of existing works on similar topics, both the positive and the negative sides of stories about DL are checked in this work. Specifically, two limiting factors of the real-life performance of deep neural networks (DNNs), limited training samples and adversarial examples, are thoroughly examined. By investigating the relationship between the DL-based algorithms proposed in various papers and linking them together to form a full picture, this work serves as a valuable source for researchers who are seeking potential research opportunities in this promising research field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART116403822&target=NART&cn=NART116403822",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep-Learning for Radar: A Survey Deep-Learning for Radar: A Survey Deep-Learning for Radar: A Survey <P>A comprehensive and well-structured review on the application of deep learning (DL) based algorithms, such as convolutional neural networks (CNN) and long-short term memory (LSTM), in radar signal processing is given. The following DL application areas are covered: i) radar waveform and antenna array design; ii) passive or low probability of interception (LPI) radar waveform recognition; iii) automatic target recognition (ATR) based on high range resolution profiles (HRRPs), Doppler signatures, and synthetic aperture radar (SAR) images; and iv) radar jamming/clutter recognition and suppression. Although DL is unanimously praised as the ultimate solution to many bottleneck problems in most of existing works on similar topics, both the positive and the negative sides of stories about DL are checked in this work. Specifically, two limiting factors of the real-life performance of deep neural networks (DNNs), limited training samples and adversarial examples, are thoroughly examined. By investigating the relationship between the DL-based algorithms proposed in various papers and linking them together to form a full picture, this work serves as a valuable source for researchers who are seeking potential research opportunities in this promising research field.</P>"
        },
        {
          "rank": 31,
          "score": 0.6268194913864136,
          "doc_id": "NART105497078",
          "title": "Deep Reinforcement Learning for Image Hashing",
          "abstract": "<P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART105497078&target=NART&cn=NART105497078",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing <P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>"
        },
        {
          "rank": 32,
          "score": 0.6265459060668945,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 33,
          "score": 0.6255531311035156,
          "doc_id": "NART98464294",
          "title": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging",
          "abstract": "<P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98464294&target=NART&cn=NART98464294",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging <P><B>Abstract</B></P>  <P>Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions.</P>"
        },
        {
          "rank": 34,
          "score": 0.6253363490104675,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 35,
          "score": 0.6252940893173218,
          "doc_id": "ATN0045840152",
          "title": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구",
          "abstract": "현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0045840152&target=NART&cn=ATN0045840152",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다."
        },
        {
          "rank": 36,
          "score": 0.6227301359176636,
          "doc_id": "JAKO200211921029418",
          "title": "식스 시그마 동향과 수행에 관한 연구",
          "abstract": "Six Sigma is one of the most active subjects in quality management. This studs deals with some existing weaknesses that may wise in implementing Six Sigma in real world situations. The main weaknesses discussed here include the lack of understanding of cultural aspects on the nations and industries, the poor linkage between quality, finance and accounting from the bottom line point of view, and the difficult development process of metrics for all improvement results to validate the effect of Six Sigma. Finally, the key success characteristics for a good Six Sigma project are presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921029418&target=NART&cn=JAKO200211921029418",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "식스 시그마 동향과 수행에 관한 연구 식스 시그마 동향과 수행에 관한 연구 식스 시그마 동향과 수행에 관한 연구 Six Sigma is one of the most active subjects in quality management. This studs deals with some existing weaknesses that may wise in implementing Six Sigma in real world situations. The main weaknesses discussed here include the lack of understanding of cultural aspects on the nations and industries, the poor linkage between quality, finance and accounting from the bottom line point of view, and the difficult development process of metrics for all improvement results to validate the effect of Six Sigma. Finally, the key success characteristics for a good Six Sigma project are presented."
        },
        {
          "rank": 37,
          "score": 0.6219484806060791,
          "doc_id": "JAKO201809863000185",
          "title": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구",
          "abstract": "본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809863000185&target=NART&cn=JAKO201809863000185",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다."
        },
        {
          "rank": 38,
          "score": 0.6207746267318726,
          "doc_id": "JAKO202209537153825",
          "title": "Comparison of GAN Deep Learning Methods for Underwater Optical Image Enhancement",
          "abstract": "Underwater optical images face various limitations that degrade the image quality compared with optical images taken in our atmosphere. Attenuation according to the wavelength of light and reflection by very small floating objects cause low contrast, blurry clarity, and color degradation in underwater images. We constructed an image data of the Korean sea and enhanced it by learning the characteristics of underwater images using the deep learning techniques of CycleGAN (cycle-consistent adversarial network), UGAN (underwater GAN), FUnIE-GAN (fast underwater image enhancement GAN). In addition, the underwater optical image was enhanced using the image processing technique of Image Fusion. For a quantitative performance comparison, UIQM (underwater image quality measure), which evaluates the performance of the enhancement in terms of colorfulness, sharpness, and contrast, and UCIQE (underwater color image quality evaluation), which evaluates the performance in terms of chroma, luminance, and saturation were calculated. For 100 underwater images taken in Korean seas, the average UIQMs of CycleGAN, UGAN, and FUnIE-GAN were 3.91, 3.42, and 2.66, respectively, and the average UCIQEs were measured to be 29.9, 26.77, and 22.88, respectively. The average UIQM and UCIQE of Image Fusion were 3.63 and 23.59, respectively. CycleGAN and UGAN qualitatively and quantitatively improved the image quality in various underwater environments, and FUnIE-GAN had performance differences depending on the underwater environment. Image Fusion showed good performance in terms of color correction and sharpness enhancement. It is expected that this method can be used for monitoring underwater works and the autonomous operation of unmanned vehicles by improving the visibility of underwater situations more accurately.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202209537153825&target=NART&cn=JAKO202209537153825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of GAN Deep Learning Methods for Underwater Optical Image Enhancement Comparison of GAN Deep Learning Methods for Underwater Optical Image Enhancement Comparison of GAN Deep Learning Methods for Underwater Optical Image Enhancement Underwater optical images face various limitations that degrade the image quality compared with optical images taken in our atmosphere. Attenuation according to the wavelength of light and reflection by very small floating objects cause low contrast, blurry clarity, and color degradation in underwater images. We constructed an image data of the Korean sea and enhanced it by learning the characteristics of underwater images using the deep learning techniques of CycleGAN (cycle-consistent adversarial network), UGAN (underwater GAN), FUnIE-GAN (fast underwater image enhancement GAN). In addition, the underwater optical image was enhanced using the image processing technique of Image Fusion. For a quantitative performance comparison, UIQM (underwater image quality measure), which evaluates the performance of the enhancement in terms of colorfulness, sharpness, and contrast, and UCIQE (underwater color image quality evaluation), which evaluates the performance in terms of chroma, luminance, and saturation were calculated. For 100 underwater images taken in Korean seas, the average UIQMs of CycleGAN, UGAN, and FUnIE-GAN were 3.91, 3.42, and 2.66, respectively, and the average UCIQEs were measured to be 29.9, 26.77, and 22.88, respectively. The average UIQM and UCIQE of Image Fusion were 3.63 and 23.59, respectively. CycleGAN and UGAN qualitatively and quantitatively improved the image quality in various underwater environments, and FUnIE-GAN had performance differences depending on the underwater environment. Image Fusion showed good performance in terms of color correction and sharpness enhancement. It is expected that this method can be used for monitoring underwater works and the autonomous operation of unmanned vehicles by improving the visibility of underwater situations more accurately."
        },
        {
          "rank": 39,
          "score": 0.6203863620758057,
          "doc_id": "NART131717213",
          "title": "Deep Learning Based Cystoscopy Image Enhancement",
          "abstract": "<P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131717213&target=NART&cn=NART131717213",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement Deep Learning Based Cystoscopy Image Enhancement <P><B><I>Background:</I></B> Endoscopy image enhancement technology provides doctors with clearer and more detailed images for observation and diagnosis, allowing doctors to assess lesions more accurately. Unlike most other endoscopy images, cystoscopy images face more complex and diverse image degradation because of their underwater imaging characteristics. Among the various causes of image degradation, the blood haze resulting from bladder mucosal bleeding make the background blurry and unclear, severely affecting diagnostic efficiency, even leading to misjudgment.</P><P><B><I>Materials and Methods:</I></B> We propose a deep learning-based approach to mitigate the impact of blood haze on cystoscopy images. The approach consists of two parts as follows: a blood haze removal network and a contrast enhancement algorithm. First, we adopt Feature Fusion Attention Network (FFA-Net) and transfer learning in the field of deep learning to remove blood haze from cystoscopy images and introduce perceptual loss to constrain the network for better visual results. Second, we enhance the image contrast by remapping the gray scale of the blood haze-free image and performing weighted fusion of the processed image and the original image.</P><P><B><I>Results:</I></B> In the blood haze removal stage, the algorithm proposed in this article achieves an average peak signal-to-noise ratio of 29.44 decibels, which is 15% higher than state-of-the-art traditional methods. The average structural similarity and perceptual image patch similarity reach 0.9269 and 0.1146, respectively, both superior to state-of-the-art traditional methods. Besides, our method is the best in keeping color balance after removing the blood haze. In the image enhancement stage, our algorithm enhances the contrast of vessels and tissues while preserving the original colors, expanding the dynamic range of the image.</P><P><B><I>Conclusion:</I></B> The deep learning-based cystoscopy image enhancement method is significantly better than other traditional methods in both qualitative and quantitative evaluation. The application of artificial intelligence will provide clearer, higher contrast cystoscopy images for medical diagnosis.</P>"
        },
        {
          "rank": 40,
          "score": 0.6198759078979492,
          "doc_id": "JAKO202029462558904",
          "title": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식",
          "abstract": "특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029462558904&target=NART&cn=JAKO202029462558904",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다."
        },
        {
          "rank": 41,
          "score": 0.6195578575134277,
          "doc_id": "JAKO202513936004376",
          "title": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구",
          "abstract": "본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202513936004376&target=NART&cn=JAKO202513936004376",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다."
        },
        {
          "rank": 42,
          "score": 0.6194707155227661,
          "doc_id": "ART003167534",
          "title": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior",
          "abstract": "Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003167534&target=NART&cn=ART003167534",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified."
        },
        {
          "rank": 43,
          "score": 0.6186633110046387,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 44,
          "score": 0.6184902191162109,
          "doc_id": "ART002832678",
          "title": "Deep learning-guided attenuation correction in the image domain for myocardial perfusion SPECT imaging",
          "abstract": "We investigate the accuracy of direct attenuation correction (AC) in the image domain for myocardial perfusion SPECT (single-photon emission computed tomography) imaging (MPI-SPECT) using residual (ResNet) and UNet deep convolutional neural networks. MPI-SPECT 99mTc-sestamibi images of 99 patients were retrospectively included. UNet and ResNet networks were trained using non-attenuation-corrected SPECT images as input, whereas CT-based attenuation-corrected (CT-AC) SPECT images served as reference. Chang’s calculated AC approach considering a uniform attenuation coefficient within the body contour was also implemented. Clinical and quantitative evaluations of the proposed methods were performed considering SPECT CT-AC images of 19 subjects (external validation set) as reference. Image-derived metrics, including the voxel-wise mean error (ME), mean absolute error, relative error, structural similarity index (SSI), and peak signal-to-noise ratio, as well as clinical relevant indices, such as total perfusion deficit (TPD), were utilized. Overall, AC SPECT images generated using the deep learning networks exhibited good agreement with SPECT CT-AC images, substantially outperforming Chang’s method. The ResNet and UNet models resulted in an ME of −6.99 ± 16.72 and −4.41 ± 11.8 and an SSI of 0.99 ± 0.04 and 0.98 ± 0.05, respectively. Chang’s approach led to ME and SSI of 25.52 ± 33.98 and 0.93 ± 0.09, respectively. Similarly, the clinical evaluation revealed a mean TPD of 12.78 ± 9.22% and 12.57 ± 8.93% for ResNet and UNet models, respectively, compared to 12.84 ± 8.63% obtained from SPECT CT-AC images. Conversely, Chang’s approach led to a mean TPD of 16.68 ± 11.24%. The deep learning AC methods have the potential to achieve reliable AC in MPI-SPECT imaging.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002832678&target=NART&cn=ART002832678",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-guided attenuation correction in the image domain for myocardial perfusion SPECT imaging Deep learning-guided attenuation correction in the image domain for myocardial perfusion SPECT imaging Deep learning-guided attenuation correction in the image domain for myocardial perfusion SPECT imaging We investigate the accuracy of direct attenuation correction (AC) in the image domain for myocardial perfusion SPECT (single-photon emission computed tomography) imaging (MPI-SPECT) using residual (ResNet) and UNet deep convolutional neural networks. MPI-SPECT 99mTc-sestamibi images of 99 patients were retrospectively included. UNet and ResNet networks were trained using non-attenuation-corrected SPECT images as input, whereas CT-based attenuation-corrected (CT-AC) SPECT images served as reference. Chang’s calculated AC approach considering a uniform attenuation coefficient within the body contour was also implemented. Clinical and quantitative evaluations of the proposed methods were performed considering SPECT CT-AC images of 19 subjects (external validation set) as reference. Image-derived metrics, including the voxel-wise mean error (ME), mean absolute error, relative error, structural similarity index (SSI), and peak signal-to-noise ratio, as well as clinical relevant indices, such as total perfusion deficit (TPD), were utilized. Overall, AC SPECT images generated using the deep learning networks exhibited good agreement with SPECT CT-AC images, substantially outperforming Chang’s method. The ResNet and UNet models resulted in an ME of −6.99 ± 16.72 and −4.41 ± 11.8 and an SSI of 0.99 ± 0.04 and 0.98 ± 0.05, respectively. Chang’s approach led to ME and SSI of 25.52 ± 33.98 and 0.93 ± 0.09, respectively. Similarly, the clinical evaluation revealed a mean TPD of 12.78 ± 9.22% and 12.57 ± 8.93% for ResNet and UNet models, respectively, compared to 12.84 ± 8.63% obtained from SPECT CT-AC images. Conversely, Chang’s approach led to a mean TPD of 16.68 ± 11.24%. The deep learning AC methods have the potential to achieve reliable AC in MPI-SPECT imaging."
        },
        {
          "rank": 45,
          "score": 0.6177883148193359,
          "doc_id": "JAKO202009759219313",
          "title": "콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교",
          "abstract": "The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256&#x00D7;256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160&#x00D7;3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256&#x00D7;256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009759219313&target=NART&cn=JAKO202009759219313",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 콘크리트 균열 탐지를 위한 딥 러닝 기반 CNN 모델 비교 The purpose of this study is to compare the models of Deep Learning-based Convolution Neural Network(CNN) for concrete crack detection. The comparison models are AlexNet, GoogLeNet, VGG16, VGG19, ResNet-18, ResNet-50, ResNet-101, and SqueezeNet which won ImageNet Large Scale Visual Recognition Challenge(ILSVRC). To train, validate and test these models, we constructed 3000 training data and 12000 validation data with 256&#x00D7;256 pixel resolution consisting of cracked and non-cracked images, and constructed 5 test data with 4160&#x00D7;3120 pixel resolution consisting of concrete images with crack. In order to increase the efficiency of the training, transfer learning was performed by taking the weight from the pre-trained network supported by MATLAB. From the trained network, the validation data is classified into crack image and non-crack image, yielding True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN), and 6 performance indicators, False Negative Rate (FNR), False Positive Rate (FPR), Error Rate, Recall, Precision, Accuracy were calculated. The test image was scanned twice with a sliding window of 256&#x00D7;256 pixel resolution to classify the cracks, resulting in a crack map. From the comparison of the performance indicators and the crack map, it was concluded that VGG16 and VGG19 were the most suitable for detecting concrete cracks."
        },
        {
          "rank": 46,
          "score": 0.6172524690628052,
          "doc_id": "NART120007501",
          "title": "Open Source Assessment of Deep Learning Visual Object Detection",
          "abstract": "<P>This paper introduces Detection Metrics, an open-source scientific software for the assessment of deep learning neural network models for visual object detection. This software provides objective performance metrics such as mean average precision and mean inference time. The most relevant international object detection datasets are supported along with the most widely used deep learning frameworks. Different network models, even those built from different frameworks, can be fairly compared in this way. This is very useful when developing deep learning applications or research. A set of tools is provided to manage and work with different datasets and models, including visualization and conversion into several common formats. Detection Metrics may also be used in automatic batch processing for large experimental tests, saving researchers time, and new domain-specific datasets can be easily created from videos or webcams. It is open-source, can be audited, extended, and adapted to particular requirements. It has been experimentally validated. The performance of the most relevant state-of-the-art neural models for object detection has been experimentally compared. In addition, it has been used in several research projects, guiding in selecting the most suitable network model architectures and training procedures. The performance of the different models and training alternatives can be easily measured, even on large datasets.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120007501&target=NART&cn=NART120007501",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Open Source Assessment of Deep Learning Visual Object Detection Open Source Assessment of Deep Learning Visual Object Detection Open Source Assessment of Deep Learning Visual Object Detection <P>This paper introduces Detection Metrics, an open-source scientific software for the assessment of deep learning neural network models for visual object detection. This software provides objective performance metrics such as mean average precision and mean inference time. The most relevant international object detection datasets are supported along with the most widely used deep learning frameworks. Different network models, even those built from different frameworks, can be fairly compared in this way. This is very useful when developing deep learning applications or research. A set of tools is provided to manage and work with different datasets and models, including visualization and conversion into several common formats. Detection Metrics may also be used in automatic batch processing for large experimental tests, saving researchers time, and new domain-specific datasets can be easily created from videos or webcams. It is open-source, can be audited, extended, and adapted to particular requirements. It has been experimentally validated. The performance of the most relevant state-of-the-art neural models for object detection has been experimentally compared. In addition, it has been used in several research projects, guiding in selecting the most suitable network model architectures and training procedures. The performance of the different models and training alternatives can be easily measured, even on large datasets.</P>"
        },
        {
          "rank": 47,
          "score": 0.6169030666351318,
          "doc_id": "JAKO202300957609703",
          "title": "딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합",
          "abstract": "위성 시계열 데이터가 증가함에 따라 원격탐사 자료의 활용도가 높아지고 있다. 시계열 자료를 통한 분석에 있어 영상 간의 상대적인 위치 정확도는 결과에 큰 영향을 미치기 때문에 이를 보정하기 위한 영상 정합 과정은 필수적으로 선행되어야 한다. 최근에는 기존 알고리즘의 성능을 상회하는 딥러닝 기반 영상 정합 연구의 사례가 증가하고 있다. 딥러닝 기반 정합 모델을 학습하기 위해서는 수 많은 영상 쌍이 필요하다. 또한, 기존 딥러닝 모델의 데이터 간의 상관도 map을 제작하고, 이에 추가적인 연산을 적용하여 정합점을 추출는데 이는 비효율적이다. 이러한 문제를 해결하기 위해 본 연구에서는 영상 정합 모델 학습을 위한 데이터 증강 기법을 구축하여 데이터셋을 제작하였고, 이를 오프셋(offset) 양 자체를 예측하는 정합 모델인 OffsetNet에 적용하여 KOMSAT-2, -3, -3A 영상 정합을 수행하였다. 모델 학습 결과, OffsetNet은 평가 데이터에 대해 높은 정확도로 오프셋 양을 예측하였고, 이를 통해 주영상과 부영상을 효과적으로 정합하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202300957609703&target=NART&cn=JAKO202300957609703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 딥러닝 기반 OffsetNet 모델을 통한 KOMPSAT 광학 영상 정합 위성 시계열 데이터가 증가함에 따라 원격탐사 자료의 활용도가 높아지고 있다. 시계열 자료를 통한 분석에 있어 영상 간의 상대적인 위치 정확도는 결과에 큰 영향을 미치기 때문에 이를 보정하기 위한 영상 정합 과정은 필수적으로 선행되어야 한다. 최근에는 기존 알고리즘의 성능을 상회하는 딥러닝 기반 영상 정합 연구의 사례가 증가하고 있다. 딥러닝 기반 정합 모델을 학습하기 위해서는 수 많은 영상 쌍이 필요하다. 또한, 기존 딥러닝 모델의 데이터 간의 상관도 map을 제작하고, 이에 추가적인 연산을 적용하여 정합점을 추출는데 이는 비효율적이다. 이러한 문제를 해결하기 위해 본 연구에서는 영상 정합 모델 학습을 위한 데이터 증강 기법을 구축하여 데이터셋을 제작하였고, 이를 오프셋(offset) 양 자체를 예측하는 정합 모델인 OffsetNet에 적용하여 KOMSAT-2, -3, -3A 영상 정합을 수행하였다. 모델 학습 결과, OffsetNet은 평가 데이터에 대해 높은 정확도로 오프셋 양을 예측하였고, 이를 통해 주영상과 부영상을 효과적으로 정합하였다."
        },
        {
          "rank": 48,
          "score": 0.6166398525238037,
          "doc_id": "NART123616052",
          "title": "Deep Learning for Image Enhancement and Correction in Magnetic Resonance Imaging&#x2014;State-of-the-Art and Challenges",
          "abstract": "<P>Magnetic resonance imaging (MRI) provides excellent soft-tissue contrast for clinical diagnoses and research which underpin many recent breakthroughs in medicine and biology. The post-processing of reconstructed MR images is often automated for incorporation into MRI scanners by the manufacturers and increasingly plays a critical role in the final image quality for clinical reporting and interpretation. For image enhancement and correction, the post-processing steps include noise reduction, image artefact correction, and image resolution improvements. With the recent success of deep learning in many research fields, there is great potential to apply deep learning for MR image enhancement, and recent publications have demonstrated promising results. Motivated by the rapidly growing literature in this area, in this review paper, we provide a comprehensive overview of deep learning-based methods for post-processing MR images to enhance image quality and correct image artefacts. We aim to provide researchers in MRI or other research fields, including computer vision and image processing, a literature survey of deep learning approaches for MR image enhancement. We discuss the current limitations of the application of artificial intelligence in MRI and highlight possible directions for future developments. In the era of deep learning, we highlight the importance of a critical appraisal of the explanatory information provided and the generalizability of deep learning algorithms in medical imaging. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123616052&target=NART&cn=NART123616052",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning for Image Enhancement and Correction in Magnetic Resonance Imaging&#x2014;State-of-the-Art and Challenges Deep Learning for Image Enhancement and Correction in Magnetic Resonance Imaging&#x2014;State-of-the-Art and Challenges Deep Learning for Image Enhancement and Correction in Magnetic Resonance Imaging&#x2014;State-of-the-Art and Challenges <P>Magnetic resonance imaging (MRI) provides excellent soft-tissue contrast for clinical diagnoses and research which underpin many recent breakthroughs in medicine and biology. The post-processing of reconstructed MR images is often automated for incorporation into MRI scanners by the manufacturers and increasingly plays a critical role in the final image quality for clinical reporting and interpretation. For image enhancement and correction, the post-processing steps include noise reduction, image artefact correction, and image resolution improvements. With the recent success of deep learning in many research fields, there is great potential to apply deep learning for MR image enhancement, and recent publications have demonstrated promising results. Motivated by the rapidly growing literature in this area, in this review paper, we provide a comprehensive overview of deep learning-based methods for post-processing MR images to enhance image quality and correct image artefacts. We aim to provide researchers in MRI or other research fields, including computer vision and image processing, a literature survey of deep learning approaches for MR image enhancement. We discuss the current limitations of the application of artificial intelligence in MRI and highlight possible directions for future developments. In the era of deep learning, we highlight the importance of a critical appraisal of the explanatory information provided and the generalizability of deep learning algorithms in medical imaging. </P>"
        },
        {
          "rank": 49,
          "score": 0.6166276335716248,
          "doc_id": "JAKO202408075073596",
          "title": "인공지능 학습데이터 라벨링 정확도에 따른 인공지능 성능",
          "abstract": "본 연구는 데이터의 품질이 인공지능(AI) 성능에 미치는 영향을 검토한다. 이를 위해, 데이터 특성변수(Feature)의 유사도와 클래스(Class) 구성의 불균형을 고려한 모의실험(Simulation)을 통해 라벨링 오류 수준이 인공지능의 성능에 미치는 영향을 비교 분석하였다. 그 결과, 특성변수 간 유사성이 높은 데이터에서는 특성 변수 간 유사성이 낮은 데이터에 비해 라벨링 정확도에 더 민감하게 반응하였으며, 클래스 불균형이 증가함에 따라 인공지능 정확도가 급격히 감소되는 경향을 관찰하였다. 이는 인공지능 학습데이터의 품질평가 기준 및 관련 연구를 위한 기초자료가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202408075073596&target=NART&cn=JAKO202408075073596",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능 학습데이터 라벨링 정확도에 따른 인공지능 성능 인공지능 학습데이터 라벨링 정확도에 따른 인공지능 성능 인공지능 학습데이터 라벨링 정확도에 따른 인공지능 성능 본 연구는 데이터의 품질이 인공지능(AI) 성능에 미치는 영향을 검토한다. 이를 위해, 데이터 특성변수(Feature)의 유사도와 클래스(Class) 구성의 불균형을 고려한 모의실험(Simulation)을 통해 라벨링 오류 수준이 인공지능의 성능에 미치는 영향을 비교 분석하였다. 그 결과, 특성변수 간 유사성이 높은 데이터에서는 특성 변수 간 유사성이 낮은 데이터에 비해 라벨링 정확도에 더 민감하게 반응하였으며, 클래스 불균형이 증가함에 따라 인공지능 정확도가 급격히 감소되는 경향을 관찰하였다. 이는 인공지능 학습데이터의 품질평가 기준 및 관련 연구를 위한 기초자료가 될 것이다."
        },
        {
          "rank": 50,
          "score": 0.6162171959877014,
          "doc_id": "DIKO0015644673",
          "title": "M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지",
          "abstract": "해상 교통량의 증가로 인해 해상 선박관리의 필요성이 늘어남에 따라 선박을 탐지하기 위한 연구들이 꾸준히 수행되어왔다. 특히 위성레이더 영상은 시간과 기후에 영향을 받지 않고 촬영할 수 있다는 장점으로 인해 선박탐지를 위한 많은 연구에서 활용되어왔다. 최근에는 딥러닝 기법의 발전으로 인해 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구들이 꾸준히 수행되고 있다. 그런데 위성레이더 영상은 값의 분포범위가 매우 넓고, 많은 스펙클 노이즈가 존재한다. 이러한 요소들은 딥러닝 모델의 학습에 부정적인 영향을 끼칠 수 있으므로 전처리를 통해 해당 요소들을 저감해줄 필요가 있다. 본 연구에서는 전처리된 위성레이더 영상으로부터 딥러닝 선박탐지를 수행하고, 영상의 전처리가 딥러닝 선박탐지에 미치는 요소를 비교분석 하고자 한다.&amp;#xD; 본 연구를 위해 TerraSAR-X와 COSMO-SkyMed 위성레이더 영상을 이용했다. 영상을 딥러닝 학습에 이용하기 전에 먼저 총 세 가지 다른 방법으로 전처리를 수행했다. 첫 번째는 위성레이더 영상에서 강도 값만을 추출한 강도 영상을 생성하는 방법이다. 강도 영상은 값의 범위가 매우 넓을 뿐만 아니라 많은 스펙클 노이즈를 가지고 있다. 두 번째는 강도영상에서 값의 단위를 데시벨로 변환한 데시벨 영상을 생성하는 방법이다. 데시벨 영상은 강도영상과 마찬가지로 많은 스펙클 노이즈를 가지고 있으나 값의 범위가 줄어들어, 더 안정적인 학습을 할 수 있다. 세 번째는 본 연구에서 제안하는 위성레이더 전처리방법으로써, 강도차분과 거칠기영상을 생성하는 방법이다. 두 영상은 중간값 필터링을 이용해 스펙클 노이즈를 줄이고, 값의 분포 대역을 좁힘으로써 빠른 학습이 가능하다.&amp;#xD; 각 전처리된 위성레이더 영상을 이용해 딥러닝 학습을 하기 위해 본 연구에서는 M2Det 객체탐지 모델을 사용했다. 객체탐지 모델을 학습시킨 뒤 테스트 영상을 이용해 선박탐지를 수행했으며, 테스트 결과는 정밀도(Precision), 재현율(Recall)을 이용해 나타냈으며, 두 지수를 하나의 값으로 표현하기 위해 AP(Average Precision)와 F1 점수(F1-score)를 이용해 나타냈다. 각 영상의 정밀도, 재현율, AP, F1 점수는 강도 영상 93.18%, 91.11%, 89.78%, 92.13%, 데시벨 영상 94.16%, 94.16%, 92.34%, 94.16%, 강도차분과 거칠기 영상 97.40%, 94.94%, 95.55%, 96.15%로 계산되었다. 강도 영상을 이용한 경우 미탐지와 오탐지 선박이 많았으며, 전처리된 영상을 이용한 경우 강도 영상에 비해 미탐지와 오탐지 선박이 줄어든 것을 확인할 수 있었다. 데시벨 영상과 강도차분, 거칠기 영상의 결과를 비교했을 때, 두 영상의 오탐지율은 유사했다. 하지만 강도차분, 거칠기 영상을 이용했을 때 강도 영상에 비해 미탐지 선박의 비율이 4% 줄어든 것을 확인할 수 있었다. 이 결과를 통해 위성레이더 영상을 전처리함으로써 딥러닝 학습을 돕고 선박탐지 결과를 향상시킬 수 있다는 것을 알 수 있다. 본 연구결과는 향후 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구의 발전에 이바지할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015644673&target=NART&cn=DIKO0015644673",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 M2Det 딥러닝 모델을 이용한 X밴드 SAR 영상으로부터 선박탐지 해상 교통량의 증가로 인해 해상 선박관리의 필요성이 늘어남에 따라 선박을 탐지하기 위한 연구들이 꾸준히 수행되어왔다. 특히 위성레이더 영상은 시간과 기후에 영향을 받지 않고 촬영할 수 있다는 장점으로 인해 선박탐지를 위한 많은 연구에서 활용되어왔다. 최근에는 딥러닝 기법의 발전으로 인해 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구들이 꾸준히 수행되고 있다. 그런데 위성레이더 영상은 값의 분포범위가 매우 넓고, 많은 스펙클 노이즈가 존재한다. 이러한 요소들은 딥러닝 모델의 학습에 부정적인 영향을 끼칠 수 있으므로 전처리를 통해 해당 요소들을 저감해줄 필요가 있다. 본 연구에서는 전처리된 위성레이더 영상으로부터 딥러닝 선박탐지를 수행하고, 영상의 전처리가 딥러닝 선박탐지에 미치는 요소를 비교분석 하고자 한다.&amp;#xD; 본 연구를 위해 TerraSAR-X와 COSMO-SkyMed 위성레이더 영상을 이용했다. 영상을 딥러닝 학습에 이용하기 전에 먼저 총 세 가지 다른 방법으로 전처리를 수행했다. 첫 번째는 위성레이더 영상에서 강도 값만을 추출한 강도 영상을 생성하는 방법이다. 강도 영상은 값의 범위가 매우 넓을 뿐만 아니라 많은 스펙클 노이즈를 가지고 있다. 두 번째는 강도영상에서 값의 단위를 데시벨로 변환한 데시벨 영상을 생성하는 방법이다. 데시벨 영상은 강도영상과 마찬가지로 많은 스펙클 노이즈를 가지고 있으나 값의 범위가 줄어들어, 더 안정적인 학습을 할 수 있다. 세 번째는 본 연구에서 제안하는 위성레이더 전처리방법으로써, 강도차분과 거칠기영상을 생성하는 방법이다. 두 영상은 중간값 필터링을 이용해 스펙클 노이즈를 줄이고, 값의 분포 대역을 좁힘으로써 빠른 학습이 가능하다.&amp;#xD; 각 전처리된 위성레이더 영상을 이용해 딥러닝 학습을 하기 위해 본 연구에서는 M2Det 객체탐지 모델을 사용했다. 객체탐지 모델을 학습시킨 뒤 테스트 영상을 이용해 선박탐지를 수행했으며, 테스트 결과는 정밀도(Precision), 재현율(Recall)을 이용해 나타냈으며, 두 지수를 하나의 값으로 표현하기 위해 AP(Average Precision)와 F1 점수(F1-score)를 이용해 나타냈다. 각 영상의 정밀도, 재현율, AP, F1 점수는 강도 영상 93.18%, 91.11%, 89.78%, 92.13%, 데시벨 영상 94.16%, 94.16%, 92.34%, 94.16%, 강도차분과 거칠기 영상 97.40%, 94.94%, 95.55%, 96.15%로 계산되었다. 강도 영상을 이용한 경우 미탐지와 오탐지 선박이 많았으며, 전처리된 영상을 이용한 경우 강도 영상에 비해 미탐지와 오탐지 선박이 줄어든 것을 확인할 수 있었다. 데시벨 영상과 강도차분, 거칠기 영상의 결과를 비교했을 때, 두 영상의 오탐지율은 유사했다. 하지만 강도차분, 거칠기 영상을 이용했을 때 강도 영상에 비해 미탐지 선박의 비율이 4% 줄어든 것을 확인할 수 있었다. 이 결과를 통해 위성레이더 영상을 전처리함으로써 딥러닝 학습을 돕고 선박탐지 결과를 향상시킬 수 있다는 것을 알 수 있다. 본 연구결과는 향후 딥러닝을 적용한 위성레이더 영상에서의 선박탐지 연구의 발전에 이바지할 수 있을 것으로 기대된다."
        }
      ]
    },
    {
      "query": "What are the strengths of deep reinforcement learning for complex image analysis?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7431535124778748,
          "doc_id": "NART105497078",
          "title": "Deep Reinforcement Learning for Image Hashing",
          "abstract": "<P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART105497078&target=NART&cn=NART105497078",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing <P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>"
        },
        {
          "rank": 2,
          "score": 0.740620493888855,
          "doc_id": "ART002574280",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002574280&target=NART&cn=ART002574280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 3,
          "score": 0.740620493888855,
          "doc_id": "JAKO202009863559871",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009863559871&target=NART&cn=JAKO202009863559871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 4,
          "score": 0.7316148281097412,
          "doc_id": "JAKO201962652079504",
          "title": "심층 강화학습 기술 동향",
          "abstract": "Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201962652079504&target=NART&cn=JAKO201962652079504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기술 동향 심층 강화학습 기술 동향 심층 강화학습 기술 동향 Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions."
        },
        {
          "rank": 5,
          "score": 0.7195857763290405,
          "doc_id": "JAKO202210351407855",
          "title": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적",
          "abstract": "Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202210351407855&target=NART&cn=JAKO202210351407855",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them."
        },
        {
          "rank": 6,
          "score": 0.7160412073135376,
          "doc_id": "NART118990104",
          "title": "Hierarchical Image Object Search Based on Deep Reinforcement Learning",
          "abstract": "<P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118990104&target=NART&cn=NART118990104",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning <P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>"
        },
        {
          "rank": 7,
          "score": 0.7011204957962036,
          "doc_id": "NART95036368",
          "title": "Deep Reinforcement Learning in Medicine",
          "abstract": "<P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95036368&target=NART&cn=NART95036368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine <P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>"
        },
        {
          "rank": 8,
          "score": 0.6996400952339172,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 9,
          "score": 0.699010968208313,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 10,
          "score": 0.6883907914161682,
          "doc_id": "ART002367528",
          "title": "Recognition of Human Motion with Deep Reinforcement Learning",
          "abstract": "Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002367528&target=NART&cn=ART002367528",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data."
        },
        {
          "rank": 11,
          "score": 0.6805210113525391,
          "doc_id": "NART136112293",
          "title": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning",
          "abstract": "<P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART136112293&target=NART&cn=NART136112293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning <P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>"
        },
        {
          "rank": 12,
          "score": 0.6796602010726929,
          "doc_id": "JAKO202223540366088",
          "title": "이미지 학습을 위한 딥러닝 프레임워크 비교분석",
          "abstract": "딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202223540366088&target=NART&cn=JAKO202223540366088",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 이미지 학습을 위한 딥러닝 프레임워크 비교분석 딥러닝 프레임워크는 현재에도 계속해서 발전되어 가고 있으며, 다양한 프레임워크들이 존재한다. 딥러닝의 대표적인 프레임워크는 TensorFlow, PyTorch, Keras 등이 있다. 딥러님 프레임워크는 이미지 학습을 통해 이미지 분류에서의 최적화 모델을 이용한다. 본 논문에서는 딥러닝 이미지 인식 분야에서 가장 많이 사용하고 있는 TensorFlow와 PyTorch 프레임워크를 활용하여 이미지 학습을 진행하였으며, 이 과정에서 도출한 결과를 비교 분석하여 최적화된 프레임워크을 알 수 있었다."
        },
        {
          "rank": 13,
          "score": 0.6774454116821289,
          "doc_id": "NART121556950",
          "title": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement",
          "abstract": "<P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121556950&target=NART&cn=NART121556950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement <P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>"
        },
        {
          "rank": 14,
          "score": 0.6753336191177368,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 15,
          "score": 0.6734145879745483,
          "doc_id": "JAKO202218262151224",
          "title": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석",
          "abstract": "생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202218262151224&target=NART&cn=JAKO202218262151224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다."
        },
        {
          "rank": 16,
          "score": 0.6728538274765015,
          "doc_id": "JAKO202106153187643",
          "title": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론",
          "abstract": "빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153187643&target=NART&cn=JAKO202106153187643",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다."
        },
        {
          "rank": 17,
          "score": 0.6706082224845886,
          "doc_id": "NART119629224",
          "title": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging",
          "abstract": "<P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119629224&target=NART&cn=NART119629224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging <P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>"
        },
        {
          "rank": 18,
          "score": 0.6699336767196655,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 19,
          "score": 0.6693915128707886,
          "doc_id": "DIKO0016950566",
          "title": "심층 강화학습을 활용한 로봇 경로 계획",
          "abstract": "강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016950566&target=NART&cn=DIKO0016950566",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다."
        },
        {
          "rank": 20,
          "score": 0.6683588027954102,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 21,
          "score": 0.6680855751037598,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 22,
          "score": 0.6679328083992004,
          "doc_id": "NART96288640",
          "title": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms",
          "abstract": "<P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96288640&target=NART&cn=NART96288640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms <P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>"
        },
        {
          "rank": 23,
          "score": 0.6678279042243958,
          "doc_id": "JAKO202109835990951",
          "title": "분해 심층 학습을 이용한 저조도 영상 개선 방식",
          "abstract": "본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109835990951&target=NART&cn=JAKO202109835990951",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다."
        },
        {
          "rank": 24,
          "score": 0.6674441695213318,
          "doc_id": "JAKO201974757494930",
          "title": "심층강화학습 라이브러리 기술동향",
          "abstract": "Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201974757494930&target=NART&cn=JAKO201974757494930",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective."
        },
        {
          "rank": 25,
          "score": 0.6667783260345459,
          "doc_id": "NART110796699",
          "title": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network",
          "abstract": "<P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110796699&target=NART&cn=NART110796699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network <P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>"
        },
        {
          "rank": 26,
          "score": 0.6665433645248413,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 27,
          "score": 0.6649254560470581,
          "doc_id": "ART002977356",
          "title": "Deep reinforcement learning based edge computing for video processing",
          "abstract": "In many of 5G applications, end devices with lack of computing power often need to carry out heavy computations involving multimedia data. Edge computing has emerged as a promising solution to circumvent scarce resources at end devices, with moderate delays compared to cloud computing. In this work, we study the problem of offloading video processing tasks to edge servers. To this end, we develop a deep reinforcement learning based method for selecting either local or edge server to process video frames. We demonstrate the performance of our method through experiments with video frame transform tasks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002977356&target=NART&cn=ART002977356",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep reinforcement learning based edge computing for video processing Deep reinforcement learning based edge computing for video processing Deep reinforcement learning based edge computing for video processing In many of 5G applications, end devices with lack of computing power often need to carry out heavy computations involving multimedia data. Edge computing has emerged as a promising solution to circumvent scarce resources at end devices, with moderate delays compared to cloud computing. In this work, we study the problem of offloading video processing tasks to edge servers. To this end, we develop a deep reinforcement learning based method for selecting either local or edge server to process video frames. We demonstrate the performance of our method through experiments with video frame transform tasks."
        },
        {
          "rank": 28,
          "score": 0.6635308265686035,
          "doc_id": "DIKO0016665339",
          "title": "심층 강화 학습 기반 애니메이션 자동 생성",
          "abstract": "최근 미디어 시장의 확대에 따라 미디어 콘텐츠의 퀄리티 향상을 위한 다양한 새로운 시도가 되고 있다. 사전 시각화(Pre-visualization)는 그 시도 중 하나인데 사전 시각화를 위해서는 가상 공간에서 캐릭터(에이전트, Agent)의 애니메이션(Animation) 연출이 필수적이다. &amp;#xD; 본 연구에서는 사전 시각화에서 좀 더 효율적인 시각화를 위해 가상 캐릭터의 애니메이션을 자동으로 생성하는 연구를 하였다. 특히, 심층 강화 학습(Deep Reinforcement Learning) 기법을 활용하여 캐릭터가 주변 환경의 상태를 감지하여 적절한 애니메이션을 자동으로 연출할 수 있는 방법을 제안하였다. &amp;#xD; 게임 엔진을 활용하여 가상 환경을 만들어 강화 학습을 할 수 있는 공간을 구성하고 python과 pytorch로 강화 학습 모델 트레이닝 환경을 구성하였다. 가상 환경과 모델 트레이닝 환경은 ml-agents 툴킷을 이용하여 통신하도록 하였다. 가상 환경에서는 캐릭터가 기본적으로 직진으로 이동하도록 했으며, 캐릭터 전방에는 임의의 위치에 3가지 장애물이 등장하도록 하였다. 캐릭터는 9가지 상태를 감지하도록 하였고 3가지 액션이 가능하도록 하였다. 캐릭터는 상태를 감지한 후 행동에 따라 리워드를 제공해 학습을 진행하였다. 성능 평가를 위해 PPO 알고리즘과 SAC알고리즘을 사용하여 강화 학습 트레이닝을 진행하였고, 배치사이즈에 따른 성능 비교도 진행하였다.&amp;#xD; 그 결과 장애물 회피 능력이 있는 강화 학습 모델을 확보할 수 있었다. 해당 모델을 캐릭터에 적용한 결과 명시적인 프로그래밍 없이도 캐릭터가 주변 환경의 상태에 따라 자동으로 애니메이션을 연출할 수 있음을 증명할 수 있었다.&amp;#xD; &amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016665339&target=NART&cn=DIKO0016665339",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화 학습 기반 애니메이션 자동 생성 심층 강화 학습 기반 애니메이션 자동 생성 심층 강화 학습 기반 애니메이션 자동 생성 최근 미디어 시장의 확대에 따라 미디어 콘텐츠의 퀄리티 향상을 위한 다양한 새로운 시도가 되고 있다. 사전 시각화(Pre-visualization)는 그 시도 중 하나인데 사전 시각화를 위해서는 가상 공간에서 캐릭터(에이전트, Agent)의 애니메이션(Animation) 연출이 필수적이다. &amp;#xD; 본 연구에서는 사전 시각화에서 좀 더 효율적인 시각화를 위해 가상 캐릭터의 애니메이션을 자동으로 생성하는 연구를 하였다. 특히, 심층 강화 학습(Deep Reinforcement Learning) 기법을 활용하여 캐릭터가 주변 환경의 상태를 감지하여 적절한 애니메이션을 자동으로 연출할 수 있는 방법을 제안하였다. &amp;#xD; 게임 엔진을 활용하여 가상 환경을 만들어 강화 학습을 할 수 있는 공간을 구성하고 python과 pytorch로 강화 학습 모델 트레이닝 환경을 구성하였다. 가상 환경과 모델 트레이닝 환경은 ml-agents 툴킷을 이용하여 통신하도록 하였다. 가상 환경에서는 캐릭터가 기본적으로 직진으로 이동하도록 했으며, 캐릭터 전방에는 임의의 위치에 3가지 장애물이 등장하도록 하였다. 캐릭터는 9가지 상태를 감지하도록 하였고 3가지 액션이 가능하도록 하였다. 캐릭터는 상태를 감지한 후 행동에 따라 리워드를 제공해 학습을 진행하였다. 성능 평가를 위해 PPO 알고리즘과 SAC알고리즘을 사용하여 강화 학습 트레이닝을 진행하였고, 배치사이즈에 따른 성능 비교도 진행하였다.&amp;#xD; 그 결과 장애물 회피 능력이 있는 강화 학습 모델을 확보할 수 있었다. 해당 모델을 캐릭터에 적용한 결과 명시적인 프로그래밍 없이도 캐릭터가 주변 환경의 상태에 따라 자동으로 애니메이션을 연출할 수 있음을 증명할 수 있었다.&amp;#xD; &amp;#xD;"
        },
        {
          "rank": 29,
          "score": 0.6633669137954712,
          "doc_id": "NART134008954",
          "title": "The advancements and applications of deep reinforcement learning in Go",
          "abstract": "<P>Combining Deep Learning's perceptual skills with Reinforcement Learning's decision-making abilities, Deep Reinforcement Learning (DRL) represents a significant breakthrough in Artificial Intelligence (AI). This paper examines the evolution and uses of Deep Reinforcement Learning (DRL), emphasizing both the theoretical underpinnings and the noteworthy real-world applications-like AlphaGo's triumph over elite Go players-of the technology. DRL systems learn optimal policies through interactions with their environment, maximizing long-term cumulative rewards. DRL has achieved remarkable results in complex decision-making tasks through the combination of deep learning models like Convolutional Neural Networks (CNN) and reinforcement learning techniques. DRL's potential to transform AI applications is demonstrated by its success in a number of industries, including robotics, autonomous driving, and video games. AlphaGo's success, leveraging DRL and Monte Carlo Tree Search (MCTS), exemplifies the impact of this method on game theory and strategic decision-making. This paper aims to explore the key concepts of DRL, its historical evolution, and its future prospects in advanced AI research.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART134008954&target=NART&cn=NART134008954",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The advancements and applications of deep reinforcement learning in Go The advancements and applications of deep reinforcement learning in Go The advancements and applications of deep reinforcement learning in Go <P>Combining Deep Learning's perceptual skills with Reinforcement Learning's decision-making abilities, Deep Reinforcement Learning (DRL) represents a significant breakthrough in Artificial Intelligence (AI). This paper examines the evolution and uses of Deep Reinforcement Learning (DRL), emphasizing both the theoretical underpinnings and the noteworthy real-world applications-like AlphaGo's triumph over elite Go players-of the technology. DRL systems learn optimal policies through interactions with their environment, maximizing long-term cumulative rewards. DRL has achieved remarkable results in complex decision-making tasks through the combination of deep learning models like Convolutional Neural Networks (CNN) and reinforcement learning techniques. DRL's potential to transform AI applications is demonstrated by its success in a number of industries, including robotics, autonomous driving, and video games. AlphaGo's success, leveraging DRL and Monte Carlo Tree Search (MCTS), exemplifies the impact of this method on game theory and strategic decision-making. This paper aims to explore the key concepts of DRL, its historical evolution, and its future prospects in advanced AI research.</P>"
        },
        {
          "rank": 30,
          "score": 0.662071943283081,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 31,
          "score": 0.6608766317367554,
          "doc_id": "DIKO0015391154",
          "title": "심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현",
          "abstract": "딥 러닝과 강화학습을 접목한 딥 강화학습은 다양한 분야에 활용 가능성을 보이며 실생활에 적용되고 있다. 또한 성공한 몇몇 사례들의 커다란 가능성을 통해 여러 분야에 걸쳐 폭 넓은 연구들이 이루어지고 있다.&amp;#xD; 본 논문은 오델로, 바둑, 체스 등과 같은 지능적 사고를 필요로 하는 보드게임에서 복잡한 상태와 형세판단 사이의 상관관계를 찾기 위해 실제 프로기사들의 대국을 답습한 CNN을 설계하고, 판단한 형세를 근거 삼아 최소최대탐색을 이용해 최적의 수를 찾는 의사 결정을 한다. 또한 형세 판단의 근거를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안한다.&amp;#xD; 지도학습 과정의 성능을 비교하기 위해 본 연구자가 선행연구 했었던 비교적 간단한 구조를 가진 지도학습 기반의 ANN 가치평가 네트워크[1]와 본 논문에서 제안하는 지도학습 기반 CNN 가치평가 네트워크와의 대국을 실행하여, 흑일 때 69.7%, 백일 때 72.1%의 승률을 보였다. 또한 지도학습 네트워크를 자가대국으로 policy-iteration기반의 강화 학습을 적용하여 발전시킨 네트워크와 앞서 말한 두 네트워크(ANN, CNN)와의 성능 비교도 실시하였으며 최종적인 승률은 흑일 때 ANN을 상대로100%, CNN을 상대로76%의 승률을 보였으며, 백일 때 ANN을 상대로100%, CNN을 상대로 78%의 승률을 보였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015391154&target=NART&cn=DIKO0015391154",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 심층신경망 및 강화학습을 이용한 인공지능 게임 에이전트 구현 딥 러닝과 강화학습을 접목한 딥 강화학습은 다양한 분야에 활용 가능성을 보이며 실생활에 적용되고 있다. 또한 성공한 몇몇 사례들의 커다란 가능성을 통해 여러 분야에 걸쳐 폭 넓은 연구들이 이루어지고 있다.&amp;#xD; 본 논문은 오델로, 바둑, 체스 등과 같은 지능적 사고를 필요로 하는 보드게임에서 복잡한 상태와 형세판단 사이의 상관관계를 찾기 위해 실제 프로기사들의 대국을 답습한 CNN을 설계하고, 판단한 형세를 근거 삼아 최소최대탐색을 이용해 최적의 수를 찾는 의사 결정을 한다. 또한 형세 판단의 근거를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안한다.&amp;#xD; 지도학습 과정의 성능을 비교하기 위해 본 연구자가 선행연구 했었던 비교적 간단한 구조를 가진 지도학습 기반의 ANN 가치평가 네트워크[1]와 본 논문에서 제안하는 지도학습 기반 CNN 가치평가 네트워크와의 대국을 실행하여, 흑일 때 69.7%, 백일 때 72.1%의 승률을 보였다. 또한 지도학습 네트워크를 자가대국으로 policy-iteration기반의 강화 학습을 적용하여 발전시킨 네트워크와 앞서 말한 두 네트워크(ANN, CNN)와의 성능 비교도 실시하였으며 최종적인 승률은 흑일 때 ANN을 상대로100%, CNN을 상대로76%의 승률을 보였으며, 백일 때 ANN을 상대로100%, CNN을 상대로 78%의 승률을 보였다.&amp;#xD;"
        },
        {
          "rank": 32,
          "score": 0.6597970128059387,
          "doc_id": "JAKO201809863000185",
          "title": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구",
          "abstract": "본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809863000185&target=NART&cn=JAKO201809863000185",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다."
        },
        {
          "rank": 33,
          "score": 0.6578658819198608,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 34,
          "score": 0.657090961933136,
          "doc_id": "NART115326214",
          "title": "Deep learning-based single image face depth data enhancement",
          "abstract": "<P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART115326214&target=NART&cn=NART115326214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement <P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>"
        },
        {
          "rank": 35,
          "score": 0.6551337242126465,
          "doc_id": "NART101975410",
          "title": "Learning Mobile Manipulation through Deep Reinforcement Learning",
          "abstract": "<P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART101975410&target=NART&cn=NART101975410",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning <P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>"
        },
        {
          "rank": 36,
          "score": 0.6533902883529663,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 37,
          "score": 0.6533055305480957,
          "doc_id": "JAKO202126048601456",
          "title": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구",
          "abstract": "딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202126048601456&target=NART&cn=JAKO202126048601456",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 유사 이미지 분류를 위한 딥 러닝 성능 향상 기법 연구 딥 러닝을 활용한 컴퓨터 비전 연구는 여전히 대규모의 학습 데이터와 컴퓨팅 파워가 필수적이며, 최적의 네트워크 구조를 도출하기 위해 많은 시행착오가 수반된다. 본 연구에서는 네트워크 최적화나 데이터를 보강하는 것과 무관하게 데이터 자체의 특성만을 고려한 CR(Confusion Rate)기반의 유사 이미지 분류 성능 향상 기법을 제안한다. 제안 방법은 유사한 이미지 데이터를 정확히 분류하기 위해 CR을 산출하고 이를 손실 함수의 가중치에 반영함으로서 딥 러닝 모델의 성능을 향상시키는 기법을 제안한다. 제안 방법은 네트워크 최적화 결과와 독립적으로 이미지 분류 성능의 향상을 가져올 수 있으며, 클래스 간의 유사성을 고려해 유사도가 높은 이미지 식별에 적합하다. 제안 방법의 평가결과 HanDB에서는 0.22%, Animal-10N에서는 3.38%의 성능향상을 보였다. 제안한 방법은 다양한 Noisy Labeled 데이터를 활용한 인공지능 연구에 기반이 될 것을 기대한다."
        },
        {
          "rank": 38,
          "score": 0.6530141830444336,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 39,
          "score": 0.6513452529907227,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 40,
          "score": 0.6506069898605347,
          "doc_id": "JAKO202102153821210",
          "title": "교차로에서 자율주행을 위한 심층 강화 학습 활성화 함수 비교 분석",
          "abstract": "자율주행은 자동차가 사람 없이 운전할 수 있도록 해 주며 최근 인공지능 기술의 발전에 힘입어 매우 활발히 연구되고 있다. 인공지능 기술 중에서도 특히 심층 강화 학습이 가장 효과적으로 사용되는데 이를 위해서는 적절한 활성화 함수를 이용한 신경망 구축이 필수적이다. 여태껏 많은 활성화 함수가 제시됐으나 적용 분야에 따라 서로 다른 성능을 보여주었다. 본 논문은 교차로에서 자율주행을 학습하기 위해 심층 강화 학습을 사용할 때 어떤 활성화 함수를 사용하는 것이 효과적인지 성능을 비교 평가한다. 이를 위해 평가에서 사용할 성능 메트릭을 정의하고 각 활성화 함수에 따른 메트릭의 값을 그래프로 비교하였다. 그 결과 Mish를 사용할 경우 보상이 다른 활성화 함수보다 평균적으로 높은 것을 알 수 있었고 보상이 가장 낮은 활성화 함수와의 차이는 9.8%였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202102153821210&target=NART&cn=JAKO202102153821210",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교차로에서 자율주행을 위한 심층 강화 학습 활성화 함수 비교 분석 교차로에서 자율주행을 위한 심층 강화 학습 활성화 함수 비교 분석 교차로에서 자율주행을 위한 심층 강화 학습 활성화 함수 비교 분석 자율주행은 자동차가 사람 없이 운전할 수 있도록 해 주며 최근 인공지능 기술의 발전에 힘입어 매우 활발히 연구되고 있다. 인공지능 기술 중에서도 특히 심층 강화 학습이 가장 효과적으로 사용되는데 이를 위해서는 적절한 활성화 함수를 이용한 신경망 구축이 필수적이다. 여태껏 많은 활성화 함수가 제시됐으나 적용 분야에 따라 서로 다른 성능을 보여주었다. 본 논문은 교차로에서 자율주행을 학습하기 위해 심층 강화 학습을 사용할 때 어떤 활성화 함수를 사용하는 것이 효과적인지 성능을 비교 평가한다. 이를 위해 평가에서 사용할 성능 메트릭을 정의하고 각 활성화 함수에 따른 메트릭의 값을 그래프로 비교하였다. 그 결과 Mish를 사용할 경우 보상이 다른 활성화 함수보다 평균적으로 높은 것을 알 수 있었고 보상이 가장 낮은 활성화 함수와의 차이는 9.8%였다."
        },
        {
          "rank": 41,
          "score": 0.6503055095672607,
          "doc_id": "JAKO202105953625631",
          "title": "상태 표현 방식에 따른 심층 강화 학습 기반 캐릭터 제어기의 학습 성능 비교",
          "abstract": "물리 시뮬레이션 기반의 캐릭터 동작 제어 문제를 강화학습을 이용하여 해결해나가는 연구들이 계속해서 진행되고 있다. 강화학습을 사용하여 문제를 풀기 위해서는 네트워크 구조, 하이퍼파라미터 튜닝, 상태(state), 행동(action), 보상(reward)이 문제에 맞게 적절히 설정이 되어야 한다. 많은 연구들에서 다양한 조합으로 상태, 행동, 보상을 정의하였고, 성공적으로 문제에 적용하였다. 상태, 행동, 보상을 정의함에 다양한 조합이 있다보니 학습 성능을 향상시키는 최적의 조합을 찾기 위해서 각각의 요소들이 미치는 영향을 분석하는 연구도 진행되고 있다. 우리는 지금까지 이뤄지지 않았던 상태 표현 방식에 따른 강화학습성능에 미치는 영향을 분석하였다. 첫째로, root attached frame, root aligned frame, projected aligned frame 3가지로 좌표계를 정의하였고, 이에 대해 표현된 상태를 이용하여 강화학습에 미치는 영향을 분석하였다. 둘째로, 상태를 정의 할 때, 관절의 위치, 각도로 다양하게 조합하는 경우에 학습성능에 어떠한 영향을 미치는지 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202105953625631&target=NART&cn=JAKO202105953625631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "상태 표현 방식에 따른 심층 강화 학습 기반 캐릭터 제어기의 학습 성능 비교 상태 표현 방식에 따른 심층 강화 학습 기반 캐릭터 제어기의 학습 성능 비교 상태 표현 방식에 따른 심층 강화 학습 기반 캐릭터 제어기의 학습 성능 비교 물리 시뮬레이션 기반의 캐릭터 동작 제어 문제를 강화학습을 이용하여 해결해나가는 연구들이 계속해서 진행되고 있다. 강화학습을 사용하여 문제를 풀기 위해서는 네트워크 구조, 하이퍼파라미터 튜닝, 상태(state), 행동(action), 보상(reward)이 문제에 맞게 적절히 설정이 되어야 한다. 많은 연구들에서 다양한 조합으로 상태, 행동, 보상을 정의하였고, 성공적으로 문제에 적용하였다. 상태, 행동, 보상을 정의함에 다양한 조합이 있다보니 학습 성능을 향상시키는 최적의 조합을 찾기 위해서 각각의 요소들이 미치는 영향을 분석하는 연구도 진행되고 있다. 우리는 지금까지 이뤄지지 않았던 상태 표현 방식에 따른 강화학습성능에 미치는 영향을 분석하였다. 첫째로, root attached frame, root aligned frame, projected aligned frame 3가지로 좌표계를 정의하였고, 이에 대해 표현된 상태를 이용하여 강화학습에 미치는 영향을 분석하였다. 둘째로, 상태를 정의 할 때, 관절의 위치, 각도로 다양하게 조합하는 경우에 학습성능에 어떠한 영향을 미치는지 분석하였다."
        },
        {
          "rank": 42,
          "score": 0.6495800018310547,
          "doc_id": "NART119879737",
          "title": "Image Enhancement Method Based on Deep Learning",
          "abstract": "<P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119879737&target=NART&cn=NART119879737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning <P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>"
        },
        {
          "rank": 43,
          "score": 0.6487014293670654,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 44,
          "score": 0.646780252456665,
          "doc_id": "NART104701803",
          "title": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go",
          "abstract": "<P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART104701803&target=NART&cn=NART104701803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go <P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>"
        },
        {
          "rank": 45,
          "score": 0.6461646556854248,
          "doc_id": "NART113995599",
          "title": "Deep image enhancement for ill light imaging",
          "abstract": "<P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113995599&target=NART&cn=NART113995599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging <P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>"
        },
        {
          "rank": 46,
          "score": 0.6459976434707642,
          "doc_id": "ART003179947",
          "title": "Enhancing architectural space layout design by pretraining deep reinforcement learning agents",
          "abstract": "Space layout design is a fundamental yet complex problem in architecture. This task’s inherent complexity, arising from the need to balance numerous geometric configurations and topological relations while adhering to specific constraints, poses significant challenges. Recent advancements in deep reinforcement learning have shown promise in addressing similar planning problems, suggesting its potential utility for innovative space layout solutions. However, a critical limitation of deep reinforcement learning is its struggle with generalizing learned strategies to unseen scenarios. In the context of architectural design, this limitation could prevent deep reinforcement learning from being a scalable design method. Pretraining has emerged as a transformative strategy within the field of artificial intelligence, especially in the realm of foundational models, to enhance the generalization capabilities of learning algorithms. While pretraining is being the central focus of this paper, our approach diverges from conventional pretraining methods that focus on pixel-level design of layouts as is in diffusion based model. Instead, we propose an architectural simulation of space layout design that could embody the multifaceted essence of architectural design. To this end, we have developed a space layout simulator called SpaceLayoutGym that serves dual purposes: first, as an environment for the reinforcement learning agent to interact with and learn the intricacies of design, and second, as a tool for generating a dataset of design scenarios and their corresponding design solutions for model pretraining. We then used imitation learning to pretrain the agent on the generated training design scenarios. This process is being followed by a fine-tuning phase by using proximal policy optimization algorithm on new design scenarios. Our results demonstrate that pretraining can enhance the generalization capabilities of deep reinforcement learning in space layout design, paving the way for more adaptable and scalable artificial intelligence-aided architectural design.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003179947&target=NART&cn=ART003179947",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancing architectural space layout design by pretraining deep reinforcement learning agents Enhancing architectural space layout design by pretraining deep reinforcement learning agents Enhancing architectural space layout design by pretraining deep reinforcement learning agents Space layout design is a fundamental yet complex problem in architecture. This task’s inherent complexity, arising from the need to balance numerous geometric configurations and topological relations while adhering to specific constraints, poses significant challenges. Recent advancements in deep reinforcement learning have shown promise in addressing similar planning problems, suggesting its potential utility for innovative space layout solutions. However, a critical limitation of deep reinforcement learning is its struggle with generalizing learned strategies to unseen scenarios. In the context of architectural design, this limitation could prevent deep reinforcement learning from being a scalable design method. Pretraining has emerged as a transformative strategy within the field of artificial intelligence, especially in the realm of foundational models, to enhance the generalization capabilities of learning algorithms. While pretraining is being the central focus of this paper, our approach diverges from conventional pretraining methods that focus on pixel-level design of layouts as is in diffusion based model. Instead, we propose an architectural simulation of space layout design that could embody the multifaceted essence of architectural design. To this end, we have developed a space layout simulator called SpaceLayoutGym that serves dual purposes: first, as an environment for the reinforcement learning agent to interact with and learn the intricacies of design, and second, as a tool for generating a dataset of design scenarios and their corresponding design solutions for model pretraining. We then used imitation learning to pretrain the agent on the generated training design scenarios. This process is being followed by a fine-tuning phase by using proximal policy optimization algorithm on new design scenarios. Our results demonstrate that pretraining can enhance the generalization capabilities of deep reinforcement learning in space layout design, paving the way for more adaptable and scalable artificial intelligence-aided architectural design."
        },
        {
          "rank": 47,
          "score": 0.644768238067627,
          "doc_id": "JAKO202221359246132",
          "title": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정",
          "abstract": "영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202221359246132&target=NART&cn=JAKO202221359246132",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다."
        },
        {
          "rank": 48,
          "score": 0.6442433595657349,
          "doc_id": "JAKO202131452818717",
          "title": "강화학습 에이전트 시야 정보 차이에 의한 학습 성능 비교",
          "abstract": "인공지능 스스로가 자신을 발전시켜 최적의 문제 해결 방법을 찾는 강화학습은 여러 분야에서 활용 가치가 높은 기술이다. 특히 게임 분야는 강화학습 인공지능에 문제 해결을 위한 가상환경을 제공할 수 있다는 장점이 있으며 강화학습 에이전트는 주어진 환경에 대한 정보인 관측변수를 사용하여 자신의 상황과 환경에 대한 정보를 파악하여 환경에 대한 문제를 해결한다. 본 실험에서는 롤플레잉 게임의 인스턴트 던전 환경을 간략화하여 제작하고 에이전트에게 관측변수 중 시야에 관련된 관측변수를 다양하게 설정하였다. 실험 결과 각 설정된 변수들이 학습속도에 얼마나 영향을 주는지를 파악할 수 있었고, 이러한 결과는 롤플레잉 게임 강화학습 연구에 참고할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202131452818717&target=NART&cn=JAKO202131452818717",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "강화학습 에이전트 시야 정보 차이에 의한 학습 성능 비교 강화학습 에이전트 시야 정보 차이에 의한 학습 성능 비교 강화학습 에이전트 시야 정보 차이에 의한 학습 성능 비교 인공지능 스스로가 자신을 발전시켜 최적의 문제 해결 방법을 찾는 강화학습은 여러 분야에서 활용 가치가 높은 기술이다. 특히 게임 분야는 강화학습 인공지능에 문제 해결을 위한 가상환경을 제공할 수 있다는 장점이 있으며 강화학습 에이전트는 주어진 환경에 대한 정보인 관측변수를 사용하여 자신의 상황과 환경에 대한 정보를 파악하여 환경에 대한 문제를 해결한다. 본 실험에서는 롤플레잉 게임의 인스턴트 던전 환경을 간략화하여 제작하고 에이전트에게 관측변수 중 시야에 관련된 관측변수를 다양하게 설정하였다. 실험 결과 각 설정된 변수들이 학습속도에 얼마나 영향을 주는지를 파악할 수 있었고, 이러한 결과는 롤플레잉 게임 강화학습 연구에 참고할 수 있다."
        },
        {
          "rank": 49,
          "score": 0.6420571804046631,
          "doc_id": "ART003167534",
          "title": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior",
          "abstract": "Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003167534&target=NART&cn=ART003167534",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Unsupervised deep learning method for single image super-resolution of the thick pinhole imaging system using deep image prior Thick pinhole imaging system is widely used for diagnosing intense pulsed radiation sources. However, owing to the trade-off among spatial resolution, field of view (FOV) and signal-to-noise ratio (SNR), the imaging system normally falls short in achieving high-precision spatial diagnosis. In this paper, we propose an unsupervised deep learning method for single image super-resolution (SISR) of the thick pinhole imaging system. The point spread function (PSF) of the imaging system is obtained by analytical calculation and Monte Carlo simulation methods, and the mathematical model of the imaging system is established using a linear equation. To solve the ill-posed inverse problem, we adopt randomly initialized deep convolutional neural networks (DCNNs) as an image prior without pre-training, which is named deep image prior (DIP). The results demonstrate that, by utilizing the SISR technique to increase the number of pixels in reconstructed images, the proposed DIP algorithm can mitigate the spatial resolution degradation caused by an insufficient spatial sampling frequency of the camera. Compared with various classical algorithms, the proposed DIP algorithm exhibits superior capabilities in recovering highfrequency signals and suppressing ringing artifacts. Furthermore, the convergence and robustness of the proposed DIP algorithm under different random seeds and SNR conditions are also verified."
        },
        {
          "rank": 50,
          "score": 0.6417996883392334,
          "doc_id": "JAKO202513936004376",
          "title": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구",
          "abstract": "본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202513936004376&target=NART&cn=JAKO202513936004376",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 딥러닝 기반 공동주택 외벽 균열 탐지 정확도 향상에 대한 연구 본 연구는 딥러닝 기술을 활용하여 공동주택 외벽의 균열 탐지를 효과적으로 하기 위한 다양한 데이터 전처리 방법을 비교 분석하였다. 특히, 표준 균열 데이터셋에 일반적으로 나타나지 않는 오탐균열을 식별하는 데 중점을 두고 있다. 이 연구는 탐지 정확도를 최적화하기 위해 여러 이미지 전처리 기법을 적용한 결과를 비교한다. 객체 탐지를 위한 엣지 필터링과 RGB 색 필터 등을 이용한 색상 정규화를 결합한 방법을 집중적으로 검증하였다. 이러한 기술들은 실제 균열과 오탐균열을 구분하기 위해 적용되었으며, 이들의 탐지 성능에 미치는 영향을 철저히 조사하였다. 효율적인 균열 탐지 모델을 찾기 위해 EfficientNet V2s 기반 모델을 적용하였다. RGB, YUV, LAB, HSV 네 가지 이미지 필터가 원본 이미지와 CLAHE 정규화된 이미지에 적용되었는데, 그 결과 단색 콘크리트 균열 탐지에 효과적인 전통적인 정규화 방법이 공동주택 외벽 균열 탐지에는 제한적인 효과를 보인다는 것을 확인하였다. 또한, 단일 색 필터의 적용이 일관된 탐지 결과 개선 효과를 주지 않는다는 것을 밝혔다. 결국, 본 연구를 통해 다양한 이미지 정규화와 색 필터 조합의 균열 탐지 성능을 검증하였으며, 실제 균열과 오탐균열을 구분하는 탐지 성능 향상을 위해 추가적으로 다양한 접근의 연구가 필요하다는 것을 확인하였다."
        }
      ]
    },
    {
      "query": "What are the weaknesses of deep reinforcement learning for complex image analysis?",
      "query_meta": {
        "type": "single_hop",
        "index": 3
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7646243572235107,
          "doc_id": "ART002574280",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002574280&target=NART&cn=ART002574280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 2,
          "score": 0.7646243572235107,
          "doc_id": "JAKO202009863559871",
          "title": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis",
          "abstract": "The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202009863559871&target=NART&cn=JAKO202009863559871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information."
        },
        {
          "rank": 3,
          "score": 0.7175889015197754,
          "doc_id": "NART105497078",
          "title": "Deep Reinforcement Learning for Image Hashing",
          "abstract": "<P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART105497078&target=NART&cn=NART105497078",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing Deep Reinforcement Learning for Image Hashing <P>Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new <I>Deep Reinforcement Learning approach for Image Hashing (DRLIH)</I>. Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the <I>first</I> work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a <B>deep reinforcement learning hashing network</B>. In the proposed network, we utilize recurrent neural network (RNN) as <I>agents</I> to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions&#x2019; error into account. (2) We propose a <B>sequential learning strategy</B> based on proposed DRLIH. We define the state as a tuple of internal features of RNN&#x0027;s hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.</P>"
        },
        {
          "rank": 4,
          "score": 0.6823277473449707,
          "doc_id": "NART118990104",
          "title": "Hierarchical Image Object Search Based on Deep Reinforcement Learning",
          "abstract": "<P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118990104&target=NART&cn=NART118990104",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning Hierarchical Image Object Search Based on Deep Reinforcement Learning <P><B>Abstract</B></P><P>Object detection technology occupies a pivotal position in the field of modern computer vision research, its purpose is to accurately locate the object human beings are looking for in the image and classify the object. With the development of deep learning technology, convolutional neural networks are widely used because of their outstanding performance in feature extraction, which greatly improves the speed and accuracy of object detection. In recent years, reinforcement learning technology has emerged in the field of artificial intelligence, showing excellent decision-making ability to deal with problems. In order to combine the perception ability of deep learning technology with the decision-making ability of reinforcement learning technology, this paper incorporate reinforcement learning into the convolutional neural network, and propose a hierarchical deep reinforcement learning object detection model.</P>"
        },
        {
          "rank": 5,
          "score": 0.6759548187255859,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 6,
          "score": 0.6733357906341553,
          "doc_id": "JAKO202210351407855",
          "title": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적",
          "abstract": "Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202210351407855&target=NART&cn=JAKO202210351407855",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 심층 강화학습을 이용한 디지털트윈 및 시각적 객체 추적 Nowadays, the complexity of object tracking models among hardware applications has become a more in-demand duty to complete in various indeterminable environment tracking situations with multifunctional algorithm skills. In this paper, we propose a virtual city environment using AirSim (Aerial Informatics and Robotics Simulation - AirSim, CityEnvironment) and use the DQN (Deep Q-Learning) model of deep reinforcement learning model in the virtual environment. The proposed object tracking DQN network observes the environment using a deep reinforcement learning model that receives continuous images taken by a virtual environment simulation system as input to control the operation of a virtual drone. The deep reinforcement learning model is pre-trained using various existing continuous image sets. Since the existing various continuous image sets are image data of real environments and objects, it is implemented in 3D to track virtual environments and moving objects in them."
        },
        {
          "rank": 7,
          "score": 0.6719557046890259,
          "doc_id": "JAKO202218262151224",
          "title": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석",
          "abstract": "생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202218262151224&target=NART&cn=JAKO202218262151224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 딥러닝 기반 단일 이미지 생성적 적대 신경망 기법 비교 분석 생성적 적대 신경망(GAN, Generative Adversarial Networks)는 이미지 생성 분야에서 주목할 만한 발전을 이루었다. 하지만 큰 데이터 셋에서 불안정한 모습을 보인다는 한계 때문에 다양한 응용 분야에 쉽게 적용하기 어렵다. 단일 이미지 생성적 적대 신경망은 한장의 이미지의 내부 분포를 잘 학습하여 다양한 영상을 생성하는 분야이다. 큰 데이터셋이 아닌 단 한장만 학습함으로써 안정적인 학습이 가능하며 이미지 리타겟팅, 이미지 조작, super resolution 등 다양한 분야에 활용 가능하다. 본 논문에서는 SinGAN, ConSinGAN, InGAN, DeepSIM, 그리고 One-Shot GAN 총 다섯 개의 단일 이미지 생성적 적대 신경망을 살펴본다. 우리는 각각의 단일 이미지 생성적 적대 신경망 모델들의 성능을 비교하고 장단점을 분석한다."
        },
        {
          "rank": 8,
          "score": 0.6706396341323853,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 9,
          "score": 0.6677944660186768,
          "doc_id": "JAKO201962652079504",
          "title": "심층 강화학습 기술 동향",
          "abstract": "Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201962652079504&target=NART&cn=JAKO201962652079504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기술 동향 심층 강화학습 기술 동향 심층 강화학습 기술 동향 Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions."
        },
        {
          "rank": 10,
          "score": 0.6645512580871582,
          "doc_id": "NART95036368",
          "title": "Deep Reinforcement Learning in Medicine",
          "abstract": "<P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95036368&target=NART&cn=NART95036368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine <P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>"
        },
        {
          "rank": 11,
          "score": 0.6573201417922974,
          "doc_id": "JAKO202106153187643",
          "title": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론",
          "abstract": "빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153187643&target=NART&cn=JAKO202106153187643",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 이질적 이미지의 딥러닝 분석을 위한 적대적 학습기반 이미지 보정 방법론 빅데이터 시대의 도래는 데이터에서 스스로 규칙을 배우는 딥러닝의 비약적인 발전을 가능하게 하였으며, 특히 CNN 알고리즘이 거둔 성과는 모델의 구조를 넘어 소스 데이터 자체를 조정하는 수준에 이르렀다. 하지만 기존의 이미지 처리 방법은 이미지 데이터 자체를 다룰 뿐, 해당 이미지가 생성된 이질적 환경을 충분히 고려하지 않았다. 이질적 환경에서 촬영된 이미지는 동일한 정보임에도 촬영 환경에 따라 각 이미지의 특징(Feature)이 상이하게 표현될 수 있다. 이는 각 이미지가 갖는 상이한 환경 정보뿐 아니라 이미지 고유의 정보조차 서로 상이한 특징으로 표현되며, 이로 인해 이들 이미지 정보는 서로 잡음(Noise)으로 작용해 모델의 분석 성능을 저해할 수 있음을 의미한다. 따라서 본 논문은 이질적 환경에서 생성된 이미지 데이터들을 동시에 사용하는 앤드-투-앤드(End-To-End) 구조의 적대적 학습(Adversarial Learning) 기반의 이미지 색 항상성 모델 성능 향상 방안을 제안한다. 구체적으로 제안 방법론은 이미지가 촬영된 환경인 도메인을 예측하는 '도메인 분류기'와 조명 값을 예측하는 '조명 예측기'의 상호 작용으로 동작하며, 도메인 분류의 성능을 떨어뜨리는 방향의 학습을 통해 도메인 특성을 제거한다. 제안 방법론의 성능을 평가하기 위해 이질적 환경에서 촬영된 이미지 데이터 셋 7,022장에 대한 색 항상성 실험을 수행한 결과, 제안 방법론이 기존 방법론에 비해 Angular Error 측면에서 우수한 성능을 나타냄을 확인하였다."
        },
        {
          "rank": 12,
          "score": 0.6572678089141846,
          "doc_id": "ART002367528",
          "title": "Recognition of Human Motion with Deep Reinforcement Learning",
          "abstract": "Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002367528&target=NART&cn=ART002367528",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Recognition of Human Motion with Deep Reinforcement Learning Human–computer interaction (HCI) has become an important research area for improving the user experience on Internet of Things (IoT) devices. In particular, gesture recognition and dailyactivity recognition have attracted the interest of numerous researchers. Human motions have been predicted by analyzing accelerometer data from which features were extracted to be classified into a specific activity. However, due to the memory limitations of IoT devices, it is hard to utilize all the raw data from an accelerometer sensor. This paper proposes a deep reinforcement learning algorithm to recognize human arm movements using a commercial wearable device, the Myo armband. Agents learn the patterns that are the acceleration data of human motion. In addition, using raw accelerometer sensor data without feature extraction could make an end-to-end structure.In order to demonstrate the performance of the proposed method, a deep neural network (DNN) and a deep reinforcement learning algorithm are compared. As a result, a deep reinforcement learning agent yielded accuracy similar to a DNN using less data, and the agent could learn time-series human motion acceleration data."
        },
        {
          "rank": 13,
          "score": 0.6558784246444702,
          "doc_id": "NART121556950",
          "title": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement",
          "abstract": "<P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121556950&target=NART&cn=NART121556950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement Integrating deep learning and traditional image enhancement techniques for underwater image enhancement <P><B>Abstract</B><P>Underwater images usually suffer from colour distortion, blur, and low contrast, which hinder the subsequent processing of underwater information. To address these problems, this paper proposes a novel approach for single underwater images enhancement by integrating data&#x2010;driven deep learning and hand&#x2010;crafted image enhancement techniques. First, a statistical analysis is made on the average deviation of each channel of input underwater images to that of its corresponding ground truths, and it is found that both the red channel and the green channel of an underwater image contribute to its colour distortion. Concretely, the red channel of an underwater image is usually seriously attenuated, and the green channel is usually over strengthened. Motivated by such an observation, an attention mechanism guided residual module for underwater image colour correction is proposed, where the colour of the red channel of the underwater image and that of the green channel is compensated in a different way, respectively. Coupled with an attention mechanism, the residual module can adaptively extract and integrate the most discriminative features for colour correction. For scene contrast enhancement and scene deblurring, the traditional image enhancement techniques such as CLAHE (contrast limited adaptive histogram equalization) and Gamma correction are coupled with a multi&#x2010;scale convolutional neural network (MSCNN), where CLAHE and Gamma correction are used as complement to deal with the complex and changeable underwater imaging environment. Experiments on synthetic and real underwater images demonstrate that the proposed method performs favourably against the state&#x2010;of&#x2010;the&#x2010;art underwater image enhancement methods.</P></P>"
        },
        {
          "rank": 14,
          "score": 0.6517975330352783,
          "doc_id": "ART003179947",
          "title": "Enhancing architectural space layout design by pretraining deep reinforcement learning agents",
          "abstract": "Space layout design is a fundamental yet complex problem in architecture. This task’s inherent complexity, arising from the need to balance numerous geometric configurations and topological relations while adhering to specific constraints, poses significant challenges. Recent advancements in deep reinforcement learning have shown promise in addressing similar planning problems, suggesting its potential utility for innovative space layout solutions. However, a critical limitation of deep reinforcement learning is its struggle with generalizing learned strategies to unseen scenarios. In the context of architectural design, this limitation could prevent deep reinforcement learning from being a scalable design method. Pretraining has emerged as a transformative strategy within the field of artificial intelligence, especially in the realm of foundational models, to enhance the generalization capabilities of learning algorithms. While pretraining is being the central focus of this paper, our approach diverges from conventional pretraining methods that focus on pixel-level design of layouts as is in diffusion based model. Instead, we propose an architectural simulation of space layout design that could embody the multifaceted essence of architectural design. To this end, we have developed a space layout simulator called SpaceLayoutGym that serves dual purposes: first, as an environment for the reinforcement learning agent to interact with and learn the intricacies of design, and second, as a tool for generating a dataset of design scenarios and their corresponding design solutions for model pretraining. We then used imitation learning to pretrain the agent on the generated training design scenarios. This process is being followed by a fine-tuning phase by using proximal policy optimization algorithm on new design scenarios. Our results demonstrate that pretraining can enhance the generalization capabilities of deep reinforcement learning in space layout design, paving the way for more adaptable and scalable artificial intelligence-aided architectural design.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003179947&target=NART&cn=ART003179947",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancing architectural space layout design by pretraining deep reinforcement learning agents Enhancing architectural space layout design by pretraining deep reinforcement learning agents Enhancing architectural space layout design by pretraining deep reinforcement learning agents Space layout design is a fundamental yet complex problem in architecture. This task’s inherent complexity, arising from the need to balance numerous geometric configurations and topological relations while adhering to specific constraints, poses significant challenges. Recent advancements in deep reinforcement learning have shown promise in addressing similar planning problems, suggesting its potential utility for innovative space layout solutions. However, a critical limitation of deep reinforcement learning is its struggle with generalizing learned strategies to unseen scenarios. In the context of architectural design, this limitation could prevent deep reinforcement learning from being a scalable design method. Pretraining has emerged as a transformative strategy within the field of artificial intelligence, especially in the realm of foundational models, to enhance the generalization capabilities of learning algorithms. While pretraining is being the central focus of this paper, our approach diverges from conventional pretraining methods that focus on pixel-level design of layouts as is in diffusion based model. Instead, we propose an architectural simulation of space layout design that could embody the multifaceted essence of architectural design. To this end, we have developed a space layout simulator called SpaceLayoutGym that serves dual purposes: first, as an environment for the reinforcement learning agent to interact with and learn the intricacies of design, and second, as a tool for generating a dataset of design scenarios and their corresponding design solutions for model pretraining. We then used imitation learning to pretrain the agent on the generated training design scenarios. This process is being followed by a fine-tuning phase by using proximal policy optimization algorithm on new design scenarios. Our results demonstrate that pretraining can enhance the generalization capabilities of deep reinforcement learning in space layout design, paving the way for more adaptable and scalable artificial intelligence-aided architectural design."
        },
        {
          "rank": 15,
          "score": 0.6499161720275879,
          "doc_id": "NART113995599",
          "title": "Deep image enhancement for ill light imaging",
          "abstract": "<P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113995599&target=NART&cn=NART113995599",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging Deep image enhancement for ill light imaging <P>Imaging in the natural scene under ill lighting conditions (e.g., low light, back-lit, over-exposed front-lit, and any combinations of them) suffers from both over- and under-exposure at the same time, whereas processing of such images often results in over- and under-enhancement. A single small image sensor can hardly provide satisfactory quality for ill lighting conditions with ordinary optical lenses in capturing devices. Challenges arise in the maintenance of a visual smoothness between those regions, while color and contrast should be well preserved. The problem has been approached by various methods, including multiple sensors and handcrafted parameters, but extant model capacity is limited to only some specific scenes (i.e., lighting conditions). Motivated by these challenges, in this paper, we propose a deep image enhancement method for color images captured under ill lighting conditions. In this method, input images are first decomposed into reflection and illumination maps with the proposed <I>layer distribution loss net</I>, where the illumination blindness and structure degradation problem can be subsequently solved via these two components, respectively. The hidden degradation in reflection and illumination is tuned with a knowledge-based adaptive enhancement constraint designed for ill illuminated images. The model can maintain a balance of smoothness and contribute to solving the problem of noise besides over- and under-enhancement. The local consistency in illumination is achieved via a repairing operation performed in the proposed <I>Repair-Net</I>. The total variation operator is optimized to acquire local consistency, and the image gradient is guided with the proposed enhancement constraint. Finally, a product of updated reflection and illumination maps reconstructs an enhanced image. Experiments are organized under both very low exposure and ill illumination conditions, where a new dataset is also proposed. Results on both experiments show that our method has superior performance in preserving structural and textural details compared to other states of the art, which suggests that our method is more practical in future visual applications.</P>"
        },
        {
          "rank": 16,
          "score": 0.6427849531173706,
          "doc_id": "NART136112293",
          "title": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning",
          "abstract": "<P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART136112293&target=NART&cn=NART136112293",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning Enhancement of Image Quality in Low-Field Knee MR Imaging Using Deep Learning <P>Purpose:&nbsp;The purpose of this study is to investigate the potential of deep learning (DL) techniques to enhance the image quality of low-field knee MR images, with the ultimate goal of approximating the standards of&nbsp;high-field knee MR imaging.</P><P>Methods: We analyzed knee MR images collected from 45 patients with knee disorders and six normal subjects using a 3T MR scanner&nbsp;and those collected from 25 patients with knee disorders using a 0.4T MR scanner. Two DL models were developed: a fat-suppression contrast-generation model and a super-resolution model. These DL models were trained using 3T knee MR imaging data and applied to 0.4T knee MR imaging data. Visual assessments of anatomical structures and image noise and abnormality detection with diagnostic confidence levels on the original 0.4T MR images and those after&nbsp;DL enhancement were conducted by two board-certified radiologists. Statistical analyses were performed using McNemar&rsquo;s test and the Wilcoxon signed-rank test.</P><P>Results:&nbsp;DL-enhanced MR images significantly improved the depiction of anatomical structures and reduced image noise compared to the original MR images. The number of abnormal findings detected and the diagnostic confidence levels were higher in the DL-enhanced MR images, indicating the potential for more accurate diagnoses.</P><P>Conclusion: DL techniques effectively enhance the image quality of low-field knee MR images by leveraging 3T MR imaging data. This enhancement significantly improves image quality and diagnostic confidence levels, making low-field MR images much more reliable for detecting abnormalities. This advancement offers a useful alternative for clinical settings, especially in resource-limited environments, without compromising diagnostic accuracy.</P>"
        },
        {
          "rank": 17,
          "score": 0.6407240629196167,
          "doc_id": "JAKO202313933270962",
          "title": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석",
          "abstract": "Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202313933270962&target=NART&cn=JAKO202313933270962",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 딥 러닝 기반 이미지 압축 기법의 성능 비교 분석 Image compression is a fundamental technique in the field of digital image processing, which will help to decrease the storage space and to transmit the files efficiently. Recently many deep learning techniques have been proposed to promise results on image compression field. Since many image compression techniques have artifact problems, this paper has compared two deep learning approaches to verify their performance experimentally to solve the problems. One of the approaches is a deep autoencoder technique, and another is a deep convolutional neural network (CNN). For those results in the performance of peak signal-to-noise and root mean square error, this paper shows that deep autoencoder method has more advantages than deep CNN approach."
        },
        {
          "rank": 18,
          "score": 0.6405643224716187,
          "doc_id": "NART96288640",
          "title": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms",
          "abstract": "<P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96288640&target=NART&cn=NART96288640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms Open Source Robotic Simulators Platforms for Teaching Deep Reinforcement Learning Algorithms <P><B>Abstract</B></P>  <P>One of the primary goals of the artificial intelligence field is to produce fully autonomous agents that interact with theirenvironments to learn optimal behaviors, improving over time through trial and error. A mathematical principled framework for experience-driven autonomous learning is reinforcement learning, but they are inherently limited to low-dimensional problems,but the deep learning boom has provided new tools to overcome these problems. For deep reinforcement learning teaching, we do not have an appropriate platform for making optimal labs. In the article, after studying the theoretical foundations and the requirements of the main platforms, we selected two open source platforms, according to their characteristics: robotic simulators platforms for teaching and benchmarking deep reinforcement learning algorithms. The first platform was <I>Gym and V-REP</I> and the second one, <I>KNIME Deeplearning4J Integration supports and Teaching-Box.</I> </P>"
        },
        {
          "rank": 19,
          "score": 0.6402724981307983,
          "doc_id": "NART101975410",
          "title": "Learning Mobile Manipulation through Deep Reinforcement Learning",
          "abstract": "<P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART101975410&target=NART&cn=NART101975410",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning Learning Mobile Manipulation through Deep Reinforcement Learning <P>Mobile manipulation has a broad range of applications in robotics. However, it is usually more challenging than fixed-base manipulation due to the complex coordination of a mobile base and a manipulator. Although recent works have demonstrated that deep reinforcement learning is a powerful technique for fixed-base manipulation tasks, most of them are not applicable to mobile manipulation. This paper investigates how to leverage deep reinforcement learning to tackle whole-body mobile manipulation tasks in unstructured environments using only on-board sensors. A novel mobile manipulation system which integrates the state-of-the-art deep reinforcement learning algorithms with visual perception is proposed. It has an efficient framework decoupling visual perception from the deep reinforcement learning control, which enables its generalization from simulation training to real-world testing. Extensive simulation and experiment results show that the proposed mobile manipulation system is able to grasp different types of objects autonomously in various simulation and real-world scenarios, verifying the effectiveness of the proposed mobile manipulation system.</P>"
        },
        {
          "rank": 20,
          "score": 0.6399069428443909,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 21,
          "score": 0.6372041702270508,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 22,
          "score": 0.6370664238929749,
          "doc_id": "JAKO202226461575702",
          "title": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰",
          "abstract": "Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202226461575702&target=NART&cn=JAKO202226461575702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 의료영상 분야를 위한 설명가능한 인공지능 기술 리뷰 Artificial intelligence (AI) has been studied in various fields of medical imaging. Currently, top-notch deep learning (DL) techniques have led to high diagnostic accuracy and fast computation. However, they are rarely used in real clinical practices because of a lack of reliability concerning their results. Most DL models can achieve high performance by extracting features from large volumes of data. However, increasing model complexity and nonlinearity turn such models into black boxes that are seldom accessible, interpretable, and transparent. As a result, scientific interest in the field of explainable artificial intelligence (XAI) is gradually emerging. This study aims to review diverse XAI approaches currently exploited in medical imaging. We identify the concepts of the methods, introduce studies applying them to imaging modalities such as computational tomography (CT), magnetic resonance imaging (MRI), and endoscopy, and lastly discuss limitations and challenges faced by XAI for future studies."
        },
        {
          "rank": 23,
          "score": 0.6365456581115723,
          "doc_id": "JAKO202320150299733",
          "title": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가",
          "abstract": "본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202320150299733&target=NART&cn=JAKO202320150299733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 RapidEye 위성영상과 Semantic Segmentation 기반 딥러닝 모델을 이용한 토지피복분류의 정확도 평가 본 연구는 딥러닝 모델(deep learning model)을 활용하여 토지피복분류를 수행하였으며 입력 이미지의 크기, Stride 적용 등 데이터세트(dataset)의 조절을 통해 토지피복분류를 위한 최적의 딥러닝 모델 선정을 목적으로 하였다. 적용한 딥러닝 모델은 3종류로 Encoder-Decoder 구조를 가진 U-net과 DeeplabV3+, 두 가지 모델을 결합한 앙상블(Ensemble) 모델을 활용하였다. 데이터세트는 RapidEye 위성영상을 입력영상으로, 라벨(label) 이미지는 Intergovernmental Panel on Climate Change 토지이용의 6가지 범주에 따라 구축한 Raster 이미지를 참값으로 활용하였다. 딥러닝 모델의 정확도 향상을 위해 데이터세트의 질적 향상 문제에 대해 주목하였으며 딥러닝 모델(U-net, DeeplabV3+, Ensemble), 입력 이미지 크기(64 &#x00D7; 64 pixel, 256 &#x00D7; 256 pixel), Stride 적용(50%, 100%) 조합을 통해 12가지 토지피복도를 구축하였다. 라벨 이미지와 딥러닝 모델 기반의 토지피복도의 정합성 평가결과, U-net과 DeeplabV3+ 모델의 전체 정확도는 각각 최대 약 87.9%와 89.8%, kappa 계수는 모두 약 72% 이상으로 높은 정확도를 보였으며, 64 &#x00D7; 64 pixel 크기의 데이터세트를 활용한 U-net 모델의 정확도가 가장 높았다. 또한 딥러닝 모델에 앙상블 및 Stride를 적용한 결과, 최대 약 3% 정확도가 상승하였으며 Semantic Segmentation 기반 딥러닝 모델의 단점인 경계간의 불일치가 개선됨을 확인하였다."
        },
        {
          "rank": 24,
          "score": 0.6351912021636963,
          "doc_id": "JAKO202318443290723",
          "title": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구",
          "abstract": "오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202318443290723&target=NART&cn=JAKO202318443290723",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 딥 러닝 기반의 전이 학습을 이용한 이미지 분류에 관한 연구 오래전부터 연구자들은 CBIR에 대한 많은 연구로 인해 이미지 검색 분야에 우수한 결과를 제시하였다. 그러나 이미지에 대한 이러한 검색 결과와 사람이 인식하는 결과 사이에 의미적 격차는 여전히 존재한다. 적은 수의 이미지를 사용하여 사람이 인식하는 수준의 이미지를 분류하는 것은 아직까지 어려운 문제이다. 따라서 본 논문은 이미지 검색에서 사람과 검색 시스템의 이미지의 의미적 격차를 최소화하기 위해 딥 러닝 기반의 전이 학습을 이용한 이미지 분류 모델을 제안한다. 실험 결과, 학습 모델의 손실률은 0.2451%, 정확도는 0.8922%로 제안한 이미지 분류 방법의 구현은 원하는 목표를 달성할 수 있었다. 그리고 딥 러닝에서 CNN의 전이 학습 모델 방법이 새로운 데이터를 추가하여 이미지 데이터베이스를 구축하는데 효과적인 결과를 확인할 수 있었다."
        },
        {
          "rank": 25,
          "score": 0.6343665719032288,
          "doc_id": "JAKO202109835990951",
          "title": "분해 심층 학습을 이용한 저조도 영상 개선 방식",
          "abstract": "본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109835990951&target=NART&cn=JAKO202109835990951",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 분해 심층 학습을 이용한 저조도 영상 개선 방식 본 논문에서는 저조도 영상을 개선하기 위한 영상 분해 기반 심층 학습 방법 및 분해 채널 특성에 따른 손실함수를 제안한다. 기존 기법들의 문제점인 색신호 왜곡 및 할로 현상을 제거하기 위해, 입력 영상의 휘도 채널을 반사 성분과 조도 성분으로 분해하고, 반사 성분, 조도 성분 및 색차 신호를 신호 특성에 적합한 심층학습 과정을 적용하는 분해 기반 다중 구조 심층 학습 방법을 제안한다. 더불어, 분해 채널들의 특성에 따른 혼합 놈 기반의 손실함수를 정의하여 복원 영상의 안정성을 증대하고 열화 현상을 제거하기 위한 기법에 대해 기술한다. 실험 결과를 통해 제안한 방법이 다양한 저조도 영상을 효과적으로 개선하였음을 확인할 수 있었다."
        },
        {
          "rank": 26,
          "score": 0.6336593627929688,
          "doc_id": "NART115326214",
          "title": "Deep learning-based single image face depth data enhancement",
          "abstract": "<P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART115326214&target=NART&cn=NART115326214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement Deep learning-based single image face depth data enhancement <P><B>Abstract</B></P>  <P>Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Pure depth image enhancement using deep learning is effective for facial biometrics. </LI> <LI>  Synthesis of realistic low detail face depth enhancer training data is viable. </LI> <LI>  Comparisons with more general enhancers favor the face-specific model. </LI> <LI>  Depth is not overly falsified for non-face input during enhancement. </LI> <LI>  Face depth enhancement can be used to aid real-time presentation attack detection. </LI> </UL> </P>"
        },
        {
          "rank": 27,
          "score": 0.6322338581085205,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 28,
          "score": 0.6319377422332764,
          "doc_id": "NPAP12546494",
          "title": "Deep learning for radar",
          "abstract": "<P>Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12546494&target=NART&cn=NPAP12546494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning for radar Deep learning for radar Deep learning for radar <P>Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem.</P>"
        },
        {
          "rank": 29,
          "score": 0.628369927406311,
          "doc_id": "JAKO201974757494930",
          "title": "심층강화학습 라이브러리 기술동향",
          "abstract": "Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201974757494930&target=NART&cn=JAKO201974757494930",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective."
        },
        {
          "rank": 30,
          "score": 0.6269642114639282,
          "doc_id": "NART126940867",
          "title": "Developments in Image Processing Using Deep Learning and Reinforcement Learning",
          "abstract": "<P>The growth in the volume of data generated, consumed, and stored, which is estimated to exceed 180 zettabytes in 2025, represents a major challenge both for organizations and for society in general. In addition to being larger, datasets are increasingly complex, bringing new theoretical and computational challenges. Alongside this evolution, data science tools have exploded in popularity over the past two decades due to their myriad of applications when dealing with complex data, their high accuracy, flexible customization, and excellent adaptability. When it comes to images, data analysis presents additional challenges because as the quality of an image increases, which is desirable, so does the volume of data to be processed. Although classic machine learning (ML) techniques are still widely used in different research fields and industries, there has been great interest from the scientific community in the development of new artificial intelligence (AI) techniques. The resurgence of neural networks has boosted remarkable advances in areas such as the understanding and processing of images. In this study, we conducted a comprehensive survey regarding advances in AI design and the optimization solutions proposed to deal with image processing challenges. Despite the good results that have been achieved, there are still many challenges to face in this field of study. In this work, we discuss the main and more recent improvements, applications, and developments when targeting image processing applications, and we propose future research directions in this field of constant and fast evolution.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART126940867&target=NART&cn=NART126940867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Developments in Image Processing Using Deep Learning and Reinforcement Learning Developments in Image Processing Using Deep Learning and Reinforcement Learning Developments in Image Processing Using Deep Learning and Reinforcement Learning <P>The growth in the volume of data generated, consumed, and stored, which is estimated to exceed 180 zettabytes in 2025, represents a major challenge both for organizations and for society in general. In addition to being larger, datasets are increasingly complex, bringing new theoretical and computational challenges. Alongside this evolution, data science tools have exploded in popularity over the past two decades due to their myriad of applications when dealing with complex data, their high accuracy, flexible customization, and excellent adaptability. When it comes to images, data analysis presents additional challenges because as the quality of an image increases, which is desirable, so does the volume of data to be processed. Although classic machine learning (ML) techniques are still widely used in different research fields and industries, there has been great interest from the scientific community in the development of new artificial intelligence (AI) techniques. The resurgence of neural networks has boosted remarkable advances in areas such as the understanding and processing of images. In this study, we conducted a comprehensive survey regarding advances in AI design and the optimization solutions proposed to deal with image processing challenges. Despite the good results that have been achieved, there are still many challenges to face in this field of study. In this work, we discuss the main and more recent improvements, applications, and developments when targeting image processing applications, and we propose future research directions in this field of constant and fast evolution.</P>"
        },
        {
          "rank": 31,
          "score": 0.6268795132637024,
          "doc_id": "ART002977356",
          "title": "Deep reinforcement learning based edge computing for video processing",
          "abstract": "In many of 5G applications, end devices with lack of computing power often need to carry out heavy computations involving multimedia data. Edge computing has emerged as a promising solution to circumvent scarce resources at end devices, with moderate delays compared to cloud computing. In this work, we study the problem of offloading video processing tasks to edge servers. To this end, we develop a deep reinforcement learning based method for selecting either local or edge server to process video frames. We demonstrate the performance of our method through experiments with video frame transform tasks.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002977356&target=NART&cn=ART002977356",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep reinforcement learning based edge computing for video processing Deep reinforcement learning based edge computing for video processing Deep reinforcement learning based edge computing for video processing In many of 5G applications, end devices with lack of computing power often need to carry out heavy computations involving multimedia data. Edge computing has emerged as a promising solution to circumvent scarce resources at end devices, with moderate delays compared to cloud computing. In this work, we study the problem of offloading video processing tasks to edge servers. To this end, we develop a deep reinforcement learning based method for selecting either local or edge server to process video frames. We demonstrate the performance of our method through experiments with video frame transform tasks."
        },
        {
          "rank": 32,
          "score": 0.6252005696296692,
          "doc_id": "NART110796699",
          "title": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network",
          "abstract": "<P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110796699&target=NART&cn=NART110796699",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network Inverse synthetic aperture radar imaging using complex&#x2010;value deep neural network <P>As compared with traditional ISAR imaging methods, the compressive sensing (CS)&#x2010;based imaging methods can obtain high&#x2010;quality images using much less under&#x2010;sampled data. However, the availability or appropriateness of the sparse representation of the target scene and the relatively low computational efficiency of image reconstruction algorithms limit the performance and application of the CS&#x2010;based ISAR imaging methods. In recent years, the deep learning technology has been applied in many fields and achieved outstanding performance in image classification, image reconstruction etc. DL implements the tasks using the deep neural network (DNN), which composes multiple hidden layers and non&#x2010;linear activation layer. In this study, a novel ISAR imaging method that uses a complex&#x2010;value deep neural network (CV&#x2010;DNN) to perform the image formation using under&#x2010;sampled data is proposed. The CV&#x2010;DNN architecture can extract and exploit the sparse feature of the target image extremely well by multilayer non&#x2010;linear processing. The experimental results show that the proposed CV&#x2010;DNN&#x2010;based ISAR imaging method can provide better shape reconstruction of target with less data than state&#x2010;of&#x2010;the&#x2010;art CS reconstruction algorithms and improve the imaging efficiency obviously.</P>"
        },
        {
          "rank": 33,
          "score": 0.6249402165412903,
          "doc_id": "DIKO0016950566",
          "title": "심층 강화학습을 활용한 로봇 경로 계획",
          "abstract": "강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016950566&target=NART&cn=DIKO0016950566",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다."
        },
        {
          "rank": 34,
          "score": 0.6240614056587219,
          "doc_id": "NART119629224",
          "title": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging",
          "abstract": "<P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119629224&target=NART&cn=NART119629224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging 65&#x2010;3: <i>Invited Paper:</i> Deep Learning&#x2010;Based Image Enhancement for HDR Imaging <P>High dynamic range (HDR) techniques have received significant attention in generating realistic, high&#x2010;quality images and videos and improving visual quality in new display systems. We have witnessed remarkable advances in HDR reconstruction using deep learning technologies in recent years. This review examines recent developments in HDR reconstruction using a deep learning approach, which takes a single low dynamic range (LDR) image as an input and aims to restore an HDR image featuring higher color gamut and a higher detail retention than the LDR image. We aim to provide a comprehensive survey in this field. Since there are numerous HDR algorithms, it is necessary to evaluate and organize theirperformance, therefore, we evaluate them using two objective evaluation metrics.</P>"
        },
        {
          "rank": 35,
          "score": 0.6235771179199219,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 36,
          "score": 0.6234686374664307,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 37,
          "score": 0.6232369542121887,
          "doc_id": "JAKO202431343317630",
          "title": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능",
          "abstract": "인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202431343317630&target=NART&cn=JAKO202431343317630",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 의료 영상 분석을 위한 설명 가능하고 안전한 인공지능 인공지능(artificial intelligence; 이하 AI)은 진단 정확도와 효율성을 높여 영상의학 분야에 변화를 가져오고 있지만, 예측 불확실성은 여전히 중요한 과제로 남아 있다. 본 리뷰에서는 주요 불확실성의 원인인 분포 외(out-of-distribution) 불확실성, 데이터 내재적 불확실성(aleatoric uncertainty), 모델 불확실성을 다루며, 안전한 AI 통합을 위해 독립적인 신뢰성 지표와 설명 가능한 AI의 중요성을 강조한다. 독립적인 신뢰성 지표는 AI 예측의 신뢰성을 평가하는 데 기여하며, 설명 가능한 AI는 투명성을 제공하여 AI와 영상의학 전문의 간의 협업을 강화한다. 오류 무관용(zero error tolerance) 모델의 개발은 오류를 최소화하도록 설계되어, 안전성의 새로운 기준을 제시하였다. 이러한 문제를 해결함으로써 AI는 영상의학에서 신뢰할 수 있는 동반자로 자리 잡아, 환자 진료 수준과 결과를 개선하는 데 기여할 것이다."
        },
        {
          "rank": 38,
          "score": 0.6228528618812561,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 39,
          "score": 0.6223970651626587,
          "doc_id": "JAKO202221359246132",
          "title": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정",
          "abstract": "영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202221359246132&target=NART&cn=JAKO202221359246132",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 불균일 안개 영상 합성을 이용한 딥러닝 기반 안개 영상 깊이 추정 영상의 깊이 추정은 다양한 영상 분석의 기반이 되는 기술이다. 딥러닝 모델을 활용한 분석 방법이 대두되면서, 영상의 깊이 추정 분야 또한 딥러닝을 활용하는 연구가 활발하게 이루어지고 있다. 현재 대부분의 딥러닝 영상 깊이 추정 모델들은 깨끗하고 이상적인 환경에서 학습되고 있다. 하지만 연무, 안개가 낀 열악한 환경에서도 깊이 추정 기술이 잘 동작할 수 있으려면 이러한 환경의 데이터를 포함하여야 한다. 하지만 열악한 환경의 영상을 충분히 확보하는 것이 어려운 실정이며, 불균일한 안개 데이터를 얻는 것은 특히 어려운 문제이다. 이를 해결하기 위해, 본 연구에서는 불균일 안개 영상 합성 방법과 이를 활용한 단안 기반의 깊이 추정 딥러닝 모델의 학습을 제안한다. 안개가 주로 실외에서 발생하는 것을 고려하여, 실외 위주의 데이터 세트를 구축한다. 그리고 실험을 통해 제안된 방법으로 학습된 모델이 합성 데이터와 실제 데이터에서 깊이를 잘 추정하는 것을 보인다."
        },
        {
          "rank": 40,
          "score": 0.6208468675613403,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 41,
          "score": 0.620460033416748,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 42,
          "score": 0.6199116706848145,
          "doc_id": "ATN0045840152",
          "title": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구",
          "abstract": "현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0045840152&target=NART&cn=ATN0045840152",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다."
        },
        {
          "rank": 43,
          "score": 0.6194534301757812,
          "doc_id": "NART104701803",
          "title": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go",
          "abstract": "<P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART104701803&target=NART&cn=NART104701803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go <P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>"
        },
        {
          "rank": 44,
          "score": 0.6186390519142151,
          "doc_id": "NART119879737",
          "title": "Image Enhancement Method Based on Deep Learning",
          "abstract": "<P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119879737&target=NART&cn=NART119879737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning Image Enhancement Method Based on Deep Learning <P>Image enhancement and reconstruction are the basic processing steps of many real vision systems. Their purpose is to improve the visual quality of images and provide reliable information for subsequent visual decision-making. In this paper, convolution neural network, residual neural network, and generative countermeasure network are studied. A rain fog image enhancement generative countermeasure network model structure including a scalable auxiliary generation network is proposed. The objective loss function is defined, and the periodic consistency loss and periodic perceptual consistency loss analysis are introduced. The core problem of image layering is discussed, and a layering solution framework with a deep expansion structure is proposed. This method realizes multitasking through adaptive feature learning, which has a good theoretical guarantee. This paper can not only bring a pleasant visual experience to viewers but also help to improve the performance of computer vision applications. Through image enhancement technology, the quality of low illumination image can be effectively improved, so that the image has better definition, richer texture details, and lower image noise.</P>"
        },
        {
          "rank": 45,
          "score": 0.6176662445068359,
          "doc_id": "NART84975182",
          "title": "Deep Learning for Passive Synthetic Aperture Radar",
          "abstract": "<P>We introduce a deep learning (DL) framework for inverse problems in imaging, and demonstrate the advantages and applicability of this approach in passive synthetic aperture radar (SAR) image reconstruction. We interpret image reconstruction as a machine learning task and utilize deep networks as forward and inverse solvers for imaging. Specifically, we design a recurrent neural network (RNN) architecture as an inverse solver based on the iterations of proximal gradient descent optimization methods. We further adapt the RNN architecture to image reconstruction problems by transforming the network into a recurrent auto-encoder, thereby allowing for unsupervised training. Our DL based inverse solver is particularly suitable for a class of image formation problems in which the forward model is only partially known. The ability to learn forward models and hyper parameters combined with unsupervised training approach establish our recurrent auto-encoder suitable for real world applications. We demonstrate the performance of our method in passive SAR image reconstruction. In this regime a source of opportunity, with unknown location and transmitted waveform, is used to illuminate a scene of interest. We investigate recurrent auto-encoder architecture based on the <TEX>$\\ell _1$</TEX> and <TEX>$\\ell _0$</TEX> constrained least-squares problem. We present a projected stochastic gradient descent based training scheme which incorporates constraints of the unknown model parameters. We demonstrate through extensive numerical simulations that our DL based approach out performs conventional sparse coding methods in terms of computation and reconstructed image quality, specifically, when no information about the transmitter is available.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART84975182&target=NART&cn=NART84975182",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning for Passive Synthetic Aperture Radar Deep Learning for Passive Synthetic Aperture Radar Deep Learning for Passive Synthetic Aperture Radar <P>We introduce a deep learning (DL) framework for inverse problems in imaging, and demonstrate the advantages and applicability of this approach in passive synthetic aperture radar (SAR) image reconstruction. We interpret image reconstruction as a machine learning task and utilize deep networks as forward and inverse solvers for imaging. Specifically, we design a recurrent neural network (RNN) architecture as an inverse solver based on the iterations of proximal gradient descent optimization methods. We further adapt the RNN architecture to image reconstruction problems by transforming the network into a recurrent auto-encoder, thereby allowing for unsupervised training. Our DL based inverse solver is particularly suitable for a class of image formation problems in which the forward model is only partially known. The ability to learn forward models and hyper parameters combined with unsupervised training approach establish our recurrent auto-encoder suitable for real world applications. We demonstrate the performance of our method in passive SAR image reconstruction. In this regime a source of opportunity, with unknown location and transmitted waveform, is used to illuminate a scene of interest. We investigate recurrent auto-encoder architecture based on the <TEX>$\\ell _1$</TEX> and <TEX>$\\ell _0$</TEX> constrained least-squares problem. We present a projected stochastic gradient descent based training scheme which incorporates constraints of the unknown model parameters. We demonstrate through extensive numerical simulations that our DL based approach out performs conventional sparse coding methods in terms of computation and reconstructed image quality, specifically, when no information about the transmitter is available.</P>"
        },
        {
          "rank": 46,
          "score": 0.6166157722473145,
          "doc_id": "NART116403822",
          "title": "Deep-Learning for Radar: A Survey",
          "abstract": "<P>A comprehensive and well-structured review on the application of deep learning (DL) based algorithms, such as convolutional neural networks (CNN) and long-short term memory (LSTM), in radar signal processing is given. The following DL application areas are covered: i) radar waveform and antenna array design; ii) passive or low probability of interception (LPI) radar waveform recognition; iii) automatic target recognition (ATR) based on high range resolution profiles (HRRPs), Doppler signatures, and synthetic aperture radar (SAR) images; and iv) radar jamming/clutter recognition and suppression. Although DL is unanimously praised as the ultimate solution to many bottleneck problems in most of existing works on similar topics, both the positive and the negative sides of stories about DL are checked in this work. Specifically, two limiting factors of the real-life performance of deep neural networks (DNNs), limited training samples and adversarial examples, are thoroughly examined. By investigating the relationship between the DL-based algorithms proposed in various papers and linking them together to form a full picture, this work serves as a valuable source for researchers who are seeking potential research opportunities in this promising research field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART116403822&target=NART&cn=NART116403822",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep-Learning for Radar: A Survey Deep-Learning for Radar: A Survey Deep-Learning for Radar: A Survey <P>A comprehensive and well-structured review on the application of deep learning (DL) based algorithms, such as convolutional neural networks (CNN) and long-short term memory (LSTM), in radar signal processing is given. The following DL application areas are covered: i) radar waveform and antenna array design; ii) passive or low probability of interception (LPI) radar waveform recognition; iii) automatic target recognition (ATR) based on high range resolution profiles (HRRPs), Doppler signatures, and synthetic aperture radar (SAR) images; and iv) radar jamming/clutter recognition and suppression. Although DL is unanimously praised as the ultimate solution to many bottleneck problems in most of existing works on similar topics, both the positive and the negative sides of stories about DL are checked in this work. Specifically, two limiting factors of the real-life performance of deep neural networks (DNNs), limited training samples and adversarial examples, are thoroughly examined. By investigating the relationship between the DL-based algorithms proposed in various papers and linking them together to form a full picture, this work serves as a valuable source for researchers who are seeking potential research opportunities in this promising research field.</P>"
        },
        {
          "rank": 47,
          "score": 0.6161615252494812,
          "doc_id": "JAKO202013562119985",
          "title": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석",
          "abstract": "Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013562119985&target=NART&cn=JAKO202013562119985",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 딥 러닝 기반의 초해상도 이미지 복원 기법 성능 분석 Convolutional Neural Networks (CNN) have been used extensively in recent times to solve image classification and segmentation problems. However, the use of CNNs in image super-resolution problems remains largely unexploited. Filter interpolation and prediction model methods are the most commonly used algorithms in super-resolution algorithm implementations. The major limitation in the above named methods is that images become totally blurred and a lot of the edge information are lost. In this paper, we analyze super resolution based on CNN and the wavelet transform super resolution method. We compare and analyze the performance according to the number of layers and the training data of the CNN."
        },
        {
          "rank": 48,
          "score": 0.6159234046936035,
          "doc_id": "JAKO202033759655983",
          "title": "공 던지기 로봇의 정책 예측 심층 강화학습",
          "abstract": "Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202033759655983&target=NART&cn=JAKO202033759655983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate."
        },
        {
          "rank": 49,
          "score": 0.6156599521636963,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 50,
          "score": 0.6142206192016602,
          "doc_id": "NART120416967",
          "title": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement",
          "abstract": "<P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120416967&target=NART&cn=NART120416967",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement CIEGAN: A Deep Learning Tool for Cell Image Enhancement <P>Long-term live-cell imaging technology has emerged in the study of cell culture and development, and it is expected to elucidate the differentiation or reprogramming morphology of cells and the dynamic process of interaction between cells. There are some advantages to this technique: it is noninvasive, high-throughput, low-cost, and it can help researchers explore phenomena that are otherwise difficult to observe. Many challenges arise in the real-time process, for example, low-quality micrographs are often obtained due to unavoidable human factors or technical factors in the long-term experimental period. Moreover, some core dynamics in the developmental process are rare and fleeting in imaging observation and difficult to recapture again. Therefore, this study proposes a deep learning method for microscope cell image enhancement to reconstruct sharp images. We combine generative adversarial nets and various loss functions to make blurry images sharp again, which is much more convenient for researchers to carry out further analysis. This technology can not only make up the blurry images of critical moments of the development process through image enhancement but also allows long-term live-cell imaging to find a balance between imaging speed and image quality. Furthermore, the scalability of this technology makes the methods perform well in fluorescence image enhancement. Finally, the method is tested in long-term live-cell imaging of human-induced pluripotent stem cell-derived cardiomyocyte differentiation experiments, and it can greatly improve the image space resolution ratio.</P>"
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}