{
  "id": "row_000018",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:34.529306+09:00",
  "trial_id": "c45f031f",
  "queries": [
    {
      "query": "빅데이터 처리 과정별 위험요인 유형과 우선순위를 간략하게 요약해 주시겠습니까?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8695673942565918,
          "doc_id": "DIKO0013687737",
          "title": "빅데이터 처리 프로세스의 위험요인에 관한 연구",
          "abstract": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687737&target=NART&cn=DIKO0013687737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다."
        },
        {
          "rank": 2,
          "score": 0.8449546098709106,
          "doc_id": "ATN0030056853",
          "title": "빅데이터의 위험유형 분류에 관한 연구",
          "abstract": "본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030056853&target=NART&cn=ATN0030056853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다."
        },
        {
          "rank": 3,
          "score": 0.8194167613983154,
          "doc_id": "JAKO201914260900587",
          "title": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석",
          "abstract": "최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914260900587&target=NART&cn=JAKO201914260900587",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다."
        },
        {
          "rank": 4,
          "score": 0.8101141452789307,
          "doc_id": "JAKO201424750260451",
          "title": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석",
          "abstract": "Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424750260451&target=NART&cn=JAKO201424750260451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk."
        },
        {
          "rank": 5,
          "score": 0.7068194150924683,
          "doc_id": "NPAP12215574",
          "title": "Toward big data risk analysis",
          "abstract": "<P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12215574&target=NART&cn=NPAP12215574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Toward big data risk analysis Toward big data risk analysis Toward big data risk analysis <P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>"
        },
        {
          "rank": 6,
          "score": 0.7055200934410095,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 7,
          "score": 0.7040489912033081,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 8,
          "score": 0.7019773721694946,
          "doc_id": "JAKO201814446221611",
          "title": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현",
          "abstract": "본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201814446221611&target=NART&cn=JAKO201814446221611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다."
        },
        {
          "rank": 9,
          "score": 0.6936696171760559,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 10,
          "score": 0.6925003528594971,
          "doc_id": "NART96173512",
          "title": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발",
          "abstract": "본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96173512&target=NART&cn=NART96173512",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다."
        },
        {
          "rank": 11,
          "score": 0.6886551380157471,
          "doc_id": "ATN0037494703",
          "title": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연",
          "abstract": "인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037494703&target=NART&cn=ATN0037494703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다."
        },
        {
          "rank": 12,
          "score": 0.6861746907234192,
          "doc_id": "JAKO201331935804086",
          "title": "빅데이터와 통계학",
          "abstract": "빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201331935804086&target=NART&cn=JAKO201331935804086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 통계학 빅데이터와 통계학 빅데이터와 통계학 빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다."
        },
        {
          "rank": 13,
          "score": 0.6838763952255249,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 14,
          "score": 0.6837403774261475,
          "doc_id": "NART78301306",
          "title": "Advances in Risk Analysis with Big Data",
          "abstract": "<P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78301306&target=NART&cn=NART78301306",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data <P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>"
        },
        {
          "rank": 15,
          "score": 0.6824618577957153,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 16,
          "score": 0.6820278167724609,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 17,
          "score": 0.6816636323928833,
          "doc_id": "ATN0030204222",
          "title": "AHP를 활용한 빅데이터 역량모델 개발 연구",
          "abstract": "Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030204222&target=NART&cn=ATN0030204222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data."
        },
        {
          "rank": 18,
          "score": 0.6802735924720764,
          "doc_id": "JAKO201436351075064",
          "title": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구",
          "abstract": "정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201436351075064&target=NART&cn=JAKO201436351075064",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다."
        },
        {
          "rank": 19,
          "score": 0.6784331798553467,
          "doc_id": "JAKO202125659014584",
          "title": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구",
          "abstract": "모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659014584&target=NART&cn=JAKO202125659014584",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다."
        },
        {
          "rank": 20,
          "score": 0.677442729473114,
          "doc_id": "JAKO202125761334616",
          "title": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구",
          "abstract": "4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125761334616&target=NART&cn=JAKO202125761334616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다."
        },
        {
          "rank": 21,
          "score": 0.6772039532661438,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 22,
          "score": 0.675224781036377,
          "doc_id": "JAKO201303840307260",
          "title": "빅데이터 패키지 선정 방법",
          "abstract": "빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303840307260&target=NART&cn=JAKO201303840307260",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다."
        },
        {
          "rank": 23,
          "score": 0.674578070640564,
          "doc_id": "NPAP13087662",
          "title": "Cloud, Big Data & IoT: Risk Management",
          "abstract": "<P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13087662&target=NART&cn=NPAP13087662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management <P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>"
        },
        {
          "rank": 24,
          "score": 0.6741387844085693,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 25,
          "score": 0.6719670295715332,
          "doc_id": "NART79753361",
          "title": "BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES",
          "abstract": "<P> With the rapid growth of emerging applications like social network, semantic web, sensor networks and LBS (Location Based Service) applications, a variety of data to be processed continues to witness a quick increase. Effective management and processing of large-scale data poses an interesting but critical challenge. Recently, big data has attracted a lot of attention from academia, industry as well as government. This paper introduces several big data processing techniques from system and application aspects. First, from the view of cloud data management and big data processing mechanisms, we present the key issues of big data processing, including definition of big data, big data management platform, big data service models, distributed file system, data storage, data virtualization platform and distributed applications. Following the MapReduce parallel processing framework, we introduce some MapReduce optimization strategies reported in the literature. Finally, we discuss the open issues and challenges, and deeply explore the research directions in the future on big data processing in cloud computing environments. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART79753361&target=NART&cn=NART79753361",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES <P> With the rapid growth of emerging applications like social network, semantic web, sensor networks and LBS (Location Based Service) applications, a variety of data to be processed continues to witness a quick increase. Effective management and processing of large-scale data poses an interesting but critical challenge. Recently, big data has attracted a lot of attention from academia, industry as well as government. This paper introduces several big data processing techniques from system and application aspects. First, from the view of cloud data management and big data processing mechanisms, we present the key issues of big data processing, including definition of big data, big data management platform, big data service models, distributed file system, data storage, data virtualization platform and distributed applications. Following the MapReduce parallel processing framework, we introduce some MapReduce optimization strategies reported in the literature. Finally, we discuss the open issues and challenges, and deeply explore the research directions in the future on big data processing in cloud computing environments. </P>"
        },
        {
          "rank": 26,
          "score": 0.6708061695098877,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 27,
          "score": 0.6691792607307434,
          "doc_id": "NART118817514",
          "title": "Ensuring the ethical use of big data: lessons from secure data access",
          "abstract": "<▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118817514&target=NART&cn=NART118817514",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access <▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>"
        },
        {
          "rank": 28,
          "score": 0.6658933162689209,
          "doc_id": "JAKO202225947837166",
          "title": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구-",
          "abstract": "본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202225947837166&target=NART&cn=JAKO202225947837166",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다."
        },
        {
          "rank": 29,
          "score": 0.6658897995948792,
          "doc_id": "NART89644555",
          "title": "Big Data Analytics in Medicine and Healthcare",
          "abstract": "<P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART89644555&target=NART&cn=NART89644555",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare <P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>"
        },
        {
          "rank": 30,
          "score": 0.6648932099342346,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 31,
          "score": 0.6645371913909912,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 32,
          "score": 0.6644412279129028,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 33,
          "score": 0.6638971567153931,
          "doc_id": "NART69876343",
          "title": "빅데이터 처리 프로세스 플랫폼 서비스 고찰",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69876343&target=NART&cn=NART69876343",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 <P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>"
        },
        {
          "rank": 34,
          "score": 0.6635071039199829,
          "doc_id": "JAKO201713551814199",
          "title": "빅데이터와 U-City 서비스",
          "abstract": "소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713551814199&target=NART&cn=JAKO201713551814199",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다."
        },
        {
          "rank": 35,
          "score": 0.6601527333259583,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        },
        {
          "rank": 36,
          "score": 0.6595628261566162,
          "doc_id": "NART85081386",
          "title": "Searching for big data : How incumbents explore a possible adoption of big data technologies",
          "abstract": "<P><B>Abstract</B></P>  <P>Big data is often described as a new frontier of IT-enabled competitive advantage. A limited number of exemplary firms have been used recurrently in the big data debate to serve as successful illustrations of what big data technologies can offer. These firms are well-known, data-driven organizations that often, but not always, are born digital companies. Comparatively little attention has been paid to the challenges that many incumbent organizations face when they try to explore a possible adoption of such technologies. This study investigates how incumbents handle such an exploration and what challenges they face. Drawing on a four-year qualitative field study of four large Scandinavian firms, we are able to develop a typology of how incumbents handle the exploration of and resistance to adopting big data technologies. Directly affecting the incumbents&rsquo; exploration are two aspects that separate the adoption of big data technologies from that of other technologies. First, being an elusive concept, big data technologies can mean different things to different organizations. This makes the technologies difficult to explain before an investing body, while it simultaneously opens up possibilities for creative definitions. Second, big data technologies have a transformative effect on the organization of work in firms. This transformative capability will make managers wary as it might threaten their position in the firm, and it will create ripple effects, transforming other systems besides those directly connected to the technology.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We have developed a typology for how incumbent organizations handle the exploration of and resistance to big data technologies. </LI> <LI>  The typology is: (1) capitulation, (2) subterfuge, (3) expansion of an investment decision, and (4) normal investment decision. </LI> <LI>  Adoption of big data technologies is different than adoption of other technologies due to the elusiveness of the concept. </LI> <LI>  Adoption of big data technologies is different due to the transformative effect of them on the organization of work. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART85081386&target=NART&cn=NART85081386",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Searching for big data : How incumbents explore a possible adoption of big data technologies Searching for big data : How incumbents explore a possible adoption of big data technologies Searching for big data : How incumbents explore a possible adoption of big data technologies <P><B>Abstract</B></P>  <P>Big data is often described as a new frontier of IT-enabled competitive advantage. A limited number of exemplary firms have been used recurrently in the big data debate to serve as successful illustrations of what big data technologies can offer. These firms are well-known, data-driven organizations that often, but not always, are born digital companies. Comparatively little attention has been paid to the challenges that many incumbent organizations face when they try to explore a possible adoption of such technologies. This study investigates how incumbents handle such an exploration and what challenges they face. Drawing on a four-year qualitative field study of four large Scandinavian firms, we are able to develop a typology of how incumbents handle the exploration of and resistance to adopting big data technologies. Directly affecting the incumbents&rsquo; exploration are two aspects that separate the adoption of big data technologies from that of other technologies. First, being an elusive concept, big data technologies can mean different things to different organizations. This makes the technologies difficult to explain before an investing body, while it simultaneously opens up possibilities for creative definitions. Second, big data technologies have a transformative effect on the organization of work in firms. This transformative capability will make managers wary as it might threaten their position in the firm, and it will create ripple effects, transforming other systems besides those directly connected to the technology.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We have developed a typology for how incumbent organizations handle the exploration of and resistance to big data technologies. </LI> <LI>  The typology is: (1) capitulation, (2) subterfuge, (3) expansion of an investment decision, and (4) normal investment decision. </LI> <LI>  Adoption of big data technologies is different than adoption of other technologies due to the elusiveness of the concept. </LI> <LI>  Adoption of big data technologies is different due to the transformative effect of them on the organization of work. </LI> </UL> </P>"
        },
        {
          "rank": 37,
          "score": 0.6589237451553345,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 38,
          "score": 0.6581208109855652,
          "doc_id": "JAKO201615262489668",
          "title": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향",
          "abstract": "정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201615262489668&target=NART&cn=JAKO201615262489668",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다."
        },
        {
          "rank": 39,
          "score": 0.6572169661521912,
          "doc_id": "NART76320729",
          "title": "Demystifying big data: Anatomy of big data developmental process",
          "abstract": "<P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART76320729&target=NART&cn=NART76320729",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process <P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>"
        },
        {
          "rank": 40,
          "score": 0.6563087701797485,
          "doc_id": "JAKO201321353692848",
          "title": "빅데이터 개인정보 위험 분석 기술",
          "abstract": "본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353692848&target=NART&cn=JAKO201321353692848",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다."
        },
        {
          "rank": 41,
          "score": 0.6554433107376099,
          "doc_id": "JAKO202111735182702",
          "title": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향",
          "abstract": "본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202111735182702&target=NART&cn=JAKO202111735182702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다."
        },
        {
          "rank": 42,
          "score": 0.6553974151611328,
          "doc_id": "JAKO201723954939431",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723954939431&target=NART&cn=JAKO201723954939431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다."
        },
        {
          "rank": 43,
          "score": 0.6551237106323242,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 44,
          "score": 0.6543604731559753,
          "doc_id": "JAKO201529539328686",
          "title": "자연재해 분석을 위한 빅데이터 마이닝 기술",
          "abstract": "자연재해 빅데이터 분석은 현재 소셜 미디어 데이터 등 텍스트 데이터를 중심으로 시작되고 있으며 이는 재난관리의 네 단계인 예방, 대비, 대응, 복구에서 마지막 두 단계에 주로 해당된다. 반면 기상 데이터 자체에 대한 빅데이터 분석은 사전 관리에 해당하는 예방, 대비 단계에 활용될 수 있어 이와 관련한 연구 사례에 대한 체계적인 정리가 필요하다. 본 논문은 리뷰 논문으로서, 자연재해 영역에서 텍스트 데이터 외의 빅데이터를 다루는 분석 기술들에 대해 소개한다. 이를 위해 기상 관련 분야에서 사용되고 있는 데이터 마이닝 및 기계 학습 기술들을 살피고 각 기상 데이터의 특성에 맞춰 기존의 기술들이 어떻게 변형되는 지 밝힌다. 우선 2절에서 빅데이터, 데이터 마이닝, 기계 학습에 대한 기본 개념을 설명하고 3절에서 데이터 마이닝 및 기계 학습 기술의 실제 적용 사례를 상세히 정리한다. 4절에서는 자연재해 대응에 이러한 기술들이 직접 활용되는 예를 소개하고 마지막에 결론으로 마무리한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201529539328686&target=NART&cn=JAKO201529539328686",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 빅데이터 분석은 현재 소셜 미디어 데이터 등 텍스트 데이터를 중심으로 시작되고 있으며 이는 재난관리의 네 단계인 예방, 대비, 대응, 복구에서 마지막 두 단계에 주로 해당된다. 반면 기상 데이터 자체에 대한 빅데이터 분석은 사전 관리에 해당하는 예방, 대비 단계에 활용될 수 있어 이와 관련한 연구 사례에 대한 체계적인 정리가 필요하다. 본 논문은 리뷰 논문으로서, 자연재해 영역에서 텍스트 데이터 외의 빅데이터를 다루는 분석 기술들에 대해 소개한다. 이를 위해 기상 관련 분야에서 사용되고 있는 데이터 마이닝 및 기계 학습 기술들을 살피고 각 기상 데이터의 특성에 맞춰 기존의 기술들이 어떻게 변형되는 지 밝힌다. 우선 2절에서 빅데이터, 데이터 마이닝, 기계 학습에 대한 기본 개념을 설명하고 3절에서 데이터 마이닝 및 기계 학습 기술의 실제 적용 사례를 상세히 정리한다. 4절에서는 자연재해 대응에 이러한 기술들이 직접 활용되는 예를 소개하고 마지막에 결론으로 마무리한다."
        },
        {
          "rank": 45,
          "score": 0.6537972688674927,
          "doc_id": "JAKO202323638418644",
          "title": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방",
          "abstract": "최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202323638418644&target=NART&cn=JAKO202323638418644",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다."
        },
        {
          "rank": 46,
          "score": 0.6532739996910095,
          "doc_id": "ATN0037480329",
          "title": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안",
          "abstract": "정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037480329&target=NART&cn=ATN0037480329",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다."
        },
        {
          "rank": 47,
          "score": 0.6524208784103394,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 48,
          "score": 0.6507490873336792,
          "doc_id": "NART71376020",
          "title": "Comparative effectiveness research and big data: balancing potential with legal and ethical considerations",
          "abstract": "<P>Big data holds big potential for comparative effectiveness research. The ability to quickly synthesize and use vast amounts of health data to compare medical interventions across settings of care, patient populations, payers and time will greatly inform efforts to improve quality, reduce costs and deliver more patient-centered care. However, the use of big data raises significant legal and ethical issues that may present barriers or limitations to the full potential of big data. This paper addresses the scope of some of these legal and ethical issues and how they may be managed effectively to fully realize the potential of big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART71376020&target=NART&cn=NART71376020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparative effectiveness research and big data: balancing potential with legal and ethical considerations Comparative effectiveness research and big data: balancing potential with legal and ethical considerations Comparative effectiveness research and big data: balancing potential with legal and ethical considerations <P>Big data holds big potential for comparative effectiveness research. The ability to quickly synthesize and use vast amounts of health data to compare medical interventions across settings of care, patient populations, payers and time will greatly inform efforts to improve quality, reduce costs and deliver more patient-centered care. However, the use of big data raises significant legal and ethical issues that may present barriers or limitations to the full potential of big data. This paper addresses the scope of some of these legal and ethical issues and how they may be managed effectively to fully realize the potential of big data.</P>"
        },
        {
          "rank": 49,
          "score": 0.6493788957595825,
          "doc_id": "ATN0037467542",
          "title": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구",
          "abstract": "4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037467542&target=NART&cn=ATN0037467542",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다."
        },
        {
          "rank": 50,
          "score": 0.6488832235336304,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        }
      ]
    },
    {
      "query": "빅데이터 처리 과정은 일반적으로 어떻게 구성됩니까?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7608071565628052,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 2,
          "score": 0.7377672791481018,
          "doc_id": "NART69876343",
          "title": "빅데이터 처리 프로세스 플랫폼 서비스 고찰",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69876343&target=NART&cn=NART69876343",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 <P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>"
        },
        {
          "rank": 3,
          "score": 0.728023886680603,
          "doc_id": "JAKO201424750260451",
          "title": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석",
          "abstract": "Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424750260451&target=NART&cn=JAKO201424750260451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk."
        },
        {
          "rank": 4,
          "score": 0.717004120349884,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 5,
          "score": 0.7142876386642456,
          "doc_id": "DIKO0013687737",
          "title": "빅데이터 처리 프로세스의 위험요인에 관한 연구",
          "abstract": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687737&target=NART&cn=DIKO0013687737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다."
        },
        {
          "rank": 6,
          "score": 0.7088413238525391,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        },
        {
          "rank": 7,
          "score": 0.7076111435890198,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 8,
          "score": 0.7044042348861694,
          "doc_id": "JAKO201331935804086",
          "title": "빅데이터와 통계학",
          "abstract": "빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201331935804086&target=NART&cn=JAKO201331935804086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 통계학 빅데이터와 통계학 빅데이터와 통계학 빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다."
        },
        {
          "rank": 9,
          "score": 0.7024989128112793,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 10,
          "score": 0.7021136283874512,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        },
        {
          "rank": 11,
          "score": 0.6867300271987915,
          "doc_id": "ATN0030204222",
          "title": "AHP를 활용한 빅데이터 역량모델 개발 연구",
          "abstract": "Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030204222&target=NART&cn=ATN0030204222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data."
        },
        {
          "rank": 12,
          "score": 0.6854541301727295,
          "doc_id": "NART111547998",
          "title": "Big Data Processing-Beyond Batch Processing",
          "abstract": "<P>This paper mainly focus on analysis of large sets of students data with one of the batch processing analysis techniques Beyond batch process, analysis of data streaming is done based on program of word counting program which executes data with HDFS along with dynamic created data. To compute similar coherent strategies one can implement a schema named batch and streaming process which dynamically creates data. The architecture is reduced to serve as X-Platform which uses ample number of tools for batch and stream analysis on this proposed frame work. Here we use spark-sql, a query language which acts as interface for interactive process to have iterative processes. Real time streaming data processing involves spark streaming works. Here we focus on preliminary evaluation of results and analysis report which compares data sets performance and also achieve low latency rate with usage of RDD.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111547998&target=NART&cn=NART111547998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing-Beyond Batch Processing Big Data Processing-Beyond Batch Processing Big Data Processing-Beyond Batch Processing <P>This paper mainly focus on analysis of large sets of students data with one of the batch processing analysis techniques Beyond batch process, analysis of data streaming is done based on program of word counting program which executes data with HDFS along with dynamic created data. To compute similar coherent strategies one can implement a schema named batch and streaming process which dynamically creates data. The architecture is reduced to serve as X-Platform which uses ample number of tools for batch and stream analysis on this proposed frame work. Here we use spark-sql, a query language which acts as interface for interactive process to have iterative processes. Real time streaming data processing involves spark streaming works. Here we focus on preliminary evaluation of results and analysis report which compares data sets performance and also achieve low latency rate with usage of RDD.</P>"
        },
        {
          "rank": 13,
          "score": 0.6833693981170654,
          "doc_id": "ATN0037461993",
          "title": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법",
          "abstract": "This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037461993&target=NART&cn=ATN0037461993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis."
        },
        {
          "rank": 14,
          "score": 0.6826047897338867,
          "doc_id": "JAKO201835146902109",
          "title": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법",
          "abstract": "인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201835146902109&target=NART&cn=JAKO201835146902109",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다."
        },
        {
          "rank": 15,
          "score": 0.6802812814712524,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 16,
          "score": 0.6783232688903809,
          "doc_id": "JAKO201303840307260",
          "title": "빅데이터 패키지 선정 방법",
          "abstract": "빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303840307260&target=NART&cn=JAKO201303840307260",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다."
        },
        {
          "rank": 17,
          "score": 0.677071213722229,
          "doc_id": "NART76320729",
          "title": "Demystifying big data: Anatomy of big data developmental process",
          "abstract": "<P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART76320729&target=NART&cn=NART76320729",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process <P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>"
        },
        {
          "rank": 18,
          "score": 0.6768113970756531,
          "doc_id": "JAKO201823952425544",
          "title": "에너지 빅데이터를 수용하는 빅데이터 시스템 개발",
          "abstract": "본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201823952425544&target=NART&cn=JAKO201823952425544",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "에너지 빅데이터를 수용하는 빅데이터 시스템 개발 에너지 빅데이터를 수용하는 빅데이터 시스템 개발 에너지 빅데이터를 수용하는 빅데이터 시스템 개발 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다."
        },
        {
          "rank": 19,
          "score": 0.6751718521118164,
          "doc_id": "JAKO201533678910724",
          "title": "빅데이터 정보시스템의 구축 및 사례에 관한 연구",
          "abstract": "빅데이터와 관련하여 많은 성공사례들이 보고되었지만 실제로 시스템을 구축하는 데 있어서는 여전히 많은 어려움이 있다. 기술적인 측면에서 데이터의 수집과 저장, 처리와 분석, 그리고 표현과 사용에 이르는 전 과정을 포괄적으로 이해해야 하고, 비즈니스적 측면에서는 구축된 시스템으로부터 얻을 수 있는 가치를 미리 파악하여 투자를 감행해야 하는 경영진에게 설명해야 한다. 본 연구는 빅데이터 정보시스템을 구축하는 것과 관련된 사항들을 쉽게 파악할 수 있는 5W 1H 프레임워크를 제공하고, 제시된 프레임워크를 기존의 빅데이터 사례들에 적용한 예시를 보여주었다. 투자를 위한 경영진의 의사결정을 이끌어내고 빅데이터 프로젝트의 종합적인 이해와 관리에 도움을 줄 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201533678910724&target=NART&cn=JAKO201533678910724",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 정보시스템의 구축 및 사례에 관한 연구 빅데이터 정보시스템의 구축 및 사례에 관한 연구 빅데이터 정보시스템의 구축 및 사례에 관한 연구 빅데이터와 관련하여 많은 성공사례들이 보고되었지만 실제로 시스템을 구축하는 데 있어서는 여전히 많은 어려움이 있다. 기술적인 측면에서 데이터의 수집과 저장, 처리와 분석, 그리고 표현과 사용에 이르는 전 과정을 포괄적으로 이해해야 하고, 비즈니스적 측면에서는 구축된 시스템으로부터 얻을 수 있는 가치를 미리 파악하여 투자를 감행해야 하는 경영진에게 설명해야 한다. 본 연구는 빅데이터 정보시스템을 구축하는 것과 관련된 사항들을 쉽게 파악할 수 있는 5W 1H 프레임워크를 제공하고, 제시된 프레임워크를 기존의 빅데이터 사례들에 적용한 예시를 보여주었다. 투자를 위한 경영진의 의사결정을 이끌어내고 빅데이터 프로젝트의 종합적인 이해와 관리에 도움을 줄 수 있을 것으로 기대된다."
        },
        {
          "rank": 20,
          "score": 0.6732953190803528,
          "doc_id": "NART79753361",
          "title": "BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES",
          "abstract": "<P> With the rapid growth of emerging applications like social network, semantic web, sensor networks and LBS (Location Based Service) applications, a variety of data to be processed continues to witness a quick increase. Effective management and processing of large-scale data poses an interesting but critical challenge. Recently, big data has attracted a lot of attention from academia, industry as well as government. This paper introduces several big data processing techniques from system and application aspects. First, from the view of cloud data management and big data processing mechanisms, we present the key issues of big data processing, including definition of big data, big data management platform, big data service models, distributed file system, data storage, data virtualization platform and distributed applications. Following the MapReduce parallel processing framework, we introduce some MapReduce optimization strategies reported in the literature. Finally, we discuss the open issues and challenges, and deeply explore the research directions in the future on big data processing in cloud computing environments. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART79753361&target=NART&cn=NART79753361",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES BIG DATA PROCESSING: BIG CHALLENGES AND OPPORTUNITIES <P> With the rapid growth of emerging applications like social network, semantic web, sensor networks and LBS (Location Based Service) applications, a variety of data to be processed continues to witness a quick increase. Effective management and processing of large-scale data poses an interesting but critical challenge. Recently, big data has attracted a lot of attention from academia, industry as well as government. This paper introduces several big data processing techniques from system and application aspects. First, from the view of cloud data management and big data processing mechanisms, we present the key issues of big data processing, including definition of big data, big data management platform, big data service models, distributed file system, data storage, data virtualization platform and distributed applications. Following the MapReduce parallel processing framework, we introduce some MapReduce optimization strategies reported in the literature. Finally, we discuss the open issues and challenges, and deeply explore the research directions in the future on big data processing in cloud computing environments. </P>"
        },
        {
          "rank": 21,
          "score": 0.6696479320526123,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 22,
          "score": 0.6689261794090271,
          "doc_id": "NART69876324",
          "title": "생물정보의 빅데이터 처리",
          "abstract": "<P>&nbsp&#59;&nbsp&#59;Frederick Sanger에 의해서 DNA 시컨싱 기술이 개발된 이후 과학자들에 의해 많은 생물정보를 밝혀내기 위해 전 세계 다양한 종에 걸쳐 시컨싱이 이뤄지고 있다. 유전체 연구의 새로운 토대를 만들어가고 NGS의 기술개발로 시컨싱 시간뿐만 아니라 경제적인 비용까지 줄일 수 있게 되었다. NGS 기술은 수백 mega bp에서 수백 giga bp에 이르는 엄청난 양의 염기서열 분석 데이터를 생산하고 있지만 이러한 bp들을 생산하기 위한 중간 과정 생산 데이터를 포함하면 최소 몇 테라바이트 이상의 데이터를 생산하게 된다. 따라서 이 NGS 기술은 빅데이터의 정확하고 효율적인 계산처리 뿐만 아니라 데이터 저장을 위한 패러다임을 바꾸고 있다. 본고에서는 NGS를 통한 생물정보 빅데이터의 발생의 원인과 많은 컴퓨팅 파워를 요구하는 생물정보 빅데이터 분석을 위한 처리 과정 등을 조사하였으며 생물학자들이 이러한 빅데이터를 보다 용이하게 처리할 수 있는 클라우드 서비스에 대해서 조사하였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69876324&target=NART&cn=NART69876324",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "생물정보의 빅데이터 처리 생물정보의 빅데이터 처리 생물정보의 빅데이터 처리 <P>&nbsp&#59;&nbsp&#59;Frederick Sanger에 의해서 DNA 시컨싱 기술이 개발된 이후 과학자들에 의해 많은 생물정보를 밝혀내기 위해 전 세계 다양한 종에 걸쳐 시컨싱이 이뤄지고 있다. 유전체 연구의 새로운 토대를 만들어가고 NGS의 기술개발로 시컨싱 시간뿐만 아니라 경제적인 비용까지 줄일 수 있게 되었다. NGS 기술은 수백 mega bp에서 수백 giga bp에 이르는 엄청난 양의 염기서열 분석 데이터를 생산하고 있지만 이러한 bp들을 생산하기 위한 중간 과정 생산 데이터를 포함하면 최소 몇 테라바이트 이상의 데이터를 생산하게 된다. 따라서 이 NGS 기술은 빅데이터의 정확하고 효율적인 계산처리 뿐만 아니라 데이터 저장을 위한 패러다임을 바꾸고 있다. 본고에서는 NGS를 통한 생물정보 빅데이터의 발생의 원인과 많은 컴퓨팅 파워를 요구하는 생물정보 빅데이터 분석을 위한 처리 과정 등을 조사하였으며 생물학자들이 이러한 빅데이터를 보다 용이하게 처리할 수 있는 클라우드 서비스에 대해서 조사하였다.</P>"
        },
        {
          "rank": 23,
          "score": 0.6678248643875122,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 24,
          "score": 0.6672158241271973,
          "doc_id": "JAKO201617338764393",
          "title": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구",
          "abstract": "본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201617338764393&target=NART&cn=JAKO201617338764393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다."
        },
        {
          "rank": 25,
          "score": 0.6650781631469727,
          "doc_id": "NPAP12116569",
          "title": "Big data analytics on large-scale socio-technical software engineering archives",
          "abstract": "<P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12116569&target=NART&cn=NPAP12116569",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives Big data analytics on large-scale socio-technical software engineering archives <P>Given the fast growing nature of software engineering data in online software repositories and open source communities, it would be helpful to analyse these assets to discover valuable information about the software engineering development process and other related data. Big Data Analytics (BDA) techniques and frameworks can be applied on these data resources to achieve a high-performance and relevant data collection and analysis. Software engineering is a socio-technical process which needs development team collaboration and technical knowledge to develop a high-quality application. GitHub, as an online social coding foundation, contains valuable information about the software engineers' communications and project life cycles. In this paper, unsupervised data mining techniques are applied on the data collected by general Big Data approaches to analyse GitHub projects, source codes and interactions. Source codes and projects are clustered using features and metrics derived from historical data in repositories, object oriented programming metrics and the influences of developers on source codes.</P>"
        },
        {
          "rank": 26,
          "score": 0.6650058627128601,
          "doc_id": "JAKO201713551814199",
          "title": "빅데이터와 U-City 서비스",
          "abstract": "소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713551814199&target=NART&cn=JAKO201713551814199",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다."
        },
        {
          "rank": 27,
          "score": 0.66379714012146,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 28,
          "score": 0.6629468202590942,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 29,
          "score": 0.6613928079605103,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 30,
          "score": 0.6597216129302979,
          "doc_id": "JAKO201507639684549",
          "title": "공간빅데이터를 위한 정보 시각화 방법",
          "abstract": "본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201507639684549&target=NART&cn=JAKO201507639684549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다."
        },
        {
          "rank": 31,
          "score": 0.6578822135925293,
          "doc_id": "ATN0042342282",
          "title": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구",
          "abstract": "자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0042342282&target=NART&cn=ATN0042342282",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다."
        },
        {
          "rank": 32,
          "score": 0.6568853855133057,
          "doc_id": "JAKO202514057605142",
          "title": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구",
          "abstract": "분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514057605142&target=NART&cn=JAKO202514057605142",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다."
        },
        {
          "rank": 33,
          "score": 0.6550692915916443,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 34,
          "score": 0.6549171209335327,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 35,
          "score": 0.6523748636245728,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 36,
          "score": 0.6521196961402893,
          "doc_id": "NART97710485",
          "title": "Big data analytics for personalized medicine",
          "abstract": "<P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97710485&target=NART&cn=NART97710485",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics for personalized medicine Big data analytics for personalized medicine Big data analytics for personalized medicine <P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
        },
        {
          "rank": 37,
          "score": 0.6520299911499023,
          "doc_id": "ATN0037490138",
          "title": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크",
          "abstract": "In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037490138&target=NART&cn=ATN0037490138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 웹 서비스 기반 빅 데이터 서비스 조합 프레임워크 In recent years, demand for big data analysis service is increasing in Korea and abroad. However, the development of big data service requires a substantial amount of time and human resources. In this paper, we suggest a “Big data Service Composition Framework” for the development of a new big data service that easily combines various big data services. Users can develop a big data analysis service easily through the framework. The earlier studies about service composition already exist, but the framework has specific structure to execute composite service for solving problems about adapting to big data. We present the structure and the execution method and an application of the framework in Transportation domain. In the future, we can solve problems with expenses and human resources when developing a big data service by applying the service composition framework to various domains."
        },
        {
          "rank": 38,
          "score": 0.65152508020401,
          "doc_id": "JAKO201352057197183",
          "title": "빅데이터 기반 음성언어 처리 기술",
          "abstract": "음성언어 처리 분야는 인간의 자연어 발화를 컴퓨터가 자동으로 이해하고 처리하는 알고리즘을 연구하는 분야로, 자동 통번역, Siri와 같은 음성 대화 시스템, 차세대 인터페이스, 질의 응답 시스템 등 다양한 응용군을 포함한다. 특히, 음성언어 처리 기술은, 최근 빅데이터(big data) 시대를 맞이하여, 방대한 음성/텍스트 정보를 처리하기 위한 필수 기술로 각광받고 있다. 한편, 빅데이터는 그 자체가 거대한 말뭉치 데이터로서 음성언어 처리 기술의 성능을 향상시키는 주된 리소스가 된다. 이에 따라, 최근 빅데이터를 이용하여 음성언어 처리 기술의 성능을 개선시키고자 하는 연구가 활발히 진행되고 있는데, 본고에서는 이들 연구의 배경 및 연구 동향들을 소개하기로 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201352057197183&target=NART&cn=JAKO201352057197183",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 음성언어 처리 기술 빅데이터 기반 음성언어 처리 기술 빅데이터 기반 음성언어 처리 기술 음성언어 처리 분야는 인간의 자연어 발화를 컴퓨터가 자동으로 이해하고 처리하는 알고리즘을 연구하는 분야로, 자동 통번역, Siri와 같은 음성 대화 시스템, 차세대 인터페이스, 질의 응답 시스템 등 다양한 응용군을 포함한다. 특히, 음성언어 처리 기술은, 최근 빅데이터(big data) 시대를 맞이하여, 방대한 음성/텍스트 정보를 처리하기 위한 필수 기술로 각광받고 있다. 한편, 빅데이터는 그 자체가 거대한 말뭉치 데이터로서 음성언어 처리 기술의 성능을 향상시키는 주된 리소스가 된다. 이에 따라, 최근 빅데이터를 이용하여 음성언어 처리 기술의 성능을 개선시키고자 하는 연구가 활발히 진행되고 있는데, 본고에서는 이들 연구의 배경 및 연구 동향들을 소개하기로 한다."
        },
        {
          "rank": 39,
          "score": 0.6514904499053955,
          "doc_id": "NPAP12688093",
          "title": "A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis",
          "abstract": "빅데이터 분석은 데이터베이스에 잘 정리된 정형 데이터뿐만 아니라 인터넷, 소셜 네트워크 서비스, 모바일 환경에서 생성되는 웹 문서, 이메일, 소셜 데이터 등 비정형 데이터를 효과적으로 분석하는 기술을 말한다. 대부분의 빅데이터 분석 기술 방법들은 기존 통계학과 전산학에서 사용되던 데이터 마이닝, 기계 학습, 자연 언어 처리, 패턴 인식 등이 이에 해당된다. 글로벌 리서치 기관들은 빅데이터 분석을 2011년 이래로 가장 주목받는 신기술로 지목해오고 있다. 따라서 대부분의 산업에서 기업들은 빅데이터의 적용을 통해 새로운 가치 창출을 위해 노력을 하고 있다. 본 연구에서는 다음 커뮤니케이션의 빅데이터 분석 도구인 소셜 매트릭스를 활용하여 분석하였다. 2018년 5월 19일 시점 1개월 기간을 설정하여 &quot;인공지능&quot; 키워드에 대한 대중들의 인식을 분석하였다. 빅데이터 분석의 결과는 다음과 같다. 첫째, 인공지능에 대한 1위 연관 검색어는 중국(4,122)인 것으로 나타났다. 결과를 바탕으로 연구의 한계와 시사점을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12688093&target=NART&cn=NPAP12688093",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis 빅데이터 분석은 데이터베이스에 잘 정리된 정형 데이터뿐만 아니라 인터넷, 소셜 네트워크 서비스, 모바일 환경에서 생성되는 웹 문서, 이메일, 소셜 데이터 등 비정형 데이터를 효과적으로 분석하는 기술을 말한다. 대부분의 빅데이터 분석 기술 방법들은 기존 통계학과 전산학에서 사용되던 데이터 마이닝, 기계 학습, 자연 언어 처리, 패턴 인식 등이 이에 해당된다. 글로벌 리서치 기관들은 빅데이터 분석을 2011년 이래로 가장 주목받는 신기술로 지목해오고 있다. 따라서 대부분의 산업에서 기업들은 빅데이터의 적용을 통해 새로운 가치 창출을 위해 노력을 하고 있다. 본 연구에서는 다음 커뮤니케이션의 빅데이터 분석 도구인 소셜 매트릭스를 활용하여 분석하였다. 2018년 5월 19일 시점 1개월 기간을 설정하여 &quot;인공지능&quot; 키워드에 대한 대중들의 인식을 분석하였다. 빅데이터 분석의 결과는 다음과 같다. 첫째, 인공지능에 대한 1위 연관 검색어는 중국(4,122)인 것으로 나타났다. 결과를 바탕으로 연구의 한계와 시사점을 제시하고자 한다."
        },
        {
          "rank": 40,
          "score": 0.651454746723175,
          "doc_id": "JAKO201721961719817",
          "title": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법",
          "abstract": "제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721961719817&target=NART&cn=JAKO201721961719817",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다."
        },
        {
          "rank": 41,
          "score": 0.651089072227478,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 42,
          "score": 0.6499072313308716,
          "doc_id": "JAKO201503340570903",
          "title": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치",
          "abstract": "본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201503340570903&target=NART&cn=JAKO201503340570903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다."
        },
        {
          "rank": 43,
          "score": 0.6491409540176392,
          "doc_id": "ATN0025427128",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025427128&target=NART&cn=ATN0025427128",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice."
        },
        {
          "rank": 44,
          "score": 0.6481714248657227,
          "doc_id": "JAKO202024758672089",
          "title": "Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information",
          "abstract": "In this study, the information from environmental impact statements was converted into spatial data because environmental data from development sites are collected during the environmental impact assessment (EIA) process. Spatiotemporal big data were built from environmental spatial data for each environmental medium for 2,235 development sites during 2007-2018, available from public data portals. Comparing air-quality monitoring stations, 33,863 measurement points were constructed, which is approximately 75 times more measurement points than that 452 in Air Korea's real-time measurement network. Here, spatiotemporal big data from 2,677,260 EIAs were constructed. In the future, such data might be used not only for EIAs but also for various spatial plans.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202024758672089&target=NART&cn=JAKO202024758672089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information Construction of Spatiotemporal Big Data Using Environmental Impact Assessment Information In this study, the information from environmental impact statements was converted into spatial data because environmental data from development sites are collected during the environmental impact assessment (EIA) process. Spatiotemporal big data were built from environmental spatial data for each environmental medium for 2,235 development sites during 2007-2018, available from public data portals. Comparing air-quality monitoring stations, 33,863 measurement points were constructed, which is approximately 75 times more measurement points than that 452 in Air Korea's real-time measurement network. Here, spatiotemporal big data from 2,677,260 EIAs were constructed. In the future, such data might be used not only for EIAs but also for various spatial plans."
        },
        {
          "rank": 45,
          "score": 0.6478215456008911,
          "doc_id": "NART97302075",
          "title": "Big data processing framework for manufacturing",
          "abstract": "<P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97302075&target=NART&cn=NART97302075",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data processing framework for manufacturing Big data processing framework for manufacturing Big data processing framework for manufacturing <P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>"
        },
        {
          "rank": 46,
          "score": 0.6476790904998779,
          "doc_id": "ATN0030112964",
          "title": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석",
          "abstract": "Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030112964&target=NART&cn=ATN0030112964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users."
        },
        {
          "rank": 47,
          "score": 0.6475787162780762,
          "doc_id": "JAKO201310635656321",
          "title": "빅 데이터의 품질 요소 제안",
          "abstract": "빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201310635656321&target=NART&cn=JAKO201310635656321",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다."
        },
        {
          "rank": 48,
          "score": 0.6469496488571167,
          "doc_id": "ATN0025420762",
          "title": "의료기관 빅데이터 품질관리의 필요성과 사례 분석",
          "abstract": "The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420762&target=NART&cn=ATN0025420762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented."
        },
        {
          "rank": 49,
          "score": 0.6466718912124634,
          "doc_id": "ART002687869",
          "title": "Optimized Data Processing Analysis Using Big Data Cloud Platform",
          "abstract": "Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002687869&target=NART&cn=ART002687869",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimized Data Processing Analysis Using Big Data Cloud Platform Optimized Data Processing Analysis Using Big Data Cloud Platform Optimized Data Processing Analysis Using Big Data Cloud Platform Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems."
        },
        {
          "rank": 50,
          "score": 0.6455643773078918,
          "doc_id": "JAKO202032362242307",
          "title": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용",
          "abstract": "본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242307&target=NART&cn=JAKO202032362242307",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다."
        }
      ]
    },
    {
      "query": "각 빅데이터 처리 과정별로 발생할 수 있는 위험요인의 유형은 무엇입니까?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8646837472915649,
          "doc_id": "DIKO0013687737",
          "title": "빅데이터 처리 프로세스의 위험요인에 관한 연구",
          "abstract": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687737&target=NART&cn=DIKO0013687737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다."
        },
        {
          "rank": 2,
          "score": 0.8577107787132263,
          "doc_id": "ATN0030056853",
          "title": "빅데이터의 위험유형 분류에 관한 연구",
          "abstract": "본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030056853&target=NART&cn=ATN0030056853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다."
        },
        {
          "rank": 3,
          "score": 0.8067105412483215,
          "doc_id": "JAKO201424750260451",
          "title": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석",
          "abstract": "Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424750260451&target=NART&cn=JAKO201424750260451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk."
        },
        {
          "rank": 4,
          "score": 0.7995360493659973,
          "doc_id": "JAKO201914260900587",
          "title": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석",
          "abstract": "최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914260900587&target=NART&cn=JAKO201914260900587",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다."
        },
        {
          "rank": 5,
          "score": 0.7022643089294434,
          "doc_id": "ATN0037494703",
          "title": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연",
          "abstract": "인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037494703&target=NART&cn=ATN0037494703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다."
        },
        {
          "rank": 6,
          "score": 0.6969925165176392,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 7,
          "score": 0.6944501996040344,
          "doc_id": "NPAP12215574",
          "title": "Toward big data risk analysis",
          "abstract": "<P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12215574&target=NART&cn=NPAP12215574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Toward big data risk analysis Toward big data risk analysis Toward big data risk analysis <P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>"
        },
        {
          "rank": 8,
          "score": 0.692082405090332,
          "doc_id": "NART96173512",
          "title": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발",
          "abstract": "본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96173512&target=NART&cn=NART96173512",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다."
        },
        {
          "rank": 9,
          "score": 0.6898102164268494,
          "doc_id": "NART78301306",
          "title": "Advances in Risk Analysis with Big Data",
          "abstract": "<P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78301306&target=NART&cn=NART78301306",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data <P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>"
        },
        {
          "rank": 10,
          "score": 0.6861933469772339,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 11,
          "score": 0.6852225065231323,
          "doc_id": "JAKO201814446221611",
          "title": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현",
          "abstract": "본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201814446221611&target=NART&cn=JAKO201814446221611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다."
        },
        {
          "rank": 12,
          "score": 0.6849576234817505,
          "doc_id": "JAKO201529539328679",
          "title": "소셜 빅데이터를 활용한 담배 위험 예측",
          "abstract": "본 연구는 국내의 블로그, 카페, SNS 등 인터넷을 통해 수집된 소셜 빅데이터를 데이터마이닝 분석 기법을 적용하여 우리나라 국민의 담배에 대한 위험요인을 예측하고자 하였다. 주요분석 결과는 다음과 같다. 첫째, 온라인상에 '담뱃값인상'이 언급될 경우 담배에 대한 일반군 (negative)이 58.6%에서 74.8%로 증가하며, '폐암'이 언급될 경우 73.1%로 증가하는 것으로 나타났다. 둘째, 담뱃값인상 이후 담배에 대한 위험군 (positive)은 5.6% 감소하고, 일반군은 6.1% 증가한 것으로 나타났다. 셋째, 'FCTC, 담뱃값인상, 금연관련법, 흡연규제, 금연광고, 금연사업'과 관련된 정책이 온라인상에 많이 언급될수록 담배에 대한 위험군이 감소하는 것으로 나타났다. 마지막으로 '금연약, 금연패치, 금연껌'이 온라인 상에 언급될수록 담배에 대한 위험군이 감소하나, '전자담배와 보조제'가 온라인상에 언급될수록 담배에 대한 위험군을 증가시키는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201529539328679&target=NART&cn=JAKO201529539328679",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소셜 빅데이터를 활용한 담배 위험 예측 소셜 빅데이터를 활용한 담배 위험 예측 소셜 빅데이터를 활용한 담배 위험 예측 본 연구는 국내의 블로그, 카페, SNS 등 인터넷을 통해 수집된 소셜 빅데이터를 데이터마이닝 분석 기법을 적용하여 우리나라 국민의 담배에 대한 위험요인을 예측하고자 하였다. 주요분석 결과는 다음과 같다. 첫째, 온라인상에 '담뱃값인상'이 언급될 경우 담배에 대한 일반군 (negative)이 58.6%에서 74.8%로 증가하며, '폐암'이 언급될 경우 73.1%로 증가하는 것으로 나타났다. 둘째, 담뱃값인상 이후 담배에 대한 위험군 (positive)은 5.6% 감소하고, 일반군은 6.1% 증가한 것으로 나타났다. 셋째, 'FCTC, 담뱃값인상, 금연관련법, 흡연규제, 금연광고, 금연사업'과 관련된 정책이 온라인상에 많이 언급될수록 담배에 대한 위험군이 감소하는 것으로 나타났다. 마지막으로 '금연약, 금연패치, 금연껌'이 온라인 상에 언급될수록 담배에 대한 위험군이 감소하나, '전자담배와 보조제'가 온라인상에 언급될수록 담배에 대한 위험군을 증가시키는 것으로 나타났다."
        },
        {
          "rank": 13,
          "score": 0.6845221519470215,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 14,
          "score": 0.6842378973960876,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 15,
          "score": 0.6810904145240784,
          "doc_id": "JAKO201321353692848",
          "title": "빅데이터 개인정보 위험 분석 기술",
          "abstract": "본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353692848&target=NART&cn=JAKO201321353692848",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다."
        },
        {
          "rank": 16,
          "score": 0.6786494255065918,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 17,
          "score": 0.6765420436859131,
          "doc_id": "NPAP13087662",
          "title": "Cloud, Big Data & IoT: Risk Management",
          "abstract": "<P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13087662&target=NART&cn=NPAP13087662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management <P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>"
        },
        {
          "rank": 18,
          "score": 0.6763900518417358,
          "doc_id": "NART69876343",
          "title": "빅데이터 처리 프로세스 플랫폼 서비스 고찰",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69876343&target=NART&cn=NART69876343",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 <P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>"
        },
        {
          "rank": 19,
          "score": 0.6752808094024658,
          "doc_id": "JAKO201436351075064",
          "title": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구",
          "abstract": "정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201436351075064&target=NART&cn=JAKO201436351075064",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다."
        },
        {
          "rank": 20,
          "score": 0.6752011179924011,
          "doc_id": "JAKO201331935804086",
          "title": "빅데이터와 통계학",
          "abstract": "빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201331935804086&target=NART&cn=JAKO201331935804086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 통계학 빅데이터와 통계학 빅데이터와 통계학 빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다."
        },
        {
          "rank": 21,
          "score": 0.6743987798690796,
          "doc_id": "ATN0030204222",
          "title": "AHP를 활용한 빅데이터 역량모델 개발 연구",
          "abstract": "Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030204222&target=NART&cn=ATN0030204222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data."
        },
        {
          "rank": 22,
          "score": 0.6727218627929688,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 23,
          "score": 0.6712987422943115,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 24,
          "score": 0.6682546138763428,
          "doc_id": "NART89644555",
          "title": "Big Data Analytics in Medicine and Healthcare",
          "abstract": "<P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART89644555&target=NART&cn=NART89644555",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare <P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>"
        },
        {
          "rank": 25,
          "score": 0.6673059463500977,
          "doc_id": "JAKO202125761334616",
          "title": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구",
          "abstract": "4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125761334616&target=NART&cn=JAKO202125761334616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다."
        },
        {
          "rank": 26,
          "score": 0.6668658256530762,
          "doc_id": "JAKO202225947837166",
          "title": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구-",
          "abstract": "본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202225947837166&target=NART&cn=JAKO202225947837166",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다."
        },
        {
          "rank": 27,
          "score": 0.6623308658599854,
          "doc_id": "ATN0037467542",
          "title": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구",
          "abstract": "4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037467542&target=NART&cn=ATN0037467542",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다."
        },
        {
          "rank": 28,
          "score": 0.6604474782943726,
          "doc_id": "JAKO201713551814199",
          "title": "빅데이터와 U-City 서비스",
          "abstract": "소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713551814199&target=NART&cn=JAKO201713551814199",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다."
        },
        {
          "rank": 29,
          "score": 0.6604087948799133,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 30,
          "score": 0.658094584941864,
          "doc_id": "DIKO0015936637",
          "title": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구",
          "abstract": "시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015936637&target=NART&cn=DIKO0015936637",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다."
        },
        {
          "rank": 31,
          "score": 0.6579928398132324,
          "doc_id": "JAKO201607564005851",
          "title": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시",
          "abstract": "본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201607564005851&target=NART&cn=JAKO201607564005851",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다."
        },
        {
          "rank": 32,
          "score": 0.6579352617263794,
          "doc_id": "JAKO202323638418644",
          "title": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방",
          "abstract": "최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202323638418644&target=NART&cn=JAKO202323638418644",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다."
        },
        {
          "rank": 33,
          "score": 0.6573230624198914,
          "doc_id": "NART85081386",
          "title": "Searching for big data : How incumbents explore a possible adoption of big data technologies",
          "abstract": "<P><B>Abstract</B></P>  <P>Big data is often described as a new frontier of IT-enabled competitive advantage. A limited number of exemplary firms have been used recurrently in the big data debate to serve as successful illustrations of what big data technologies can offer. These firms are well-known, data-driven organizations that often, but not always, are born digital companies. Comparatively little attention has been paid to the challenges that many incumbent organizations face when they try to explore a possible adoption of such technologies. This study investigates how incumbents handle such an exploration and what challenges they face. Drawing on a four-year qualitative field study of four large Scandinavian firms, we are able to develop a typology of how incumbents handle the exploration of and resistance to adopting big data technologies. Directly affecting the incumbents&rsquo; exploration are two aspects that separate the adoption of big data technologies from that of other technologies. First, being an elusive concept, big data technologies can mean different things to different organizations. This makes the technologies difficult to explain before an investing body, while it simultaneously opens up possibilities for creative definitions. Second, big data technologies have a transformative effect on the organization of work in firms. This transformative capability will make managers wary as it might threaten their position in the firm, and it will create ripple effects, transforming other systems besides those directly connected to the technology.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We have developed a typology for how incumbent organizations handle the exploration of and resistance to big data technologies. </LI> <LI>  The typology is: (1) capitulation, (2) subterfuge, (3) expansion of an investment decision, and (4) normal investment decision. </LI> <LI>  Adoption of big data technologies is different than adoption of other technologies due to the elusiveness of the concept. </LI> <LI>  Adoption of big data technologies is different due to the transformative effect of them on the organization of work. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART85081386&target=NART&cn=NART85081386",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Searching for big data : How incumbents explore a possible adoption of big data technologies Searching for big data : How incumbents explore a possible adoption of big data technologies Searching for big data : How incumbents explore a possible adoption of big data technologies <P><B>Abstract</B></P>  <P>Big data is often described as a new frontier of IT-enabled competitive advantage. A limited number of exemplary firms have been used recurrently in the big data debate to serve as successful illustrations of what big data technologies can offer. These firms are well-known, data-driven organizations that often, but not always, are born digital companies. Comparatively little attention has been paid to the challenges that many incumbent organizations face when they try to explore a possible adoption of such technologies. This study investigates how incumbents handle such an exploration and what challenges they face. Drawing on a four-year qualitative field study of four large Scandinavian firms, we are able to develop a typology of how incumbents handle the exploration of and resistance to adopting big data technologies. Directly affecting the incumbents&rsquo; exploration are two aspects that separate the adoption of big data technologies from that of other technologies. First, being an elusive concept, big data technologies can mean different things to different organizations. This makes the technologies difficult to explain before an investing body, while it simultaneously opens up possibilities for creative definitions. Second, big data technologies have a transformative effect on the organization of work in firms. This transformative capability will make managers wary as it might threaten their position in the firm, and it will create ripple effects, transforming other systems besides those directly connected to the technology.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We have developed a typology for how incumbent organizations handle the exploration of and resistance to big data technologies. </LI> <LI>  The typology is: (1) capitulation, (2) subterfuge, (3) expansion of an investment decision, and (4) normal investment decision. </LI> <LI>  Adoption of big data technologies is different than adoption of other technologies due to the elusiveness of the concept. </LI> <LI>  Adoption of big data technologies is different due to the transformative effect of them on the organization of work. </LI> </UL> </P>"
        },
        {
          "rank": 34,
          "score": 0.6572386026382446,
          "doc_id": "JAKO202125659014584",
          "title": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구",
          "abstract": "모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659014584&target=NART&cn=JAKO202125659014584",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다."
        },
        {
          "rank": 35,
          "score": 0.6562097072601318,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 36,
          "score": 0.655281662940979,
          "doc_id": "JAKO201303840307260",
          "title": "빅데이터 패키지 선정 방법",
          "abstract": "빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303840307260&target=NART&cn=JAKO201303840307260",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다."
        },
        {
          "rank": 37,
          "score": 0.654913067817688,
          "doc_id": "JAKO201615262489668",
          "title": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향",
          "abstract": "정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201615262489668&target=NART&cn=JAKO201615262489668",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다."
        },
        {
          "rank": 38,
          "score": 0.6547596454620361,
          "doc_id": "ATN0025420762",
          "title": "의료기관 빅데이터 품질관리의 필요성과 사례 분석",
          "abstract": "The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420762&target=NART&cn=ATN0025420762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented."
        },
        {
          "rank": 39,
          "score": 0.6534019112586975,
          "doc_id": "JAKO201723954939431",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723954939431&target=NART&cn=JAKO201723954939431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다."
        },
        {
          "rank": 40,
          "score": 0.6505904197692871,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 41,
          "score": 0.6505794525146484,
          "doc_id": "NART76320729",
          "title": "Demystifying big data: Anatomy of big data developmental process",
          "abstract": "<P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART76320729&target=NART&cn=NART76320729",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process <P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>"
        },
        {
          "rank": 42,
          "score": 0.6504840850830078,
          "doc_id": "ATN0030112964",
          "title": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석",
          "abstract": "Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030112964&target=NART&cn=ATN0030112964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users."
        },
        {
          "rank": 43,
          "score": 0.6498556137084961,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 44,
          "score": 0.6485446691513062,
          "doc_id": "NART100569121",
          "title": "Financial risk assessment model based on big data",
          "abstract": "<P>Conventional financial risk assessment is not accurate and its adaptive assessment ability is low. In order to solve this problem, a financial risk assessment model based on big data is proposed. In this method, the quantitative analysis method is adopted to analyze the explanatory variable model and the control variable model of financial risk assessment. The market-to-book ratio, asset-liability ratio, cash flow ratio and financing structure model are adopted as constraint parameters to construct a big data analysis model for financial risk assessment. On this basis, the adaptive fuzzy weighted control method is adopted for information fusion of financial risk assessment data and big data classification, and the asset income control and innovative evaluation model are adopted for linear planning and square fitting during financial risk assessment. Based on the intervention factors of financial market participants, quantitative regression analysis is performed, and according to the economic game theory, big data analysis and prediction of financial risk assessment are performed through the regression analysis method. Then the big data fusion and clustering algorithms are adopted for financial risk assessment. The simulation results show that this method can provide a relatively high accuracy in financial risk assessment, and has relatively strong adaptive evaluation capability to the risk coefficient, so it has a good application value in the prevention and control of risk factors in financial systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART100569121&target=NART&cn=NART100569121",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Financial risk assessment model based on big data Financial risk assessment model based on big data Financial risk assessment model based on big data <P>Conventional financial risk assessment is not accurate and its adaptive assessment ability is low. In order to solve this problem, a financial risk assessment model based on big data is proposed. In this method, the quantitative analysis method is adopted to analyze the explanatory variable model and the control variable model of financial risk assessment. The market-to-book ratio, asset-liability ratio, cash flow ratio and financing structure model are adopted as constraint parameters to construct a big data analysis model for financial risk assessment. On this basis, the adaptive fuzzy weighted control method is adopted for information fusion of financial risk assessment data and big data classification, and the asset income control and innovative evaluation model are adopted for linear planning and square fitting during financial risk assessment. Based on the intervention factors of financial market participants, quantitative regression analysis is performed, and according to the economic game theory, big data analysis and prediction of financial risk assessment are performed through the regression analysis method. Then the big data fusion and clustering algorithms are adopted for financial risk assessment. The simulation results show that this method can provide a relatively high accuracy in financial risk assessment, and has relatively strong adaptive evaluation capability to the risk coefficient, so it has a good application value in the prevention and control of risk factors in financial systems.</P>"
        },
        {
          "rank": 45,
          "score": 0.647847056388855,
          "doc_id": "JAKO202111735182702",
          "title": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향",
          "abstract": "본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202111735182702&target=NART&cn=JAKO202111735182702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다."
        },
        {
          "rank": 46,
          "score": 0.6477837562561035,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 47,
          "score": 0.6477189064025879,
          "doc_id": "NART118817514",
          "title": "Ensuring the ethical use of big data: lessons from secure data access",
          "abstract": "<▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118817514&target=NART&cn=NART118817514",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access <▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>"
        },
        {
          "rank": 48,
          "score": 0.6466536521911621,
          "doc_id": "JAKO201726163273232",
          "title": "나이브 베이즈 빅데이터 분류기를 이용한 렌터카 교통사고 심각도 예측",
          "abstract": "교통사고는 인적요인, 차량요인, 환경요인이 복합적으로 작용하여 발생한다. 이 중 렌터카 교통사고는 운전자의 평소 익숙하지 않은 환경 등으로 인해 교통사고 발생 가능성과 심각도가 다른 교통사고와는 다를 것으로 예상된다. 이에 본 연구에서는 국내 대표 관광도시인 부산광역시, 강릉시, 제주시를 대상으로 최근 빅데이터 분석에 사용되는 기계학습 기법중 하나인 나이브 베이즈 분류기를 이용하여 렌터카 교통사고의 심각도를 예측하는 모형을 개발하였다. 또한, 기존 연구에 유의성이 검증된 변수와 수집 가능한 모든 변수를 이용하는 두 가지 모형에 대하여 모형의 예측 정확도를 비교하였다. 비교 결과 통계적 기법을 통해 유의성이 검증된 변수를 사용할 경우 모형이 더 높은 예측 정확도를 보이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163273232&target=NART&cn=JAKO201726163273232",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "나이브 베이즈 빅데이터 분류기를 이용한 렌터카 교통사고 심각도 예측 나이브 베이즈 빅데이터 분류기를 이용한 렌터카 교통사고 심각도 예측 나이브 베이즈 빅데이터 분류기를 이용한 렌터카 교통사고 심각도 예측 교통사고는 인적요인, 차량요인, 환경요인이 복합적으로 작용하여 발생한다. 이 중 렌터카 교통사고는 운전자의 평소 익숙하지 않은 환경 등으로 인해 교통사고 발생 가능성과 심각도가 다른 교통사고와는 다를 것으로 예상된다. 이에 본 연구에서는 국내 대표 관광도시인 부산광역시, 강릉시, 제주시를 대상으로 최근 빅데이터 분석에 사용되는 기계학습 기법중 하나인 나이브 베이즈 분류기를 이용하여 렌터카 교통사고의 심각도를 예측하는 모형을 개발하였다. 또한, 기존 연구에 유의성이 검증된 변수와 수집 가능한 모든 변수를 이용하는 두 가지 모형에 대하여 모형의 예측 정확도를 비교하였다. 비교 결과 통계적 기법을 통해 유의성이 검증된 변수를 사용할 경우 모형이 더 높은 예측 정확도를 보이는 것으로 나타났다."
        },
        {
          "rank": 49,
          "score": 0.6464262008666992,
          "doc_id": "ATN0025418068",
          "title": "도로 기상 빅데이터 유형별 활용 전략: 국내외 사례 분석",
          "abstract": "Weather acts through low visibility, precipitation, high winds, and temperature extremes to affect driver capabilities, vehicle performance (i.e., traction, stability and maneuverability), pavement friction, roadway infrastructure, crash risk, traffic flow, and agency productivity. Recently a variety of road weather big data sources such as CCTV, road sensor/systems, car sensor have been developed to solve the weather-related problems, This study identifies and defines the types and characteristics of these sources to suggest how to utilize them for car safety and efficiency as well as road management through analyzing domestic and oversea cases of road weather big data applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025418068&target=NART&cn=ATN0025418068",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "도로 기상 빅데이터 유형별 활용 전략: 국내외 사례 분석 도로 기상 빅데이터 유형별 활용 전략: 국내외 사례 분석 도로 기상 빅데이터 유형별 활용 전략: 국내외 사례 분석 Weather acts through low visibility, precipitation, high winds, and temperature extremes to affect driver capabilities, vehicle performance (i.e., traction, stability and maneuverability), pavement friction, roadway infrastructure, crash risk, traffic flow, and agency productivity. Recently a variety of road weather big data sources such as CCTV, road sensor/systems, car sensor have been developed to solve the weather-related problems, This study identifies and defines the types and characteristics of these sources to suggest how to utilize them for car safety and efficiency as well as road management through analyzing domestic and oversea cases of road weather big data applications."
        },
        {
          "rank": 50,
          "score": 0.6462080478668213,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        }
      ]
    },
    {
      "query": "각 빅데이터 처리 과정별 위험요인 유형의 우선순위는 어떻게 됩니까?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.865698516368866,
          "doc_id": "DIKO0013687737",
          "title": "빅데이터 처리 프로세스의 위험요인에 관한 연구",
          "abstract": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687737&target=NART&cn=DIKO0013687737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다."
        },
        {
          "rank": 2,
          "score": 0.8580745458602905,
          "doc_id": "ATN0030056853",
          "title": "빅데이터의 위험유형 분류에 관한 연구",
          "abstract": "본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030056853&target=NART&cn=ATN0030056853",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 빅데이터의 위험유형 분류에 관한 연구 본 연구는 빅데이터가 초래할 수 있는 다양한 위험들을 도출하고 이를 일정한 기준에 따라 분류함으로써 빅데이터의 위험에 대한 이해도를 높이고 정책적 대응 기반을 다지기 위한 목적으로 수행되었다. 먼저, 국내외의 선행연구를 통해서 빅데이터가 초래할 수 있는 20개의 실제적･잠재적 위험을 도출하였고, 이를 위험의 성격에 따라 기술적･인적･법제도적･경제적･사회문화적 위험의 5가지로 분류하였고, 위험의 심각성 기준에 따라 위험 심각성이 높음･보통･낮음 등 3가지 유형으로 분류하였으며, 최종적으로 2가지 기준 분류결과를 종합하여 2차원적 도표에 총 15가지의 유형으로 분류하였다. 분류결과 위험의 성격에 따른 5개 유형 중에서 위험의 심각성이 높아 정부가 가장 우선적으로 대응해야 할 위험으로는 기술적 위험에서는 해킹･사이버테러, 법제도적 위험에서는 개인정보(프라이버시) 침해인 것으로 나타났다. 기술적 위험 중에서 천재지변과 사고, 법제도적 위험 중에서 감시의 문제, 법제도적 충돌과 혼란, 경제적 위험 중에서 산업경쟁력 약화, 사회문화적 위험 중에서 빅데이터로 인한 사회적 병리현상 등도 정책적 우선순위가 높은 위험인 것으로 나타났다."
        },
        {
          "rank": 3,
          "score": 0.8134750127792358,
          "doc_id": "JAKO201424750260451",
          "title": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석",
          "abstract": "Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424750260451&target=NART&cn=JAKO201424750260451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석 Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk."
        },
        {
          "rank": 4,
          "score": 0.8110775351524353,
          "doc_id": "JAKO201914260900587",
          "title": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석",
          "abstract": "최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914260900587&target=NART&cn=JAKO201914260900587",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 빅데이터 프로젝트의 위험요인 식별과 우선순위 분석 최근 많은 기업들이 대용량의 빅데이터 분석을 통하여 신사업을 발굴하거나 경영 및 기술 전략의 전환에 앞서 명시적인 근거를 마련하기 위하여 빅데이터 분석 및 활용을 위한 프로젝트를 수행하고 있다. 그러나 다수의 빅데이터 프로젝트가 정해진 기한 내에 종료를 못하여 실패하고 있음이 국내외적 문제로 대두되고 있다. 이는 공학적 관점에서 빅데이터 프로젝트의 위험 관리를 위한 지식 기반이 매우 미흡한 현 상황과 무관하지 않다. 따라서 본 논문에서는 빅데이터 구축 및 활용 프로젝트의 위험 요인을 분석하고, 중요도가 높은 위험 요인들을 도출한다. 이를 위해 문헌 연구로부터 프로젝트 위험 요인을 추출하고 친화도 기법을 통해 그룹화한 후 전문가 설문을 통해 중요도가 높은 위험 요인을 도출한다. 도출된 요인들을 대상으로 요인분석을 통해 빅데이터 프로젝트의 위험요인 분류표를 도출한다. 본 연구는 빅데이터 프로젝트에 대한 위험 식별, 위험 평가, 위험 분석을 위한 가장 기초가 되는 통제 지표의 개발이라는 데 큰 의미가 있으며, 향후 빅데이터 프로젝트와 관련된 효율적인 위험 관리의 이론적 근거를 제공함으로써 성공적인 빅데이터 프로젝트를 견인하는데 기초자료로써 크게 기여할 것으로 사료된다."
        },
        {
          "rank": 5,
          "score": 0.7108762860298157,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 6,
          "score": 0.7107857465744019,
          "doc_id": "JAKO201814446221611",
          "title": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현",
          "abstract": "본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201814446221611&target=NART&cn=JAKO201814446221611",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 빅데이터 기반 재난 재해 위험도 분석 프레임워크 설계 및 구현 본 연구는 재난 재해 시 해당 지역의 취약성 및 재해 위험성분석을 보다 세밀하고 광범위한 분석을 진행하기 위하여 빅데이터 기반 재난 재해 위험도 분석 프레임워크를 제안하였다. 오픈소스 기반 재해 위험도 평가 분석 소프트웨어를 활용하여 대용량의 데이터가 단 시간 내에 처리될 수 있도록 분산 및 병렬처리가 가능한 프레임 워크를 소개한다. 제안하는 시스템의 재난재해 분석 성능평가 시 기존 시스템에 비해 빠른 분석 처리 성능 결과를 도출하였으며 재난 재해 상황 분석 및 재난 유형별 최적화된 의사결정을 지원하는데 주요 프레임워크로 활용될 수 있을 것이다. 본 연구를 통해 재난 재해 상황 시 정확한 판단과 분석과 효과적인 대응을 통한 사전대비가 가능할 것이며, 정확한 피해 산정 예측에 따른 신속한 대응이 가능하여 피해 규모를 최소화시키는데 기여할 수 있을 것이다."
        },
        {
          "rank": 7,
          "score": 0.7054591178894043,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 8,
          "score": 0.7014150619506836,
          "doc_id": "NART96173512",
          "title": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발",
          "abstract": "본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART96173512&target=NART&cn=NART96173512",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 빅데이터 처리 활용 및 머신러닝 기법 적용으로 인한 도로 손상 예측 모형 개발 본 연구는 운전자 및 보행자의 안전성을 확보하기 위해, 최근 사회적 중점사항으로 부상하고 있는 포트홀, 지반침하 및 도로함몰에 대한 예측모형을 개발하는 것에 그 목적을 두고 있다. 포트홀, 지반침하 및 도로함몰은 운전자의 안전성을 저해할 뿐만 아니라 2차 사고를 발생시킬 수 있으며, 나아가 경제적 손실, 국가적 이미지 실축 등의 다양한 문제를 야기시킬 수 있다. 이와 관련하여 본 연구에서는 국가적 예측모형의 확장을 위한 방안으로 최근 도로 파손이 가장 빈번하게 발생하는 지역을 대상으로 예측모형을 개발했다. 예측모형 개발에 있어서 빅데이터의 활용과 인공지능기술(AI, Artificial Intelligence)의 적용에 중점을 두었다. 세부적인 예측 모형을 개발하는 과정에서는 구축된 빅데이터에 역학적-확률적 접근방법을 적용하여 독립변수의 차원을 축소시켰으며, 이 데이터의 불확실성을 저감시킬 목적으로 데이터 표준화를 실시했다. 표준화과정을 거친 인자들을 이용하여 19가지의 알고리즘으로 구성된 머신러닝의 학습을 실시했으며, 최소 오차비교로 최적의 알고리즘을 구축했다. 그 결과, 다중회귀분석으로 수행된 포트홀 예측모형과 로버스트 회귀분석을 통한 지반침하 & 도로함몰 예측모형을 개발했다. 이 예측 모형은 각각 70% 및 73%의 정확성을 가지고 있는 것으로 판단되었다."
        },
        {
          "rank": 9,
          "score": 0.7009345293045044,
          "doc_id": "NPAP12215574",
          "title": "Toward big data risk analysis",
          "abstract": "<P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12215574&target=NART&cn=NPAP12215574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Toward big data risk analysis Toward big data risk analysis Toward big data risk analysis <P>The advent of social networks and Internet-of-Things has resulted in unprecedented capability of collecting, sharing and analyzing massive amounts of data. From a security perspective, Big Data may seriously weaken confidentiality, as techniques for improving Big Data analytics performance-including early fusion of heterogeneous data sources - increase the hidden redundancy of data representation, generating ill-protected copies. This gray area of redundancy triggers new disclosure threats that challenge traditional techniques to protect privacy and confidentiality. This position paper starts by proposing a definition of the Big Data Leak threat (as opposed to the one of data breach) and its role as a component of disclosure risk. Then, it discusses how a paradigm of Known, Detect, Contain and Recover could be used to establish Big Data security practices for containing disclosure risks connected to Big Data analytics.</P>"
        },
        {
          "rank": 10,
          "score": 0.6979561448097229,
          "doc_id": "ATN0037494703",
          "title": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연",
          "abstract": "인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037494703&target=NART&cn=ATN0037494703",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 빅데이터 분석을 통한 인공지능 오용 사례에 대한 연 인간의 사고능력을 컴퓨터로 구현한 인공지능이 4차 산업혁명의 핵심 경쟁력으로 부상하였다. 다양한 영역에서 인공지능의 적용과 사용이 빠른 속도로 증가하고 있지만, 생명을 위협하거나 편견을 전파하고 심각한 사회적인 피해를 초래하는 인공지능 기술의 역기능이 발생하며 인공지능 기술은 양날의 검으로 인식되고 있다. 이에 따라 인공지능의 위험 완화를 위한 규제가 필요하게 되었다. 본 논문에서는 인공지능의 위험 완화 규제 체제 마련의 근거가 될 수 있는 라이브러리 구축을 위해 여러 국가의 다양한 분야에서 인공지능의 악의적인 사용과 사회적 위협에 대한 사례들에 대한 연구를 수행하였다. 한국, 미국, 영국, 중국 등의 국가에서 여러 사회영역에서의 인공지능의 악의적인 사용과 사회적 위협에 대한 실제 사례에 대한 데이터를 수집 및 분석하여 시각화 하였다."
        },
        {
          "rank": 11,
          "score": 0.6979280114173889,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 12,
          "score": 0.6947759389877319,
          "doc_id": "NART78301306",
          "title": "Advances in Risk Analysis with Big Data",
          "abstract": "<P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78301306&target=NART&cn=NART78301306",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data Advances in Risk Analysis with Big Data <P>With cloud computing, Internet&#8208;of&#8208;things, wireless sensors, social media, fast storage and retrieval, etc., organizations and enterprises have access to unprecedented amounts and varieties of data. Current risk analysis methodology and applications are experiencing related advances and breakthroughs. For example, highway operations data are readily available, and making use of them reduces risks of traffic crashes and travel delays. Massive data of financial and enterprise systems support decision making under risk by individuals, industries, regulators, etc. In this introductory article, we first discuss the meaning of big data for risk analysis. We then examine recent advances in risk analysis with big data in several topic areas. For each area, we identify and introduce the relevant articles that are featured in the special issue. We conclude with a discussion on future research opportunities.</P>"
        },
        {
          "rank": 13,
          "score": 0.6933765411376953,
          "doc_id": "ATN0030204222",
          "title": "AHP를 활용한 빅데이터 역량모델 개발 연구",
          "abstract": "Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030204222&target=NART&cn=ATN0030204222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data."
        },
        {
          "rank": 14,
          "score": 0.6930232048034668,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 15,
          "score": 0.6920591592788696,
          "doc_id": "JAKO201303840307260",
          "title": "빅데이터 패키지 선정 방법",
          "abstract": "빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201303840307260&target=NART&cn=JAKO201303840307260",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 패키지 선정 방법 빅데이터 분석은 데이터의 양, 처리속도, 다양성 측면에서 데이터 마이닝과 달리 문제해결과 의사결정을 위해서는 새로운 도구를 필요로 한다. 많은 글로벌 IT기업들은 사용하기 쉽고 기능성이 우수한 모델링 능력을 가진 다양한 빅데이터 제품을 출시하고 있다. 빅데이터 패키지는 분석도구, 인프라, 플랫폼 형태로 하드웨어와 소프트웨어를 포함한 솔루션이다. 빅데이터의 수집, 저장, 분석, 시각화가 가능한 제품이다. 빅데이터 패키지는 업체별로 제품 종류가 많고 복잡한 기능을 가질 뿐만 아니라 선정에 있어서 전문 지식을 필요로 하며 일반적인 소프트웨어 패키지보다 그 중요성이 높기 때문에 의사결정 방법의 개발이 요구된다. 본 연구는 빅데이터 패키지 도입을 위한 의사결정지원방법을 제안하는 것이 목표이다. 문헌적 고찰을 통하여 빅데이터 패키지의 특징과 기능을 비교하고, 선정기준을 제안한다. 패키지 도입 타당성을 평가하기 위하여 비용과 혜택 각각을 목표노드로 하는 AHP 모델 및 선정기준을 목표노드로 하는 AHP 모델을 제안하고 이들을 결합하여 최적의 패키지를 선정하는 과정을 보인다."
        },
        {
          "rank": 16,
          "score": 0.6830633878707886,
          "doc_id": "JAKO202125659014584",
          "title": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구",
          "abstract": "모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659014584&target=NART&cn=JAKO202125659014584",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 빅데이터 컴퓨팅을 위한 분석기법에 관한 연구 모바일 컴퓨팅과 클라우드 컴퓨팅 기술 그리고 소셜 네트워크 서비스의 급속한 발전과 더불어, 우리들은 시시각각 양산되고 있는 데이터의 홍수 속에서 살고 있으며, 이러한 대규모의 데이터는 매우 가치가 높은 중요한 정보를 품고 있다는 사실을 알게 되었다. 하지만 빅데이터는 잠재적인 유용한 가치와 치명적인 위험을 모두 가지고 있으며 오늘날 이러한 빅데이터로부터 유용한 정보를 효율적으로 추출해 내고 잠재된 정보를 효과적으로 활용하기 위한 연구와 응용이 활발하게 이루어지고 있는 상황이다. 여기서 빅데이터 컴퓨팅 과정 중 무엇보다도 중요한 것은 대용량 데이터로부터 유용하고 귀중한 정보를 효율적으로 추출해 낼 수 있는 적절한 데이터 분석기법을 찾아 적용하는 것이다. 본 연구에서는 이러한 빅데이터 컴퓨팅을 효율적으로 수행하여 원하는 유용한 정보를 추출할 수 있는 기존의 다양한 빅데이터 분석기법들을 조사하여, 그 특징과 장&#x00B7;단점 등을 비교 분석하고, 특별한 상황에서 빅데이터 분석기법을 이용하여 유용한 정보를 효율적으로 추출해 내고, 이들 잠재된 정보를 효과적으로 활용할 수 있도록 하는 방안을 제시하고자 한다."
        },
        {
          "rank": 17,
          "score": 0.6815282106399536,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 18,
          "score": 0.681203305721283,
          "doc_id": "JAKO201436351075064",
          "title": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구",
          "abstract": "정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201436351075064&target=NART&cn=JAKO201436351075064",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다."
        },
        {
          "rank": 19,
          "score": 0.6809564828872681,
          "doc_id": "NPAP13087662",
          "title": "Cloud, Big Data & IoT: Risk Management",
          "abstract": "<P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13087662&target=NART&cn=NPAP13087662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management Cloud, Big Data & IoT: Risk Management <P>The heart of research pumps for analyzing risks in today&#x2019;s competitive business environment where big, massive computations are performed on interconnected devices pervasively. Advanced computing environments i.e. Cloud, big data and Internet of things are taken under consideration for finding and analyzing business risks developed from evolutionary, interoperable and digital devices communications with massive volume of data generated. Various risks in advanced computational environment have been identified in this research and are provided with risks mitigation strategies. We have also focused on how risk management affects these environments and how that effect can be mitigated for software and business quality improvement.</P>"
        },
        {
          "rank": 20,
          "score": 0.6790710091590881,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 21,
          "score": 0.6785469055175781,
          "doc_id": "JAKO202225947837166",
          "title": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구-",
          "abstract": "본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202225947837166&target=NART&cn=JAKO202225947837166",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 빅데이터 분석에 기반한 아동학대의 이해 -머신러닝 알고리즘 개발 기초연구- 본 연구의 목적은 아동학대 예방을 위한 방안 마련의 일환으로 빅데이터 분석과 머신러닝 알고리즘을 활용한 정책개발의 기초자료를 제공하는데 있다. 아동학대 예방을 위한 머신러닝 알고리즘 개발을 위한 빅데이터 분석을 위해 학술데이터베이스와 사회관계망서비스 자료를 빅데이터로 정의하고 빈도, 연관어, 감성분석을 시행하였다. 연구결과 예방적 아동학대 알고리즘은 학술빅데이터 분석에 나타난 아동학대 관련 세 주체 피해아동, 가해양육자, 정부당국의 관점에서 아동학대 예방을 위한 데이터 수집 및 공유 네트워크 시스템 마련을 통해 개발이 가능할 것이다. 또한 아동학대 피해아동의 특성에서 자아개념 저하 등으로 우울 및 불안이 나타남을 단서로 영유아 자아존중감 및 우울, 불안 검사를 제도화함으로써 가능할 것이다. 아동학대 예방을 위한 빅데이터 수집 및 분석, 알고리즘 개발 연구의 지속적 진행을 제안하며 아동학대 예방을 위한 실효적 정책 마련이 실현되어 아동학대범죄가 근절되기를 기대한다."
        },
        {
          "rank": 22,
          "score": 0.6768398880958557,
          "doc_id": "JAKO201331935804086",
          "title": "빅데이터와 통계학",
          "abstract": "빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201331935804086&target=NART&cn=JAKO201331935804086",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 통계학 빅데이터와 통계학 빅데이터와 통계학 빅데이터 시대를 맞이하여 통계학과 통계학자의 역할에 대하여 살펴본다. 빅데이터에 대한 정의 및 응용분야를 살펴보고, 빅데이터 자료의 통계학적 특징들 및 이와 관련한 통계학적 의의에 대해서 설명한다. 빅데이터 자료 분석에 유용하게 사용되는 통계적 방법론들에 대해서 살펴보고, 국외와 국내의 빅데이터 관련 프로젝트를 소개한다."
        },
        {
          "rank": 23,
          "score": 0.6766785979270935,
          "doc_id": "JAKO201713551814199",
          "title": "빅데이터와 U-City 서비스",
          "abstract": "소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713551814199&target=NART&cn=JAKO201713551814199",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다."
        },
        {
          "rank": 24,
          "score": 0.6743217706680298,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 25,
          "score": 0.6739108562469482,
          "doc_id": "JAKO201529539328679",
          "title": "소셜 빅데이터를 활용한 담배 위험 예측",
          "abstract": "본 연구는 국내의 블로그, 카페, SNS 등 인터넷을 통해 수집된 소셜 빅데이터를 데이터마이닝 분석 기법을 적용하여 우리나라 국민의 담배에 대한 위험요인을 예측하고자 하였다. 주요분석 결과는 다음과 같다. 첫째, 온라인상에 '담뱃값인상'이 언급될 경우 담배에 대한 일반군 (negative)이 58.6%에서 74.8%로 증가하며, '폐암'이 언급될 경우 73.1%로 증가하는 것으로 나타났다. 둘째, 담뱃값인상 이후 담배에 대한 위험군 (positive)은 5.6% 감소하고, 일반군은 6.1% 증가한 것으로 나타났다. 셋째, 'FCTC, 담뱃값인상, 금연관련법, 흡연규제, 금연광고, 금연사업'과 관련된 정책이 온라인상에 많이 언급될수록 담배에 대한 위험군이 감소하는 것으로 나타났다. 마지막으로 '금연약, 금연패치, 금연껌'이 온라인 상에 언급될수록 담배에 대한 위험군이 감소하나, '전자담배와 보조제'가 온라인상에 언급될수록 담배에 대한 위험군을 증가시키는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201529539328679&target=NART&cn=JAKO201529539328679",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소셜 빅데이터를 활용한 담배 위험 예측 소셜 빅데이터를 활용한 담배 위험 예측 소셜 빅데이터를 활용한 담배 위험 예측 본 연구는 국내의 블로그, 카페, SNS 등 인터넷을 통해 수집된 소셜 빅데이터를 데이터마이닝 분석 기법을 적용하여 우리나라 국민의 담배에 대한 위험요인을 예측하고자 하였다. 주요분석 결과는 다음과 같다. 첫째, 온라인상에 '담뱃값인상'이 언급될 경우 담배에 대한 일반군 (negative)이 58.6%에서 74.8%로 증가하며, '폐암'이 언급될 경우 73.1%로 증가하는 것으로 나타났다. 둘째, 담뱃값인상 이후 담배에 대한 위험군 (positive)은 5.6% 감소하고, 일반군은 6.1% 증가한 것으로 나타났다. 셋째, 'FCTC, 담뱃값인상, 금연관련법, 흡연규제, 금연광고, 금연사업'과 관련된 정책이 온라인상에 많이 언급될수록 담배에 대한 위험군이 감소하는 것으로 나타났다. 마지막으로 '금연약, 금연패치, 금연껌'이 온라인 상에 언급될수록 담배에 대한 위험군이 감소하나, '전자담배와 보조제'가 온라인상에 언급될수록 담배에 대한 위험군을 증가시키는 것으로 나타났다."
        },
        {
          "rank": 26,
          "score": 0.6737267971038818,
          "doc_id": "JAKO201321353692848",
          "title": "빅데이터 개인정보 위험 분석 기술",
          "abstract": "본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353692848&target=NART&cn=JAKO201321353692848",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 빅데이터 개인정보 위험 분석 기술 본 논문은 온라인에 공개된 다양한 개인정보의 위험도를 분석하는 기술을 제안한다. 인터넷, SNS에 공개된 다양한 데이터를 수집, 분석하여 개인성향을 파악하고 타겟팅하는 가운데, 분산된 정보를 조합하고 추론하면 공개자의 의도와는 달리 신상이나 민감정보가 노출될 가능성이 크다. 본 논문에서는 이러한 데이터 수집 및 분석을 직접 수행하여 개인정보의 위험도를 분석할 수 있는 기술을 제안한다. 제안 기술이 개발되면, 개인정보 위험도에 따른 클라이언트, 웹사이트, 인터넷 전체 규모의 프라이버시 필터링이 가능해질 것으로 기대된다."
        },
        {
          "rank": 27,
          "score": 0.6736041307449341,
          "doc_id": "JAKO202125761334616",
          "title": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구",
          "abstract": "4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125761334616&target=NART&cn=JAKO202125761334616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다."
        },
        {
          "rank": 28,
          "score": 0.6727973818778992,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 29,
          "score": 0.672768235206604,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 30,
          "score": 0.6675136089324951,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 31,
          "score": 0.6673223972320557,
          "doc_id": "JAKO201723954939431",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723954939431&target=NART&cn=JAKO201723954939431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다."
        },
        {
          "rank": 32,
          "score": 0.6672203540802002,
          "doc_id": "JAKO202323638418644",
          "title": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방",
          "abstract": "최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202323638418644&target=NART&cn=JAKO202323638418644",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 하이브리드 빅데이터 분석을 통한 홍수 재해 예측 및 예방 최근에 우리나라에서 뿐만 아니라, 세계 곳곳에서 태풍, 산불, 장마 등으로 인한 재해가 끊이지 않고 있고, 우리나라 태풍 및 호우로 인한 재산 피해액만 1조원이 넘고 있다. 이러한 재난으로 인해 많은 인명 및 물적 피해가 발생하고, 복구하는 데도 상당한 기간이 걸리며, 정부 예비비도 부족한 실정이다. 이러한 문제점들을 사전에 예방하고 효과적으로 대응하기 위해서는 우선 정확한 데이터를 실시간 수집하고 분석하는 작업이 필요하다. 그러나, 센서들이 위치한 환경, 통신 네트워크 및 수신 서버들의 상황에 따라 지연 및 데이터 손실 등이 발생할 수 있다. 따라서, 본 논문에서는 이러한 통신네트워크 상황에서도 분석을 정확하게 할 수 있는 2단계 하이브리드 상황 분석 및 예측 알고리즘을 제안한다. 1단계에서는 이기종의 다양한 센서로부터 강, 하천, 수위 및 경사지의 경사각 데이터를 수집/필터링/정제하여 빅데이터 DB에 저장하고, 인공지능 규칙기반 추론 알고리즘을 적용하여, 위기 경보 4단계를 판단한다. 강수량이 일정값 이상인데도 불구하고 1단계 결과가 관심 이하 단계에 있으면, 2단계 딥러닝 영상 분석을 수행한 후 최종 위기 경보단계를 결정한다."
        },
        {
          "rank": 33,
          "score": 0.6651220917701721,
          "doc_id": "NART69876343",
          "title": "빅데이터 처리 프로세스 플랫폼 서비스 고찰",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69876343&target=NART&cn=NART69876343",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 빅데이터 처리 프로세스 플랫폼 서비스 고찰 <P>&amp;nbsp;&amp;nbsp;최근 우리 생활 주변에서는 무수한 데이터들이 발생하고 있다. 이같은 이유는 스마트폰의 대중화현상으로부터 시작되었지만 추가적으로 태블릿 pc 및 게임기등과 같은 디바이스들에서 만들어지는 데이터들도 무수히 증가하고 있는 상황이다. 또한 IT 기술을 이용한 융합화가 가속화되면서 이에 따른 새로운 데이터들도 생성되고 있다. 현재 다양한 분야에서 이러한 빅데이터를 활용하여 새로운 가치 창출을 이루고자 하고 있다. 본고에서는 이러한 빅데이터를 처리하고 있는 처리 프로세스와 관련된 플랫폼 서비스들에 대한 현황을 고찰하였다.</P>"
        },
        {
          "rank": 34,
          "score": 0.6647118330001831,
          "doc_id": "JAKO201615262489668",
          "title": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향",
          "abstract": "정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201615262489668&target=NART&cn=JAKO201615262489668",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 빅데이터 환경에서 분석 자원이 기업 성과에 미치는 영향 정보기술 발전은 기업이 보유하고 있는 다양한 구조 및 비구조 데이터를 관리할 수 있게 하였다. 이러한 빅데이터 활용은 기업의 새로운 비즈니스 핵심가치로 평가 받고 있다. 본 연구에서는 빅데이터로 인해 더욱 중요하게 평가받는 데이터 자원이 기업 분석 활용에 미치는 영향을 연구하고자 한다. 최신 해외 보고서들을 살펴보면, 빅데이터 활용성과에 대한 실증 연구를 보여주고 있다. 이러한 해외 실증 연구와 비교하여 국내 기업의 빅데이터 활용 특성을 분석하고자 한다. 본 연구 결과는 향후 빅데이터 활용 기업에 적용 가능한 성숙모형 개발에 도움을 줄 수 있을 것이다."
        },
        {
          "rank": 35,
          "score": 0.6632584929466248,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 36,
          "score": 0.6624600887298584,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 37,
          "score": 0.6614431142807007,
          "doc_id": "JAKO201529539328686",
          "title": "자연재해 분석을 위한 빅데이터 마이닝 기술",
          "abstract": "자연재해 빅데이터 분석은 현재 소셜 미디어 데이터 등 텍스트 데이터를 중심으로 시작되고 있으며 이는 재난관리의 네 단계인 예방, 대비, 대응, 복구에서 마지막 두 단계에 주로 해당된다. 반면 기상 데이터 자체에 대한 빅데이터 분석은 사전 관리에 해당하는 예방, 대비 단계에 활용될 수 있어 이와 관련한 연구 사례에 대한 체계적인 정리가 필요하다. 본 논문은 리뷰 논문으로서, 자연재해 영역에서 텍스트 데이터 외의 빅데이터를 다루는 분석 기술들에 대해 소개한다. 이를 위해 기상 관련 분야에서 사용되고 있는 데이터 마이닝 및 기계 학습 기술들을 살피고 각 기상 데이터의 특성에 맞춰 기존의 기술들이 어떻게 변형되는 지 밝힌다. 우선 2절에서 빅데이터, 데이터 마이닝, 기계 학습에 대한 기본 개념을 설명하고 3절에서 데이터 마이닝 및 기계 학습 기술의 실제 적용 사례를 상세히 정리한다. 4절에서는 자연재해 대응에 이러한 기술들이 직접 활용되는 예를 소개하고 마지막에 결론으로 마무리한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201529539328686&target=NART&cn=JAKO201529539328686",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 분석을 위한 빅데이터 마이닝 기술 자연재해 빅데이터 분석은 현재 소셜 미디어 데이터 등 텍스트 데이터를 중심으로 시작되고 있으며 이는 재난관리의 네 단계인 예방, 대비, 대응, 복구에서 마지막 두 단계에 주로 해당된다. 반면 기상 데이터 자체에 대한 빅데이터 분석은 사전 관리에 해당하는 예방, 대비 단계에 활용될 수 있어 이와 관련한 연구 사례에 대한 체계적인 정리가 필요하다. 본 논문은 리뷰 논문으로서, 자연재해 영역에서 텍스트 데이터 외의 빅데이터를 다루는 분석 기술들에 대해 소개한다. 이를 위해 기상 관련 분야에서 사용되고 있는 데이터 마이닝 및 기계 학습 기술들을 살피고 각 기상 데이터의 특성에 맞춰 기존의 기술들이 어떻게 변형되는 지 밝힌다. 우선 2절에서 빅데이터, 데이터 마이닝, 기계 학습에 대한 기본 개념을 설명하고 3절에서 데이터 마이닝 및 기계 학습 기술의 실제 적용 사례를 상세히 정리한다. 4절에서는 자연재해 대응에 이러한 기술들이 직접 활용되는 예를 소개하고 마지막에 결론으로 마무리한다."
        },
        {
          "rank": 38,
          "score": 0.6613348126411438,
          "doc_id": "NART76320729",
          "title": "Demystifying big data: Anatomy of big data developmental process",
          "abstract": "<P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART76320729&target=NART&cn=NART76320729",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process Demystifying big data: Anatomy of big data developmental process <P>This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved.</P>"
        },
        {
          "rank": 39,
          "score": 0.6606911420822144,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 40,
          "score": 0.66042160987854,
          "doc_id": "NART100569121",
          "title": "Financial risk assessment model based on big data",
          "abstract": "<P>Conventional financial risk assessment is not accurate and its adaptive assessment ability is low. In order to solve this problem, a financial risk assessment model based on big data is proposed. In this method, the quantitative analysis method is adopted to analyze the explanatory variable model and the control variable model of financial risk assessment. The market-to-book ratio, asset-liability ratio, cash flow ratio and financing structure model are adopted as constraint parameters to construct a big data analysis model for financial risk assessment. On this basis, the adaptive fuzzy weighted control method is adopted for information fusion of financial risk assessment data and big data classification, and the asset income control and innovative evaluation model are adopted for linear planning and square fitting during financial risk assessment. Based on the intervention factors of financial market participants, quantitative regression analysis is performed, and according to the economic game theory, big data analysis and prediction of financial risk assessment are performed through the regression analysis method. Then the big data fusion and clustering algorithms are adopted for financial risk assessment. The simulation results show that this method can provide a relatively high accuracy in financial risk assessment, and has relatively strong adaptive evaluation capability to the risk coefficient, so it has a good application value in the prevention and control of risk factors in financial systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART100569121&target=NART&cn=NART100569121",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Financial risk assessment model based on big data Financial risk assessment model based on big data Financial risk assessment model based on big data <P>Conventional financial risk assessment is not accurate and its adaptive assessment ability is low. In order to solve this problem, a financial risk assessment model based on big data is proposed. In this method, the quantitative analysis method is adopted to analyze the explanatory variable model and the control variable model of financial risk assessment. The market-to-book ratio, asset-liability ratio, cash flow ratio and financing structure model are adopted as constraint parameters to construct a big data analysis model for financial risk assessment. On this basis, the adaptive fuzzy weighted control method is adopted for information fusion of financial risk assessment data and big data classification, and the asset income control and innovative evaluation model are adopted for linear planning and square fitting during financial risk assessment. Based on the intervention factors of financial market participants, quantitative regression analysis is performed, and according to the economic game theory, big data analysis and prediction of financial risk assessment are performed through the regression analysis method. Then the big data fusion and clustering algorithms are adopted for financial risk assessment. The simulation results show that this method can provide a relatively high accuracy in financial risk assessment, and has relatively strong adaptive evaluation capability to the risk coefficient, so it has a good application value in the prevention and control of risk factors in financial systems.</P>"
        },
        {
          "rank": 41,
          "score": 0.6601138114929199,
          "doc_id": "DIKO0015936637",
          "title": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구",
          "abstract": "시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015936637&target=NART&cn=DIKO0015936637",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다."
        },
        {
          "rank": 42,
          "score": 0.6597979068756104,
          "doc_id": "JAKO201616363646697",
          "title": "빅데이터 보안 분야의 연구동향 분석",
          "abstract": "본 연구의 목적은 빅데이터 보안 분야의 기존 연구를 분석하고, 향후 연구 방향을 모색하는 것이다. 이를 위해 국내외의 총62편의 논문을 식별하여, 발간년도, 게재 매체, 전반적인 연구접근 방법, 세부적 연구 방법, 연구 주제 등을 분석하였다. 분석 결과, 빅데이터 보안 연구는 매우 초기 단계로서, 비실증 연구가 압도적인 비중을 차지하고 있고, 관련 개념/기법에 대한 이해를 해나가는 과정으로서 기술-관리-통합의 단계로 진화한 정보보안 분야의 연구 동향에 동조하여 기술적인 연구가 주로 진행되고 있다. 연구 주제 측면에서도 빅데이터 보안에 대한 전반적인 이슈를 다룬 총론적인 연구들이 보안 구현 방법론, 분야별 이슈 등의 각론적 연구에 비해 높은 비중을 나타내는 등 초기 단계의 모습을 나타내고 있다. 향후 유망한 연구 분야로는 빅데이터 보안에 대한 전반적인 프레임워크 수립, 업종별 빅데이터 보안에 대한 연구, 빅데이터 보안 관련 정부 정책 분석 등을 들 수 있다. 빅데이터 보안 분야의 연구는 본격적으로 시작된 지 얼마 되지 않아, 연구 결과가 상대적으로 매우 부족한 편이다. 앞으로 다양한 관점에서 빅데이터 보안과 관련해 풍부한 주제를 다루는 연구가 진행되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201616363646697&target=NART&cn=JAKO201616363646697",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 보안 분야의 연구동향 분석 빅데이터 보안 분야의 연구동향 분석 빅데이터 보안 분야의 연구동향 분석 본 연구의 목적은 빅데이터 보안 분야의 기존 연구를 분석하고, 향후 연구 방향을 모색하는 것이다. 이를 위해 국내외의 총62편의 논문을 식별하여, 발간년도, 게재 매체, 전반적인 연구접근 방법, 세부적 연구 방법, 연구 주제 등을 분석하였다. 분석 결과, 빅데이터 보안 연구는 매우 초기 단계로서, 비실증 연구가 압도적인 비중을 차지하고 있고, 관련 개념/기법에 대한 이해를 해나가는 과정으로서 기술-관리-통합의 단계로 진화한 정보보안 분야의 연구 동향에 동조하여 기술적인 연구가 주로 진행되고 있다. 연구 주제 측면에서도 빅데이터 보안에 대한 전반적인 이슈를 다룬 총론적인 연구들이 보안 구현 방법론, 분야별 이슈 등의 각론적 연구에 비해 높은 비중을 나타내는 등 초기 단계의 모습을 나타내고 있다. 향후 유망한 연구 분야로는 빅데이터 보안에 대한 전반적인 프레임워크 수립, 업종별 빅데이터 보안에 대한 연구, 빅데이터 보안 관련 정부 정책 분석 등을 들 수 있다. 빅데이터 보안 분야의 연구는 본격적으로 시작된 지 얼마 되지 않아, 연구 결과가 상대적으로 매우 부족한 편이다. 앞으로 다양한 관점에서 빅데이터 보안과 관련해 풍부한 주제를 다루는 연구가 진행되기를 기대한다."
        },
        {
          "rank": 43,
          "score": 0.6593629121780396,
          "doc_id": "NART89644555",
          "title": "Big Data Analytics in Medicine and Healthcare",
          "abstract": "<P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART89644555&target=NART&cn=NART89644555",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare <P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>"
        },
        {
          "rank": 44,
          "score": 0.659327507019043,
          "doc_id": "ATN0037467542",
          "title": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구",
          "abstract": "4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037467542&target=NART&cn=ATN0037467542",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 국방 IT 융합 실험 프로그램의 위험관리 요인에 대한 탐색적 연구 4차 산업혁명의 영향으로 국방에서는 IT 기술을 다양한 무기 및 비무기체계에 융합하여 혁신을 추구하고 있고 융합의 대상과 규모가 확대되고 있다. 위험을 식별하고 관리하는 것은 프로젝트 관리의 관점에서 성과를 달성하기 위해 프로젝트를 성공적으로 종료하는 데 중요한 요소이다. 본 연구는 국방 IT 융합실험 프로그램의 위험관리 요소를 파악하고 체계적으로 관리하기 위해 핵심전문가들과 면담를 통한 연구이다. 국방 IT 융합실험 프로그램의 위험관리 요소는 거버넌스 위험요소, 내부 위험요소 및 외부 위험요소로 분류되며 거버넌스 위험요소는 내부 위험 요소에 영향을 미치는 것으로 식별되었다. 본 연구는 국방 IT 융합실험 프로그램 수행에 있어 위험요인의 영향을 분석하기 위한 향후 연구방향을 제시한다."
        },
        {
          "rank": 45,
          "score": 0.6589871644973755,
          "doc_id": "JAKO202111735182702",
          "title": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향",
          "abstract": "본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202111735182702&target=NART&cn=JAKO202111735182702",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 빅데이터 분석능력과 가치가 비즈니스 성과에 미치는 영향 본 연구는 기업의 빅데이터 분석가들을 대상으로 빅데이터의 분석능력과 가치, 그리고 비즈니스 성과와의 관련성을 살펴보았다. 빅데이터가 가져올 수 있는 가치를 거래적 가치, 전략적 가치, 변혁적 가치, 정보적 가치로 분류하였고, 이러한 가치들이 비즈니스 성과로 연결되는 지를 검증하고자 하였다. 빅데이터 분석을 수행한 경험이 있는 직원들을 대상으로 200부의 설문을 수거하여 분석하였다. 구조방정식 모형으로 가설을 검정하였고, 빅데이터 분석능력은 빅데이터의 가치와 비즈니스 성과에 의미있는 영향력을 미치는 것으로 나타났다. 빅데이터 가치들 중에서 거래적 가치, 전략적 가치, 그리고 변혁적 가치는 비즈니스 성과에 긍정적인 영향을 미치지만, 정보적 가치의 영향은 입증되지 않았다. 본 연구의 결과는 빅데이터를 활용하여 비즈니스 성과를 얻으려는 기업들에게 유용한 정보를 제공할 수 있을 것으로 기대된다."
        },
        {
          "rank": 46,
          "score": 0.6576834917068481,
          "doc_id": "NART118817514",
          "title": "Ensuring the ethical use of big data: lessons from secure data access",
          "abstract": "<▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118817514&target=NART&cn=NART118817514",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access Ensuring the ethical use of big data: lessons from secure data access <▼1><P>Big data holds great potential for research and for society, large volumes of varied data can be produced and made available to researchers much faster compared to &lsquo;traditional&rsquo; data. Whilst this potential is recognized, there are ethical concerns which users of big data must consider. With the volume and variety of information in big data, comes a greater risk of disclosure. Researchers and data access services working with highly detailed and sensitive, secure data have grappled with this for many years. The sector has developed both ethical frameworks and statistical disclosure control techniques which could be utilized by those working with big data. We discuss the challenges, present some of the frameworks and techniques and conclude with recommendations for secure data access of big data.</P></▼1><▼2><P>Big data, Secure data access, Statistical disclosure control.</P></▼2>"
        },
        {
          "rank": 47,
          "score": 0.6574763059616089,
          "doc_id": "JAKO201607564005851",
          "title": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시",
          "abstract": "본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201607564005851&target=NART&cn=JAKO201607564005851",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 개인정보 보안강화 및 빅데이터 활성화를 위한 새로운 빅데이터 플랫폼 제시 본 논문에서는 국내외에서 발표된 빅데이터 플랫폼을 조사 및 분석하였다. 분석결과 각 플랫폼에서 개인정보보안에 문제점이 있었다. 특히 빅데이터 플랫폼에 많이 사용되는 대표적인 NoSQL DB인 HBase에 저장된 빅데이터 개인정보 암호화의 취약점과, DB에 저장된 데이터를 암 복호화 할 때에 시스템에 부하가 발생하는 것이다. 이에 본 논문에서는 HBase의 암호화 방법, 암 복호화시 시스템 및 네트워크 통신의 부하를 경감시키는 방안과 빅데이터 플랫폼의 각 단계에 개인정보관리체계(PIMS)를 적용하는 방안을 제시한다. 그리고 이것이 반영된 새로운 빅데이터 플랫폼을 제안한다. 따라서 제안된 빅데이터 플랫폼은 개인정보보안강화 및 시스템 성능의 효율성 확보로 빅데이터 사용의 활성화에 크게 기여할 것이라 판단된다."
        },
        {
          "rank": 48,
          "score": 0.6562501788139343,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 49,
          "score": 0.655521810054779,
          "doc_id": "JAKO202032362242335",
          "title": "국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론",
          "abstract": "국내 전력산업이 스마트 그리드화 되면서 이로 인해 발생하는 빅데이터를 활용하여 수요관리, 시설물관리, 대고객서비스 등을 위한 빅데이터 플랫폼들이 도입되고 있는 추세이다. 그러나 빅데이터 프로젝트의 속성상 실제로 빅데이터 플랫폼의 활용이 업무 프로세스 상에서 정착되기 위해서는 많은 시간과 업데이트가 필요하다. 따라서 기존에 알려져 있거나 이론적인 평가 방법으로는 초기 빅데이터 플랫폼의 성과를 평가하기는 적절하지 않다. 본 논문에서는 빅데이터의 규모, 다양성, 속도에 따른 정보의 완전성/충분성, 정보의 신뢰성/정확성, 정보의 적합성/관련성, 정보의 상세성/구체성, 정보의 비교가능성, 정보의 불편성, 정보의 적시성 등 특정 정보의 7 가지 품질 측면에서 전력산업에서 초기 빅데이터 플랫폼의 성과를 평가하는 방법론을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242335&target=NART&cn=JAKO202032362242335",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업이 스마트 그리드화 되면서 이로 인해 발생하는 빅데이터를 활용하여 수요관리, 시설물관리, 대고객서비스 등을 위한 빅데이터 플랫폼들이 도입되고 있는 추세이다. 그러나 빅데이터 프로젝트의 속성상 실제로 빅데이터 플랫폼의 활용이 업무 프로세스 상에서 정착되기 위해서는 많은 시간과 업데이트가 필요하다. 따라서 기존에 알려져 있거나 이론적인 평가 방법으로는 초기 빅데이터 플랫폼의 성과를 평가하기는 적절하지 않다. 본 논문에서는 빅데이터의 규모, 다양성, 속도에 따른 정보의 완전성/충분성, 정보의 신뢰성/정확성, 정보의 적합성/관련성, 정보의 상세성/구체성, 정보의 비교가능성, 정보의 불편성, 정보의 적시성 등 특정 정보의 7 가지 품질 측면에서 전력산업에서 초기 빅데이터 플랫폼의 성과를 평가하는 방법론을 제시한다."
        },
        {
          "rank": 50,
          "score": 0.655024528503418,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}