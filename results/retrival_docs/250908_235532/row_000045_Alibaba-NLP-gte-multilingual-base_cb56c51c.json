{
  "id": "row_000045",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:38.486426+09:00",
  "trial_id": "cb56c51c",
  "queries": [
    {
      "query": "What is the essence of applying various machine and deep learning approaches to pharmacogenomics research for antidepressant treatment prediction?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8611539602279663,
          "doc_id": "ART002777203",
          "title": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments",
          "abstract": "A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002777203&target=NART&cn=ART002777203",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms."
        },
        {
          "rank": 2,
          "score": 0.7364320158958435,
          "doc_id": "JAKO202510839606788",
          "title": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할",
          "abstract": "우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510839606788&target=NART&cn=JAKO202510839606788",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다."
        },
        {
          "rank": 3,
          "score": 0.7255864143371582,
          "doc_id": "JAKO200135164626995",
          "title": "우울증의 약물유전체학",
          "abstract": "The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200135164626995&target=NART&cn=JAKO200135164626995",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증의 약물유전체학 우울증의 약물유전체학 우울증의 약물유전체학 The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine."
        },
        {
          "rank": 4,
          "score": 0.7021256685256958,
          "doc_id": "JAKO202117563196990",
          "title": "약물유전체학에서 약물반응 예측모형과 변수선택 방법",
          "abstract": "약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202117563196990&target=NART&cn=JAKO202117563196990",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다."
        },
        {
          "rank": 5,
          "score": 0.6950902938842773,
          "doc_id": "PRE0001266558",
          "title": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models",
          "abstract": "<jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=PRE0001266558&target=NART&cn=PRE0001266558",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models <jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>"
        },
        {
          "rank": 6,
          "score": 0.6913429498672485,
          "doc_id": "JAKO200235164627099",
          "title": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측",
          "abstract": "우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200235164627099&target=NART&cn=JAKO200235164627099",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다."
        },
        {
          "rank": 7,
          "score": 0.6683722734451294,
          "doc_id": "NART118947969",
          "title": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction",
          "abstract": "<P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118947969&target=NART&cn=NART118947969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction <P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>"
        },
        {
          "rank": 8,
          "score": 0.6580815315246582,
          "doc_id": "JAKO202211040631899",
          "title": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석",
          "abstract": "국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202211040631899&target=NART&cn=JAKO202211040631899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다."
        },
        {
          "rank": 9,
          "score": 0.6544197797775269,
          "doc_id": "DIKO0014389969",
          "title": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors",
          "abstract": "Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014389969&target=NART&cn=DIKO0014389969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다."
        },
        {
          "rank": 10,
          "score": 0.6470661163330078,
          "doc_id": "NART123506805",
          "title": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review",
          "abstract": "<P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123506805&target=NART&cn=NART123506805",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review <P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>"
        },
        {
          "rank": 11,
          "score": 0.6456668972969055,
          "doc_id": "NART131648944",
          "title": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning",
          "abstract": "<P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131648944&target=NART&cn=NART131648944",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning <P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>"
        },
        {
          "rank": 12,
          "score": 0.6417536735534668,
          "doc_id": "JAKO202523357605044",
          "title": "기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구",
          "abstract": "당뇨병의 조기 진단과 예측은 질환 진행을 막고 효과적인 치료 전략을 수립하는 데 필수적이다. 본 연구는 머신러닝(SVM, Random Forest, XGBoost) 및 딥러닝(ANN, CNN, LSTM) 기법을 활용하여 당뇨병 예측 모델을 개발하고 성능을 비교&#x00B7;분석하였다. 데이터 불균형 해결을 위해 GAN 기반 데이터 증강을 적용하고, SHAP 기법을 활용해 모델의 예측 과정을 설명 가능하도록 설계하였다. 또한, 국내 병원 EHR 및 웨어러블 데이터 활용을 통해 한국인의 특성을 반영한 모델을 구축하였다. 향후 연구에서는 당뇨병뿐만 아니라 다양한 만성질환 예측과 실시간 모니터링 및 맞춤형 예방 시스템 개발에 기여하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202523357605044&target=NART&cn=JAKO202523357605044",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 당뇨병의 조기 진단과 예측은 질환 진행을 막고 효과적인 치료 전략을 수립하는 데 필수적이다. 본 연구는 머신러닝(SVM, Random Forest, XGBoost) 및 딥러닝(ANN, CNN, LSTM) 기법을 활용하여 당뇨병 예측 모델을 개발하고 성능을 비교&#x00B7;분석하였다. 데이터 불균형 해결을 위해 GAN 기반 데이터 증강을 적용하고, SHAP 기법을 활용해 모델의 예측 과정을 설명 가능하도록 설계하였다. 또한, 국내 병원 EHR 및 웨어러블 데이터 활용을 통해 한국인의 특성을 반영한 모델을 구축하였다. 향후 연구에서는 당뇨병뿐만 아니라 다양한 만성질환 예측과 실시간 모니터링 및 맞춤형 예방 시스템 개발에 기여하고자 한다."
        },
        {
          "rank": 13,
          "score": 0.6379454135894775,
          "doc_id": "JAKO202022560454224",
          "title": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용",
          "abstract": "Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202022560454224&target=NART&cn=JAKO202022560454224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models."
        },
        {
          "rank": 14,
          "score": 0.6359877586364746,
          "doc_id": "ATN0038661375",
          "title": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험",
          "abstract": "Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038661375&target=NART&cn=ATN0038661375",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
        },
        {
          "rank": 15,
          "score": 0.6289843916893005,
          "doc_id": "DIKO0013687734",
          "title": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발",
          "abstract": "현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687734&target=NART&cn=DIKO0013687734",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다."
        },
        {
          "rank": 16,
          "score": 0.6240934729576111,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 17,
          "score": 0.6229729056358337,
          "doc_id": "DIKO0016916476",
          "title": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening",
          "abstract": "단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016916476&target=NART&cn=DIKO0016916476",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening 단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다."
        },
        {
          "rank": 18,
          "score": 0.6213833689689636,
          "doc_id": "NART124447608",
          "title": "Lifelong Machine Learning Potentials",
          "abstract": "<P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART124447608&target=NART&cn=NART124447608",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials <P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>"
        },
        {
          "rank": 19,
          "score": 0.6199542284011841,
          "doc_id": "NART95036368",
          "title": "Deep Reinforcement Learning in Medicine",
          "abstract": "<P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95036368&target=NART&cn=NART95036368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine <P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>"
        },
        {
          "rank": 20,
          "score": 0.6192096471786499,
          "doc_id": "DIKO0016784632",
          "title": "기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법",
          "abstract": "현대인의 식습관 변화로 인해 당뇨병 발병률은 점점 증가하고, 전 세계적인 건강문제로 인식되고 있다. 합병증으로 인한 사망자도 매년 증가하고 있다. 당뇨병을 조기에 예방하여 치료할 수 있도록 하고, 건강한 삶을 유지하기 위해 당뇨병 조기진단을 예측할 연구가 필요하다.&amp;#xD; 본 논문에서는 당뇨병 초기 증상데이터를 이용하여 당뇨병 진단을 예측하기 위한 시스템 구성도를 제시하고, 기계학습분류 알고리즘을 이용하여 데이터를 분석하고, 당뇨병 진단에 대해 정확한 예측을 하도록 실험하였다. 실험은 R 언어로 기계학습 분류 알고리즘을 수행하고, 수행결과를 비교하여 성능이 좋게 나온 모델에 대해 하이퍼 파라미터 조정을 통해 정확도를 개선함으로써, 최종 선정된 랜덤 포레스트 모형 정확도는 약 99%로 성능이 우수하였다. 당뇨병 예방 및 치료 전략에 모형 성능이 우수한 지도학습 분류모델인 랜덤 포레스트 모형을 제안한다.&amp;#xD; 기계학습을 통한 예측모델은 의료분야에서 유용하게 활용될 수 있으며, 당뇨병 조기 발견과 예방에 이바지할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016784632&target=NART&cn=DIKO0016784632",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 현대인의 식습관 변화로 인해 당뇨병 발병률은 점점 증가하고, 전 세계적인 건강문제로 인식되고 있다. 합병증으로 인한 사망자도 매년 증가하고 있다. 당뇨병을 조기에 예방하여 치료할 수 있도록 하고, 건강한 삶을 유지하기 위해 당뇨병 조기진단을 예측할 연구가 필요하다.&amp;#xD; 본 논문에서는 당뇨병 초기 증상데이터를 이용하여 당뇨병 진단을 예측하기 위한 시스템 구성도를 제시하고, 기계학습분류 알고리즘을 이용하여 데이터를 분석하고, 당뇨병 진단에 대해 정확한 예측을 하도록 실험하였다. 실험은 R 언어로 기계학습 분류 알고리즘을 수행하고, 수행결과를 비교하여 성능이 좋게 나온 모델에 대해 하이퍼 파라미터 조정을 통해 정확도를 개선함으로써, 최종 선정된 랜덤 포레스트 모형 정확도는 약 99%로 성능이 우수하였다. 당뇨병 예방 및 치료 전략에 모형 성능이 우수한 지도학습 분류모델인 랜덤 포레스트 모형을 제안한다.&amp;#xD; 기계학습을 통한 예측모델은 의료분야에서 유용하게 활용될 수 있으며, 당뇨병 조기 발견과 예방에 이바지할 수 있다."
        },
        {
          "rank": 21,
          "score": 0.6171887516975403,
          "doc_id": "DIKO0015784784",
          "title": "머신러닝/딥러닝을 통한 지역별 발병 빈도 예측",
          "abstract": "의료데이터 분석을 이용한 의료/헬스케어 서비스에 대한 관심은 본격적으로&amp;#xD; 빅데이터/AI 의 가능성이 논의되기 이전부터 의료업계 및 IT 산업에서 큰 관심의&amp;#xD; 대상이었으며, 특히 의료 서비스의 비용 문제가 커다란 사회적 이슈인 미국에서는&amp;#xD; 의료서비스의 비용을 낮추면서도 그 질을 높일 수 있는 대안으로 의료 빅데이터에&amp;#xD; 대한 연구가 활발히 진행되어 왔다. 하지만 데이터의 익명성 문제와 보안 문제,&amp;#xD; 특히 의료데이터는 유출시 프라이버시와 관련하여 심각한 문제를 초래할 수 있어&amp;#xD; 의료데이터의 사용에는 많은 난관이 있었다.&amp;#xD; 본 연구는 이러한 문제점을 해결하기 위해 만들어진 컨소시엄에 포함된 전국&amp;#xD; 30 개의 병원 및 의료기관의 데이터를 활용하여 특정한 다빈도 발병 질병의 지역별&amp;#xD; 발병 빈도를 예측하는 것을 목적으로 하였다. 이를 위해 환자 데이터 및 발병&amp;#xD; 데이터, 기후 데이터, 재난 데이터를 수집하였으며, 병원 내부 데이터의 사용을&amp;#xD; 위해 비식별화를 통한 전처리를 수행하였다. 이렇게 만들어진 데이터를 활용하여&amp;#xD; 머신러닝 기법(Stepwise Feature Selection Linear Regression, Random Forest) 및&amp;#xD; 딥러닝 모델(MLP, LSTM)을 통해 결과값(7 개 다빈도 질병의 지역별 발병 빈도수&amp;#xD; 예측)을 도출하였다. 그 결과 Random Forest 와 LSTM 이 각기 다른 질병에서 가장&amp;#xD; 높은 성능을 보여주었고 이를 최종 모델로 선정하였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015784784&target=NART&cn=DIKO0015784784",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 의료데이터 분석을 이용한 의료/헬스케어 서비스에 대한 관심은 본격적으로&amp;#xD; 빅데이터/AI 의 가능성이 논의되기 이전부터 의료업계 및 IT 산업에서 큰 관심의&amp;#xD; 대상이었으며, 특히 의료 서비스의 비용 문제가 커다란 사회적 이슈인 미국에서는&amp;#xD; 의료서비스의 비용을 낮추면서도 그 질을 높일 수 있는 대안으로 의료 빅데이터에&amp;#xD; 대한 연구가 활발히 진행되어 왔다. 하지만 데이터의 익명성 문제와 보안 문제,&amp;#xD; 특히 의료데이터는 유출시 프라이버시와 관련하여 심각한 문제를 초래할 수 있어&amp;#xD; 의료데이터의 사용에는 많은 난관이 있었다.&amp;#xD; 본 연구는 이러한 문제점을 해결하기 위해 만들어진 컨소시엄에 포함된 전국&amp;#xD; 30 개의 병원 및 의료기관의 데이터를 활용하여 특정한 다빈도 발병 질병의 지역별&amp;#xD; 발병 빈도를 예측하는 것을 목적으로 하였다. 이를 위해 환자 데이터 및 발병&amp;#xD; 데이터, 기후 데이터, 재난 데이터를 수집하였으며, 병원 내부 데이터의 사용을&amp;#xD; 위해 비식별화를 통한 전처리를 수행하였다. 이렇게 만들어진 데이터를 활용하여&amp;#xD; 머신러닝 기법(Stepwise Feature Selection Linear Regression, Random Forest) 및&amp;#xD; 딥러닝 모델(MLP, LSTM)을 통해 결과값(7 개 다빈도 질병의 지역별 발병 빈도수&amp;#xD; 예측)을 도출하였다. 그 결과 Random Forest 와 LSTM 이 각기 다른 질병에서 가장&amp;#xD; 높은 성능을 보여주었고 이를 최종 모델로 선정하였다.&amp;#xD;"
        },
        {
          "rank": 22,
          "score": 0.6159276962280273,
          "doc_id": "DIKO0015372556",
          "title": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용",
          "abstract": "머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015372556&target=NART&cn=DIKO0015372556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다."
        },
        {
          "rank": 23,
          "score": 0.6156308054924011,
          "doc_id": "JAKO201925462478017",
          "title": "딥러닝 기반 항생제 내성균 감염 예측",
          "abstract": "세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201925462478017&target=NART&cn=JAKO201925462478017",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다."
        },
        {
          "rank": 24,
          "score": 0.6067746877670288,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 25,
          "score": 0.6066159009933472,
          "doc_id": "NART103136065",
          "title": "Portfolio optimization with return prediction using deep learning and machine learning",
          "abstract": "<P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103136065&target=NART&cn=NART103136065",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning <P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>"
        },
        {
          "rank": 26,
          "score": 0.6065995097160339,
          "doc_id": "NART126947704",
          "title": "Hybrid CNN-LSTM for Predicting Diabetes: A Review",
          "abstract": "<P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART126947704&target=NART&cn=NART126947704",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review <P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>"
        },
        {
          "rank": 27,
          "score": 0.6062589883804321,
          "doc_id": "NART116354539",
          "title": "Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network",
          "abstract": "<P><B>Abstract</B></P>  <P>Alcoholism is a serious disorder that poses a problem for modern society, but the detection of alcoholism has no widely accepted standard tests or procedures. If alcoholism goes undetected at its early stages, it can create havoc in the patient's life. An electroencephalography (EEG) is a method used to measure the brain's electrical activity and can detect alcoholism. EEG signals are complex and multi-channel and thus can be difficult to interpret manually. Several previous works have tried to classify a subject as alcoholic or control (non-alcoholic) based on EEG signals. Such works have mainly used machine learning or statistical techniques along with handcrafted features such as entropy, correlation dimension, Hurst exponent. With the growth in computational power and data volume worldwide, deep learning models have recently been gaining momentum in various fields. However, only a few studies are available on the application of deep learning models for the classification of alcoholism using EEG signals. This paper proposes a deep learning architecture that uses a combination of fast Fourier transform (FFT), a convolution neural network (CNN), long short-term memory (LSTM), and a recently proposed attention mechanism for extracting Spatio-temporal features from multi-channel EEG signals. The proposed architecture can classify a subject as an alcoholic or control with a high degree of accuracy by analyzing EEG signals of that subject and can be used for automating alcoholism detection. The analytical results using the proposed architecture show a 98.83% accuracy, making it better than most state-of-the-art algorithms.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The previous studies used statistical handcrafted features for classification, which requires domain-level knowledge. </LI> <LI>  Existing studies use a few samples, which resulted in less generalized results in most cases. </LI> <LI>  Spatio-temporal EEG signals require architectures that can capture both spatial and temporal features. </LI> <LI>  A combination of FFT-CNN-LSTM-ATTN architecture is proposed to extract Spatio-temporal features. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART116354539&target=NART&cn=NART116354539",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network <P><B>Abstract</B></P>  <P>Alcoholism is a serious disorder that poses a problem for modern society, but the detection of alcoholism has no widely accepted standard tests or procedures. If alcoholism goes undetected at its early stages, it can create havoc in the patient's life. An electroencephalography (EEG) is a method used to measure the brain's electrical activity and can detect alcoholism. EEG signals are complex and multi-channel and thus can be difficult to interpret manually. Several previous works have tried to classify a subject as alcoholic or control (non-alcoholic) based on EEG signals. Such works have mainly used machine learning or statistical techniques along with handcrafted features such as entropy, correlation dimension, Hurst exponent. With the growth in computational power and data volume worldwide, deep learning models have recently been gaining momentum in various fields. However, only a few studies are available on the application of deep learning models for the classification of alcoholism using EEG signals. This paper proposes a deep learning architecture that uses a combination of fast Fourier transform (FFT), a convolution neural network (CNN), long short-term memory (LSTM), and a recently proposed attention mechanism for extracting Spatio-temporal features from multi-channel EEG signals. The proposed architecture can classify a subject as an alcoholic or control with a high degree of accuracy by analyzing EEG signals of that subject and can be used for automating alcoholism detection. The analytical results using the proposed architecture show a 98.83% accuracy, making it better than most state-of-the-art algorithms.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The previous studies used statistical handcrafted features for classification, which requires domain-level knowledge. </LI> <LI>  Existing studies use a few samples, which resulted in less generalized results in most cases. </LI> <LI>  Spatio-temporal EEG signals require architectures that can capture both spatial and temporal features. </LI> <LI>  A combination of FFT-CNN-LSTM-ATTN architecture is proposed to extract Spatio-temporal features. </LI> </UL> </P>"
        },
        {
          "rank": 28,
          "score": 0.6060093641281128,
          "doc_id": "NPAP12734426",
          "title": "Deep sequential model for review rating prediction",
          "abstract": "<P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12734426&target=NART&cn=NPAP12734426",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep sequential model for review rating prediction Deep sequential model for review rating prediction Deep sequential model for review rating prediction <P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>"
        },
        {
          "rank": 29,
          "score": 0.6059404611587524,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 30,
          "score": 0.6056886911392212,
          "doc_id": "JAKO201820765437174",
          "title": "토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구",
          "abstract": "본 연구는 LDA 토픽 모델과 딥 러닝을 적용한 단어 임베딩 기반의 Doc2Vec 기법을 활용하여 자질을 선정하고 자질집합의 크기와 종류 및 분류 알고리즘에 따른 분류 성능의 차이를 평가하였다. 또한 자질집합의 적절한 크기를 확인하고 문헌의 위치에 따라 종류를 다르게 구성하여 분류에 이용할 때 높은 성능을 나타내는 자질집합이 무엇인지 확인하였다. 마지막으로 딥 러닝을 활용한 실험에서는 학습 횟수와 문맥 추론 정보의 유무에 따른 분류 성능을 비교하였다. 실험문헌집단은 PMC에서 제공하는 생의학 학술문헌을 수집하고 질병 범주 체계에 따라 구분하여 Disease-35083을 구축하였다. 연구를 통하여 가장 높은 성능을 나타낸 자질집합의 종류와 크기를 확인하고 학습 시간에 효율성을 나타냄으로써 자질로의 확장 가능성을 가지는 자질집합을 제시하였다. 또한 딥 러닝과 기존 방법 간의 차이점을 비교하고 분류 환경에 따라 적합한 방법을 제안하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201820765437174&target=NART&cn=JAKO201820765437174",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 본 연구는 LDA 토픽 모델과 딥 러닝을 적용한 단어 임베딩 기반의 Doc2Vec 기법을 활용하여 자질을 선정하고 자질집합의 크기와 종류 및 분류 알고리즘에 따른 분류 성능의 차이를 평가하였다. 또한 자질집합의 적절한 크기를 확인하고 문헌의 위치에 따라 종류를 다르게 구성하여 분류에 이용할 때 높은 성능을 나타내는 자질집합이 무엇인지 확인하였다. 마지막으로 딥 러닝을 활용한 실험에서는 학습 횟수와 문맥 추론 정보의 유무에 따른 분류 성능을 비교하였다. 실험문헌집단은 PMC에서 제공하는 생의학 학술문헌을 수집하고 질병 범주 체계에 따라 구분하여 Disease-35083을 구축하였다. 연구를 통하여 가장 높은 성능을 나타낸 자질집합의 종류와 크기를 확인하고 학습 시간에 효율성을 나타냄으로써 자질로의 확장 가능성을 가지는 자질집합을 제시하였다. 또한 딥 러닝과 기존 방법 간의 차이점을 비교하고 분류 환경에 따라 적합한 방법을 제안하였다."
        },
        {
          "rank": 31,
          "score": 0.6056687235832214,
          "doc_id": "DIKO0016741012",
          "title": "머신러닝, 딥러닝을 활용한 질병여부 예측",
          "abstract": "The data is analyzed through machine learning and deep learning with data on heart disease, stroke, and diabetes, which are the top causes of death in Korea, and depression, which ranked first in OECD countries after COVID-19. The algorithms used here are Logistic Regression, Support Vector Classifier (SVC), K-Nearest Neighbor (K-NN), Decision Tree, Gaussian Naive Bayes Classifier, Bernoulli Naive Bayes Classifier, Ridge Classifier, Random Forest Classifier, Ada Boosting Classifier, Extreme Gradient Boosting Analyze using Classifier(XGB), DNN, CNN. In DNN, hyperparameter setting is the optimizer function, which uses Adam, Epoch uses 1000, batch_size 256, Activation Function uses ReLU, Output Activation Function uses Sigmoid, Loss Function uses binary cross entropy In CNN, it is the same as DNN, but Activation Function uses LeakyReLU, Output Activation Function uses Sigmoid, Learning rate is 0.001, Convolution layer uses Conv1d, Kernel size is 2, Polling layer uses Maxpolling, Poll size is set to 2. Accuracy, F1 Score, and ROC_AUC Score are used as evaluation methods, and in deep learning, we check how well training is performed with Lossfucntion.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016741012&target=NART&cn=DIKO0016741012",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝, 딥러닝을 활용한 질병여부 예측 머신러닝, 딥러닝을 활용한 질병여부 예측 머신러닝, 딥러닝을 활용한 질병여부 예측 The data is analyzed through machine learning and deep learning with data on heart disease, stroke, and diabetes, which are the top causes of death in Korea, and depression, which ranked first in OECD countries after COVID-19. The algorithms used here are Logistic Regression, Support Vector Classifier (SVC), K-Nearest Neighbor (K-NN), Decision Tree, Gaussian Naive Bayes Classifier, Bernoulli Naive Bayes Classifier, Ridge Classifier, Random Forest Classifier, Ada Boosting Classifier, Extreme Gradient Boosting Analyze using Classifier(XGB), DNN, CNN. In DNN, hyperparameter setting is the optimizer function, which uses Adam, Epoch uses 1000, batch_size 256, Activation Function uses ReLU, Output Activation Function uses Sigmoid, Loss Function uses binary cross entropy In CNN, it is the same as DNN, but Activation Function uses LeakyReLU, Output Activation Function uses Sigmoid, Learning rate is 0.001, Convolution layer uses Conv1d, Kernel size is 2, Polling layer uses Maxpolling, Poll size is set to 2. Accuracy, F1 Score, and ROC_AUC Score are used as evaluation methods, and in deep learning, we check how well training is performed with Lossfucntion."
        },
        {
          "rank": 32,
          "score": 0.605006217956543,
          "doc_id": "NART133954270",
          "title": "Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models",
          "abstract": "<P>Heart disease prediction is a critical area in healthcare, where accurate and timely diagnosis can lead to better patient outcomes and reduced mortality rates. This study compares the performance of various machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, and Neural Networks, alongside advanced deep learning models such as Convolutional Neural Networks (CNN) and VGG16, a pre-trained deep learning architecture. The models are evaluated using precision, recall, F1-score, and accuracy, with accuracy being the primary metric for comparison. Experimental results demonstrate that while traditional machine learning models like Random Forest and Logistic Regression perform adequately, deep learning models, particularly CNN and VGG16, excel in predictive accuracy and other performance metrics. Among all models, CNN and VGG16 deliver superior results, with VGG16 slightly outperforming CNN in terms of precision and recall due to its ability to leverage pre-trained features and deeper architecture.The findings highlight the efficacy of deep learning techniques, especially VGG16, in heart disease prediction, emphasizing their ability to capture complex patterns and improve diagnostic accuracy. This study provides valuable insights into the potential of leveraging state-of-the-art deep learning architectures for enhancing predictive models in healthcare applications, setting the stage for future real-time diagnostic tools.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133954270&target=NART&cn=NART133954270",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models <P>Heart disease prediction is a critical area in healthcare, where accurate and timely diagnosis can lead to better patient outcomes and reduced mortality rates. This study compares the performance of various machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, and Neural Networks, alongside advanced deep learning models such as Convolutional Neural Networks (CNN) and VGG16, a pre-trained deep learning architecture. The models are evaluated using precision, recall, F1-score, and accuracy, with accuracy being the primary metric for comparison. Experimental results demonstrate that while traditional machine learning models like Random Forest and Logistic Regression perform adequately, deep learning models, particularly CNN and VGG16, excel in predictive accuracy and other performance metrics. Among all models, CNN and VGG16 deliver superior results, with VGG16 slightly outperforming CNN in terms of precision and recall due to its ability to leverage pre-trained features and deeper architecture.The findings highlight the efficacy of deep learning techniques, especially VGG16, in heart disease prediction, emphasizing their ability to capture complex patterns and improve diagnostic accuracy. This study provides valuable insights into the potential of leveraging state-of-the-art deep learning architectures for enhancing predictive models in healthcare applications, setting the stage for future real-time diagnostic tools.</P>"
        },
        {
          "rank": 33,
          "score": 0.6046872138977051,
          "doc_id": "ATN0052776138",
          "title": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구",
          "abstract": "첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0052776138&target=NART&cn=ATN0052776138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다."
        },
        {
          "rank": 34,
          "score": 0.6045874357223511,
          "doc_id": "NART97710485",
          "title": "Big data analytics for personalized medicine",
          "abstract": "<P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97710485&target=NART&cn=NART97710485",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics for personalized medicine Big data analytics for personalized medicine Big data analytics for personalized medicine <P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
        },
        {
          "rank": 35,
          "score": 0.6036863923072815,
          "doc_id": "JAKO201909358629867",
          "title": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석",
          "abstract": "인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629867&target=NART&cn=JAKO201909358629867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다."
        },
        {
          "rank": 36,
          "score": 0.6036826968193054,
          "doc_id": "JAKO202121055483964",
          "title": "딥러닝을 통한 드론의 비정상 진동 예측",
          "abstract": "본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202121055483964&target=NART&cn=JAKO202121055483964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다."
        },
        {
          "rank": 37,
          "score": 0.6034748554229736,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 38,
          "score": 0.6013195514678955,
          "doc_id": "DIKO0011931938",
          "title": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators",
          "abstract": "Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011931938&target=NART&cn=DIKO0011931938",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다."
        },
        {
          "rank": 39,
          "score": 0.6010966300964355,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 40,
          "score": 0.6005326509475708,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 41,
          "score": 0.5996875762939453,
          "doc_id": "NART106279808",
          "title": "Machine learning for site-adaptation and solar radiation forecasting",
          "abstract": "<P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106279808&target=NART&cn=NART106279808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting <P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>"
        },
        {
          "rank": 42,
          "score": 0.5972583889961243,
          "doc_id": "JAKO202211540146433",
          "title": "머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구",
          "abstract": "본 논문은 만성콩팥병 환자의 음성을 사용하여 질병을 자동으로 진단하고 중증도를 예측하는 최적의 방법론을 제안한다. 만성콩팥병 환자는 호흡계 근력의 약화와 성대 부종 등으로 인해 음성이 변화하게 된다. 만성콩팥병 환자의 음성을 음성학적으로 분석한 선행 연구는 존재했으나, 환자의 음성을 분류하는 연구는 진행된 바가 없다. 본 논문에서는 모음연장발화, 유성음 문장 발화, 일반 문장 발화의 발화 목록과, 수제 특징 집합, eGeMAPS, CNN 추출 특징의 특징 집합, SVM, XGBoost의 머신러닝 분류기를 사용하여 만성콩팥병 환자의 음성을 분류하였다. 총 3시간 26분 25초 분량의 1,523개 발화가 실험에 사용되었다. 그 결과, 질병을 자동으로 진단하는 데에는 0.93, 중증도를 예측하는 3분류 문제에서는 0.89, 5분류 문제에서는 0.84의 F1-score가 나타났고, 모든 과제에서 일반 문장 발화, 수제 특징 집합, XGBoost의 조합을 사용했을 때 가장 높은 성능이 나타났다. 이는 만성콩팥병 음성 자동 분류에는 화자의 발화 특성을 모두 반영할 수 있는 일반 문장 발화와 거기로부터 추출한 적절한 특징 집합이 효과적임을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202211540146433&target=NART&cn=JAKO202211540146433",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구 머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구 머신러닝 분류기를 사용한 만성콩팥병 자동 진단 및 중증도 예측 연구 본 논문은 만성콩팥병 환자의 음성을 사용하여 질병을 자동으로 진단하고 중증도를 예측하는 최적의 방법론을 제안한다. 만성콩팥병 환자는 호흡계 근력의 약화와 성대 부종 등으로 인해 음성이 변화하게 된다. 만성콩팥병 환자의 음성을 음성학적으로 분석한 선행 연구는 존재했으나, 환자의 음성을 분류하는 연구는 진행된 바가 없다. 본 논문에서는 모음연장발화, 유성음 문장 발화, 일반 문장 발화의 발화 목록과, 수제 특징 집합, eGeMAPS, CNN 추출 특징의 특징 집합, SVM, XGBoost의 머신러닝 분류기를 사용하여 만성콩팥병 환자의 음성을 분류하였다. 총 3시간 26분 25초 분량의 1,523개 발화가 실험에 사용되었다. 그 결과, 질병을 자동으로 진단하는 데에는 0.93, 중증도를 예측하는 3분류 문제에서는 0.89, 5분류 문제에서는 0.84의 F1-score가 나타났고, 모든 과제에서 일반 문장 발화, 수제 특징 집합, XGBoost의 조합을 사용했을 때 가장 높은 성능이 나타났다. 이는 만성콩팥병 음성 자동 분류에는 화자의 발화 특성을 모두 반영할 수 있는 일반 문장 발화와 거기로부터 추출한 적절한 특징 집합이 효과적임을 시사한다."
        },
        {
          "rank": 43,
          "score": 0.596665620803833,
          "doc_id": "NART111572458",
          "title": "광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교",
          "abstract": "This study examines the classification characteristics of various machine learning classifiers for pain assessment using photoplethysmogram. The presence of pain was assessed using waveform characteristics derived from photoplethysmogram obtained from 73 patients before and after surgery. Classification performance was evaluated using logistic regression, random forest, multi-layer perceptron, and 1-D convolutional neural network, and was validated with nested k-fold cross validation. As a result, pain classification accuracy was highest in order of logistic regression, convolutional neural network, multi-layer perceptron, and random forest classifier. In addition, logistic regression, random forest, multi-layer perceptron, and convolutional neural network were shown to be robust to overfitting in order.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111572458&target=NART&cn=NART111572458",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 This study examines the classification characteristics of various machine learning classifiers for pain assessment using photoplethysmogram. The presence of pain was assessed using waveform characteristics derived from photoplethysmogram obtained from 73 patients before and after surgery. Classification performance was evaluated using logistic regression, random forest, multi-layer perceptron, and 1-D convolutional neural network, and was validated with nested k-fold cross validation. As a result, pain classification accuracy was highest in order of logistic regression, convolutional neural network, multi-layer perceptron, and random forest classifier. In addition, logistic regression, random forest, multi-layer perceptron, and convolutional neural network were shown to be robust to overfitting in order."
        },
        {
          "rank": 44,
          "score": 0.5966153740882874,
          "doc_id": "NART98545871",
          "title": "Review of bankruptcy prediction using machine learning and deep learning techniques",
          "abstract": "<P><B>Abstract</B></P>  <P>Bankruptcy prediction has long been a significant issue in finance and management science, which attracts the attention of researchers and practitioners. With the great development of modern information technology, it has evolved into using machine learning or deep learning algorithms to do the prediction, from the initial analysis of financial statements. In this paper, we will review the machine learning or deep learning models used in bankruptcy prediction, including the classical machine learning models such as Multivariant Discriminant Analysis (MDA), Logistic Regression (LR), Ensemble method, Neural Networks (NN) and Support Vector Machines (SVM), and major deep learning methods such as Deep Belief Network (DBN) and Convolutional Neural Network (CNN). In each model, the specific process of experiment and characteristics will be summarized through analyzing some typical articles. Finally, possible innovative changes of bankruptcy prediction and its future trends will be discussed.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98545871&target=NART&cn=NART98545871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Review of bankruptcy prediction using machine learning and deep learning techniques Review of bankruptcy prediction using machine learning and deep learning techniques Review of bankruptcy prediction using machine learning and deep learning techniques <P><B>Abstract</B></P>  <P>Bankruptcy prediction has long been a significant issue in finance and management science, which attracts the attention of researchers and practitioners. With the great development of modern information technology, it has evolved into using machine learning or deep learning algorithms to do the prediction, from the initial analysis of financial statements. In this paper, we will review the machine learning or deep learning models used in bankruptcy prediction, including the classical machine learning models such as Multivariant Discriminant Analysis (MDA), Logistic Regression (LR), Ensemble method, Neural Networks (NN) and Support Vector Machines (SVM), and major deep learning methods such as Deep Belief Network (DBN) and Convolutional Neural Network (CNN). In each model, the specific process of experiment and characteristics will be summarized through analyzing some typical articles. Finally, possible innovative changes of bankruptcy prediction and its future trends will be discussed.</P>"
        },
        {
          "rank": 45,
          "score": 0.5963582992553711,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 46,
          "score": 0.5956451296806335,
          "doc_id": "JAKO202307361686821",
          "title": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰",
          "abstract": "Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202307361686821&target=NART&cn=JAKO202307361686821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke."
        },
        {
          "rank": 47,
          "score": 0.5956258773803711,
          "doc_id": "DIKO0014912357",
          "title": "딥러닝 기반 기술융합 예측 방법론",
          "abstract": "오늘날 기업들은 전략적인 관점에서 기술변화를 예측하고, 이를 활용한 기술전략 수립이 반드시 필요하다고 요구된다. 특히 기술융합 현상은 기술혁신을 주도하고 시장과 산업의 변화를 이끈 다고 할 수 있기 때문에, 기술융합을 정량적으로 측정하고 관측하기 위한 연구가 다수 이루어졌다. 선행 연구에서는 계량서지분석을 이용해 기술 구조를 분석하고, 기술네트워크를 통해 기술융합 현상을 분석하는데 그쳤다. 본 연구에서는 미래의 기술융합 구조를 예상할 수 있는 예측 방법론을 제시한다. 링크 예측은 현재 시점의 네트워크를 통해 미래 시점의 네트워크에 추가되거나 제거 될 링크를 예측하는 문제를 의미한다. 본 연구에서는 기술네트워크 형태로 표현 된 기술시스템에 링크 예측을 적용하여 미래 기술융합 관계에 대해 예측하는 것을 목적으로 한다. 특히 딥러닝 기법을 이용한 학습 기반 링크 예측을 수행한다는 특징이 있다. 기존에 링크 예측을 적용해 기술융합 예측을 시도한 연구가 일부 있었으나, 네트워크 내 이웃관계에 의한 토폴로지 유사도를 의사결정 척도로 이용했다는 점에서 한계에 머물렀다. 기술융합 예측이라는 도메인 속성이 고려되지 않았다는 점인데, 본 연구에서는 기존 링크 예측에서 보편적으로 사용되었던 이웃관계에 의한 네트워크 토폴로지 유사도와 인용관계에 의한 유사도를 함께 고려한 기술융합 예측모델을 제시한다. 또한 학습 기반 링크 예측에서는 기술네트워크에 대한 정보를 노드 쌍 조합 단위의 레코드를 갖는 정형화 된 데이터 구조로 변화해 이진분류 문제로 기술융합 예측 문제를 재정의 하였기 때문에, 다양한 교사학습 기반의 기계학습 알고리즘 적용이 가능하다. 본 연구에서는 분류 성능이 우수해 최근 주목받고 있는 딥러닝 기법의 DNN 알고리즘을 사용하여 학습 기반 링크 예측을 수행하고, SVM, 로지스틱회귀(logistic regression), 랜덤포레스트(random foreset)와 같은 보편적인 분류 알고리즘을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014912357&target=NART&cn=DIKO0014912357",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 기술융합 예측 방법론 딥러닝 기반 기술융합 예측 방법론 딥러닝 기반 기술융합 예측 방법론 오늘날 기업들은 전략적인 관점에서 기술변화를 예측하고, 이를 활용한 기술전략 수립이 반드시 필요하다고 요구된다. 특히 기술융합 현상은 기술혁신을 주도하고 시장과 산업의 변화를 이끈 다고 할 수 있기 때문에, 기술융합을 정량적으로 측정하고 관측하기 위한 연구가 다수 이루어졌다. 선행 연구에서는 계량서지분석을 이용해 기술 구조를 분석하고, 기술네트워크를 통해 기술융합 현상을 분석하는데 그쳤다. 본 연구에서는 미래의 기술융합 구조를 예상할 수 있는 예측 방법론을 제시한다. 링크 예측은 현재 시점의 네트워크를 통해 미래 시점의 네트워크에 추가되거나 제거 될 링크를 예측하는 문제를 의미한다. 본 연구에서는 기술네트워크 형태로 표현 된 기술시스템에 링크 예측을 적용하여 미래 기술융합 관계에 대해 예측하는 것을 목적으로 한다. 특히 딥러닝 기법을 이용한 학습 기반 링크 예측을 수행한다는 특징이 있다. 기존에 링크 예측을 적용해 기술융합 예측을 시도한 연구가 일부 있었으나, 네트워크 내 이웃관계에 의한 토폴로지 유사도를 의사결정 척도로 이용했다는 점에서 한계에 머물렀다. 기술융합 예측이라는 도메인 속성이 고려되지 않았다는 점인데, 본 연구에서는 기존 링크 예측에서 보편적으로 사용되었던 이웃관계에 의한 네트워크 토폴로지 유사도와 인용관계에 의한 유사도를 함께 고려한 기술융합 예측모델을 제시한다. 또한 학습 기반 링크 예측에서는 기술네트워크에 대한 정보를 노드 쌍 조합 단위의 레코드를 갖는 정형화 된 데이터 구조로 변화해 이진분류 문제로 기술융합 예측 문제를 재정의 하였기 때문에, 다양한 교사학습 기반의 기계학습 알고리즘 적용이 가능하다. 본 연구에서는 분류 성능이 우수해 최근 주목받고 있는 딥러닝 기법의 DNN 알고리즘을 사용하여 학습 기반 링크 예측을 수행하고, SVM, 로지스틱회귀(logistic regression), 랜덤포레스트(random foreset)와 같은 보편적인 분류 알고리즘을 비교한다."
        },
        {
          "rank": 48,
          "score": 0.595317006111145,
          "doc_id": "NART99478101",
          "title": "Building thermal load prediction through shallow machine learning and deep learning",
          "abstract": "<P><B>Abstract</B></P>  <P>Building thermal load prediction informs the optimization of cooling plant and thermal energy storage. Physics-based prediction models of building thermal load are constrained by the model and input complexity. In this study, we developed 12 data-driven models (7 shallow learning, 2 deep learning, and 3 heuristic methods) to predict building thermal load and compared shallow machine learning and deep learning. The 12 prediction models were compared with the measured cooling demand. It was found XGBoost (Extreme Gradient Boost) and LSTM (Long Short Term Memory) provided the most accurate load prediction in the shallow and deep learning category, and both outperformed the best baseline model, which uses the previous day&rsquo;s data for prediction. Then, we discussed how the prediction horizon and input uncertainty would influence the load prediction accuracy. Major conclusions are twofold: first, LSTM performs well in short-term prediction (1 h ahead) but not in long term prediction (24 h ahead), because the sequential information becomes less relevant and accordingly not so useful when the prediction horizon is long. Second, the presence of weather forecast uncertainty deteriorates XGBoost&rsquo;s accuracy and favors LSTM, because the sequential information makes the model more robust to input uncertainty. Training the model with the uncertain rather than accurate weather data could enhance the model&rsquo;s robustness. Our findings have two implications for practice. First, LSTM is recommended for short-term load prediction given that weather forecast uncertainty is unavoidable. Second, XGBoost is recommended for long term prediction, and the model should be trained with the presence of input uncertainty.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Building load prediction informs chiller plant and thermal storage optimization. </LI> <LI>  We used and compared 9 machine learning algorithms and 3 heuristic prediction methods. </LI> <LI>  XGBoost and LSTM are found to be the best shallow and deep learning algorithm. </LI> <LI>  LSTM is better for short term prediction, while XGBoost for long term prediction. </LI> <LI>  It is better to train the model with uncertain rather than accurate weather data. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99478101&target=NART&cn=NART99478101",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Building thermal load prediction through shallow machine learning and deep learning Building thermal load prediction through shallow machine learning and deep learning Building thermal load prediction through shallow machine learning and deep learning <P><B>Abstract</B></P>  <P>Building thermal load prediction informs the optimization of cooling plant and thermal energy storage. Physics-based prediction models of building thermal load are constrained by the model and input complexity. In this study, we developed 12 data-driven models (7 shallow learning, 2 deep learning, and 3 heuristic methods) to predict building thermal load and compared shallow machine learning and deep learning. The 12 prediction models were compared with the measured cooling demand. It was found XGBoost (Extreme Gradient Boost) and LSTM (Long Short Term Memory) provided the most accurate load prediction in the shallow and deep learning category, and both outperformed the best baseline model, which uses the previous day&rsquo;s data for prediction. Then, we discussed how the prediction horizon and input uncertainty would influence the load prediction accuracy. Major conclusions are twofold: first, LSTM performs well in short-term prediction (1 h ahead) but not in long term prediction (24 h ahead), because the sequential information becomes less relevant and accordingly not so useful when the prediction horizon is long. Second, the presence of weather forecast uncertainty deteriorates XGBoost&rsquo;s accuracy and favors LSTM, because the sequential information makes the model more robust to input uncertainty. Training the model with the uncertain rather than accurate weather data could enhance the model&rsquo;s robustness. Our findings have two implications for practice. First, LSTM is recommended for short-term load prediction given that weather forecast uncertainty is unavoidable. Second, XGBoost is recommended for long term prediction, and the model should be trained with the presence of input uncertainty.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Building load prediction informs chiller plant and thermal storage optimization. </LI> <LI>  We used and compared 9 machine learning algorithms and 3 heuristic prediction methods. </LI> <LI>  XGBoost and LSTM are found to be the best shallow and deep learning algorithm. </LI> <LI>  LSTM is better for short term prediction, while XGBoost for long term prediction. </LI> <LI>  It is better to train the model with uncertain rather than accurate weather data. </LI> </UL> </P>"
        },
        {
          "rank": 49,
          "score": 0.5948855876922607,
          "doc_id": "JAKO201924064455520",
          "title": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용",
          "abstract": "Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201924064455520&target=NART&cn=JAKO201924064455520",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
        },
        {
          "rank": 50,
          "score": 0.5943590998649597,
          "doc_id": "JAKO202108360626662",
          "title": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측",
          "abstract": "본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108360626662&target=NART&cn=JAKO202108360626662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다."
        }
      ]
    },
    {
      "query": "What are the primary challenges in predicting antidepressant treatment response using pharmacogenomic data?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7721887230873108,
          "doc_id": "ART002777203",
          "title": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments",
          "abstract": "A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002777203&target=NART&cn=ART002777203",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms."
        },
        {
          "rank": 2,
          "score": 0.7710860967636108,
          "doc_id": "JAKO200135164626995",
          "title": "우울증의 약물유전체학",
          "abstract": "The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200135164626995&target=NART&cn=JAKO200135164626995",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증의 약물유전체학 우울증의 약물유전체학 우울증의 약물유전체학 The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine."
        },
        {
          "rank": 3,
          "score": 0.7672548294067383,
          "doc_id": "JAKO202510839606788",
          "title": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할",
          "abstract": "우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510839606788&target=NART&cn=JAKO202510839606788",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다."
        },
        {
          "rank": 4,
          "score": 0.7361953854560852,
          "doc_id": "JAKO200235164627099",
          "title": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측",
          "abstract": "우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200235164627099&target=NART&cn=JAKO200235164627099",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다."
        },
        {
          "rank": 5,
          "score": 0.6529727578163147,
          "doc_id": "JAKO202117563196990",
          "title": "약물유전체학에서 약물반응 예측모형과 변수선택 방법",
          "abstract": "약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202117563196990&target=NART&cn=JAKO202117563196990",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다."
        },
        {
          "rank": 6,
          "score": 0.6319899559020996,
          "doc_id": "PRE0001266558",
          "title": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models",
          "abstract": "<jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=PRE0001266558&target=NART&cn=PRE0001266558",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models <jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>"
        },
        {
          "rank": 7,
          "score": 0.6284493207931519,
          "doc_id": "DIKO0014389969",
          "title": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors",
          "abstract": "Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014389969&target=NART&cn=DIKO0014389969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다."
        },
        {
          "rank": 8,
          "score": 0.6107778549194336,
          "doc_id": "JAKO200613067170583",
          "title": "항우울제와 자살",
          "abstract": "Depression is a frequent cause of suicide. Although there have been reports that SSRIs might increase suicidal ideations and behaviors, most studies found antidepressants are effective treatments of suicidal ideations and behaviors. Antidepressants have also been shown to have prophylactic effects in preventing suicidal behaviors. Most double-blind studies do not suggest a causal relationship between antidepressant and the increased suicidality. Our review results suggest that the undertreatments of depression are more significant problems with the use of antidepressants in suicidal patients.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200613067170583&target=NART&cn=JAKO200613067170583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "항우울제와 자살 항우울제와 자살 항우울제와 자살 Depression is a frequent cause of suicide. Although there have been reports that SSRIs might increase suicidal ideations and behaviors, most studies found antidepressants are effective treatments of suicidal ideations and behaviors. Antidepressants have also been shown to have prophylactic effects in preventing suicidal behaviors. Most double-blind studies do not suggest a causal relationship between antidepressant and the increased suicidality. Our review results suggest that the undertreatments of depression are more significant problems with the use of antidepressants in suicidal patients."
        },
        {
          "rank": 9,
          "score": 0.5952698588371277,
          "doc_id": "JAKO202022560454224",
          "title": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용",
          "abstract": "Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202022560454224&target=NART&cn=JAKO202022560454224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models."
        },
        {
          "rank": 10,
          "score": 0.5950696468353271,
          "doc_id": "JAKO202211040631899",
          "title": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석",
          "abstract": "국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202211040631899&target=NART&cn=JAKO202211040631899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다."
        },
        {
          "rank": 11,
          "score": 0.5942820310592651,
          "doc_id": "NART116924295",
          "title": "Big data and innovative bioinformatics approaches in personalized genomic medicine",
          "abstract": "<P>The field of human genetics has been radically changed by the introduction of massive parallel sequencing, also called next generation sequencing, approaches. Instead of studying a single gene or a few genetic variants, nowadays we can study genetic variation present in all genes and even throughout the entire human genome. For the first time in history, we can really study what makes us unique and use that to explain differences in for example disease susceptibility or response to treatment. In rare disease, genetics research is essential to identify the molecular diagnosis that provides the basis for a personalized patient management approach. It allows for more precise answers about the underlying cause and family recurrence risk, but also aids in optimizing treatment plans aimed at reducing co-morbidities and providing information about potential drugs or participation in drug trials, with an increasing number focused on gene therapy. These high-throughput sequencing technologies generate enormous amounts of data in order to assemble a genome and identify all of the variation present at different levels, from single nucleotide variations to chromosomal abnormalities. In addition, a genome sequence of a person in itself is not very useful. Value is derived from annotation of all the variation, and integration of the genome sequence with information about the patient involved (clinical information, disease-specific information, family history) as well as biological information (gene as well as variant-specific information, including population variation frequency, pathogenicity predictions, gene-expression information, etc). In this presentation, I will give an overview of the impact of genomics on the diagnosis of patients with rare developmental disorders and fertility disorders. I will highlight the importance of innovative bioinformatics approaches to detect and interpret genetic variation in a clinical context. Also, I will highlight some of the challenges that individual research and diagnostics units face in dealing with the data generated, discuss some of the ethical/privacy issues related to these approaches and discuss some of the latest genomics technologies being developed and validated.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART116924295&target=NART&cn=NART116924295",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data and innovative bioinformatics approaches in personalized genomic medicine Big data and innovative bioinformatics approaches in personalized genomic medicine Big data and innovative bioinformatics approaches in personalized genomic medicine <P>The field of human genetics has been radically changed by the introduction of massive parallel sequencing, also called next generation sequencing, approaches. Instead of studying a single gene or a few genetic variants, nowadays we can study genetic variation present in all genes and even throughout the entire human genome. For the first time in history, we can really study what makes us unique and use that to explain differences in for example disease susceptibility or response to treatment. In rare disease, genetics research is essential to identify the molecular diagnosis that provides the basis for a personalized patient management approach. It allows for more precise answers about the underlying cause and family recurrence risk, but also aids in optimizing treatment plans aimed at reducing co-morbidities and providing information about potential drugs or participation in drug trials, with an increasing number focused on gene therapy. These high-throughput sequencing technologies generate enormous amounts of data in order to assemble a genome and identify all of the variation present at different levels, from single nucleotide variations to chromosomal abnormalities. In addition, a genome sequence of a person in itself is not very useful. Value is derived from annotation of all the variation, and integration of the genome sequence with information about the patient involved (clinical information, disease-specific information, family history) as well as biological information (gene as well as variant-specific information, including population variation frequency, pathogenicity predictions, gene-expression information, etc). In this presentation, I will give an overview of the impact of genomics on the diagnosis of patients with rare developmental disorders and fertility disorders. I will highlight the importance of innovative bioinformatics approaches to detect and interpret genetic variation in a clinical context. Also, I will highlight some of the challenges that individual research and diagnostics units face in dealing with the data generated, discuss some of the ethical/privacy issues related to these approaches and discuss some of the latest genomics technologies being developed and validated.</P>"
        },
        {
          "rank": 12,
          "score": 0.5765210390090942,
          "doc_id": "DIKO0016916476",
          "title": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening",
          "abstract": "단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016916476&target=NART&cn=DIKO0016916476",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening 단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다."
        },
        {
          "rank": 13,
          "score": 0.5762189626693726,
          "doc_id": "DIKO0013687734",
          "title": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발",
          "abstract": "현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687734&target=NART&cn=DIKO0013687734",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다."
        },
        {
          "rank": 14,
          "score": 0.57528156042099,
          "doc_id": "DIKO0012481742",
          "title": "Molecular modeling studies for the discovery of potent A₃ ar and TRPV1 modulators and in silico prediction of CYP inhibition and BBB permeability",
          "abstract": "Part I. Molecular modeling studies for the discovery of selective and potent A₃ AR modulators Adenosine receptors은 GPCR superfamily에 속하며, 4개의 subtype (A1, A2A, A2B, A3)으로 구성되어있다. 그 중 가장 최근에 밝혀진 A₃ AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A₃ 효능제는 허혈성 심질환과 암 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 선택적이며 효능이 뛰어난 A₃ AR의 조절자들을 개발하기 위해, 기계학습(machine learning)방법을 이용한 분류기 모델(classification model)을 만들고 상동수용체 모델을 이용한 도킹 연구를 하였다. Laplacian-modified na&amp;iuml;ve Bayesian, recursive partitioning, support vector machine의 세 가지 방법을 통한 분류기 모델은 정확성, 민감도, 특수성에서 뛰어난 결과를 보여주었다. 또한, 효현제와 길항제가 결합된 A2A AR 결정구조를 바탕으로 A₃ AR의 상동 수용체 모델들을 만들었다. 효현제와 길항제를 위한 최적의 모델을 선정하기 위해 multiple receptor conformations (MRC) 도킹을 하였다. 선정된 최적의 모델에 대한 대표 효현제와 길항제의 Induced fit 도킹을 통해 A₃ AR의 결합자리에서의 상호작용을 이해하였다. 분류기 모델링과 도킹 연구의 조합을 통해 분자수준에서 A₃ AR과 효현제 및 길항제 간의 중요한 통찰을 얻을 수 있었으며 본 연구 결과는 새로운 A₃ AR 효현제와 길항제의 설계에 이용될 것이다. Part II. In silico prediction of CYP Inhibition and BBB permeability Cytochrome P450 저해로 인해 발생한 약물 상호작용에 따른 부작용과 중추신경계약물에 대한 혈액뇌관문(BBB)의 분포는 신약개발에서 중요하다. 본 연구에서는 주요한 5개의 CYP isoform에 대한 저해 예측 및 BBB 통과를 예측하는 분류기 모델을 Laplacian-modified na&amp;iuml;ve Bayesian, recursive partitioning, random forest 및 support vector machine의 세 가지 방법을 이용하여 만들었다. Public domain으로부터 data set을 수집하여 training과 test set을 7 대 3으로 나누어 VolSurf+, ADRIANA.Code와 fingerprints descriptor들을 이용하여 모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 수치를 이용하여 평가하였다. 본 연구에서는 CYP 저해와 BBB 통과 예측을 위한 모델을 성공적으로 만들었으며 이 모델들은 신약개발의 초기단계에서 유용하게 활용될 것이다. Part III. Structural insights into Transient Receptor Potential Vanilloid Type 1 (TRPV1) from homology modeling, flexible docking, and mutational studies Transient receptor potential vanilloid subtype 1 (TPRV1)은 비선택적 양이온 채널로 6개의 transmembrane(TM1-TM6)을 가진 4개의 monomer로 이루어져 있다. TRPV1은 중추와 말초신경계에서 존재하며 통증완화에 대한 중요한 치료 표적이다. 본 연구에서는 rat TRPV1(rTRPV1)의 tetrameric 상동수용체 모델을 수립하였다. 또한 TRPV1 효현제인 capsaicin과 resiniferatoxin(RTX)의 결합에 기여하는 rTRPV1의 중요 잔기들에 대한 역할을 돌연변이 분석(mutational analysis)을 통해 평가하였다. 본 연구에서 수립한 상동수용체 모델을 이용하여 capsaicin과 RTX의 도킹연구를 수행하였으며, 이들의 도킹 결과는 mutation data와 일치하며 상동수용체 모델이 의미 있음을 뒷받침한다. 더 나아가, 모델링을 통해 예측된 simplified RTX(sRTX)의 결합모드는 capsaicin 및 RTX 유사하였으며, 이는 TRPV1에 대한 sRTX의 높은 결합력을 설명할 수 있다. 상동수용체 모델링, 도킹 및 돌연변이 연구를 통해서 리간드와 수용체간의 상호작용을 분자적 수준에서 이해할 수 있었으며, 새로운 TRPV1 리간드 설계에 기여할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012481742&target=NART&cn=DIKO0012481742",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Molecular modeling studies for the discovery of potent A₃ ar and TRPV1 modulators and in silico prediction of CYP inhibition and BBB permeability Molecular modeling studies for the discovery of potent A₃ ar and TRPV1 modulators and in silico prediction of CYP inhibition and BBB permeability Molecular modeling studies for the discovery of potent A₃ ar and TRPV1 modulators and in silico prediction of CYP inhibition and BBB permeability Part I. Molecular modeling studies for the discovery of selective and potent A₃ AR modulators Adenosine receptors은 GPCR superfamily에 속하며, 4개의 subtype (A1, A2A, A2B, A3)으로 구성되어있다. 그 중 가장 최근에 밝혀진 A₃ AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A₃ 효능제는 허혈성 심질환과 암 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 선택적이며 효능이 뛰어난 A₃ AR의 조절자들을 개발하기 위해, 기계학습(machine learning)방법을 이용한 분류기 모델(classification model)을 만들고 상동수용체 모델을 이용한 도킹 연구를 하였다. Laplacian-modified na&amp;iuml;ve Bayesian, recursive partitioning, support vector machine의 세 가지 방법을 통한 분류기 모델은 정확성, 민감도, 특수성에서 뛰어난 결과를 보여주었다. 또한, 효현제와 길항제가 결합된 A2A AR 결정구조를 바탕으로 A₃ AR의 상동 수용체 모델들을 만들었다. 효현제와 길항제를 위한 최적의 모델을 선정하기 위해 multiple receptor conformations (MRC) 도킹을 하였다. 선정된 최적의 모델에 대한 대표 효현제와 길항제의 Induced fit 도킹을 통해 A₃ AR의 결합자리에서의 상호작용을 이해하였다. 분류기 모델링과 도킹 연구의 조합을 통해 분자수준에서 A₃ AR과 효현제 및 길항제 간의 중요한 통찰을 얻을 수 있었으며 본 연구 결과는 새로운 A₃ AR 효현제와 길항제의 설계에 이용될 것이다. Part II. In silico prediction of CYP Inhibition and BBB permeability Cytochrome P450 저해로 인해 발생한 약물 상호작용에 따른 부작용과 중추신경계약물에 대한 혈액뇌관문(BBB)의 분포는 신약개발에서 중요하다. 본 연구에서는 주요한 5개의 CYP isoform에 대한 저해 예측 및 BBB 통과를 예측하는 분류기 모델을 Laplacian-modified na&amp;iuml;ve Bayesian, recursive partitioning, random forest 및 support vector machine의 세 가지 방법을 이용하여 만들었다. Public domain으로부터 data set을 수집하여 training과 test set을 7 대 3으로 나누어 VolSurf+, ADRIANA.Code와 fingerprints descriptor들을 이용하여 모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 수치를 이용하여 평가하였다. 본 연구에서는 CYP 저해와 BBB 통과 예측을 위한 모델을 성공적으로 만들었으며 이 모델들은 신약개발의 초기단계에서 유용하게 활용될 것이다. Part III. Structural insights into Transient Receptor Potential Vanilloid Type 1 (TRPV1) from homology modeling, flexible docking, and mutational studies Transient receptor potential vanilloid subtype 1 (TPRV1)은 비선택적 양이온 채널로 6개의 transmembrane(TM1-TM6)을 가진 4개의 monomer로 이루어져 있다. TRPV1은 중추와 말초신경계에서 존재하며 통증완화에 대한 중요한 치료 표적이다. 본 연구에서는 rat TRPV1(rTRPV1)의 tetrameric 상동수용체 모델을 수립하였다. 또한 TRPV1 효현제인 capsaicin과 resiniferatoxin(RTX)의 결합에 기여하는 rTRPV1의 중요 잔기들에 대한 역할을 돌연변이 분석(mutational analysis)을 통해 평가하였다. 본 연구에서 수립한 상동수용체 모델을 이용하여 capsaicin과 RTX의 도킹연구를 수행하였으며, 이들의 도킹 결과는 mutation data와 일치하며 상동수용체 모델이 의미 있음을 뒷받침한다. 더 나아가, 모델링을 통해 예측된 simplified RTX(sRTX)의 결합모드는 capsaicin 및 RTX 유사하였으며, 이는 TRPV1에 대한 sRTX의 높은 결합력을 설명할 수 있다. 상동수용체 모델링, 도킹 및 돌연변이 연구를 통해서 리간드와 수용체간의 상호작용을 분자적 수준에서 이해할 수 있었으며, 새로운 TRPV1 리간드 설계에 기여할 것이다."
        },
        {
          "rank": 15,
          "score": 0.5741611123085022,
          "doc_id": "NART52558674",
          "title": "CoMFA and molecular docking studies of benzoxazoles and benzothiazoles as CYP450 1A1 inhibitors",
          "abstract": "For better understanding of the molecular interactions of inhibitors    with CYP450 1A1, a series of benzoxazoles and benzothiazoles were analyzed    by comparative molecular field analysis (CoMFA) and molecular docking. Two    conformer-based alignment strategies were employed to construct reliable    CoMFA models. The best CoMFA model yielded a predictive correlation    coefficient r<SUP>2</SUP><SUB>pred</SUB> value of 0.809. Furthermore, a three-dimensional    model of CYP450 1A1 was generated by homology modeling using CYP450 1A2 as    a template, and docking of 48 CYP450 1A1 inhibitors into the putative    binding sites of the CYP450 1A1 were studied. The results obtained from    this study will be helpful in the design of potentially active CYP450 1A1    inhibitors.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART52558674&target=NART&cn=NART52558674",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CoMFA and molecular docking studies of benzoxazoles and benzothiazoles as CYP450 1A1 inhibitors CoMFA and molecular docking studies of benzoxazoles and benzothiazoles as CYP450 1A1 inhibitors CoMFA and molecular docking studies of benzoxazoles and benzothiazoles as CYP450 1A1 inhibitors For better understanding of the molecular interactions of inhibitors    with CYP450 1A1, a series of benzoxazoles and benzothiazoles were analyzed    by comparative molecular field analysis (CoMFA) and molecular docking. Two    conformer-based alignment strategies were employed to construct reliable    CoMFA models. The best CoMFA model yielded a predictive correlation    coefficient r<SUP>2</SUP><SUB>pred</SUB> value of 0.809. Furthermore, a three-dimensional    model of CYP450 1A1 was generated by homology modeling using CYP450 1A2 as    a template, and docking of 48 CYP450 1A1 inhibitors into the putative    binding sites of the CYP450 1A1 were studied. The results obtained from    this study will be helpful in the design of potentially active CYP450 1A1    inhibitors."
        },
        {
          "rank": 16,
          "score": 0.5699620842933655,
          "doc_id": "NART95875714",
          "title": "Advancing Personalized Medicine Through the Application of Whole Exome Sequencing and Big Data Analytics",
          "abstract": "<P>There is a growing attention toward personalized medicine. This is led by a fundamental shift from the ‘one size fits all’ paradigm for treatment of patients with conditions or predisposition to diseases, to one that embraces novel approaches, such as tailored target therapies, to achieve the best possible outcomes. Driven by these, several national and international genome projects have been initiated to reap the benefits of personalized medicine. Exome and targeted sequencing provide a balance between cost and benefit, in contrast to whole genome sequencing (WGS). Whole exome sequencing (WES) targets approximately 3% of the whole genome, which is the basis for protein-coding genes. Nonetheless, it has the characteristics of big data in large deployment. Herein, the application of WES and its relevance in advancing personalized medicine is reviewed. WES is mapped to Big Data “10 Vs” and the resulting challenges discussed. Application of existing biological databases and bioinformatics tools to address the bottleneck in data processing and analysis are presented, including the need for new generation big data analytics for the multi-omics challenges of personalized medicine. This includes the incorporation of artificial intelligence (AI) in the clinical utility landscape of genomic information, and future consideration to create a new frontier toward advancing the field of personalized medicine.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95875714&target=NART&cn=NART95875714",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Advancing Personalized Medicine Through the Application of Whole Exome Sequencing and Big Data Analytics Advancing Personalized Medicine Through the Application of Whole Exome Sequencing and Big Data Analytics Advancing Personalized Medicine Through the Application of Whole Exome Sequencing and Big Data Analytics <P>There is a growing attention toward personalized medicine. This is led by a fundamental shift from the ‘one size fits all’ paradigm for treatment of patients with conditions or predisposition to diseases, to one that embraces novel approaches, such as tailored target therapies, to achieve the best possible outcomes. Driven by these, several national and international genome projects have been initiated to reap the benefits of personalized medicine. Exome and targeted sequencing provide a balance between cost and benefit, in contrast to whole genome sequencing (WGS). Whole exome sequencing (WES) targets approximately 3% of the whole genome, which is the basis for protein-coding genes. Nonetheless, it has the characteristics of big data in large deployment. Herein, the application of WES and its relevance in advancing personalized medicine is reviewed. WES is mapped to Big Data “10 Vs” and the resulting challenges discussed. Application of existing biological databases and bioinformatics tools to address the bottleneck in data processing and analysis are presented, including the need for new generation big data analytics for the multi-omics challenges of personalized medicine. This includes the incorporation of artificial intelligence (AI) in the clinical utility landscape of genomic information, and future consideration to create a new frontier toward advancing the field of personalized medicine.</P>"
        },
        {
          "rank": 17,
          "score": 0.568087100982666,
          "doc_id": "ART002568673",
          "title": "Effect of ligand torsion number on the AutoDock mediated prediction of protein-ligand binding affinity",
          "abstract": "Molecular docking simulation is a useful tool in the prediction of protein-ligand binding affinity on alarge scale and has great potential in various applicationfields such as virtual screening of potentialdrug molecules. However, the reliability of molecular docking is still weak in the estimation of ligand-binding free energy, which limits the applicability of molecular docking simulation. Ligand torsionnumber is related to theflexibility of ligand and generally incorporated as a crucial variable in thethermodynamic function of binding free energy. In this study, we investigated how the ligand torsionnumber has influence on the binding affinity prediction of AutoDock, a popular molecular dockingsimulation tool. The pKd values of various protein-ligands were estimated by using the binding freeenergy function of AutoDock and compared with their experimental pKd values. The torsion numberdependent comparison showed that the predicted binding affinities were mostly underestimated inthe complexes of higher torsion numbers, whereas the underestimated and overestimated cases wererelatively balanced at relatively lower torsion numbers. A new weight factor for torsion-free energyterm of binding energy function was determined and introduced to make correction to theunderestimation of binding affinity of ligands with high torsion numbers. It is expected that the torsionnumber dependent deviation pattern of AutoDock and its correction strategy are useful in the large-scale validation of protein-ligand binding affinity.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002568673&target=NART&cn=ART002568673",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Effect of ligand torsion number on the AutoDock mediated prediction of protein-ligand binding affinity Effect of ligand torsion number on the AutoDock mediated prediction of protein-ligand binding affinity Effect of ligand torsion number on the AutoDock mediated prediction of protein-ligand binding affinity Molecular docking simulation is a useful tool in the prediction of protein-ligand binding affinity on alarge scale and has great potential in various applicationfields such as virtual screening of potentialdrug molecules. However, the reliability of molecular docking is still weak in the estimation of ligand-binding free energy, which limits the applicability of molecular docking simulation. Ligand torsionnumber is related to theflexibility of ligand and generally incorporated as a crucial variable in thethermodynamic function of binding free energy. In this study, we investigated how the ligand torsionnumber has influence on the binding affinity prediction of AutoDock, a popular molecular dockingsimulation tool. The pKd values of various protein-ligands were estimated by using the binding freeenergy function of AutoDock and compared with their experimental pKd values. The torsion numberdependent comparison showed that the predicted binding affinities were mostly underestimated inthe complexes of higher torsion numbers, whereas the underestimated and overestimated cases wererelatively balanced at relatively lower torsion numbers. A new weight factor for torsion-free energyterm of binding energy function was determined and introduced to make correction to theunderestimation of binding affinity of ligands with high torsion numbers. It is expected that the torsionnumber dependent deviation pattern of AutoDock and its correction strategy are useful in the large-scale validation of protein-ligand binding affinity."
        },
        {
          "rank": 18,
          "score": 0.5626301765441895,
          "doc_id": "JAKO200727500193746",
          "title": "유전체 코호트 연구의 윤리적 고려 사항",
          "abstract": "During the last decade, genomic cohort study has been developed in many countries by linking health data and genetic data in stored samples. Genomic cohort study is expected to find key genetic components that contribute to common diseases, thereby promising great advance in genome medicine. While many countries endeavor to build biobank systems, biobank-based genome research has raised important ethical concerns including genetic privacy, confidentiality, discrimination, and informed consent. Informed consent for biobank poses an important question: whether true informed consent is possible in population-based genomic cohort research where the nature of future studies is unforeseeable when consent is obtained. Due to the sensitive character of genetic information, protecting privacy and keeping confidentiality become important topics. To minimize ethical problems and achieve scientific goals to its maximum degree, each country strives to build population-based genomic cohort research project, by organizing public consultation, trying public and expert consensus in research, and providing safeguards to protect privacy and confidentiality.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200727500193746&target=NART&cn=JAKO200727500193746",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유전체 코호트 연구의 윤리적 고려 사항 유전체 코호트 연구의 윤리적 고려 사항 유전체 코호트 연구의 윤리적 고려 사항 During the last decade, genomic cohort study has been developed in many countries by linking health data and genetic data in stored samples. Genomic cohort study is expected to find key genetic components that contribute to common diseases, thereby promising great advance in genome medicine. While many countries endeavor to build biobank systems, biobank-based genome research has raised important ethical concerns including genetic privacy, confidentiality, discrimination, and informed consent. Informed consent for biobank poses an important question: whether true informed consent is possible in population-based genomic cohort research where the nature of future studies is unforeseeable when consent is obtained. Due to the sensitive character of genetic information, protecting privacy and keeping confidentiality become important topics. To minimize ethical problems and achieve scientific goals to its maximum degree, each country strives to build population-based genomic cohort research project, by organizing public consultation, trying public and expert consensus in research, and providing safeguards to protect privacy and confidentiality."
        },
        {
          "rank": 19,
          "score": 0.561174750328064,
          "doc_id": "DIKO0015809825",
          "title": "Study on the Effect of Protein-Ligand Properties on the Prediction Accuracy of a Molecular Docking Tool, AutoDock",
          "abstract": "단백질-리간드 상호 작용은 분자 수준에서 다양한 생물학적 메카니즘을 이해하는 데 중요하며, 이러한 상호 작용에 대한 연구는 새로운 약물 분자의 개발 및 식별, 결합 부위 식별 등에 대한 중요한 통찰력을 제공 할 수 있다. 분자 도킹 시뮬레이션은 대규모 단백질-리간드 상호 작용 예측에 널리 사용되는 방법이나, 단백질-리간드 부착 친화도와 구조의 예측성에 한계를 보이고있다. 본 연구에서는 분자 도킹 시뮬레이션의 한계를 이해하고 극복하기 위하여 단백질-리간드 복합체의 분자 특성 및 성질에 따른 단백질-리간드 상호작용에 관한 도킹 시뮬레이션 효율성에 대한 분석을 단백질-리간드 상호 작용 연구에 널리 사용되는 도킹 프로그램인 AutoDock (버전 4.2.6)을 대상으로 수행하였다.&amp;#xD; 리간드 torsion number는 리간드 분자의 유연성과 관련이 있으며 AutoDock의 에너지 함수에서 torsion 에너지 항과 관계가 있다. AutoDock에 의해 예측 된 172 개 복합체의 결합 친화도를 해당 실험 결합 친화도와 비교하였으며, 예측 친화도는 torsion number가 높은 리간드의 경우 실험값에 비해 낮게 예측되는 경향을 보임을 알 수 있었다. 결합 친화도의 과소 평가 경향을 보정하기 위해 높은 torsion number를 가지는 리간드에 대하여 torsion number 에너지 항에 새로운 중량계수를 도입하여 이라한 문제점을 해결할 수 있었다. 한편, 단백질-리간드 결합 친화도에 대한 분자 특성의 영향을 이해하기 위해 리간드 및 결합 포켓의 소수성과 실험적 결합 친화도와 비교하여 분석하였다. 이 분석을 통해 소수성 리간드와 결합 포켓 사이의 상호 작용이 친수성 리간드에 비해 높은 친화성을 보임을 알 수 있었으며, 친수성 리간드는 친수성 포켓에 특이적으로 결합하는 반면 소수성 리간드는 특이성을 나타내지 않는 것을 알 수 있었다. 단백질에 결합된 리간드의 결합 구조의 예측성이 리간드의 특성에 어떻게 영향을 받는지를 확인하기 위하여 다음과 같은 연구를 수행하였다. 먼저 리간드 torsion number, 리간드 소수성, 결합 포켓 소수성에 대한 결합 구조 예측성을 예측된 구조와 실험적으로 확인된 결합 구조를 비교 분석함으로써 확인하였고, 소수성 리간드가 친수성 리간드보다 상대적으로 오차가 큼을 알 수 있었다. 다음으로 리간드의 고리 구조 유무에 따른 단백질-리간드 결합구조에 대한 예측 효율성에 대한 영향을 조사하였고, 고리가없는 리간드가 고리가있는 리간드보다 예측 효율성이 낮음을 알 수 있었다. 이러한 분자특성에 따른 예측 효율성의 차이는 Autodock의 에너지 함수를 통한 스코어링 기능이 단백질-리간드 상호 작용을 정확하게 평가할 수 없기 때문이라 추정된다. 예를 들면 리간드의 고리 구조와 아미노산 잔기 사이의 방향족 상호 작용은 전체 최소 에너지에 영향을 미칠 수있는 스코어링 기능에 의해 정확하게 평가되지 않을 수 있으며, 이는 구조예측성에 영향을 미칠 수 있을 것으로 사료된다. 본 연구 단백질-리간드 복합체의 분자 특성에 따라 AutoDock 친화도 및 결합구조의 예측성이 다르다는 것을 보여주고 있으며 이러한 연구 결과들은 Autodock 결과들의 해석 및 예측성 향상, 더 나아가 분자도킹 시뮬레이션을 이용한 약물 개발 등의 응용에 기여할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015809825&target=NART&cn=DIKO0015809825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Study on the Effect of Protein-Ligand Properties on the Prediction Accuracy of a Molecular Docking Tool, AutoDock Study on the Effect of Protein-Ligand Properties on the Prediction Accuracy of a Molecular Docking Tool, AutoDock Study on the Effect of Protein-Ligand Properties on the Prediction Accuracy of a Molecular Docking Tool, AutoDock 단백질-리간드 상호 작용은 분자 수준에서 다양한 생물학적 메카니즘을 이해하는 데 중요하며, 이러한 상호 작용에 대한 연구는 새로운 약물 분자의 개발 및 식별, 결합 부위 식별 등에 대한 중요한 통찰력을 제공 할 수 있다. 분자 도킹 시뮬레이션은 대규모 단백질-리간드 상호 작용 예측에 널리 사용되는 방법이나, 단백질-리간드 부착 친화도와 구조의 예측성에 한계를 보이고있다. 본 연구에서는 분자 도킹 시뮬레이션의 한계를 이해하고 극복하기 위하여 단백질-리간드 복합체의 분자 특성 및 성질에 따른 단백질-리간드 상호작용에 관한 도킹 시뮬레이션 효율성에 대한 분석을 단백질-리간드 상호 작용 연구에 널리 사용되는 도킹 프로그램인 AutoDock (버전 4.2.6)을 대상으로 수행하였다.&amp;#xD; 리간드 torsion number는 리간드 분자의 유연성과 관련이 있으며 AutoDock의 에너지 함수에서 torsion 에너지 항과 관계가 있다. AutoDock에 의해 예측 된 172 개 복합체의 결합 친화도를 해당 실험 결합 친화도와 비교하였으며, 예측 친화도는 torsion number가 높은 리간드의 경우 실험값에 비해 낮게 예측되는 경향을 보임을 알 수 있었다. 결합 친화도의 과소 평가 경향을 보정하기 위해 높은 torsion number를 가지는 리간드에 대하여 torsion number 에너지 항에 새로운 중량계수를 도입하여 이라한 문제점을 해결할 수 있었다. 한편, 단백질-리간드 결합 친화도에 대한 분자 특성의 영향을 이해하기 위해 리간드 및 결합 포켓의 소수성과 실험적 결합 친화도와 비교하여 분석하였다. 이 분석을 통해 소수성 리간드와 결합 포켓 사이의 상호 작용이 친수성 리간드에 비해 높은 친화성을 보임을 알 수 있었으며, 친수성 리간드는 친수성 포켓에 특이적으로 결합하는 반면 소수성 리간드는 특이성을 나타내지 않는 것을 알 수 있었다. 단백질에 결합된 리간드의 결합 구조의 예측성이 리간드의 특성에 어떻게 영향을 받는지를 확인하기 위하여 다음과 같은 연구를 수행하였다. 먼저 리간드 torsion number, 리간드 소수성, 결합 포켓 소수성에 대한 결합 구조 예측성을 예측된 구조와 실험적으로 확인된 결합 구조를 비교 분석함으로써 확인하였고, 소수성 리간드가 친수성 리간드보다 상대적으로 오차가 큼을 알 수 있었다. 다음으로 리간드의 고리 구조 유무에 따른 단백질-리간드 결합구조에 대한 예측 효율성에 대한 영향을 조사하였고, 고리가없는 리간드가 고리가있는 리간드보다 예측 효율성이 낮음을 알 수 있었다. 이러한 분자특성에 따른 예측 효율성의 차이는 Autodock의 에너지 함수를 통한 스코어링 기능이 단백질-리간드 상호 작용을 정확하게 평가할 수 없기 때문이라 추정된다. 예를 들면 리간드의 고리 구조와 아미노산 잔기 사이의 방향족 상호 작용은 전체 최소 에너지에 영향을 미칠 수있는 스코어링 기능에 의해 정확하게 평가되지 않을 수 있으며, 이는 구조예측성에 영향을 미칠 수 있을 것으로 사료된다. 본 연구 단백질-리간드 복합체의 분자 특성에 따라 AutoDock 친화도 및 결합구조의 예측성이 다르다는 것을 보여주고 있으며 이러한 연구 결과들은 Autodock 결과들의 해석 및 예측성 향상, 더 나아가 분자도킹 시뮬레이션을 이용한 약물 개발 등의 응용에 기여할 수 있을 것으로 기대된다."
        },
        {
          "rank": 20,
          "score": 0.5605052709579468,
          "doc_id": "NART127298646",
          "title": "CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction",
          "abstract": "<P>For ligand binding prediction, it is crucial for molecular docking programs to integrate template-based modeling with a precise scoring function. Here, we proposed the CoDock-Ligand docking method that combines template-based modeling and the GNINA scoring function, a Convolutional Neural Network-based scoring function, for the ligand binding prediction in CASP15. Among the 21 targets, we obtained successful predictions in top 5 submissions for 14 targets and partially successful predictions for 4 targets. In particular, for the most complicated target, H1114, which contains 56 metal cofactors and small molecules, our docking method successfully predicted the binding of most ligands. Analysis of the failed systems showed that the predicted receptor protein presented conformational changes in the backbone and side chains of the binding site residues, which may cause large structural deviations in the ligand binding prediction. In summary, our hybrid docking scheme was efficiently adapted to the ligand binding prediction challenges in CASP15.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART127298646&target=NART&cn=NART127298646",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction <P>For ligand binding prediction, it is crucial for molecular docking programs to integrate template-based modeling with a precise scoring function. Here, we proposed the CoDock-Ligand docking method that combines template-based modeling and the GNINA scoring function, a Convolutional Neural Network-based scoring function, for the ligand binding prediction in CASP15. Among the 21 targets, we obtained successful predictions in top 5 submissions for 14 targets and partially successful predictions for 4 targets. In particular, for the most complicated target, H1114, which contains 56 metal cofactors and small molecules, our docking method successfully predicted the binding of most ligands. Analysis of the failed systems showed that the predicted receptor protein presented conformational changes in the backbone and side chains of the binding site residues, which may cause large structural deviations in the ligand binding prediction. In summary, our hybrid docking scheme was efficiently adapted to the ligand binding prediction challenges in CASP15.</P>"
        },
        {
          "rank": 21,
          "score": 0.5596095323562622,
          "doc_id": "JAKO202213157607071",
          "title": "기업부도 예측 앙상블 모형의 최적화",
          "abstract": "본 연구에서는 범주 불균형 문제가 내재된 기업부도 예측 AdaBoost 앙상블 모형의 성과를 개선하기 위하여 GMOPTBoost 알고리즘을 제안한다. AdaBoost 알고리즘은 오분류 표본에 대하여 강건한 학습기회를 제공한다는 장점이 있지만, 산술평균 정확도에 기반하기 때문에 범주 불균형 문제를 효과적으로 해결하지 못한다는 한계점이 존재한다. GMOPTBoost는 가우시안 경사하강법(Gaussian gradient descent)을 적용하여 기하평균 정확도를 최적화하고 범주 불균형 문제를 효과적으로 해결할 수 있다는 장점이 있다. 본 연구에서는 첫째, 범주 불균형 문제가 예측 모형의 성과에 미치는 효과와 GMOPTBoost의 성과 개선 효과를 검증하기 위하여 5개의 범주 불균형 데이터를 구성하였으며, 둘째, 범주 균형 데이터에 대한 GMOPTBoost의 성과 개선 효과를 검증하기 위하여 데이터 샘플링 기법을 통하여 구성된 균형 데이터를 구성하였다. 30회의 교차타당성 분석의 주요 결과는 다음과 같다. 첫째, 범주 불균형 문제는 예측 성과에 부정적인 영향을 미친다. 둘째, GMOPTBoost는 불균형 데이터에 적용된 AdaBoost의 성과를 유의적으로 개선시키는 긍정적인 효과를 제공한다. 셋째, 데이터 샘플링 기법은 성과 개선에 긍정적인 영향을 미친다. 마지막으로 데이터 샘플링 기법을 적용한 범주 균형 데이터에서도 GMOPTBoost는 유의적인 성과 개선에 기여한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213157607071&target=NART&cn=JAKO202213157607071",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업부도 예측 앙상블 모형의 최적화 기업부도 예측 앙상블 모형의 최적화 기업부도 예측 앙상블 모형의 최적화 본 연구에서는 범주 불균형 문제가 내재된 기업부도 예측 AdaBoost 앙상블 모형의 성과를 개선하기 위하여 GMOPTBoost 알고리즘을 제안한다. AdaBoost 알고리즘은 오분류 표본에 대하여 강건한 학습기회를 제공한다는 장점이 있지만, 산술평균 정확도에 기반하기 때문에 범주 불균형 문제를 효과적으로 해결하지 못한다는 한계점이 존재한다. GMOPTBoost는 가우시안 경사하강법(Gaussian gradient descent)을 적용하여 기하평균 정확도를 최적화하고 범주 불균형 문제를 효과적으로 해결할 수 있다는 장점이 있다. 본 연구에서는 첫째, 범주 불균형 문제가 예측 모형의 성과에 미치는 효과와 GMOPTBoost의 성과 개선 효과를 검증하기 위하여 5개의 범주 불균형 데이터를 구성하였으며, 둘째, 범주 균형 데이터에 대한 GMOPTBoost의 성과 개선 효과를 검증하기 위하여 데이터 샘플링 기법을 통하여 구성된 균형 데이터를 구성하였다. 30회의 교차타당성 분석의 주요 결과는 다음과 같다. 첫째, 범주 불균형 문제는 예측 성과에 부정적인 영향을 미친다. 둘째, GMOPTBoost는 불균형 데이터에 적용된 AdaBoost의 성과를 유의적으로 개선시키는 긍정적인 효과를 제공한다. 셋째, 데이터 샘플링 기법은 성과 개선에 긍정적인 영향을 미친다. 마지막으로 데이터 샘플링 기법을 적용한 범주 균형 데이터에서도 GMOPTBoost는 유의적인 성과 개선에 기여한다."
        },
        {
          "rank": 22,
          "score": 0.5595030784606934,
          "doc_id": "JAKO199603039532832",
          "title": "흰쥐의 뇌의<TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제에 관한 연구",
          "abstract": "전통적인 수용체 이론에 따르면 상경적 길항제는 효현제와 수용체의 같은 부위에 작용하지만, 효능(efficacy)이 없기 때문에 생물학적 반응을 일으키지는 않는다. 그러나 최근에 발표되는 자료들에 따르면 모든 길항체의 효능(efficacy)이 0가 아니라 음수도 될 수가 있다고 생각된다. 이러한 음수의 효능을 갖는 약물을 역효현제라 부른다. 본 연구에서는 쥐의 cerebral cortex에서 얻은 membranes을 사용하여, <TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제를 인구하였다. 8개의 길항제로 알려진 약물들이 G단백에 대한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> 결합을 감소시키는 정도를 측정함으로써 역효현제의 특성을 검색하였다. 효현제에 의한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> 결합의 증가는 이틀 길항제틀에 의해 완전히 억제되었지만, 검색한 8개의 길항제는 두 군으로 구분되었다. DPCPX를 포함한 7개 길항제는 효현제 부재시의 basal <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding을 통계적으로 의의있게 감소시켜 역효현제의 특성을 나타내는 반면, CCS-15943은 basal <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding에 아무런 영향을 주지 않았다. NEM을 membranes에 처치하면 PIA에 의한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding이나 basal binding 둘다 감소하는데 이는 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding의 상당부분이 G단백의 activated state를 나타내는 것을 알 수 있다. 또한 <TEX>$[^3H]DPCPX$</TEX>를 이용한 competitive binding assay에서 0.1 mM GTP는 효현제인 PIA의 apparent affinity를 감소시켰으며, DPCPX의 apparent affinity는 증가시키고, CGS-15943에는 아무런 영향을 미치지 않았다. 이것은 상기의 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding의 결과를 뒤받침해 주는 결과라고 생각된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199603039532832&target=NART&cn=JAKO199603039532832",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "흰쥐의 뇌의<TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제에 관한 연구 흰쥐의 뇌의<TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제에 관한 연구 흰쥐의 뇌의<TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제에 관한 연구 전통적인 수용체 이론에 따르면 상경적 길항제는 효현제와 수용체의 같은 부위에 작용하지만, 효능(efficacy)이 없기 때문에 생물학적 반응을 일으키지는 않는다. 그러나 최근에 발표되는 자료들에 따르면 모든 길항체의 효능(efficacy)이 0가 아니라 음수도 될 수가 있다고 생각된다. 이러한 음수의 효능을 갖는 약물을 역효현제라 부른다. 본 연구에서는 쥐의 cerebral cortex에서 얻은 membranes을 사용하여, <TEX>$A_1$</TEX> 아데노신 수용체에 작용하는 역효현제를 인구하였다. 8개의 길항제로 알려진 약물들이 G단백에 대한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> 결합을 감소시키는 정도를 측정함으로써 역효현제의 특성을 검색하였다. 효현제에 의한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> 결합의 증가는 이틀 길항제틀에 의해 완전히 억제되었지만, 검색한 8개의 길항제는 두 군으로 구분되었다. DPCPX를 포함한 7개 길항제는 효현제 부재시의 basal <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding을 통계적으로 의의있게 감소시켜 역효현제의 특성을 나타내는 반면, CCS-15943은 basal <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding에 아무런 영향을 주지 않았다. NEM을 membranes에 처치하면 PIA에 의한 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding이나 basal binding 둘다 감소하는데 이는 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding의 상당부분이 G단백의 activated state를 나타내는 것을 알 수 있다. 또한 <TEX>$[^3H]DPCPX$</TEX>를 이용한 competitive binding assay에서 0.1 mM GTP는 효현제인 PIA의 apparent affinity를 감소시켰으며, DPCPX의 apparent affinity는 증가시키고, CGS-15943에는 아무런 영향을 미치지 않았다. 이것은 상기의 <TEX>$[^{35}S]GTP_{\\gamma}S$</TEX> binding의 결과를 뒤받침해 주는 결과라고 생각된다."
        },
        {
          "rank": 23,
          "score": 0.5594503879547119,
          "doc_id": "DIKO0014553403",
          "title": "Understanding the ligand interactions in the cancer therapy and Toll-like receptors",
          "abstract": "Cytarabine, daunorubicin, doxorubicin, and vincristine are used as a chemotherapy medication used to treat acute lymphocytic leukemia, chronic myelogenous leukemia, and non-Hodgkin's lymphoma. But, the metabolism of these drugs as well as the binding modes with cytochrome P450 are unexplored both computationally as well as in other wet-lab experiments. Hence, we utilized protein-ligand docking to predict the productive as well as nonproductive binding modes. We used both rigid (Autodock) and flexible docking (MOE) in our analysis. We also used SmartCyp web server to predict the plausible metabolic sites in the drugs. Based on the consensus docking results as well as the plausible metabolic sites we divided the binding modes into productive as well as nonproductive binding modes. Moreover, we selected both productive and nonproductive binding modes for MD simulations. We determined Ser119, Arg212, and Arg72 were the critical residues that interact with CYP34A. The significants of the hydrophobic forces in the drug interactions were observed in the analysis. Further, the predicted amino acid residues were observed to be essential in site-directed experiments. The productive and nonproductive binding modes of the drugs may broaden the understanding as well as provide the way to design drugs with less toxicity. Additionally, our analysis adds the knowledge of metabolism of the selected cancer drugs.&amp;#xD; &amp;#xD; High mobility group box protein 1 (HMGB1) plays a critical role in autoimmune diseases. It is an adequate, conserved nuclear protein. HMGB1 has an intracellular function as well as in few circumstance (e.g. necrosis) it plays a critical role in cytokine activation. The activity of HMGB1 regulated (extracellular) by the redox-sensitive cysteines namely Cys23, Cys45, and Cys106. We have built models as well as did Molecular Dynamic simulations for different states of HMGB1 including the mutants. Also, we did protein-protein interactions, to understand the interaction of HMGB1 with TLR4. The simulations reveal that the redox states affects the domain movement of the protein. The change in the domain movement, in turn, has an impact on the cytokine activity. The Free energy landscape suggests the lowest energy structure for the active and inactive redox states. Moreover, we docked the inactive as well as active HMGB1 with Toll-like receptor 4 to understand the structural role. These interactions provided the significant insights that might be helpful in several autoimmune diseases.&amp;#xD; &amp;#xD; Toll-like receptor 8 (TLR8) modulators are an attractive target for treating cancer as well as other inflammatory diseases. Several agonists and antagonists have been reported in the literature. We have used and built the QSAR models using the reported agonists to screen novel modulators. The models were built using the rigorous approach and did an external five-fold cross-validation. We screened around eight million compounds and selected 2000 small molecules based on similarity fingerprints. The selected small molecules were used to screen against the built models. The consensus small molecules from six models were carefully selected. We tested 15 compounds and found one antagonists (named as X5) in the range of 50 µM without any toxicity. This lead molecule will be helpful in designing drug molecule for various inflammatory diseases. TNF-α level was measured and the compound X5 significantly repressed TNF-a production at 50 μM..",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014553403&target=NART&cn=DIKO0014553403",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Understanding the ligand interactions in the cancer therapy and Toll-like receptors Understanding the ligand interactions in the cancer therapy and Toll-like receptors Understanding the ligand interactions in the cancer therapy and Toll-like receptors Cytarabine, daunorubicin, doxorubicin, and vincristine are used as a chemotherapy medication used to treat acute lymphocytic leukemia, chronic myelogenous leukemia, and non-Hodgkin's lymphoma. But, the metabolism of these drugs as well as the binding modes with cytochrome P450 are unexplored both computationally as well as in other wet-lab experiments. Hence, we utilized protein-ligand docking to predict the productive as well as nonproductive binding modes. We used both rigid (Autodock) and flexible docking (MOE) in our analysis. We also used SmartCyp web server to predict the plausible metabolic sites in the drugs. Based on the consensus docking results as well as the plausible metabolic sites we divided the binding modes into productive as well as nonproductive binding modes. Moreover, we selected both productive and nonproductive binding modes for MD simulations. We determined Ser119, Arg212, and Arg72 were the critical residues that interact with CYP34A. The significants of the hydrophobic forces in the drug interactions were observed in the analysis. Further, the predicted amino acid residues were observed to be essential in site-directed experiments. The productive and nonproductive binding modes of the drugs may broaden the understanding as well as provide the way to design drugs with less toxicity. Additionally, our analysis adds the knowledge of metabolism of the selected cancer drugs.&amp;#xD; &amp;#xD; High mobility group box protein 1 (HMGB1) plays a critical role in autoimmune diseases. It is an adequate, conserved nuclear protein. HMGB1 has an intracellular function as well as in few circumstance (e.g. necrosis) it plays a critical role in cytokine activation. The activity of HMGB1 regulated (extracellular) by the redox-sensitive cysteines namely Cys23, Cys45, and Cys106. We have built models as well as did Molecular Dynamic simulations for different states of HMGB1 including the mutants. Also, we did protein-protein interactions, to understand the interaction of HMGB1 with TLR4. The simulations reveal that the redox states affects the domain movement of the protein. The change in the domain movement, in turn, has an impact on the cytokine activity. The Free energy landscape suggests the lowest energy structure for the active and inactive redox states. Moreover, we docked the inactive as well as active HMGB1 with Toll-like receptor 4 to understand the structural role. These interactions provided the significant insights that might be helpful in several autoimmune diseases.&amp;#xD; &amp;#xD; Toll-like receptor 8 (TLR8) modulators are an attractive target for treating cancer as well as other inflammatory diseases. Several agonists and antagonists have been reported in the literature. We have used and built the QSAR models using the reported agonists to screen novel modulators. The models were built using the rigorous approach and did an external five-fold cross-validation. We screened around eight million compounds and selected 2000 small molecules based on similarity fingerprints. The selected small molecules were used to screen against the built models. The consensus small molecules from six models were carefully selected. We tested 15 compounds and found one antagonists (named as X5) in the range of 50 µM without any toxicity. This lead molecule will be helpful in designing drug molecule for various inflammatory diseases. TNF-α level was measured and the compound X5 significantly repressed TNF-a production at 50 μM.."
        },
        {
          "rank": 24,
          "score": 0.5592635869979858,
          "doc_id": "NART118947969",
          "title": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction",
          "abstract": "<P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118947969&target=NART&cn=NART118947969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction <P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>"
        },
        {
          "rank": 25,
          "score": 0.5590669512748718,
          "doc_id": "DIKO0014669150",
          "title": "만성 질환에서 아데노신 수용체 유전자 다형성과 환경적 요인 사이의 연관 연구",
          "abstract": "아데노신 수용체 (Adenosine receptor, ADORA)는 아데노신을 결합하여 기능한 G단백질 결합 수용체 (G-protein coupled receptor)로서 인체에 ADORA1, ADORA2A, ADORA2B, ADORA3 네 가지 형태로 존재한다. 아데노신 수용체의 기능은 심장 및 혈관, 뇌세포 등 다양한 기관에서 연구되고 있으며, 이들의 기능은 생리적, 심리적, 영양적 요소와 같은 환경 요소에 의해 영향을 받는다. 아데노신 수용체의 비정상적인 기능은 비만, 당뇨 및 심혈관질환과 같은 대사질환과 밀접한 연관성을 보인다. 더욱이 환경인자로 인한 대사질환의 취약성은 유전형에 따라 다양하게 나타난다. 따라서, 본 연구는 대규모 코호트 자료를 바탕으로 아데노신 수용체의 유전적 다형성이 당뇨, 심혈관계 질환과 같은 대사 질환과 어떠한 상관성이 있는지 분석하고 대사 질환 모델에서 환경인자와의 상관성을 조사하고자 한다. &amp;#xD; 첫번째 연구는 아데노신 수용체의 유전적 다형성에 따라 이상지질혈증의 발병률에 미치는 커피 섭취의 효과에 대해 조사했다. 본 연구는 한국인 유전체 역학 조사 사업 (KoGES)의 안산-안성 코호트의 역학자료 및 유전자 자료를 이용하여 실시되었다. 총 3366 여성 참여자를 대상으로 연구를 진행하였다. 커피 섭취량은 식품섭취빈도조사지를 이용해 조사되었으며 하루 한 잔 이상 커피 섭취자 (MOC), 이하 섭취자 (LOC)를 분류하였다. 결과적으로, 커피 섭취량은 이상지질혈증과 상관성을 보이지 않았다. 하지만 아데노신 수용체 유전자 중 ADORA2A의 유전적 다형성이 있는 참여자는 증가된 커피 섭취량을 보였으며, 이상지질혈증의 위험 역시 높았다 (rs4822499, OR: 1.609, 95% CI: 1.076 - 2.405, p = 0.0204). 더욱 흥미로운 점은 이상지질혈증의 위험이 높은 유전형을 가진 대상자들이 커피 섭취량이 적을 경우 이상지질혈증의 위험이 증가하는 것을 확인할 수 있었다 (rs4822499, OR: 2.194, 95% CI: 1.262 – 3.813, p = 0.0053). 즉, 커피 섭취량은 ADORA2A 유전형에 따라 이상지질혈증의 위험에 영향을 미친다는 것을 알 수 있었다.&amp;#xD; 두번째 연구는 아데노신 수용체 유전형이 스트레스 정도에 따라 당뇨와 연관성을 보이는지를 조사하였다. 본 연구 역시 한국인 유전체 역학 조사 사업 (KoGES)의 안산-안성 코호트의 역학자료 및 유전자 자료를 이용하여 실시되었다. 총 6418명의 대상자 중 스트레스 자가진단 테스트 (PWI-SF) 점수가 27이상인 경우 고스트레스군 (HSG), 이하인 경우 저스트레스군 (LSG)로 분류되었다. HSG의 경우 LSG에 비해 당뇨의 유병률이 더 높았다. 또한, 아데노신 수용체 유전형을 고려했을 때, ADORA1 rs6701725의 경우 LSG일 때 당뇨의 위험이 높았다 (OR: 1.471, 95% CI: 1.102 – 1.965, p = 0.0088). 반면, ADORA3 rs2786967(OR: 1.443, 95% CI: 1.081 – 1.928, p = 0.0129)의 경우 HSG일 때 당뇨의 위험이 더 높았다. 결론적으로, 당뇨의 유병률은 아데노신 수용체의 다형성과 밀접하게 연관되어 있으며, 그 연관성은 스트레스 정도에 따라 달라짐을 확인 할 수 있었다. &amp;#xD; 종합하자면, 본 연구는 영양 및 심리적 요소와 같은 환경인자가 대사질환에 미치는 영향이 아데노신 수용체 유전자의 다형성의 영향을 받음을 증명하였다. 우리의 결과는 같은 유전형을 가진 사람일지라도, 그들이 겪은 환경에 따라 질병의 위험이 달라질 수 있다는 것을 제시한다. 따라서 본 연구는 유전적 다형성과 환경인자 사이의 연관성이 대사질환의 예방 및 관리를 위해 중요함을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014669150&target=NART&cn=DIKO0014669150",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "만성 질환에서 아데노신 수용체 유전자 다형성과 환경적 요인 사이의 연관 연구 만성 질환에서 아데노신 수용체 유전자 다형성과 환경적 요인 사이의 연관 연구 만성 질환에서 아데노신 수용체 유전자 다형성과 환경적 요인 사이의 연관 연구 아데노신 수용체 (Adenosine receptor, ADORA)는 아데노신을 결합하여 기능한 G단백질 결합 수용체 (G-protein coupled receptor)로서 인체에 ADORA1, ADORA2A, ADORA2B, ADORA3 네 가지 형태로 존재한다. 아데노신 수용체의 기능은 심장 및 혈관, 뇌세포 등 다양한 기관에서 연구되고 있으며, 이들의 기능은 생리적, 심리적, 영양적 요소와 같은 환경 요소에 의해 영향을 받는다. 아데노신 수용체의 비정상적인 기능은 비만, 당뇨 및 심혈관질환과 같은 대사질환과 밀접한 연관성을 보인다. 더욱이 환경인자로 인한 대사질환의 취약성은 유전형에 따라 다양하게 나타난다. 따라서, 본 연구는 대규모 코호트 자료를 바탕으로 아데노신 수용체의 유전적 다형성이 당뇨, 심혈관계 질환과 같은 대사 질환과 어떠한 상관성이 있는지 분석하고 대사 질환 모델에서 환경인자와의 상관성을 조사하고자 한다. &amp;#xD; 첫번째 연구는 아데노신 수용체의 유전적 다형성에 따라 이상지질혈증의 발병률에 미치는 커피 섭취의 효과에 대해 조사했다. 본 연구는 한국인 유전체 역학 조사 사업 (KoGES)의 안산-안성 코호트의 역학자료 및 유전자 자료를 이용하여 실시되었다. 총 3366 여성 참여자를 대상으로 연구를 진행하였다. 커피 섭취량은 식품섭취빈도조사지를 이용해 조사되었으며 하루 한 잔 이상 커피 섭취자 (MOC), 이하 섭취자 (LOC)를 분류하였다. 결과적으로, 커피 섭취량은 이상지질혈증과 상관성을 보이지 않았다. 하지만 아데노신 수용체 유전자 중 ADORA2A의 유전적 다형성이 있는 참여자는 증가된 커피 섭취량을 보였으며, 이상지질혈증의 위험 역시 높았다 (rs4822499, OR: 1.609, 95% CI: 1.076 - 2.405, p = 0.0204). 더욱 흥미로운 점은 이상지질혈증의 위험이 높은 유전형을 가진 대상자들이 커피 섭취량이 적을 경우 이상지질혈증의 위험이 증가하는 것을 확인할 수 있었다 (rs4822499, OR: 2.194, 95% CI: 1.262 – 3.813, p = 0.0053). 즉, 커피 섭취량은 ADORA2A 유전형에 따라 이상지질혈증의 위험에 영향을 미친다는 것을 알 수 있었다.&amp;#xD; 두번째 연구는 아데노신 수용체 유전형이 스트레스 정도에 따라 당뇨와 연관성을 보이는지를 조사하였다. 본 연구 역시 한국인 유전체 역학 조사 사업 (KoGES)의 안산-안성 코호트의 역학자료 및 유전자 자료를 이용하여 실시되었다. 총 6418명의 대상자 중 스트레스 자가진단 테스트 (PWI-SF) 점수가 27이상인 경우 고스트레스군 (HSG), 이하인 경우 저스트레스군 (LSG)로 분류되었다. HSG의 경우 LSG에 비해 당뇨의 유병률이 더 높았다. 또한, 아데노신 수용체 유전형을 고려했을 때, ADORA1 rs6701725의 경우 LSG일 때 당뇨의 위험이 높았다 (OR: 1.471, 95% CI: 1.102 – 1.965, p = 0.0088). 반면, ADORA3 rs2786967(OR: 1.443, 95% CI: 1.081 – 1.928, p = 0.0129)의 경우 HSG일 때 당뇨의 위험이 더 높았다. 결론적으로, 당뇨의 유병률은 아데노신 수용체의 다형성과 밀접하게 연관되어 있으며, 그 연관성은 스트레스 정도에 따라 달라짐을 확인 할 수 있었다. &amp;#xD; 종합하자면, 본 연구는 영양 및 심리적 요소와 같은 환경인자가 대사질환에 미치는 영향이 아데노신 수용체 유전자의 다형성의 영향을 받음을 증명하였다. 우리의 결과는 같은 유전형을 가진 사람일지라도, 그들이 겪은 환경에 따라 질병의 위험이 달라질 수 있다는 것을 제시한다. 따라서 본 연구는 유전적 다형성과 환경인자 사이의 연관성이 대사질환의 예방 및 관리를 위해 중요함을 시사한다."
        },
        {
          "rank": 26,
          "score": 0.5586721897125244,
          "doc_id": "ART003035150",
          "title": "A Study on Big Data-Based Analysis of Risk Factors for Depression in Adolescents",
          "abstract": "The purpose of this study is to explore adolescent depression, increase understanding of social problems, and develop prevention and intervention strategies. As a research method, social big data was used to collect information related to 'youth depression', and related factors were identified through data mining and analysis of related rules. We used 'Sometrend Biz Tool' to collect and clean data from the web and then analyzed data in various languages. The study found that online articles about depression decreased during the school holidays (January to March), then increased from March to the end of June, and then decreased again from July. Therefore, it is important to establish a government-wide depression management monitoring system that can detect risk signs of adolescent depression in real time. In addition, regular stress relief and mental health education are needed during the semester, and measures must be prepared to deal with at-risk youth who share their depressed feelings in cyberspace. Results from these studies can be expected to provide important information in investigating and preventing youth depression and to contribute to policy development and intervention.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003035150&target=NART&cn=ART003035150",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Study on Big Data-Based Analysis of Risk Factors for Depression in Adolescents A Study on Big Data-Based Analysis of Risk Factors for Depression in Adolescents A Study on Big Data-Based Analysis of Risk Factors for Depression in Adolescents The purpose of this study is to explore adolescent depression, increase understanding of social problems, and develop prevention and intervention strategies. As a research method, social big data was used to collect information related to 'youth depression', and related factors were identified through data mining and analysis of related rules. We used 'Sometrend Biz Tool' to collect and clean data from the web and then analyzed data in various languages. The study found that online articles about depression decreased during the school holidays (January to March), then increased from March to the end of June, and then decreased again from July. Therefore, it is important to establish a government-wide depression management monitoring system that can detect risk signs of adolescent depression in real time. In addition, regular stress relief and mental health education are needed during the semester, and measures must be prepared to deal with at-risk youth who share their depressed feelings in cyberspace. Results from these studies can be expected to provide important information in investigating and preventing youth depression and to contribute to policy development and intervention."
        },
        {
          "rank": 27,
          "score": 0.555570125579834,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 28,
          "score": 0.5555296540260315,
          "doc_id": "DIKO0015919977",
          "title": "유도진화기술을 이용한 시토크롬 P450 2C8 효소의 구조 기능 연관성 분석 연구",
          "abstract": "인간 게놈에는 4가지의 시토크롬 P450 2C 효소(2C8, 2C9, 2C18, 2C19)가 암호화되어 있으며, 이들 효소는 임상적으로 사용되는 상당수의 약물 대사에 관여한다. 특히, 시토크롬 P450 2C8 (CYP2C8)은 다양한 다형적(polymorphic) 결과뿐만 아니라 약물-약물상호작용에 관여하기 때문에 지속적인 관심을 받고 있다. 본 연구에서는 CYP2C8의 구조-기능 관계의 복잡성을 밝히기 위해 유도 진화 분석법을 사용하였으며, 돌연변이에 의한 촉매 활성 변화를 측정하였다. 히스티딘-태그가 부착된 CYP2C8 및 NADPH-시토크롬 P450 환원효소(NPR)를 포함하는 pCW 플라스미드를 확립하여, CYP2C8의 무작위적인 돌연변이 라이브러리를 만드는 데에 사용하였다. 무작위 돌연변이 유발 및 6-메톡시-루시페린(루시페린-ME)을 이용한 발광분석-기반 스크리닝을 통해 CYP2C8의 두 가지 돌연변이체를 선별하였다(D349Y 및 D349Y/V237A). 그리고 이들 돌연변이체는 기질로 사용된 루시페린-ME에 대해서, 야생형에 비해 상당히 증가된 활성을 나타냈다. 야생형과 선택된 두 가지 돌연변이체를 E. coli DH5α에서 대량 배양하였으며, Ni2+-NTA 친화성 컬럼 크로마토그래피를 이용하여 성공적으로 정제하였다. D349Y 및 D349Y/V237A 돌연변이체의 발현 수준은 전체 세포 수준에서 각각 310, 460 nmol/L였다. 정제된 돌연변이체 단백질을 이용한 촉매 활성 측정에서, 루시페린-ME을 기질로 하였을 때 야생형에 비해 각각 19, 10배 증가된 활성을 나타냈으며(D349Y 및 D349Y/V237A), 파클리탁셀 6α-수산화 및 아라키돈산 에폭시화에 대한 정류 상태 속도 분석(steady-state kinetic analysis)을 시행한 결과, 파클리탁셀 6α-수산화 반응의 전환수(kcat; turnover number)는 야생형에 비해 5~7배, 촉매 효율(kcat/Km)은 3~5배 증가하였으며, 아라키돈산 에폭시화 반응의 전환수는 야생형에 비해 30~150배, 촉매 효율은 40~110배 증가하였다. 기질 결합에 의한 흡광도 변화를 측정하여 적정한 결과, D349Y/V237A 돌연변이체는 두 가지 기질 모두에서 야생형에 비해 대략 4배가량 낮아진 Kd를 보였다. 또한 CYP2C의 X-선 결정구조를 참고한 결과, D349Y 돌연변이의 경우, CYP의 전자 전달 효소와의 결합 부위에 가깝게 위치하여, 해당 위치의 아미노산이 치환됨에 따라 전자 전달 효소 결합 부위의 표면 전하가 변화하여 CYP의 촉매 활성에도 영향을 미쳤을 것이라고 유추할 수 있었다. V237A 돌연변이의 경우, CYP2C8의 기질-결합 부위의 바깥 면에 위치하여 CYP2C8과 기질의 상호작용 과정에 변화가 야기되었을 것으로 보인다. 본 연구에서는 효소 활성 부위 외에 위치하는 두 가지 돌연변이를 선별하여 CYP2C8의 구조-기능 관계에 대해 연구하였으며, 시토크롬 P450 간의 구조적 연관성을 고려할 때, 본 연구 결과가 다른 시토크롬 P450의 구조 연구에도 일부 도움이 될 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015919977&target=NART&cn=DIKO0015919977",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유도진화기술을 이용한 시토크롬 P450 2C8 효소의 구조 기능 연관성 분석 연구 유도진화기술을 이용한 시토크롬 P450 2C8 효소의 구조 기능 연관성 분석 연구 유도진화기술을 이용한 시토크롬 P450 2C8 효소의 구조 기능 연관성 분석 연구 인간 게놈에는 4가지의 시토크롬 P450 2C 효소(2C8, 2C9, 2C18, 2C19)가 암호화되어 있으며, 이들 효소는 임상적으로 사용되는 상당수의 약물 대사에 관여한다. 특히, 시토크롬 P450 2C8 (CYP2C8)은 다양한 다형적(polymorphic) 결과뿐만 아니라 약물-약물상호작용에 관여하기 때문에 지속적인 관심을 받고 있다. 본 연구에서는 CYP2C8의 구조-기능 관계의 복잡성을 밝히기 위해 유도 진화 분석법을 사용하였으며, 돌연변이에 의한 촉매 활성 변화를 측정하였다. 히스티딘-태그가 부착된 CYP2C8 및 NADPH-시토크롬 P450 환원효소(NPR)를 포함하는 pCW 플라스미드를 확립하여, CYP2C8의 무작위적인 돌연변이 라이브러리를 만드는 데에 사용하였다. 무작위 돌연변이 유발 및 6-메톡시-루시페린(루시페린-ME)을 이용한 발광분석-기반 스크리닝을 통해 CYP2C8의 두 가지 돌연변이체를 선별하였다(D349Y 및 D349Y/V237A). 그리고 이들 돌연변이체는 기질로 사용된 루시페린-ME에 대해서, 야생형에 비해 상당히 증가된 활성을 나타냈다. 야생형과 선택된 두 가지 돌연변이체를 E. coli DH5α에서 대량 배양하였으며, Ni2+-NTA 친화성 컬럼 크로마토그래피를 이용하여 성공적으로 정제하였다. D349Y 및 D349Y/V237A 돌연변이체의 발현 수준은 전체 세포 수준에서 각각 310, 460 nmol/L였다. 정제된 돌연변이체 단백질을 이용한 촉매 활성 측정에서, 루시페린-ME을 기질로 하였을 때 야생형에 비해 각각 19, 10배 증가된 활성을 나타냈으며(D349Y 및 D349Y/V237A), 파클리탁셀 6α-수산화 및 아라키돈산 에폭시화에 대한 정류 상태 속도 분석(steady-state kinetic analysis)을 시행한 결과, 파클리탁셀 6α-수산화 반응의 전환수(kcat; turnover number)는 야생형에 비해 5~7배, 촉매 효율(kcat/Km)은 3~5배 증가하였으며, 아라키돈산 에폭시화 반응의 전환수는 야생형에 비해 30~150배, 촉매 효율은 40~110배 증가하였다. 기질 결합에 의한 흡광도 변화를 측정하여 적정한 결과, D349Y/V237A 돌연변이체는 두 가지 기질 모두에서 야생형에 비해 대략 4배가량 낮아진 Kd를 보였다. 또한 CYP2C의 X-선 결정구조를 참고한 결과, D349Y 돌연변이의 경우, CYP의 전자 전달 효소와의 결합 부위에 가깝게 위치하여, 해당 위치의 아미노산이 치환됨에 따라 전자 전달 효소 결합 부위의 표면 전하가 변화하여 CYP의 촉매 활성에도 영향을 미쳤을 것이라고 유추할 수 있었다. V237A 돌연변이의 경우, CYP2C8의 기질-결합 부위의 바깥 면에 위치하여 CYP2C8과 기질의 상호작용 과정에 변화가 야기되었을 것으로 보인다. 본 연구에서는 효소 활성 부위 외에 위치하는 두 가지 돌연변이를 선별하여 CYP2C8의 구조-기능 관계에 대해 연구하였으며, 시토크롬 P450 간의 구조적 연관성을 고려할 때, 본 연구 결과가 다른 시토크롬 P450의 구조 연구에도 일부 도움이 될 것으로 기대한다."
        },
        {
          "rank": 29,
          "score": 0.5547690391540527,
          "doc_id": "NART131648944",
          "title": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning",
          "abstract": "<P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131648944&target=NART&cn=NART131648944",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning <P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>"
        },
        {
          "rank": 30,
          "score": 0.5547653436660767,
          "doc_id": "NART55575889",
          "title": "VoteDock: Consensus docking method for prediction of protein&#x2013;ligand interactions",
          "abstract": "<P><B>Abstract</B></P><P>Molecular recognition plays a fundamental role in all biological processes, and that is why great efforts have been made to understand and predict protein&ndash;ligand interactions. Finding a molecule that can potentially bind to a target protein is particularly essential in drug discovery and still remains an expensive and time&#8208;consuming task. <I>In silico</I>, tools are frequently used to screen molecular libraries to identify new lead compounds, and if protein structure is known, various protein&ndash;ligand docking programs can be used. The aim of docking procedure is to predict correct poses of ligand in the binding site of the protein as well as to score them according to the strength of interaction in a reasonable time frame. The purpose of our studies was to present the novel consensus approach to predict both protein&ndash;ligand complex structure and its corresponding binding affinity. Our method used as the input the results from seven docking programs (Surflex, LigandFit, Glide, GOLD, FlexX, eHiTS, and AutoDock) that are widely used for docking of ligands. We evaluated it on the extensive benchmark dataset of 1300 protein&ndash;ligands pairs from refined PDBbind database for which the structural and affinity data was available. We compared independently its ability of proper scoring and posing to the previously proposed methods. In most cases, our method is able to dock properly approximately 20% of pairs more than docking methods on average, and over 10% of pairs more than the best single program. The RMSD value of the predicted complex conformation versus its native one is reduced by a factor of 0.5 &Aring;. Finally, we were able to increase the Pearson correlation of the predicted binding affinity in comparison with the experimental value up to 0.5. &copy; 2010 Wiley Periodicals, Inc. J Comput Chem 32: 568&ndash;581, 2011</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART55575889&target=NART&cn=NART55575889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "VoteDock: Consensus docking method for prediction of protein&#x2013;ligand interactions VoteDock: Consensus docking method for prediction of protein&#x2013;ligand interactions VoteDock: Consensus docking method for prediction of protein&#x2013;ligand interactions <P><B>Abstract</B></P><P>Molecular recognition plays a fundamental role in all biological processes, and that is why great efforts have been made to understand and predict protein&ndash;ligand interactions. Finding a molecule that can potentially bind to a target protein is particularly essential in drug discovery and still remains an expensive and time&#8208;consuming task. <I>In silico</I>, tools are frequently used to screen molecular libraries to identify new lead compounds, and if protein structure is known, various protein&ndash;ligand docking programs can be used. The aim of docking procedure is to predict correct poses of ligand in the binding site of the protein as well as to score them according to the strength of interaction in a reasonable time frame. The purpose of our studies was to present the novel consensus approach to predict both protein&ndash;ligand complex structure and its corresponding binding affinity. Our method used as the input the results from seven docking programs (Surflex, LigandFit, Glide, GOLD, FlexX, eHiTS, and AutoDock) that are widely used for docking of ligands. We evaluated it on the extensive benchmark dataset of 1300 protein&ndash;ligands pairs from refined PDBbind database for which the structural and affinity data was available. We compared independently its ability of proper scoring and posing to the previously proposed methods. In most cases, our method is able to dock properly approximately 20% of pairs more than docking methods on average, and over 10% of pairs more than the best single program. The RMSD value of the predicted complex conformation versus its native one is reduced by a factor of 0.5 &Aring;. Finally, we were able to increase the Pearson correlation of the predicted binding affinity in comparison with the experimental value up to 0.5. &copy; 2010 Wiley Periodicals, Inc. J Comput Chem 32: 568&ndash;581, 2011</P>"
        },
        {
          "rank": 31,
          "score": 0.554423451423645,
          "doc_id": "NART119053407",
          "title": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review",
          "abstract": "<P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119053407&target=NART&cn=NART119053407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review <P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>"
        },
        {
          "rank": 32,
          "score": 0.5540692806243896,
          "doc_id": "NART123506805",
          "title": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review",
          "abstract": "<P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123506805&target=NART&cn=NART123506805",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review <P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>"
        },
        {
          "rank": 33,
          "score": 0.5537570118904114,
          "doc_id": "ART002405701",
          "title": "Validation on the molecular docking efficiency of lipocalin family of proteins",
          "abstract": "Lipocalins are diverse group of small extracellular proteins found in various organisms. In this study, members of 10 non-homologous lipocalin–ligand crystal complex structures were remodeled using rigid and flexible ligand modes to validate the prediction efficiency of molecular docking simulation. The modeled ligand conformations indicated a high prediction accuracy in rigid ligand mode using cluster based analysis for most cases whereas the flexible ligand mode required further considerations such as ligand binding energy and RMSD for some cases. This in silico study is expected to serve as a platform in the screening of novel ligands against lipocalin family of proteins.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002405701&target=NART&cn=ART002405701",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Validation on the molecular docking efficiency of lipocalin family of proteins Validation on the molecular docking efficiency of lipocalin family of proteins Validation on the molecular docking efficiency of lipocalin family of proteins Lipocalins are diverse group of small extracellular proteins found in various organisms. In this study, members of 10 non-homologous lipocalin–ligand crystal complex structures were remodeled using rigid and flexible ligand modes to validate the prediction efficiency of molecular docking simulation. The modeled ligand conformations indicated a high prediction accuracy in rigid ligand mode using cluster based analysis for most cases whereas the flexible ligand mode required further considerations such as ligand binding energy and RMSD for some cases. This in silico study is expected to serve as a platform in the screening of novel ligands against lipocalin family of proteins."
        },
        {
          "rank": 34,
          "score": 0.5536234974861145,
          "doc_id": "JAKO201813742061433",
          "title": "빅데이터 분석을 통한 패키징에 대한 소비자의 주요 인식 조사 -텍스트 마이닝과 의미연결망 분석을 중심으로-",
          "abstract": "패키징에 대한 소비자들의 주요인식을 조사하기 위해 빅데이터 분석방법인 텍스트 마이닝과 의미연결망 분석을 중심으로 연구를 진행하였다. 데이터 수집은 웹&SNS데이터 분석 프로그램인 텍스톰(Textom)을 사용하여 2년 7개월간의 데이터를 수집하였다. 연구 결과 네트워크 중심도는 패키징의 경우 8.9% 포장은 9.1%로 패키징이 보다 다양한 주제를 다루는 것으로 조사되었다. CONCOR 분석을 통해서 유사한 의미를 가지는 4개의 그룹으로 분류하여 패키징에 관한 소비자들의 주요인식을 연구, 개발, 산업, 소재, 기능 등으로 요약하였다. 본 연구에 따르면 소비자가 가장 많이 인식하는 패키징 소재는 합성수지이며 패키징 기능으로는 보관의 기능을 주로 인식한다. 또한 소비자들이 인식하는 패키징 관련 상품군으로 제약, 의약품인 것으로 조사되었다. 본 연구결과는 패키징에 대한 소비자들의 인식을 예측함으로써 향후 이루어질 연구와 산업발전에 기초자료로써의 활용 가능성을 가지며 빅데이터와 패키징 두 분야의 융합을 통한 패키징 분야의 새로운 연구방향을 제시한 의의가 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813742061433&target=NART&cn=JAKO201813742061433",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 통한 패키징에 대한 소비자의 주요 인식 조사 -텍스트 마이닝과 의미연결망 분석을 중심으로- 빅데이터 분석을 통한 패키징에 대한 소비자의 주요 인식 조사 -텍스트 마이닝과 의미연결망 분석을 중심으로- 빅데이터 분석을 통한 패키징에 대한 소비자의 주요 인식 조사 -텍스트 마이닝과 의미연결망 분석을 중심으로- 패키징에 대한 소비자들의 주요인식을 조사하기 위해 빅데이터 분석방법인 텍스트 마이닝과 의미연결망 분석을 중심으로 연구를 진행하였다. 데이터 수집은 웹&SNS데이터 분석 프로그램인 텍스톰(Textom)을 사용하여 2년 7개월간의 데이터를 수집하였다. 연구 결과 네트워크 중심도는 패키징의 경우 8.9% 포장은 9.1%로 패키징이 보다 다양한 주제를 다루는 것으로 조사되었다. CONCOR 분석을 통해서 유사한 의미를 가지는 4개의 그룹으로 분류하여 패키징에 관한 소비자들의 주요인식을 연구, 개발, 산업, 소재, 기능 등으로 요약하였다. 본 연구에 따르면 소비자가 가장 많이 인식하는 패키징 소재는 합성수지이며 패키징 기능으로는 보관의 기능을 주로 인식한다. 또한 소비자들이 인식하는 패키징 관련 상품군으로 제약, 의약품인 것으로 조사되었다. 본 연구결과는 패키징에 대한 소비자들의 인식을 예측함으로써 향후 이루어질 연구와 산업발전에 기초자료로써의 활용 가능성을 가지며 빅데이터와 패키징 두 분야의 융합을 통한 패키징 분야의 새로운 연구방향을 제시한 의의가 있다."
        },
        {
          "rank": 35,
          "score": 0.551312267780304,
          "doc_id": "NART32913073",
          "title": "Combining docking, scoring and molecular field analyses to probe influenza neuraminidase&ndash;ligand interactions",
          "abstract": "<P><B>Abstract</B></P><P>In this project, several docking conditions, scoring functions and corresponding protein-aligned molecular field analysis (CoMFA) models were evaluated for a diverse set of neuraminidase (NA) inhibitors. To this end, a group of inhibitors were docked into the active site of NA. The docked structures were utilized to construct a corresponding protein-aligned CoMFA models by employing probe-based (H+, OH, CH3) energy grids and genetic partial least squares (G/PLS) statistical analysis. A total of 16 different docking configurations were evaluated, of which some succeeded in producing self-consistent and predictive CoMFA models. However, the best model coincided with docking the ionized ligands into the hydrated form of the binding site via PLP1 scoring function (rLOO2=0.735, rPRESS2 against 24 test compounds=0.828). The highest-ranking CoMFA models were employed to probe NA&ndash;ligand interactions. Further validation by comparison with a co-crystallized ligand&ndash;NA crystallographic structure was performed. This combination of docking/scoring/CoMFA modeling provided interesting insights into the binding of different NA inhibitors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART32913073&target=NART&cn=NART32913073",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Combining docking, scoring and molecular field analyses to probe influenza neuraminidase&ndash;ligand interactions Combining docking, scoring and molecular field analyses to probe influenza neuraminidase&ndash;ligand interactions Combining docking, scoring and molecular field analyses to probe influenza neuraminidase&ndash;ligand interactions <P><B>Abstract</B></P><P>In this project, several docking conditions, scoring functions and corresponding protein-aligned molecular field analysis (CoMFA) models were evaluated for a diverse set of neuraminidase (NA) inhibitors. To this end, a group of inhibitors were docked into the active site of NA. The docked structures were utilized to construct a corresponding protein-aligned CoMFA models by employing probe-based (H+, OH, CH3) energy grids and genetic partial least squares (G/PLS) statistical analysis. A total of 16 different docking configurations were evaluated, of which some succeeded in producing self-consistent and predictive CoMFA models. However, the best model coincided with docking the ionized ligands into the hydrated form of the binding site via PLP1 scoring function (rLOO2=0.735, rPRESS2 against 24 test compounds=0.828). The highest-ranking CoMFA models were employed to probe NA&ndash;ligand interactions. Further validation by comparison with a co-crystallized ligand&ndash;NA crystallographic structure was performed. This combination of docking/scoring/CoMFA modeling provided interesting insights into the binding of different NA inhibitors.</P>"
        },
        {
          "rank": 36,
          "score": 0.5512052774429321,
          "doc_id": "NART89644555",
          "title": "Big Data Analytics in Medicine and Healthcare",
          "abstract": "<P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART89644555&target=NART&cn=NART89644555",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare Big Data Analytics in Medicine and Healthcare <P><B>Abstract</B></P><P>This paper surveys big data with highlighting the big data analytics in medicine and healthcare. Big data characteristics: value, volume, velocity, variety, veracity and variability are described. Big data analytics in medicine and healthcare covers integration and analysis of large amount of complex heterogeneous data such as various &#x2013; omics data (genomics, epigenomics, transcriptomics, proteomics, metabolomics, interactomics, pharmacogenomics, diseasomics), biomedical data and electronic health records data. We underline the challenging issues about big data privacy and security. Regarding big data characteristics, some directions of using suitable and promising open-source distributed data processing software platform are given.</P>"
        },
        {
          "rank": 37,
          "score": 0.5501793026924133,
          "doc_id": "JAKO201608949924368",
          "title": "한국판 주산기 외상 후 스트레스장애 척도의 신뢰도 및 타당도",
          "abstract": "Purpose: The Perinatal Post-Traumatic Stress Disorder Questionnaire (PPQ) was designed to measure post-traumatic symptoms related to childbirth and symptoms during postnatal period. The purpose of this study was to develop a translated Korean version of the PPQ and to evaluate reliability and validity of the Korean PPQ. Methods: Participants were 196 mothers at one to 18 months after giving childbirth and data were collected through e-mails. The PPQ was translated into Korean using translation guideline from World Health Organization. For this study Cronbach's alpha and split-half reliability were used to evaluate the reliability of the PPQ. Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA), and known-group validity were conducted to examine construct validity. Correlations of the PPQ with Impact of Event Scale (IES), Beck Depression Inventory II (BDI-II), and Beck Anxiety Inventory (BAI) were used to test a criterion validity of the PPQ. Results: Cronbach's alpha and Spearman-Brown split-half correlation coefficient were 0.91 and 0.77, respectively. EFA identified a 3-factor solution including arousal, avoidance, and intrusion factors and CFA revealed the strongest support for the 3-factor model. The correlations of the PPQ with IES, BDI-II, and BAI were .99, .60, and .72, respectively, pointing to criterion validity of a high level. Conclusion: The Korean version PPQ is a useful tool for screening and assessing mothers' experiencing emotional distress related to child birth and during the postnatal period. The PPQ also reflects Post Traumatic Stress Disorder's diagnostic standards well.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201608949924368&target=NART&cn=JAKO201608949924368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "한국판 주산기 외상 후 스트레스장애 척도의 신뢰도 및 타당도 한국판 주산기 외상 후 스트레스장애 척도의 신뢰도 및 타당도 한국판 주산기 외상 후 스트레스장애 척도의 신뢰도 및 타당도 Purpose: The Perinatal Post-Traumatic Stress Disorder Questionnaire (PPQ) was designed to measure post-traumatic symptoms related to childbirth and symptoms during postnatal period. The purpose of this study was to develop a translated Korean version of the PPQ and to evaluate reliability and validity of the Korean PPQ. Methods: Participants were 196 mothers at one to 18 months after giving childbirth and data were collected through e-mails. The PPQ was translated into Korean using translation guideline from World Health Organization. For this study Cronbach's alpha and split-half reliability were used to evaluate the reliability of the PPQ. Exploratory Factor Analysis (EFA), Confirmatory Factor Analysis (CFA), and known-group validity were conducted to examine construct validity. Correlations of the PPQ with Impact of Event Scale (IES), Beck Depression Inventory II (BDI-II), and Beck Anxiety Inventory (BAI) were used to test a criterion validity of the PPQ. Results: Cronbach's alpha and Spearman-Brown split-half correlation coefficient were 0.91 and 0.77, respectively. EFA identified a 3-factor solution including arousal, avoidance, and intrusion factors and CFA revealed the strongest support for the 3-factor model. The correlations of the PPQ with IES, BDI-II, and BAI were .99, .60, and .72, respectively, pointing to criterion validity of a high level. Conclusion: The Korean version PPQ is a useful tool for screening and assessing mothers' experiencing emotional distress related to child birth and during the postnatal period. The PPQ also reflects Post Traumatic Stress Disorder's diagnostic standards well."
        },
        {
          "rank": 38,
          "score": 0.5500752925872803,
          "doc_id": "JAKO201819355173332",
          "title": "Support Vector Machine을 이용한 생체 신호 분류기 개발",
          "abstract": "피부 저항을 이용한 생체 신호는 스트레스성 질환에 따라 각각 다른 특성을 보이고 있으며 이 특성을 이용하여 스트레스성 질환을 진단하는 생체진단 장비들이 개발 되었으며, 장비들은 피부 저항 측정기에서 측정한 신호를 해석하기 쉽게 출력해주며, 그 분야의 전문가는 출력 신호를 직접 보고 어떤 스트레스성 질환의 가능성이 높은지를 판단하게 된다. 하지만 각 측정 대상자에게서 측정된 생체 신호를 분석하여 측정 대상자가 어떤 스트레스성 질환을 가지고 있는지를 사람이 정확히 판단하기는 매우 어려울 뿐만 아니라 판단의 결과가 잘못될 가능성도 매우 높다. 이런 문제점을 해결하기 위하여 본 연구에서는 머신러닝 기법을 이용하여 측정된 신호가 어떤 스트레스성 질환의 신호에 해당하는지를 판단하는 기능을 구현하였다. 측정 장비의 낮은 컴퓨팅 능력을 고려하여 분류 기법은 SVM을 사용하였으며, 훈련 데이터와 테스트 데이터는 13개의 질환을 중심으로 오차범위 5를 사용하여 각 질환 당 1,000개를 랜덤하게 생성하여 사용하였다. 모의실험 결과에서 90% 이상의 판단 정확도를 보였으며 앞으로 측정 장비가 실제로 환자들에게 적용되면 다시 생성된 데이터로 분류기를 재훈련 할 수 있게 구성하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201819355173332&target=NART&cn=JAKO201819355173332",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Support Vector Machine을 이용한 생체 신호 분류기 개발 Support Vector Machine을 이용한 생체 신호 분류기 개발 Support Vector Machine을 이용한 생체 신호 분류기 개발 피부 저항을 이용한 생체 신호는 스트레스성 질환에 따라 각각 다른 특성을 보이고 있으며 이 특성을 이용하여 스트레스성 질환을 진단하는 생체진단 장비들이 개발 되었으며, 장비들은 피부 저항 측정기에서 측정한 신호를 해석하기 쉽게 출력해주며, 그 분야의 전문가는 출력 신호를 직접 보고 어떤 스트레스성 질환의 가능성이 높은지를 판단하게 된다. 하지만 각 측정 대상자에게서 측정된 생체 신호를 분석하여 측정 대상자가 어떤 스트레스성 질환을 가지고 있는지를 사람이 정확히 판단하기는 매우 어려울 뿐만 아니라 판단의 결과가 잘못될 가능성도 매우 높다. 이런 문제점을 해결하기 위하여 본 연구에서는 머신러닝 기법을 이용하여 측정된 신호가 어떤 스트레스성 질환의 신호에 해당하는지를 판단하는 기능을 구현하였다. 측정 장비의 낮은 컴퓨팅 능력을 고려하여 분류 기법은 SVM을 사용하였으며, 훈련 데이터와 테스트 데이터는 13개의 질환을 중심으로 오차범위 5를 사용하여 각 질환 당 1,000개를 랜덤하게 생성하여 사용하였다. 모의실험 결과에서 90% 이상의 판단 정확도를 보였으며 앞으로 측정 장비가 실제로 환자들에게 적용되면 다시 생성된 데이터로 분류기를 재훈련 할 수 있게 구성하였다."
        },
        {
          "rank": 39,
          "score": 0.5493420362472534,
          "doc_id": "NART111572458",
          "title": "광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교",
          "abstract": "This study examines the classification characteristics of various machine learning classifiers for pain assessment using photoplethysmogram. The presence of pain was assessed using waveform characteristics derived from photoplethysmogram obtained from 73 patients before and after surgery. Classification performance was evaluated using logistic regression, random forest, multi-layer perceptron, and 1-D convolutional neural network, and was validated with nested k-fold cross validation. As a result, pain classification accuracy was highest in order of logistic regression, convolutional neural network, multi-layer perceptron, and random forest classifier. In addition, logistic regression, random forest, multi-layer perceptron, and convolutional neural network were shown to be robust to overfitting in order.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART111572458&target=NART&cn=NART111572458",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 광용적맥파 및 머신러닝 기반 통증 평가 분류기 성능 비교 This study examines the classification characteristics of various machine learning classifiers for pain assessment using photoplethysmogram. The presence of pain was assessed using waveform characteristics derived from photoplethysmogram obtained from 73 patients before and after surgery. Classification performance was evaluated using logistic regression, random forest, multi-layer perceptron, and 1-D convolutional neural network, and was validated with nested k-fold cross validation. As a result, pain classification accuracy was highest in order of logistic regression, convolutional neural network, multi-layer perceptron, and random forest classifier. In addition, logistic regression, random forest, multi-layer perceptron, and convolutional neural network were shown to be robust to overfitting in order."
        },
        {
          "rank": 40,
          "score": 0.5492340326309204,
          "doc_id": "JAKO202219656440810",
          "title": "BERTopic을 활용한 불면증 소셜 데이터 토픽 모델링 및 불면증 경향 문헌 딥러닝 자동분류 모델 구축",
          "abstract": "불면증은 최근 5년 새 환자가 20% 이상 증가하고 있는 현대 사회의 만성적인 질병이다. 수면이 부족할 경우 나타나는 개인 및 사회적 문제가 심각하고 불면증의 유발 요인이 복합적으로 작용하고 있어서 진단 및 치료가 중요한 질환이다. 본 연구는 자유롭게 의견을 표출하는 소셜 미디어 'Reddit'의 불면증 커뮤니티인 'insomnia'를 대상으로 5,699개의 데이터를 수집하였고 이를 국제수면장애분류 ICSD-3 기준과 정신의학과 전문의의 자문을 받은 가이드라인을 바탕으로 불면증 경향 문헌과 비경향 문헌으로 태깅하여 불면증 말뭉치를 구축하였다. 구축된 불면증 말뭉치를 학습데이터로 하여 5개의 딥러닝 언어모델(BERT, RoBERTa, ALBERT, ELECTRA, XLNet)을 훈련시켰고 성능 평가 결과 RoBERTa가 정확도, 정밀도, 재현율, F1점수에서 가장 높은 성능을 보였다. 불면증 소셜 데이터를 심층적으로 분석하기 위해 기존에 많이 사용되었던 LDA의 약점을 보완하며 새롭게 등장한 BERTopic 방법을 사용하여 토픽 모델링을 진행하였다. 계층적 클러스터링 분석 결과 8개의 주제군('부정적 감정', '조언 및 도움과 감사', '불면증 관련 질병', '수면제', '운동 및 식습관', '신체적 특징', '활동적 특징', '환경적 특징')을 확인할 수 있었다. 이용자들은 불면증 커뮤니티에서 부정 감정을 표현하고 도움과 조언을 구하는 모습을 보였다. 또한, 불면증과 관련된 질병들을 언급하고 수면제 사용에 대한 담론을 나누며 운동 및 식습관에 관한 관심을 표현하고 있었다. 발견된 불면증 관련 특징으로는 호흡, 임신, 심장 등의 신체적 특징과 좀비, 수면 경련, 그로기상태 등의 활동적 특징, 햇빛, 담요, 온도, 낮잠 등의 환경적 특징이 확인되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202219656440810&target=NART&cn=JAKO202219656440810",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "BERTopic을 활용한 불면증 소셜 데이터 토픽 모델링 및 불면증 경향 문헌 딥러닝 자동분류 모델 구축 BERTopic을 활용한 불면증 소셜 데이터 토픽 모델링 및 불면증 경향 문헌 딥러닝 자동분류 모델 구축 BERTopic을 활용한 불면증 소셜 데이터 토픽 모델링 및 불면증 경향 문헌 딥러닝 자동분류 모델 구축 불면증은 최근 5년 새 환자가 20% 이상 증가하고 있는 현대 사회의 만성적인 질병이다. 수면이 부족할 경우 나타나는 개인 및 사회적 문제가 심각하고 불면증의 유발 요인이 복합적으로 작용하고 있어서 진단 및 치료가 중요한 질환이다. 본 연구는 자유롭게 의견을 표출하는 소셜 미디어 'Reddit'의 불면증 커뮤니티인 'insomnia'를 대상으로 5,699개의 데이터를 수집하였고 이를 국제수면장애분류 ICSD-3 기준과 정신의학과 전문의의 자문을 받은 가이드라인을 바탕으로 불면증 경향 문헌과 비경향 문헌으로 태깅하여 불면증 말뭉치를 구축하였다. 구축된 불면증 말뭉치를 학습데이터로 하여 5개의 딥러닝 언어모델(BERT, RoBERTa, ALBERT, ELECTRA, XLNet)을 훈련시켰고 성능 평가 결과 RoBERTa가 정확도, 정밀도, 재현율, F1점수에서 가장 높은 성능을 보였다. 불면증 소셜 데이터를 심층적으로 분석하기 위해 기존에 많이 사용되었던 LDA의 약점을 보완하며 새롭게 등장한 BERTopic 방법을 사용하여 토픽 모델링을 진행하였다. 계층적 클러스터링 분석 결과 8개의 주제군('부정적 감정', '조언 및 도움과 감사', '불면증 관련 질병', '수면제', '운동 및 식습관', '신체적 특징', '활동적 특징', '환경적 특징')을 확인할 수 있었다. 이용자들은 불면증 커뮤니티에서 부정 감정을 표현하고 도움과 조언을 구하는 모습을 보였다. 또한, 불면증과 관련된 질병들을 언급하고 수면제 사용에 대한 담론을 나누며 운동 및 식습관에 관한 관심을 표현하고 있었다. 발견된 불면증 관련 특징으로는 호흡, 임신, 심장 등의 신체적 특징과 좀비, 수면 경련, 그로기상태 등의 활동적 특징, 햇빛, 담요, 온도, 낮잠 등의 환경적 특징이 확인되었다."
        },
        {
          "rank": 41,
          "score": 0.5482146739959717,
          "doc_id": "JAKO201810256456587",
          "title": "스쿼시 심판들이 경험하는 판정어려움에 대한 현상학적 접근",
          "abstract": "이 연구는 스쿼시심판이 경험하는 판정어려움을 Giorgi의 현상학적 분석방법을 통해 심판이 처해 있는 상황과 판정 결정의 어려움에 대한 근원을 규명하고자 하는 데 그 목적이 있다. 이러한 목적을 달성하기 위하여, 경력 10년 이상의 스쿼시 전문가 중 2016년 대한스쿼시연맹에 등록되어 있는 2급 이상의 자격을 보유한 심판 5명을 연구 참여자로 선정하였으며, 참여관찰 및 비구조적 반구조적 심층 면담을 병행하여 수집한 자료는 Giorgi의 현상학적 분석방법 4단계에 따라 '개인적 상황에서 오는 어려움', '사회적 상황에서 오는 어려움', '환경적 상황에서 오는 어려움'으로 구성요소로 통합하였다. 스쿼시심판의 판정에 대한 어려움들은 '외화내빈(外華內貧)'의 의미로 함축시킬 수 있으며, 이는 심판들에게 공정하고 객관화된 판정을 기대하기 위해 판정주체자인 심판들의 처우개선과 심판들의 지속화, 전문화의 필요성을 강조하고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810256456587&target=NART&cn=JAKO201810256456587",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스쿼시 심판들이 경험하는 판정어려움에 대한 현상학적 접근 스쿼시 심판들이 경험하는 판정어려움에 대한 현상학적 접근 스쿼시 심판들이 경험하는 판정어려움에 대한 현상학적 접근 이 연구는 스쿼시심판이 경험하는 판정어려움을 Giorgi의 현상학적 분석방법을 통해 심판이 처해 있는 상황과 판정 결정의 어려움에 대한 근원을 규명하고자 하는 데 그 목적이 있다. 이러한 목적을 달성하기 위하여, 경력 10년 이상의 스쿼시 전문가 중 2016년 대한스쿼시연맹에 등록되어 있는 2급 이상의 자격을 보유한 심판 5명을 연구 참여자로 선정하였으며, 참여관찰 및 비구조적 반구조적 심층 면담을 병행하여 수집한 자료는 Giorgi의 현상학적 분석방법 4단계에 따라 '개인적 상황에서 오는 어려움', '사회적 상황에서 오는 어려움', '환경적 상황에서 오는 어려움'으로 구성요소로 통합하였다. 스쿼시심판의 판정에 대한 어려움들은 '외화내빈(外華內貧)'의 의미로 함축시킬 수 있으며, 이는 심판들에게 공정하고 객관화된 판정을 기대하기 위해 판정주체자인 심판들의 처우개선과 심판들의 지속화, 전문화의 필요성을 강조하고 있다."
        },
        {
          "rank": 42,
          "score": 0.5478822588920593,
          "doc_id": "JAKO201925462478017",
          "title": "딥러닝 기반 항생제 내성균 감염 예측",
          "abstract": "세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201925462478017&target=NART&cn=JAKO201925462478017",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다."
        },
        {
          "rank": 43,
          "score": 0.547339677810669,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 44,
          "score": 0.5467882752418518,
          "doc_id": "NART97710485",
          "title": "Big data analytics for personalized medicine",
          "abstract": "<P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97710485&target=NART&cn=NART97710485",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics for personalized medicine Big data analytics for personalized medicine Big data analytics for personalized medicine <P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
        },
        {
          "rank": 45,
          "score": 0.5465689301490784,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART88129314&target=NART&cn=NART88129314",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>"
        },
        {
          "rank": 46,
          "score": 0.5459434390068054,
          "doc_id": "NART114795860",
          "title": "Comparison of two molecular docking programs: the accuracy of ligand pose prediction",
          "abstract": "<P>The study was perform to compare the output of two different docking programs (Molegro Vritual Docker and AutoDock) in simulation of ligand-receptor interactions for &beta;1 and &beta;2 adrenergic receptors. The exactness of the predicted ligand positions was estimated on the basis of the thirteen known crystallographic structures of the ligand-receptor complexes taken from the PDB database. Significant differences in docking results obtained by using both tested programs were observed. The overall RMSD-based scoring suggests that the procedures and algorithms implemented in AutoDock lead to slightly better results.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART114795860&target=NART&cn=NART114795860",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of two molecular docking programs: the accuracy of ligand pose prediction Comparison of two molecular docking programs: the accuracy of ligand pose prediction Comparison of two molecular docking programs: the accuracy of ligand pose prediction <P>The study was perform to compare the output of two different docking programs (Molegro Vritual Docker and AutoDock) in simulation of ligand-receptor interactions for &beta;1 and &beta;2 adrenergic receptors. The exactness of the predicted ligand positions was estimated on the basis of the thirteen known crystallographic structures of the ligand-receptor complexes taken from the PDB database. Significant differences in docking results obtained by using both tested programs were observed. The overall RMSD-based scoring suggests that the procedures and algorithms implemented in AutoDock lead to slightly better results.</P>"
        },
        {
          "rank": 47,
          "score": 0.5442054867744446,
          "doc_id": "DIKO0011931938",
          "title": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators",
          "abstract": "Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011931938&target=NART&cn=DIKO0011931938",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다."
        },
        {
          "rank": 48,
          "score": 0.5435030460357666,
          "doc_id": "DIKO0016674533",
          "title": "마우스 시토크롬 P450 17A1의 효소적 특성화 연구",
          "abstract": "시토크롬 P450 17A1(CYP17A1)은 스테로이드 호르몬의 17α-수산화 및 17,20-라이에이즈 반응을 촉매한다. 마우스의 게놈에는 CYP17A1 효소 병렬상동체가 포함되어 있으며 아미노산 서열은 인간 CYP17A1과 높은 유사성을 나타낸다. 본 연구에선 마우스 Cyp17a1과 시토크롬 b5 사이의 상호 작용을 연구하는 것을 목표로 했다. 마우스 Cyp17a1의 재조합 효소를 정제하고 프로게스테론과 프레그네놀론의 산화 반응을 특성화했다. 마우스 Cyp17a1 유전자의 오픈 리딩 프레임을 삽입하여 E. coli 시스템에서 성공적으로 발현시킨 다음 Ni2+-NTA 컬럼 크로마토그래피를 사용하여 정제했다. 정제된 마우스 Cyp17a1은 프로게스테론, 17α-OH 프로게스테론, 프레그네놀론 및 17α-OH 프레그네놀론에 대한 전형적인 Type Ⅰ 스펙트럼을 나타내고 인간 CYP17A1과 유사한 기질 결합 친화도를 나타냈다. CYP17A1의 17α-수산화 및 17,20-라이에이즈 반응에 대한 촉매 활성은 UPLC-MS/MS를 사용하여 연구되었다. 마우스 Cyp17a1은 시토크롬 b5 단백질을 첨가하면 효소활성이 증가되었다. 인간 CYP17A1과 비교하여 촉매 효율(kcat/Km)의 급격한 증가가 마우스 CYP17A1에서 관찰되었다. 특히, Δ4-스테로이드(프로게스테론과 17α-OH 프로게스테론)의 반응에서 촉매 효율은 인간 CYP17A1의 6,600배까지 향상되었다. b5가 있는 반응에선, 마우스 Cyp17a1의 17,20-라이에이즈 활성이 상당히 증가되었다. 활성 부위 산성 잔기 돌연변이체 (E305G)는 WT과 유사한 촉매 활성을 나타냈다. 그러나 마우스 Cyp17a1의 두가지 Arg 돌연변이체 (R347H 및 R358Q)는 17α-수산화반응보다 17α-OH 프레그네놀론에서 DHEA로의 17,20-라이에이즈 반응에서 더 높은 감소를 보여 마우스 CYP17A1의 이러한 염기성 잔기가 b5 단백질과 상호작용하는 데 중요하다는 것을 나타낸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016674533&target=NART&cn=DIKO0016674533",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "마우스 시토크롬 P450 17A1의 효소적 특성화 연구 마우스 시토크롬 P450 17A1의 효소적 특성화 연구 마우스 시토크롬 P450 17A1의 효소적 특성화 연구 시토크롬 P450 17A1(CYP17A1)은 스테로이드 호르몬의 17α-수산화 및 17,20-라이에이즈 반응을 촉매한다. 마우스의 게놈에는 CYP17A1 효소 병렬상동체가 포함되어 있으며 아미노산 서열은 인간 CYP17A1과 높은 유사성을 나타낸다. 본 연구에선 마우스 Cyp17a1과 시토크롬 b5 사이의 상호 작용을 연구하는 것을 목표로 했다. 마우스 Cyp17a1의 재조합 효소를 정제하고 프로게스테론과 프레그네놀론의 산화 반응을 특성화했다. 마우스 Cyp17a1 유전자의 오픈 리딩 프레임을 삽입하여 E. coli 시스템에서 성공적으로 발현시킨 다음 Ni2+-NTA 컬럼 크로마토그래피를 사용하여 정제했다. 정제된 마우스 Cyp17a1은 프로게스테론, 17α-OH 프로게스테론, 프레그네놀론 및 17α-OH 프레그네놀론에 대한 전형적인 Type Ⅰ 스펙트럼을 나타내고 인간 CYP17A1과 유사한 기질 결합 친화도를 나타냈다. CYP17A1의 17α-수산화 및 17,20-라이에이즈 반응에 대한 촉매 활성은 UPLC-MS/MS를 사용하여 연구되었다. 마우스 Cyp17a1은 시토크롬 b5 단백질을 첨가하면 효소활성이 증가되었다. 인간 CYP17A1과 비교하여 촉매 효율(kcat/Km)의 급격한 증가가 마우스 CYP17A1에서 관찰되었다. 특히, Δ4-스테로이드(프로게스테론과 17α-OH 프로게스테론)의 반응에서 촉매 효율은 인간 CYP17A1의 6,600배까지 향상되었다. b5가 있는 반응에선, 마우스 Cyp17a1의 17,20-라이에이즈 활성이 상당히 증가되었다. 활성 부위 산성 잔기 돌연변이체 (E305G)는 WT과 유사한 촉매 활성을 나타냈다. 그러나 마우스 Cyp17a1의 두가지 Arg 돌연변이체 (R347H 및 R358Q)는 17α-수산화반응보다 17α-OH 프레그네놀론에서 DHEA로의 17,20-라이에이즈 반응에서 더 높은 감소를 보여 마우스 CYP17A1의 이러한 염기성 잔기가 b5 단백질과 상호작용하는 데 중요하다는 것을 나타낸다."
        },
        {
          "rank": 49,
          "score": 0.5428898334503174,
          "doc_id": "NART71376020",
          "title": "Comparative effectiveness research and big data: balancing potential with legal and ethical considerations",
          "abstract": "<P>Big data holds big potential for comparative effectiveness research. The ability to quickly synthesize and use vast amounts of health data to compare medical interventions across settings of care, patient populations, payers and time will greatly inform efforts to improve quality, reduce costs and deliver more patient-centered care. However, the use of big data raises significant legal and ethical issues that may present barriers or limitations to the full potential of big data. This paper addresses the scope of some of these legal and ethical issues and how they may be managed effectively to fully realize the potential of big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART71376020&target=NART&cn=NART71376020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparative effectiveness research and big data: balancing potential with legal and ethical considerations Comparative effectiveness research and big data: balancing potential with legal and ethical considerations Comparative effectiveness research and big data: balancing potential with legal and ethical considerations <P>Big data holds big potential for comparative effectiveness research. The ability to quickly synthesize and use vast amounts of health data to compare medical interventions across settings of care, patient populations, payers and time will greatly inform efforts to improve quality, reduce costs and deliver more patient-centered care. However, the use of big data raises significant legal and ethical issues that may present barriers or limitations to the full potential of big data. This paper addresses the scope of some of these legal and ethical issues and how they may be managed effectively to fully realize the potential of big data.</P>"
        },
        {
          "rank": 50,
          "score": 0.5427836179733276,
          "doc_id": "DIKO0017103214",
          "title": "Streptomyces avermitilis CYP107P2와 terpenoids의 상호작용에 관한 구조적 고찰",
          "abstract": "Streptomyces avermitilis 게놈에는 일산화 반응을 촉매하는 시토크롬 P450 효소를 암호화하는 33개의 유전자가 포함되어 있다. 본 논문에서는 CYP107P2의 구조와 테르펜 화합물과의 상호작용을 조사하였다. 재조합된 CYP107P2 단백질을 대장균에서 발현시킨 후, 환원 상태에서 CO 결합 시 전형적인 P450 스펙트럼을 나타내는 것을 통해 단백질이 효과적으로 정제되었음을 확인하였다. (+)-알파 피넨, (-)-알파 피넨, (-)-베타 피넨, 알파-테르피닐 아세테이트, (+)-3-카렌 등 다양한 테르펜 화합물과의 결합 친화도를 확인한 결과 I 유형의 기질 결합 스펙트럼이 관찰되었다. 결합 친화도(Kd)는 15.9에서 50.8 µM의 범위 내에 있었다. CYP107P2의 X-선 결정 구조는 1.99Å의 높은 해상도로 성공적으로 결정되었으며, 전체적으로 잘 보존된 P450 접힘 형태를 보여주었다. 이 구조 정보를 이용하여, 테르펜 화합물 도킹 모델을 제작하였고, 테르펜과 CYP107P2 사이의 상호작용을 구조적 관점으로 확인하였다. 이 모델을 통해 헴철 부분과 테르펜 사이의 거리가 3.4에서 5.4Å 범위 내에 있음을 밝혀내었다. 이러한 상호작용은 잠재적인 기질 결합 부위에 대한 정보를 제공하여, CYP107P2가 이 테르펜 화합물을 효소 반응에서 기질로 작용할 수 있음을 시사한다.&amp;#xD; 이 연구는 Streptomyces avermitilis의 P450 효소인 CYP107P2가 테르펜을 기질로 촉매할 수 있음을 보여준다. 이러한 발견은 P450 효소의 다양한 기능에 대한 이해를 크게 진전시켰으며, 특히 테르펜과 시토크롬 효소 간의 반응이라는 맥락에서 중요하다. 테르펜 화합물과 CYP107P2의 효소 활성을 규명함으로써, 이러한 천연 물질의 생화학적 경로와 그 잠재적 응용에 대한 의미 있는 통찰을 제공한다. 또한 이러한 결과를 통해 테르펜과 반응하는 새로운 P450 효소의 작용 방식을 이해하는 데 중요한 성과를 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017103214&target=NART&cn=DIKO0017103214",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Streptomyces avermitilis CYP107P2와 terpenoids의 상호작용에 관한 구조적 고찰 Streptomyces avermitilis CYP107P2와 terpenoids의 상호작용에 관한 구조적 고찰 Streptomyces avermitilis CYP107P2와 terpenoids의 상호작용에 관한 구조적 고찰 Streptomyces avermitilis 게놈에는 일산화 반응을 촉매하는 시토크롬 P450 효소를 암호화하는 33개의 유전자가 포함되어 있다. 본 논문에서는 CYP107P2의 구조와 테르펜 화합물과의 상호작용을 조사하였다. 재조합된 CYP107P2 단백질을 대장균에서 발현시킨 후, 환원 상태에서 CO 결합 시 전형적인 P450 스펙트럼을 나타내는 것을 통해 단백질이 효과적으로 정제되었음을 확인하였다. (+)-알파 피넨, (-)-알파 피넨, (-)-베타 피넨, 알파-테르피닐 아세테이트, (+)-3-카렌 등 다양한 테르펜 화합물과의 결합 친화도를 확인한 결과 I 유형의 기질 결합 스펙트럼이 관찰되었다. 결합 친화도(Kd)는 15.9에서 50.8 µM의 범위 내에 있었다. CYP107P2의 X-선 결정 구조는 1.99Å의 높은 해상도로 성공적으로 결정되었으며, 전체적으로 잘 보존된 P450 접힘 형태를 보여주었다. 이 구조 정보를 이용하여, 테르펜 화합물 도킹 모델을 제작하였고, 테르펜과 CYP107P2 사이의 상호작용을 구조적 관점으로 확인하였다. 이 모델을 통해 헴철 부분과 테르펜 사이의 거리가 3.4에서 5.4Å 범위 내에 있음을 밝혀내었다. 이러한 상호작용은 잠재적인 기질 결합 부위에 대한 정보를 제공하여, CYP107P2가 이 테르펜 화합물을 효소 반응에서 기질로 작용할 수 있음을 시사한다.&amp;#xD; 이 연구는 Streptomyces avermitilis의 P450 효소인 CYP107P2가 테르펜을 기질로 촉매할 수 있음을 보여준다. 이러한 발견은 P450 효소의 다양한 기능에 대한 이해를 크게 진전시켰으며, 특히 테르펜과 시토크롬 효소 간의 반응이라는 맥락에서 중요하다. 테르펜 화합물과 CYP107P2의 효소 활성을 규명함으로써, 이러한 천연 물질의 생화학적 경로와 그 잠재적 응용에 대한 의미 있는 통찰을 제공한다. 또한 이러한 결과를 통해 테르펜과 반응하는 새로운 P450 효소의 작용 방식을 이해하는 데 중요한 성과를 제시한다."
        }
      ]
    },
    {
      "query": "How do machine learning and deep learning approaches help overcome these challenges in pharmacogenomics research for antidepressant treatment prediction?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8618699908256531,
          "doc_id": "ART002777203",
          "title": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments",
          "abstract": "A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002777203&target=NART&cn=ART002777203",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms."
        },
        {
          "rank": 2,
          "score": 0.733672022819519,
          "doc_id": "JAKO202510839606788",
          "title": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할",
          "abstract": "우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510839606788&target=NART&cn=JAKO202510839606788",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증에 대한 맞춤형 항우울제 치료에서 CYP2D6 유전자 변이 및 가족력의 역할 우울증은 유전적, 환경적, 가족적 요인으로 인해 치료 반응에 상당한 변동성을 보이는, 전 세계적으로 만연한 정신 건강 장애이다. 주로 신경전달물질 균형을 목표로 하는 현재의 항우울제 치료법은 모든 환자에서 일관된 효과를 얻지 못하는 경우가 많으며, 일부 환자에서는 심각한 부작용을 일으킬 수 있다. 이는 개인 맞춤형 치료 접근법의 필요성을 강조하며, 약물 유전체학은 특히 다양한 항우울제 대사에 중요한 역할을 하는 CYP2D6 유전자 분석을 통해 정밀 의학의 중추적인 도구로 부상하고 있다. CYP2D6의 변이는 개인을 다양한 대사체 유형으로 분류하여 약물 효능과 부작용 위험에 직접적인 영향을 미칠 수 있다. 약물 유전체 데이터와 가족력을 통합하면 항우울제 치료를 최적화하여 임상 결과를 개선하고 의료 비용을 절감할 수 있는 포괄적인 전략이 제공된다. 그러나 약물 유전체학의 임상 구현은 다양한 인구집단에 대한 제한된 유전자 데이터, 높은 유전자 검사 비용, 표준화된 프로토콜의 부재, 유전자 정보 프라이버시와 관련된 윤리적 문제와 같은 도전에 직면해 있다. 공동 연구, 정책 개발, 의료 전문가 교육을 통해 이러한 장벽을 극복하는 것은 우울증 치료에서 약물 유전체학을 널리 채택하는 데 필수적이다. 궁극적으로 약물 유전체 인사이트에 기반한 개인 맞춤형 의약품은 우울증 치료의 효과와 안전성을 크게 개선할 가능성이 있다."
        },
        {
          "rank": 3,
          "score": 0.7153093814849854,
          "doc_id": "JAKO200135164626995",
          "title": "우울증의 약물유전체학",
          "abstract": "The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200135164626995&target=NART&cn=JAKO200135164626995",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "우울증의 약물유전체학 우울증의 약물유전체학 우울증의 약물유전체학 The pharmacotherapy of depression has reduced morbidity and improved outcome for many depressive patients. A wide range of classical and new antidepressants are available for their treatment. However, 30-40% of all patients do not respond sufficiently to the initial treatment and present adverse effects. Pharmacogenetics studies the genetic basis of an individual's ability to respond to pharmacotherapy. Recently, some reports on serotonin transporter gene polymorphisms and their influence on the response to antidepressive therapy provide an interesting diagnostic tool in assessing the chances of response to antidepressants. We also investigated the relationship between serotonin transprter polymorphisms(5-HTTLPR) and the long-term effect of the antidepressant treatment. 128 depressive patients were enrolled into 2nd year study. The therapeutic response of each subset was not different at 8th, 16th week, but the subset with homozygote(l/l) of long variant showed a better therapeutic response to antidepressant than the heterozygote(l/s) of long and short variant, which showed a better therapeutic response than the subset with homozygote (s/s) of short variant at 1st year and 2nd year after the antidepressant treatment. This result shows that the serotonin transporter polymorphisms may be related to the long-term effect of antidepressant treatment. The potential for pharmacogenomics, the use of genetic information to guide pharmacotherapy and improve outcome by providing individualized treatment decisions, has gained increasing attention. pharmacogenomics will contribute to individualize drug choice by using genotype to predict positive clinical outcomes, adverse reactions, and levels of drug metabolism. Personalized medicine, the use of marker-assisted diagnosis and targeted therapies derived from an individual molecular profile, will impact the antidepressant therapy and this approach will replace the traditional trial-and-error practice of medicine."
        },
        {
          "rank": 4,
          "score": 0.700385332107544,
          "doc_id": "PRE0001266558",
          "title": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models",
          "abstract": "<jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=PRE0001266558&target=NART&cn=PRE0001266558",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models Enhancing CYP450-Ligand Binding Predictions: A Comparative Analysis of Ligand-Based and Hybrid Machine Learning Models <jats:title>ABSTRACT</jats:title><jats:p>Predicting cytochrome P450 (CYP450) ligand binding is critical in early-stage drug discovery, as CYP450-mediated metabolism profoundly influences drug efficacy, safety, and adverse reaction risks. However, experimental determination of CYP450-ligand interactions remains resource- and time-intensive, underscoring the need for robust computational alternatives. While ligand-based methods are commonly employed, they often fail to fully account for structural intricacies governing protein-ligand interactions. To address this gap, we developed a hybrid machine learning framework integrating ligand descriptors, protein descriptors, and protein-ligand interaction descriptors, that include molecular docking-derived parameters, rescoring function components from multiple algorithms and structural interaction fingerprints (SIFt). Evaluated on CYP1A2 and CYP17A1 isoforms, our model demonstrated superior predictive accuracy in cross-validation compared to stand-alone molecular docking and ligand-based approaches. Furthermore, benchmarking against state-of-the-art tools —SwissADME and ADMETlab 3.0 — revealed enhanced performance in binding prediction. This work establishes a versatile framework for advancing computational tools to prioritize CYP450 binding assessments during drug discovery.</jats:p>"
        },
        {
          "rank": 5,
          "score": 0.6888374090194702,
          "doc_id": "JAKO202117563196990",
          "title": "약물유전체학에서 약물반응 예측모형과 변수선택 방법",
          "abstract": "약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202117563196990&target=NART&cn=JAKO202117563196990",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학에서 약물반응 예측모형과 변수선택 방법 약물유전체학 연구의 주요 목표는 고차원의 유전 변수를 기반으로 개인의 약물 반응성을 예측하는 것이다. 변수의 개수가 많기 때문에 변수의 개수를 줄이기 위해서는 변수 선택이 필요하며, 선택된 변수들은 머신러닝 알고리즘을 사용하여 예측 모델을 구축하는데 사용된다. 본 연구에서는 400명의 뇌전증 환자의 차세대 염기서열 분석 데이터에 로지스틱 회귀, ReliefF, TurF, 랜덤 포레스트, LASSO의 조합과 같은 여러 가지 혼합 변수 선택 방법을 적용하였다. 선택된 변수들에 랜덤포레스트, 그래디언트 부스팅, 서포트벡터머신을 포함한 머신러닝 방법들을 적용했고 스태킹을 통해 앙상블 모형을 구축하였다. 본 연구의 결과는 랜덤포레스트와 ReliefF의 혼합 변수 선택 방법을 이용한 스태킹 모형이 다른 모형보다 더 좋은 성능을 보인다는 것을 보여주었다. 5-폴드 교차 검증을 기반으로 하여 적합한 최적 모형의 평균 검증 정확도는 0.727이고 평균 검증 AUC 값은 0.761로 나타났다. 또한, 동일한 변수를 사용할 때 스태킹 모델이 단일 머신러닝 예측 모델보다 성능이 우수한 것으로 나타났다."
        },
        {
          "rank": 6,
          "score": 0.6843053102493286,
          "doc_id": "JAKO200235164627099",
          "title": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측",
          "abstract": "우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200235164627099&target=NART&cn=JAKO200235164627099",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 약리 유전학적 방법을 이용한 항우울제 치료반응성의 예측 우울증 환자들에게 항우울제를 처방하는 임상의들이 흔히 겪게 되는 두 가지 어려움은 약물의 치료 반응 유무를 판단하기 위하여 처음 약물을 투여한 후 4~6주 이상을 기다려야 하는 것과 어떤 종류의 항우울제라도 처음 4~6주 이후에도 반응을 보이지 않는 환자들이 30~40% 이상이 된다는 것이다. 이와 같은 어려움을 극복하기 위해서는 환자 개개인의 항우울제에 대한 반응성을 미리 예측하는 것이 필요하다. 이 논문에서는 연구자들의 과거 실험들과 이미 발표된 연구들을 중심으로 하여 항우울제에 대한 치료 반응성을 예측하는데 약리유전학적 방법을 이용한 현재까지의 연구들과 연구 결과를 해석 할때 고려해야 할 사항을 살펴보고자 한다. 세로토닌 수송체(serotonin transporter, 5-HTT)는 항우울제가 신경세포에 작용하는 주요 작용부위 중 하나이다. 최근의 연구들에 의하면 5-HTT 유전자 promoter 부위의 기능적인 다형성(5-HTT linked polymorphism repetitive element in promoter region, 5-HTTLPR)이 항우울제에 대한 치료 반응성과 관련이 있는 것으로 알려져 있으며, 5-HTTLPR 유전형의 분포빈도는 인종들 간에서 차이가 있는 것으로 알려져 있다. 연구자들은 최근의 실험을 통하여 5-HTTLPR 유전형들의 endophenotype을 혈소판 막에 분포하는 5-HTT의 약동학적 특성으로 측정할 수 있음을 발견하였다. 흥미로운 사실은 5-HTTLPR 유전형의 분포가 인종적으로 다른 양상으로 나타났듯이, 그 endophenotype인 혈소판막의 5-HTT의 약동학적 특성 역시 전혀 반대되는 양상으로 나타났다. 하지만 이 endophenotype의 특성만으로 항우울제의 치료반응을 예측하는 것은 아직까지 한계가 있으며, 향후 이러한 과제를 해결하기 위한 방법중 약리유전학적 방법을 사용할 수 있음을 제안하였다. 예비적으로 시행한 실험을 통하여 연구자들은 세로토닌 수송체의 구조와 특징이 비슷한 생체아민 수송체들의 유전자 다형성들 간에 유의한 상관관계가 있음을 발견하였으며, 이들 유의한 상관관계가 있는 유전자형을 연합하여 조합할 때 세로토닌 수송체의 유전형만의 기여도보다도 항우울제에 대한 반응 예측도의 odds ratio가 유의하게 상승함을 발견하였다. 이러한 연구 결과들은 임상의가 항우울제를 처방 할 때에 환자들의 유전적 그리고 인종적인 배경을 고려하여 개별화된 전략을 사용하여야 한다는 가설을 뒷받침한다. 앞으로 항우울제의 작용기전과 그 대사과정에 관여하는 유전자들들 중심으로 유전자 간의 상호 작용을 밝히고 그 표현형이 약물의 치료 반응도에 미치는 기여도를 평가하는 작업들은 항우울제의 치료 반응과 그 부작용을 미리 예측할 수 있는 평가 도구를 개발할 수 있는 가장 최선의 길이 될 수 있을 것이다."
        },
        {
          "rank": 7,
          "score": 0.6588748693466187,
          "doc_id": "NART118947969",
          "title": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction",
          "abstract": "<P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118947969&target=NART&cn=NART118947969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction <P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>"
        },
        {
          "rank": 8,
          "score": 0.6488893628120422,
          "doc_id": "JAKO202211040631899",
          "title": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석",
          "abstract": "국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202211040631899&target=NART&cn=JAKO202211040631899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 딥러닝 기반 소셜미디어 한글 텍스트 우울 경향 분석 국내를 비롯하여 전 세계적으로 우울증 환자 수가 매년 증가하는 추세이다. 그러나 대다수의 정신질환 환자들은 자신이 질병을 앓고 있다는 사실을 인식하지 못해서 적절한 치료가 이루어지지 않고 있다. 우울 증상이 방치되면 자살과 불안, 기타 심리적인 문제로 발전될 수 있기에 우울증의 조기 발견과 치료는 정신건강 증진에 있어 매우 중요하다. 이러한 문제점을 개선하기 위해 본 연구에서는 한국어 소셜 미디어 텍스트를 활용한 딥러닝 기반의 우울 경향 모델을 제시하였다. 네이버 지식인, 네이버 블로그, 하이닥, 트위터에서 데이터수집을 한 뒤 DSM-5 주요 우울 장애 진단 기준을 활용하여 우울 증상 개수에 따라 클래스를 구분하여 주석을 달았다. 이후 구축한 말뭉치의 클래스 별 특성을 살펴보고자 TF-IDF 분석과 동시 출현 단어 분석을 실시하였다. 또한, 다양한 텍스트 특징을 활용하여 우울 경향 분류 모델을 생성하기 위해 단어 임베딩과 사전 기반 감성 분석, LDA 토픽 모델링을 수행하였다. 이를 통해 문헌 별로 임베딩된 텍스트와 감성 점수, 토픽 번호를 산출하여 텍스트 특징으로 사용하였다. 그 결과 임베딩된 텍스트에 문서의 감성 점수와 토픽을 모두 결합하여 KorBERT 알고리즘을 기반으로 우울 경향을 분류하였을 때 가장 높은 정확률인 83.28%를 달성하는 것을 확인하였다. 본 연구는 다양한 텍스트 특징을 활용하여 보다 성능이 개선된 한국어 우울 경향 분류 모델을 구축함에 따라, 한국 온라인 커뮤니티 이용자 중 잠재적인 우울증 환자를 조기에 발견해 빠른 치료 및 예방이 가능하도록 하여 한국 사회의 정신건강 증진에 도움을 줄 수 있는 기반을 마련했다는 점에서 의의를 지닌다."
        },
        {
          "rank": 9,
          "score": 0.6409908533096313,
          "doc_id": "DIKO0014389969",
          "title": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors",
          "abstract": "Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014389969&target=NART&cn=DIKO0014389969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Comprehensive computational study of glutaminyl cyclase inhibitors, TRPV1 antagonists, and cytochrome P450 inhibitors Part I. Comprehensive Computational Study of Human Glutaminyl Cyclase Inhibitors for the Drug Discovery of Alzheimer’s Disease&amp;#xD; Glutaminyl cyclase (QC)는 N-terminal의 glutamyl 또는 glutaminyl을 pyroglutamate로 만드는 효소이다. 만들어진 pyroglutamate-modified Aβ 펩타이드는 Aβ 다량체로 응합되고, 이는 뇌세포 사멸 등 신경독성을 야기하여 신경퇴행성 질환인 알츠하이머를 악화시키는 등 매우 유해한 독성물질로 알려져 있다. 따라서 human QC(hQC)를 저해함으로써 알츠하이머 치료 효과를 발현할 수 있을 것으로 보고되고 있다. 최근들어 hQC 천연 기질의 약리작용단을 토대로 hQC 저해제들이 디자인 및 합성되었는데, 그 중에서 작용기가 덧붙여진 두 종류의 화합물들이 상당히 좋은 저해활성을 보여주고 있다. 저해활성을 보이는 제1, 2세대 화합물의 결합모드를 분석하고자 분자도킹 및 QM-Polarized 리간드 도킹을 수행하였다. 얻어진 단백질-리간드 복합체는 Local Optimization과 Monte Carlo minimization을 통해 refine하였다. 제1세대 화합물들은 Glu327의 곁사슬과의 강한 정전기적 상호작응을 통해 더 좋아진 저해활성을 보이는 것으로 나타났고, 제2세대 화합물들도 덧붙여진 작용기가 소수성 상호작용과 Glu327과의 정전기적 상호작응 등을 통해 개선된 저해효과를 나타내는 것으로 판단되었다. 이러한 결과들은 알츠하이머 치료제를 개발하는데 있어서 중요한 정보를 제공해줄 수 있을 것이다.&amp;#xD; Part II. Analyses of TRPV1 structure and binding modes of its antagonists for neuropathic pain drug discovery&amp;#xD; Transient receptor potential vanilloid subtype 1 (TPRV1)은 중추와 말초신경계에서 존재하는 비선택적 양이온 채널로서 열이나 기계적, 화학적 자극에 의해 활성화되며 염증 및 통각감지 등에 관여한다. 효과적인 통증치료제 개발을 위해 디자인 및 합성된 TRPV1 길항제인 2-(3-fluoro-4-methylsulfonylaminophenyl)propanamide 유도체들을 human TRPV1 상동수용체 모델을 이용하여 flexible한 분자도킹을 수행하였고 자세한 결합모드를 분석하였다. 활성이 높은 길항제들은 TRPV1의 결합 부위에 매우 잘 결합하였고 특히, 활성을 높이기 위해 B- 및 C-region을 치환한 화합물들의 경우, 그 치환기들이 TRPV1의 소수성 포켓 부분과 추가적인 소수성 결합을 했을 때 활성이 높아지는 것을 확인할 수 있었다.&amp;#xD; Part III. In silico classification of cytochrome P450 inhibitors using machine learning methods&amp;#xD; Cytochrome P450 (CYP)은 phase I 대사에서 산화작용을 하는 중요한 효소 superfamily이다. 특히, CYP1A2, 2C9, 2C19, 2D6와 3A4는 현재 임상에서 사용 중인 전체 약물 대사의 약 80% 이상에 관여하는 중요한 효소로 알려져있다. 약물을 병용투여하는 경우, 다른 약물의 대사를 저해하는 것은 큰 문제를 유발할 수 있으므로 약물개발 초기에 CYP 저해제들을 탐지하여 그 화합물이 약물개발 후반에서 fail될 가능성을 미리 예측할 수 있으며 비용과 시간의 손실을 줄일 수 있을 것이다. NIH에서는 17,000여개의 약물들에 대해 CYP isoform별 저해효과를 측정하였고 본 연구에서는 NIH의 big data를 이용하여 그 화합물들을 구조를 기반으로 VolSurf+ descriptor들과 Pipeline Pilot의 fingerprints descriptor들을 계산하였다. Laplacian-modified naïve Bayesian, random forest (RF), recursive partitioning (RP), support vector machine (SVM) 등 네 가지 머신러닝 방법들을 이용하여 isoform별 저해제/비저해제 분류모델을 수립하였다. 각각의 모델들은 정확도, 민감도, 특수성 및 ROC, MCC 등 방법으로 평가한 결과, 매우 높은 수준의 모델로 판명되었다. 또한, 수립된 모델들에 대해 validation data set으로 검증한 결과, 매우 신뢰도가 높은 예측 결과를 보여주었다."
        },
        {
          "rank": 10,
          "score": 0.6371577382087708,
          "doc_id": "NART123506805",
          "title": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review",
          "abstract": "<P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123506805&target=NART&cn=NART123506805",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review Prediction of Preeclampsia Using Machine Learning and Deep Learning Models: A Review <P>Preeclampsia is one of the illnesses associated with placental dysfunction and pregnancy-induced hypertension, which appears after the first 20 weeks of pregnancy and is marked by proteinuria and hypertension. It can affect pregnant women and limit fetal growth, resulting in low birth weights, a risk factor for neonatal mortality. Approximately 10% of pregnancies worldwide are affected by hypertensive disorders during pregnancy. In this review, we discuss the machine learning and deep learning methods for preeclampsia prediction that were published between 2018 and 2022. Many models have been created using a variety of data types, including demographic and clinical data. We determined the techniques that successfully predicted preeclampsia. The methods that were used the most are random forest, support vector machine, and artificial neural network (ANN). In addition, the prospects and challenges in preeclampsia prediction are discussed to boost the research on artificial intelligence systems, allowing academics and practitioners to improve their methods and advance automated prediction.</P>"
        },
        {
          "rank": 11,
          "score": 0.6337085962295532,
          "doc_id": "NART131648944",
          "title": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning",
          "abstract": "<P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART131648944&target=NART&cn=NART131648944",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning Comprehensive hepatotoxicity prediction: ensemble model integrating machine learning and deep learning <P><B>Background</B></P><P>Chemicals may lead to acute liver injuries, posing a serious threat to human health. Achieving the precise safety profile of a compound is challenging due to the complex and expensive testing procedures. In silico approaches will aid in identifying the potential risk of drug candidates in the initial stage of drug development and thus mitigating the developmental cost.</P><P><B>Methods</B></P><P>In current studies, QSAR models were developed for hepatotoxicity predictions using the ensemble strategy to integrate machine learning (ML) and deep learning (DL) algorithms using various molecular features. A large dataset of 2588 chemicals and drugs was randomly divided into training (80%) and test (20%) sets, followed by the training of individual base models using diverse machine learning or deep learning based on three different kinds of descriptors and fingerprints. Feature selection approaches were employed to proceed with model optimizations based on the model performance. Hybrid ensemble approaches were further utilized to determine the method with the best performance.</P><P><B>Results</B></P><P>The voting ensemble classifier emerged as the optimal model, achieving an excellent prediction accuracy of 80.26%, AUC of 82.84%, and recall of over 93% followed by bagging and stacking ensemble classifiers method. The model was further verified by an external test set, internal 10-fold cross-validation, and rigorous benchmark training, exhibiting much better reliability than the published models.</P><P><B>Conclusion</B></P><P>The proposed ensemble model offers a dependable assessment with a good performance for the prediction regarding the risk of chemicals and drugs to induce liver damage.</P>"
        },
        {
          "rank": 12,
          "score": 0.6244223713874817,
          "doc_id": "JAKO202022560454224",
          "title": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용",
          "abstract": "Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202022560454224&target=NART&cn=JAKO202022560454224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 텍스트 분류 기반 기계학습의 정신과 진단 예측 적용 Objectives The aim was to find effective vectorization and classification models to predict a psychiatric diagnosis from text-based medical records. Methods Electronic medical records (n = 494) of present illness were collected retrospectively in inpatient admission notes with three diagnoses of major depressive disorder, type 1 bipolar disorder, and schizophrenia. Data were split into 400 training data and 94 independent validation data. Data were vectorized by two different models such as term frequency-inverse document frequency (TF-IDF) and Doc2vec. Machine learning models for classification including stochastic gradient descent, logistic regression, support vector classification, and deep learning (DL) were applied to predict three psychiatric diagnoses. Five-fold cross-validation was used to find an effective model. Metrics such as accuracy, precision, recall, and F1-score were measured for comparison between the models. Results Five-fold cross-validation in training data showed DL model with Doc2vec was the most effective model to predict the diagnosis (accuracy = 0.87, F1-score = 0.87). However, these metrics have been reduced in independent test data set with final working DL models (accuracy = 0.79, F1-score = 0.79), while the model of logistic regression and support vector machine with Doc2vec showed slightly better performance (accuracy = 0.80, F1-score = 0.80) than the DL models with Doc2vec and others with TF-IDF. Conclusions The current results suggest that the vectorization may have more impact on the performance of classification than the machine learning model. However, data set had a number of limitations including small sample size, imbalance among the category, and its generalizability. With this regard, the need for research with multi-sites and large samples is suggested to improve the machine learning models."
        },
        {
          "rank": 13,
          "score": 0.6175715923309326,
          "doc_id": "DIKO0013687734",
          "title": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발",
          "abstract": "현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687734&target=NART&cn=DIKO0013687734",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 분자 docking 예측과 3D-QSAR를 이용한 Glutaminyl cyclase의 억제제 개발 현재 컴퓨터를 이용한 방법과 기술을 통해 대규모 분자 시뮬레이션 연구와 분석을 편리하게 사용 가능하게 됐다. Glutaminyl cyclase(QC)는 Amyloid-β의 N-terminal을 촉매 함으로써 알츠하이머 병 발병에 중요한 역할을 한다고 알려져 있다. 수정된 Amyloid-β인 Pyroglutamate Amyloid-β는 더 안정적이고, Amyloid-β와 Pyroglutamate Amyloid-β 모두 알츠하이머 병에 중요한 역할을 한다. 게다가 Glutaminyl cyclase(QC)의 촉매 작용은 Amyloid-β fibril의 응집 속도를 증가시킨다. Glutaminyl cyclase 단백질의 억제제를 확인하는 것이 알츠하이머 병 관련 의료 방법을 향상시킬 약의 개발을 이끌 것으로 보인다. 우리는 in silico적인 방법인 CoMFA를 이용해 이 효소의 잠재력 있는 억제제를 개발하는 연구를 했다. in vtro 방법은 단백질과 리간드 사이의 상호작용을 연구하기에 시간과 비용이 많이 소비된다. 그래서 in vitro 실험을 하기 전에 단백질과 리간드의 상호작용을 예측하기 위해 컴퓨터를 통한 접근(in silico)을 적용하는 것이 필요하다. 그래서 Glutaminyl cyclase 단백질의 억제제를 찾는 것이 중요하다. CoMFA(Comparative Molecular Field Analysis)는 알려진 활성 분자의 데이터를 기반으로 한 3D-QSAR 기술이다. CoMFA는 수용체의 3D 구조가 알려지지 않았을 때 적용될 수 있다. SYBYL 프로그램에 있는 CoMFA를 이용해 실험적 데이터가 있는 리간드를 통해 model을 만들고 선택된 리간드를 단백질에 docking하고, AMBER를 이용해 단백질과 리간드의 상호작용 free energy를 계산했다."
        },
        {
          "rank": 14,
          "score": 0.6175674796104431,
          "doc_id": "DIKO0016916476",
          "title": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening",
          "abstract": "단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016916476&target=NART&cn=DIKO0016916476",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening Learning from ensemble-based protein-ligand interactions to improve structure-based virtual screening 단백질의 동적 특성은 구조 기반 가상 탐색에서 도전 과제를 제기해왔으며, 특히 단백질의 유연성을 반영하는 데 어려움을 겪어왔다. 본 연구에서는 단백질의 유연성을 반영하는 기계 학습 기반의 점수 함수를 개발했다. 앙상블 도킹과 기계학습을 위한 다양한 특징화 방법을 결합하여 도킹의 점수함수 성능을 능가했다. 또한 현실의 구조 기반 신약개발 상황에서 신규 타겟의 경우에는 단백질 구조가 부족하거나 존재하지 않는 경우가 많다. 하지만 앙상블 도킹은 여러 단백질 구조를 필요로 하기 때문에, 가우시안 가속 분자 동역학을 결정 구조의 대안으로서의 잠재력을 탐구했다. 본 연구의 결과는 가우시안 가속 분자동역학의 효능을 검증하며, 심지어 결정 구조의 성능과 비슷하거나 능가함을 보여준다. 추가적으로, DUDE 데이터셋을 사용한 이전의 기계학습 기반 점수 함수 연구에서의 과대 평가가 있었으므로, 더 정확한 성능 평가를 위해 LIT-PCBA 데이터셋을 도입했다. 본 연구가 제안한 방법은 그룹화된 특징 중요도 분석을 활용하여 기계학습 모델에 대한 최적의 앙상블 조합을 선택하며, 미래의 가상 탐색 노력에 대한 선례를 제안한다."
        },
        {
          "rank": 15,
          "score": 0.6173069477081299,
          "doc_id": "NART124447608",
          "title": "Lifelong Machine Learning Potentials",
          "abstract": "<P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART124447608&target=NART&cn=NART124447608",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials <P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>"
        },
        {
          "rank": 16,
          "score": 0.6164239645004272,
          "doc_id": "JAKO202523357605044",
          "title": "기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구",
          "abstract": "당뇨병의 조기 진단과 예측은 질환 진행을 막고 효과적인 치료 전략을 수립하는 데 필수적이다. 본 연구는 머신러닝(SVM, Random Forest, XGBoost) 및 딥러닝(ANN, CNN, LSTM) 기법을 활용하여 당뇨병 예측 모델을 개발하고 성능을 비교&#x00B7;분석하였다. 데이터 불균형 해결을 위해 GAN 기반 데이터 증강을 적용하고, SHAP 기법을 활용해 모델의 예측 과정을 설명 가능하도록 설계하였다. 또한, 국내 병원 EHR 및 웨어러블 데이터 활용을 통해 한국인의 특성을 반영한 모델을 구축하였다. 향후 연구에서는 당뇨병뿐만 아니라 다양한 만성질환 예측과 실시간 모니터링 및 맞춤형 예방 시스템 개발에 기여하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202523357605044&target=NART&cn=JAKO202523357605044",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 기계학습과 딥러닝을 활용한 당뇨병 조기 예측 모델 개발 및 최적화 연구 당뇨병의 조기 진단과 예측은 질환 진행을 막고 효과적인 치료 전략을 수립하는 데 필수적이다. 본 연구는 머신러닝(SVM, Random Forest, XGBoost) 및 딥러닝(ANN, CNN, LSTM) 기법을 활용하여 당뇨병 예측 모델을 개발하고 성능을 비교&#x00B7;분석하였다. 데이터 불균형 해결을 위해 GAN 기반 데이터 증강을 적용하고, SHAP 기법을 활용해 모델의 예측 과정을 설명 가능하도록 설계하였다. 또한, 국내 병원 EHR 및 웨어러블 데이터 활용을 통해 한국인의 특성을 반영한 모델을 구축하였다. 향후 연구에서는 당뇨병뿐만 아니라 다양한 만성질환 예측과 실시간 모니터링 및 맞춤형 예방 시스템 개발에 기여하고자 한다."
        },
        {
          "rank": 17,
          "score": 0.6132866144180298,
          "doc_id": "NART95036368",
          "title": "Deep Reinforcement Learning in Medicine",
          "abstract": "<P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95036368&target=NART&cn=NART95036368",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine Deep Reinforcement Learning in Medicine <P>Reinforcement learning has achieved tremendous success in recent years, notably in complex games such as Atari, Go, and chess. In large part, this success has been made possible by powerful function approximation methods in the form of deep neural networks. The objective of this paper is to introduce the basic concepts of reinforcement learning, explain how reinforcement learning can be effectively combined with deep learning, and explore how deep reinforcement learning could be useful in a medical context.</P>"
        },
        {
          "rank": 18,
          "score": 0.6113409996032715,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 19,
          "score": 0.6077831387519836,
          "doc_id": "ATN0038661375",
          "title": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험",
          "abstract": "Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038661375&target=NART&cn=ATN0038661375",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
        },
        {
          "rank": 20,
          "score": 0.6075369715690613,
          "doc_id": "DIKO0015784784",
          "title": "머신러닝/딥러닝을 통한 지역별 발병 빈도 예측",
          "abstract": "의료데이터 분석을 이용한 의료/헬스케어 서비스에 대한 관심은 본격적으로&amp;#xD; 빅데이터/AI 의 가능성이 논의되기 이전부터 의료업계 및 IT 산업에서 큰 관심의&amp;#xD; 대상이었으며, 특히 의료 서비스의 비용 문제가 커다란 사회적 이슈인 미국에서는&amp;#xD; 의료서비스의 비용을 낮추면서도 그 질을 높일 수 있는 대안으로 의료 빅데이터에&amp;#xD; 대한 연구가 활발히 진행되어 왔다. 하지만 데이터의 익명성 문제와 보안 문제,&amp;#xD; 특히 의료데이터는 유출시 프라이버시와 관련하여 심각한 문제를 초래할 수 있어&amp;#xD; 의료데이터의 사용에는 많은 난관이 있었다.&amp;#xD; 본 연구는 이러한 문제점을 해결하기 위해 만들어진 컨소시엄에 포함된 전국&amp;#xD; 30 개의 병원 및 의료기관의 데이터를 활용하여 특정한 다빈도 발병 질병의 지역별&amp;#xD; 발병 빈도를 예측하는 것을 목적으로 하였다. 이를 위해 환자 데이터 및 발병&amp;#xD; 데이터, 기후 데이터, 재난 데이터를 수집하였으며, 병원 내부 데이터의 사용을&amp;#xD; 위해 비식별화를 통한 전처리를 수행하였다. 이렇게 만들어진 데이터를 활용하여&amp;#xD; 머신러닝 기법(Stepwise Feature Selection Linear Regression, Random Forest) 및&amp;#xD; 딥러닝 모델(MLP, LSTM)을 통해 결과값(7 개 다빈도 질병의 지역별 발병 빈도수&amp;#xD; 예측)을 도출하였다. 그 결과 Random Forest 와 LSTM 이 각기 다른 질병에서 가장&amp;#xD; 높은 성능을 보여주었고 이를 최종 모델로 선정하였다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015784784&target=NART&cn=DIKO0015784784",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 머신러닝/딥러닝을 통한 지역별 발병 빈도 예측 의료데이터 분석을 이용한 의료/헬스케어 서비스에 대한 관심은 본격적으로&amp;#xD; 빅데이터/AI 의 가능성이 논의되기 이전부터 의료업계 및 IT 산업에서 큰 관심의&amp;#xD; 대상이었으며, 특히 의료 서비스의 비용 문제가 커다란 사회적 이슈인 미국에서는&amp;#xD; 의료서비스의 비용을 낮추면서도 그 질을 높일 수 있는 대안으로 의료 빅데이터에&amp;#xD; 대한 연구가 활발히 진행되어 왔다. 하지만 데이터의 익명성 문제와 보안 문제,&amp;#xD; 특히 의료데이터는 유출시 프라이버시와 관련하여 심각한 문제를 초래할 수 있어&amp;#xD; 의료데이터의 사용에는 많은 난관이 있었다.&amp;#xD; 본 연구는 이러한 문제점을 해결하기 위해 만들어진 컨소시엄에 포함된 전국&amp;#xD; 30 개의 병원 및 의료기관의 데이터를 활용하여 특정한 다빈도 발병 질병의 지역별&amp;#xD; 발병 빈도를 예측하는 것을 목적으로 하였다. 이를 위해 환자 데이터 및 발병&amp;#xD; 데이터, 기후 데이터, 재난 데이터를 수집하였으며, 병원 내부 데이터의 사용을&amp;#xD; 위해 비식별화를 통한 전처리를 수행하였다. 이렇게 만들어진 데이터를 활용하여&amp;#xD; 머신러닝 기법(Stepwise Feature Selection Linear Regression, Random Forest) 및&amp;#xD; 딥러닝 모델(MLP, LSTM)을 통해 결과값(7 개 다빈도 질병의 지역별 발병 빈도수&amp;#xD; 예측)을 도출하였다. 그 결과 Random Forest 와 LSTM 이 각기 다른 질병에서 가장&amp;#xD; 높은 성능을 보여주었고 이를 최종 모델로 선정하였다.&amp;#xD;"
        },
        {
          "rank": 21,
          "score": 0.6026456356048584,
          "doc_id": "DIKO0015372556",
          "title": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용",
          "abstract": "머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015372556&target=NART&cn=DIKO0015372556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다."
        },
        {
          "rank": 22,
          "score": 0.599636435508728,
          "doc_id": "JAKO201925462478017",
          "title": "딥러닝 기반 항생제 내성균 감염 예측",
          "abstract": "세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201925462478017&target=NART&cn=JAKO201925462478017",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 딥러닝 기반 항생제 내성균 감염 예측 세계보건기구(WHO)를 비롯해 세계 각국의 정부기관은 항생제 오남용에 따른 항생제 내성균 감염에 대해 심각하게 경고하며 이를 예방하기 위한 관리와 감시를 강화하고 있다. 하지만 감염을 확인하기 위한 감염균 배양에 수일의 시간이 소요되면서 격리와 접촉주의를 통한 감염확산 방지 효과가 떨어져 선제적 조치를 위한 신속하고 정확한 예측 및 추정방법이 요구되고 있다. 본 연구는 Electronic Health Records에 포함된 질병 진단내역과 항생제 처방내역을 neural embedding model과 matrix factorization을 통해 embedding 하였고, 이를 활용한 딥러닝 기반분류 예측 모형을 제안하였다. 항생제 내성균 감염의 주요 원인인 질병과 항생제 정보를 embedding하여 환자의 기본정보와 병원이용 정보에 추가했을 때 딥러닝 예측 모형의 f1-score는 0.525에서 0.617로 상승하였고, 딥러닝 모형은 Super Learner와 같은 기존 기계학습 모형보다 더 나은 성능을 보여주었다. 항생제 내성균 감염환자의 특성을 분석한 결과, 감염환자는 동일한 질병을 진단받은 비감염환자에 비교해 J01 계열 항생제 사용이 많았고 WHO 권고기준(DDD)을 크게 벗어나는 오남용 청구사례가 6.3배 이상 높게 나타났으며 항생제 오남용과 항생제 내성균 감염간의 높은 연관성이 발견되었다."
        },
        {
          "rank": 23,
          "score": 0.5969128608703613,
          "doc_id": "JAKO202312473958811",
          "title": "작물 생산량 예측을 위한 심층강화학습 성능 분석",
          "abstract": "최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202312473958811&target=NART&cn=JAKO202312473958811",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 작물 생산량 예측을 위한 심층강화학습 성능 분석 최근 딥러닝 기술을 활용하여 작물 생산량 예측 연구가 많이 진행되고 있다. 딥러닝 알고리즘은 입력 데이터 세트와 작물 예측 결과에 대한 선형 맵을 구성하는데 어려움이 있다. 또한, 알고리즘 구현은 획득한 속성의 비율에 긍정적으로 의존한다. 심층강화학습을 작물 생산량 예측 응용에 적용한다면 이러한 한계점을 보완할 수 있다. 본 논문은 작물 생산량 예측을 개선하기 위해 DQN, Double DQN 및 Dueling DQN 의 성능을 분석한다. DQN 알고리즘은 과대 평가 문제가 제기되지만, Double DQN은 과대 평가를 줄이고 더 나은 결과를 얻을 수 있다. 본 논문에서 제안된 모델은 거짓 판정을 줄이고 예측 정확도를 높이는 것으로 나타났다."
        },
        {
          "rank": 24,
          "score": 0.5966099500656128,
          "doc_id": "NART106279808",
          "title": "Machine learning for site-adaptation and solar radiation forecasting",
          "abstract": "<P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106279808&target=NART&cn=NART106279808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting <P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>"
        },
        {
          "rank": 25,
          "score": 0.5950043201446533,
          "doc_id": "NART103136065",
          "title": "Portfolio optimization with return prediction using deep learning and machine learning",
          "abstract": "<P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103136065&target=NART&cn=NART103136065",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning Portfolio optimization with return prediction using deep learning and machine learning <P><B>Abstract</B></P>  <P>Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean&ndash;variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average&rsquo;s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Compares the performance of machine learning and deep learning in stock preselection. </LI> <LI>  Combining return prediction of machine learning and deep learning in portfolio formation. </LI> <LI>  Emphasis on advancing portfolio optimization with return prediction. </LI> <LI>  Advanced mean&ndash;variance model with random forest forecasts performs the best. </LI> </UL> </P>"
        },
        {
          "rank": 26,
          "score": 0.5947020053863525,
          "doc_id": "NART133954270",
          "title": "Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models",
          "abstract": "<P>Heart disease prediction is a critical area in healthcare, where accurate and timely diagnosis can lead to better patient outcomes and reduced mortality rates. This study compares the performance of various machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, and Neural Networks, alongside advanced deep learning models such as Convolutional Neural Networks (CNN) and VGG16, a pre-trained deep learning architecture. The models are evaluated using precision, recall, F1-score, and accuracy, with accuracy being the primary metric for comparison. Experimental results demonstrate that while traditional machine learning models like Random Forest and Logistic Regression perform adequately, deep learning models, particularly CNN and VGG16, excel in predictive accuracy and other performance metrics. Among all models, CNN and VGG16 deliver superior results, with VGG16 slightly outperforming CNN in terms of precision and recall due to its ability to leverage pre-trained features and deeper architecture.The findings highlight the efficacy of deep learning techniques, especially VGG16, in heart disease prediction, emphasizing their ability to capture complex patterns and improve diagnostic accuracy. This study provides valuable insights into the potential of leveraging state-of-the-art deep learning architectures for enhancing predictive models in healthcare applications, setting the stage for future real-time diagnostic tools.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133954270&target=NART&cn=NART133954270",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models Enhanced Heart Disease Prediction Using Advanced Machine Learning and Deep Learning Models <P>Heart disease prediction is a critical area in healthcare, where accurate and timely diagnosis can lead to better patient outcomes and reduced mortality rates. This study compares the performance of various machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, and Neural Networks, alongside advanced deep learning models such as Convolutional Neural Networks (CNN) and VGG16, a pre-trained deep learning architecture. The models are evaluated using precision, recall, F1-score, and accuracy, with accuracy being the primary metric for comparison. Experimental results demonstrate that while traditional machine learning models like Random Forest and Logistic Regression perform adequately, deep learning models, particularly CNN and VGG16, excel in predictive accuracy and other performance metrics. Among all models, CNN and VGG16 deliver superior results, with VGG16 slightly outperforming CNN in terms of precision and recall due to its ability to leverage pre-trained features and deeper architecture.The findings highlight the efficacy of deep learning techniques, especially VGG16, in heart disease prediction, emphasizing their ability to capture complex patterns and improve diagnostic accuracy. This study provides valuable insights into the potential of leveraging state-of-the-art deep learning architectures for enhancing predictive models in healthcare applications, setting the stage for future real-time diagnostic tools.</P>"
        },
        {
          "rank": 27,
          "score": 0.5940765738487244,
          "doc_id": "JAKO200613067170583",
          "title": "항우울제와 자살",
          "abstract": "Depression is a frequent cause of suicide. Although there have been reports that SSRIs might increase suicidal ideations and behaviors, most studies found antidepressants are effective treatments of suicidal ideations and behaviors. Antidepressants have also been shown to have prophylactic effects in preventing suicidal behaviors. Most double-blind studies do not suggest a causal relationship between antidepressant and the increased suicidality. Our review results suggest that the undertreatments of depression are more significant problems with the use of antidepressants in suicidal patients.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200613067170583&target=NART&cn=JAKO200613067170583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "항우울제와 자살 항우울제와 자살 항우울제와 자살 Depression is a frequent cause of suicide. Although there have been reports that SSRIs might increase suicidal ideations and behaviors, most studies found antidepressants are effective treatments of suicidal ideations and behaviors. Antidepressants have also been shown to have prophylactic effects in preventing suicidal behaviors. Most double-blind studies do not suggest a causal relationship between antidepressant and the increased suicidality. Our review results suggest that the undertreatments of depression are more significant problems with the use of antidepressants in suicidal patients."
        },
        {
          "rank": 28,
          "score": 0.5938719511032104,
          "doc_id": "NPAP12734426",
          "title": "Deep sequential model for review rating prediction",
          "abstract": "<P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12734426&target=NART&cn=NPAP12734426",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep sequential model for review rating prediction Deep sequential model for review rating prediction Deep sequential model for review rating prediction <P>Sentiment Analysis of review data is becoming an important task to understand the needs and expectations of customers. The challenges that lie in review sentiment analysis is capturing the long term dependencies and intricacies to model the interrelationship between the sentences of the review. In this work, we address the problem of review sentiment analysis using deep sequential model viz. Long short term memory (LSTM) and Gated Recurrent Neural Network (GRNN). LSTM, a variant of RNN is used to process the sentences to a fixed length vector. GRNN is used to capture the interdependencies that exist between the sentences of a review. The combination of LSTM and GRNN shows good performance on Amazon Electronics dataset.</P>"
        },
        {
          "rank": 29,
          "score": 0.5927714109420776,
          "doc_id": "NART98545871",
          "title": "Review of bankruptcy prediction using machine learning and deep learning techniques",
          "abstract": "<P><B>Abstract</B></P>  <P>Bankruptcy prediction has long been a significant issue in finance and management science, which attracts the attention of researchers and practitioners. With the great development of modern information technology, it has evolved into using machine learning or deep learning algorithms to do the prediction, from the initial analysis of financial statements. In this paper, we will review the machine learning or deep learning models used in bankruptcy prediction, including the classical machine learning models such as Multivariant Discriminant Analysis (MDA), Logistic Regression (LR), Ensemble method, Neural Networks (NN) and Support Vector Machines (SVM), and major deep learning methods such as Deep Belief Network (DBN) and Convolutional Neural Network (CNN). In each model, the specific process of experiment and characteristics will be summarized through analyzing some typical articles. Finally, possible innovative changes of bankruptcy prediction and its future trends will be discussed.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98545871&target=NART&cn=NART98545871",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Review of bankruptcy prediction using machine learning and deep learning techniques Review of bankruptcy prediction using machine learning and deep learning techniques Review of bankruptcy prediction using machine learning and deep learning techniques <P><B>Abstract</B></P>  <P>Bankruptcy prediction has long been a significant issue in finance and management science, which attracts the attention of researchers and practitioners. With the great development of modern information technology, it has evolved into using machine learning or deep learning algorithms to do the prediction, from the initial analysis of financial statements. In this paper, we will review the machine learning or deep learning models used in bankruptcy prediction, including the classical machine learning models such as Multivariant Discriminant Analysis (MDA), Logistic Regression (LR), Ensemble method, Neural Networks (NN) and Support Vector Machines (SVM), and major deep learning methods such as Deep Belief Network (DBN) and Convolutional Neural Network (CNN). In each model, the specific process of experiment and characteristics will be summarized through analyzing some typical articles. Finally, possible innovative changes of bankruptcy prediction and its future trends will be discussed.</P>"
        },
        {
          "rank": 30,
          "score": 0.5923325419425964,
          "doc_id": "DIKO0011931938",
          "title": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators",
          "abstract": "Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011931938&target=NART&cn=DIKO0011931938",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators Adenosine receptor (AR)는 G protein coupled receptor (GPCR)의 rhodopsin family에 속하고, A1, A2A, A2B, A3 네 개의 subtype으로 분류할 수 있다. 그 중 가장 최근에 밝혀진 A3 AR은 다양한 질병치료의 타겟 단백질로 생각되고 있다. A3 효능제는 허혈성 심질환과 허혈후 재관류시 조직손상(reperfusion injury) 등의 치료제로서 가능성을 가지고 있고, 길항제는 천식, 녹내장, 염증 치료제로 연구 중에 있다. 이 논문에서는 두 가지 리간드기반 접근 방법 (ligand-based approaches)을 적용한 실험을 하였다. 우선 Laplacian-modified naive Bayesian, recursive partitioning, support vector machine의 세 가지 machine learning 방법을 통해 분류기 모델(classification model)을 만들었다. 이 방법은 빠른 속도와 정확함을 장점으로 하여, 신약개발의 초기 단계에서 널리 사용되고 있다. 만들어진 모델을 여러 가지 수치를 이용하여 평가한 결과 정확성, 민감도, 특수성은 90% 이상, AUC와 MCC는 0.9 이상의 좋은 수치를 나타냈다. 다음으로, 효능제와 길항제 각각에 대해 3차원적인 정량적 구조-활성관계(three-dimensional quantitative structure-activity relationship; 3D-QSAR)에 대한 연구를 진행하여 신뢰성있는 model을 얻었다. 효능제의 경우 cross validation 했을 때, CoMFA의 q2이 0.594, r2이0.937의 값을, CoMSIA의 q2이0.560, r2이 0.907의 값을 나타냈으며 test set은 각각 0.768, 0.730의 r2을 보였다. 길항제에 대한 cross validation 결과 역시 CoMFA의 q2 이 0.726, r2 이 0.913을, CoMSIA의 q2이 0.665, r2이 0.915을 나타냈고, test set 예측에서는 각각의 r2이 0.808, 0.767의 높은 수치를 보였다. 분류기 모델과 3D-QSAR model 모두 성공적으로 만들어졌고, 이를 통해 agonists와 antagonists 분류에 5’-amide 위치의 수소 결합 donor의 존재유무가 중요한 요인이라는 것을 확인하였다. 이 두 모델은 앞으로 classification은 물론 새로운 효능제와 길항제 개발에 도움이 될 것으로 기대된다."
        },
        {
          "rank": 31,
          "score": 0.5910411477088928,
          "doc_id": "ATN0052776138",
          "title": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구",
          "abstract": "첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0052776138&target=NART&cn=ATN0052776138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 머신러닝과 딥러닝을 활용한 공군 수리부속 예측 정확도 개선에 관한 연구 첨단 무기체계의 도입에 따른 운영유지비 증가와 수리부속 조달환경의 악화로 인해, 정밀한 수요예측의 중요성이 더욱 강조되고 있다. 본 연구는 공군 수리부속의 수요가 소량이며 발생 간격이 불규칙한 특성으로 인해 예측이 어렵다는 점에 착안하여, 기존 통계기반 예측기법의 한계를 극복하고자 머신러닝 및 딥러닝 기반 예측모형을 적용하였다. 국방물자관리체계로 부터 수집한 약 37만 건의 수요 데이터를 유형별(Regular, Intermittent, Erratic, Lumpy)로 분류한 후, Random Forest, XG-Boost, LightGBM, LSTM, N-Beats 5가지 예측모델을 구축하고 성능을 비교하였다. 분석 결과, XG-Boost 모델이 가장 우수한 정확도(79.13%)를 기록하였으며, 그리드 서치를 통한 매개변수 최적화 결과, 품목 기준 최대 81.28%의 예측 정확도를 달성하였다. 본 연구를 통해 세부 품목별 분류 기준 정립, 최적 모델 적용 및 매개변수 튜닝 효율화 등을 통해 공군 수리부속 수요예측의 정확도를 실질적으로 향상시킬 수 있음을 실증적으로 확인하였으며, 이는 대규모 군수 데이터셋에 대한 정량적 분석과 실용적인 예측모형 적용을 통해 현장 활용 가능성이 높은 모델을 제시하였다는 점에서 기존 연구와 차별성을 지닌다. 본 연구의 결과는 향후 공군 및 국방 군수 시스템 전반의 운영 효율성 제고와 자원관리 혁신에 중요한 토대를 제공할 수 있을 것으로 기대한다."
        },
        {
          "rank": 32,
          "score": 0.5909082293510437,
          "doc_id": "NART126947704",
          "title": "Hybrid CNN-LSTM for Predicting Diabetes: A Review",
          "abstract": "<P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART126947704&target=NART&cn=NART126947704",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review Hybrid CNN-LSTM for Predicting Diabetes: A Review <P>Background:<P>Diabetes is a common and deadly chronic disease caused by high blood glucose levels that can cause heart problems, neurological damage, and other illnesses. Through the early detection of diabetes, patients can live healthier lives. Many machine learning and deep learning techniques have been applied for noninvasive diabetes prediction. The results of some studies have shown that the CNN-LSTM method, a combination of CNN and LSTM, has good performance for predicting diabetes compared to other deep learning methods.</P></P><P>Method:<P>This paper reviews CNN-LSTM-based studies for diabetes prediction. In the CNNLSTM model, the CNN includes convolution and max pooling layers and is applied for feature extraction. The output of the max-pooling layer was fed into the LSTM layer for classification.</P></P><P>Discussion:<P>The CNN-LSTM model performed well in extracting hidden features and correlations between physiological variables. Thus, it can be used to predict diabetes. The CNNLSTM model, like other deep neural network architectures, faces challenges such as training on large datasets and biological factors. Using large datasets can further improve the accuracy of detection.</P></P><P>Conclusion:<P>The CNN-LSTM model is a promising method for diabetes prediction, and compared with other deep-learning models, it is a reliable method.</P></P>"
        },
        {
          "rank": 33,
          "score": 0.5905991196632385,
          "doc_id": "NART114795860",
          "title": "Comparison of two molecular docking programs: the accuracy of ligand pose prediction",
          "abstract": "<P>The study was perform to compare the output of two different docking programs (Molegro Vritual Docker and AutoDock) in simulation of ligand-receptor interactions for &beta;1 and &beta;2 adrenergic receptors. The exactness of the predicted ligand positions was estimated on the basis of the thirteen known crystallographic structures of the ligand-receptor complexes taken from the PDB database. Significant differences in docking results obtained by using both tested programs were observed. The overall RMSD-based scoring suggests that the procedures and algorithms implemented in AutoDock lead to slightly better results.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART114795860&target=NART&cn=NART114795860",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of two molecular docking programs: the accuracy of ligand pose prediction Comparison of two molecular docking programs: the accuracy of ligand pose prediction Comparison of two molecular docking programs: the accuracy of ligand pose prediction <P>The study was perform to compare the output of two different docking programs (Molegro Vritual Docker and AutoDock) in simulation of ligand-receptor interactions for &beta;1 and &beta;2 adrenergic receptors. The exactness of the predicted ligand positions was estimated on the basis of the thirteen known crystallographic structures of the ligand-receptor complexes taken from the PDB database. Significant differences in docking results obtained by using both tested programs were observed. The overall RMSD-based scoring suggests that the procedures and algorithms implemented in AutoDock lead to slightly better results.</P>"
        },
        {
          "rank": 34,
          "score": 0.588632345199585,
          "doc_id": "DIKO0016784632",
          "title": "기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법",
          "abstract": "현대인의 식습관 변화로 인해 당뇨병 발병률은 점점 증가하고, 전 세계적인 건강문제로 인식되고 있다. 합병증으로 인한 사망자도 매년 증가하고 있다. 당뇨병을 조기에 예방하여 치료할 수 있도록 하고, 건강한 삶을 유지하기 위해 당뇨병 조기진단을 예측할 연구가 필요하다.&amp;#xD; 본 논문에서는 당뇨병 초기 증상데이터를 이용하여 당뇨병 진단을 예측하기 위한 시스템 구성도를 제시하고, 기계학습분류 알고리즘을 이용하여 데이터를 분석하고, 당뇨병 진단에 대해 정확한 예측을 하도록 실험하였다. 실험은 R 언어로 기계학습 분류 알고리즘을 수행하고, 수행결과를 비교하여 성능이 좋게 나온 모델에 대해 하이퍼 파라미터 조정을 통해 정확도를 개선함으로써, 최종 선정된 랜덤 포레스트 모형 정확도는 약 99%로 성능이 우수하였다. 당뇨병 예방 및 치료 전략에 모형 성능이 우수한 지도학습 분류모델인 랜덤 포레스트 모형을 제안한다.&amp;#xD; 기계학습을 통한 예측모델은 의료분야에서 유용하게 활용될 수 있으며, 당뇨병 조기 발견과 예방에 이바지할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016784632&target=NART&cn=DIKO0016784632",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 기계학습 분류 알고리즘을 이용한 당뇨병 진단예측 기법 현대인의 식습관 변화로 인해 당뇨병 발병률은 점점 증가하고, 전 세계적인 건강문제로 인식되고 있다. 합병증으로 인한 사망자도 매년 증가하고 있다. 당뇨병을 조기에 예방하여 치료할 수 있도록 하고, 건강한 삶을 유지하기 위해 당뇨병 조기진단을 예측할 연구가 필요하다.&amp;#xD; 본 논문에서는 당뇨병 초기 증상데이터를 이용하여 당뇨병 진단을 예측하기 위한 시스템 구성도를 제시하고, 기계학습분류 알고리즘을 이용하여 데이터를 분석하고, 당뇨병 진단에 대해 정확한 예측을 하도록 실험하였다. 실험은 R 언어로 기계학습 분류 알고리즘을 수행하고, 수행결과를 비교하여 성능이 좋게 나온 모델에 대해 하이퍼 파라미터 조정을 통해 정확도를 개선함으로써, 최종 선정된 랜덤 포레스트 모형 정확도는 약 99%로 성능이 우수하였다. 당뇨병 예방 및 치료 전략에 모형 성능이 우수한 지도학습 분류모델인 랜덤 포레스트 모형을 제안한다.&amp;#xD; 기계학습을 통한 예측모델은 의료분야에서 유용하게 활용될 수 있으며, 당뇨병 조기 발견과 예방에 이바지할 수 있다."
        },
        {
          "rank": 35,
          "score": 0.5881698131561279,
          "doc_id": "NART127298646",
          "title": "CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction",
          "abstract": "<P>For ligand binding prediction, it is crucial for molecular docking programs to integrate template-based modeling with a precise scoring function. Here, we proposed the CoDock-Ligand docking method that combines template-based modeling and the GNINA scoring function, a Convolutional Neural Network-based scoring function, for the ligand binding prediction in CASP15. Among the 21 targets, we obtained successful predictions in top 5 submissions for 14 targets and partially successful predictions for 4 targets. In particular, for the most complicated target, H1114, which contains 56 metal cofactors and small molecules, our docking method successfully predicted the binding of most ligands. Analysis of the failed systems showed that the predicted receptor protein presented conformational changes in the backbone and side chains of the binding site residues, which may cause large structural deviations in the ligand binding prediction. In summary, our hybrid docking scheme was efficiently adapted to the ligand binding prediction challenges in CASP15.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART127298646&target=NART&cn=NART127298646",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction CoDock-Ligand: combined template-based docking and CNN-based scoring in ligand binding prediction <P>For ligand binding prediction, it is crucial for molecular docking programs to integrate template-based modeling with a precise scoring function. Here, we proposed the CoDock-Ligand docking method that combines template-based modeling and the GNINA scoring function, a Convolutional Neural Network-based scoring function, for the ligand binding prediction in CASP15. Among the 21 targets, we obtained successful predictions in top 5 submissions for 14 targets and partially successful predictions for 4 targets. In particular, for the most complicated target, H1114, which contains 56 metal cofactors and small molecules, our docking method successfully predicted the binding of most ligands. Analysis of the failed systems showed that the predicted receptor protein presented conformational changes in the backbone and side chains of the binding site residues, which may cause large structural deviations in the ligand binding prediction. In summary, our hybrid docking scheme was efficiently adapted to the ligand binding prediction challenges in CASP15.</P>"
        },
        {
          "rank": 36,
          "score": 0.5873199701309204,
          "doc_id": "JAKO200111920938436",
          "title": "퍼지신경망을 이용한 기업부도예측",
          "abstract": "본 연구에서는 퍼지신경망을 이용한 기업부실예측모형을 제안한다. 신경망은 탁월한 학습능력을 가진 것으로 알려져 있으나, 잡음이 심한 재무자료에 대해서는 종종 일관되지 못하고 기대에 미치지 못하는 예측성과를 보인다. 이는 연속형의 형태를 지닌 독립변수와 과다한 양의 원자료로부터 예측에 필요한 일정한 패턴을 찾기가 어렵기 때문이다. 이러한 문제점은 예측모형에서의 독립변수와 종속변수간의 인과관계를 신경망이 용이하게 찾아낼 수 있도록 독립변수의 형태를 변환함으로써 해결한 수 있다. 이러한 해결방법의 하나는 기존 신경망에 퍼지집합의 개념을 적용하여 신경망 학습에 사용될 자료를 퍼지화하고 이를 신경망에 학습시키는 것이다 입력자료를 퍼지화 함으로써 정보의 손실 없이도 신경망이 자료 내의 복잡한 관계를 용이하게 학습하는 것이 가능하다. 본 연구에서 제안된 퍼지신경망을 기업부도예측에 적용한 결과, 퍼지신경망이 기존의 신경망보다 우월한 예측성과를 나타내었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111920938436&target=NART&cn=JAKO200111920938436",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "퍼지신경망을 이용한 기업부도예측 퍼지신경망을 이용한 기업부도예측 퍼지신경망을 이용한 기업부도예측 본 연구에서는 퍼지신경망을 이용한 기업부실예측모형을 제안한다. 신경망은 탁월한 학습능력을 가진 것으로 알려져 있으나, 잡음이 심한 재무자료에 대해서는 종종 일관되지 못하고 기대에 미치지 못하는 예측성과를 보인다. 이는 연속형의 형태를 지닌 독립변수와 과다한 양의 원자료로부터 예측에 필요한 일정한 패턴을 찾기가 어렵기 때문이다. 이러한 문제점은 예측모형에서의 독립변수와 종속변수간의 인과관계를 신경망이 용이하게 찾아낼 수 있도록 독립변수의 형태를 변환함으로써 해결한 수 있다. 이러한 해결방법의 하나는 기존 신경망에 퍼지집합의 개념을 적용하여 신경망 학습에 사용될 자료를 퍼지화하고 이를 신경망에 학습시키는 것이다 입력자료를 퍼지화 함으로써 정보의 손실 없이도 신경망이 자료 내의 복잡한 관계를 용이하게 학습하는 것이 가능하다. 본 연구에서 제안된 퍼지신경망을 기업부도예측에 적용한 결과, 퍼지신경망이 기존의 신경망보다 우월한 예측성과를 나타내었다."
        },
        {
          "rank": 37,
          "score": 0.5873113870620728,
          "doc_id": "NART108328574",
          "title": "A fully open-source framework for deep learning protein real-valued distances",
          "abstract": "<P>As deep learning algorithms drive the progress in protein structure prediction, a lot remains to be studied at this merging superhighway of deep learning and protein structure prediction. Recent findings show that inter-residue distance prediction, a more granular version of the well-known contact prediction problem, is a key to predicting accurate models. However, deep learning methods that predict these distances are still in the early stages of their development. To advance these methods and develop other novel methods, a need exists for a small and representative dataset packaged for faster development and testing. In this work, we introduce protein distance net (PDNET), a framework that consists of one such representative dataset along with the scripts for training and testing deep learning methods. The framework also includes all the scripts that were used to curate the dataset, and generate the input features and distance maps. Deep learning models can also be trained and tested in a web browser using free platforms such as Google Colab. We discuss how PDNET can be used to predict contacts, distance intervals, and real-valued distances.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108328574&target=NART&cn=NART108328574",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A fully open-source framework for deep learning protein real-valued distances A fully open-source framework for deep learning protein real-valued distances A fully open-source framework for deep learning protein real-valued distances <P>As deep learning algorithms drive the progress in protein structure prediction, a lot remains to be studied at this merging superhighway of deep learning and protein structure prediction. Recent findings show that inter-residue distance prediction, a more granular version of the well-known contact prediction problem, is a key to predicting accurate models. However, deep learning methods that predict these distances are still in the early stages of their development. To advance these methods and develop other novel methods, a need exists for a small and representative dataset packaged for faster development and testing. In this work, we introduce protein distance net (PDNET), a framework that consists of one such representative dataset along with the scripts for training and testing deep learning methods. The framework also includes all the scripts that were used to curate the dataset, and generate the input features and distance maps. Deep learning models can also be trained and tested in a web browser using free platforms such as Google Colab. We discuss how PDNET can be used to predict contacts, distance intervals, and real-valued distances.</P>"
        },
        {
          "rank": 38,
          "score": 0.5871405601501465,
          "doc_id": "DIKO0015016090",
          "title": "클러스터링을 이용한 분자 도킹 : 더 효율적인 프로세스를 위해",
          "abstract": "컴퓨터를 이용한 신약 설계는, 시간과 비용을 크게 감소시키는, 효율성이 입증 된 기술이다. 그 중에 ‘Molecular Docking’ 은 컴퓨터를 이용한 신약개발 연구에 매우 중요한 단계로 특정 단백질의 binding site에 맞는 리간드의 최적 포즈를 찾아낼 수 있도록 단백질-리간드의 상호작용을 모델링하여 단백질-리간드 결합 구조를 예측하는 것이 목적이다. 분자도킹은 빠른 시간 내에 대량의 데이터를 효율적으로 다룰 수 있지만, 도킹 스코어의 부정확성과 타겟단백질(target protein)의 유동성을 충분히 고려하지 않은 채 계산이 이루어져 상대적으로 정확도가 떨어진다. 이러한 분자 도킹의 효율성 및 정확도를 증가시키기 위한 방법이 본 논문에서 제안되었다. 본 연구에서는 PDB(Protein Data Bank)에 있는 200개의 단백질-리간드 결합정보를 이용하였다. 각 샘플에 대하여 생성된 여러 개의 리간드 conformer를 이용해 docking을 수행하였고, 그 docking pose들을 여러 가지 클러스터링 기법을 이용해 테스트하였다. 그 결과 hierarchical clustering기법을 사용하였을 때 65% 이상의 확률로 정답이 상위 5개 군집 내에 존재함을 확인 할 수 있었다. 이로써 상위 5 군집의 대푯값을 뽑아 Molecular Dynamics를 시행함으로 써 정확도와 효율성을 갖춘 binding pose의 예측이 가능해 질 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015016090&target=NART&cn=DIKO0015016090",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "클러스터링을 이용한 분자 도킹 : 더 효율적인 프로세스를 위해 클러스터링을 이용한 분자 도킹 : 더 효율적인 프로세스를 위해 클러스터링을 이용한 분자 도킹 : 더 효율적인 프로세스를 위해 컴퓨터를 이용한 신약 설계는, 시간과 비용을 크게 감소시키는, 효율성이 입증 된 기술이다. 그 중에 ‘Molecular Docking’ 은 컴퓨터를 이용한 신약개발 연구에 매우 중요한 단계로 특정 단백질의 binding site에 맞는 리간드의 최적 포즈를 찾아낼 수 있도록 단백질-리간드의 상호작용을 모델링하여 단백질-리간드 결합 구조를 예측하는 것이 목적이다. 분자도킹은 빠른 시간 내에 대량의 데이터를 효율적으로 다룰 수 있지만, 도킹 스코어의 부정확성과 타겟단백질(target protein)의 유동성을 충분히 고려하지 않은 채 계산이 이루어져 상대적으로 정확도가 떨어진다. 이러한 분자 도킹의 효율성 및 정확도를 증가시키기 위한 방법이 본 논문에서 제안되었다. 본 연구에서는 PDB(Protein Data Bank)에 있는 200개의 단백질-리간드 결합정보를 이용하였다. 각 샘플에 대하여 생성된 여러 개의 리간드 conformer를 이용해 docking을 수행하였고, 그 docking pose들을 여러 가지 클러스터링 기법을 이용해 테스트하였다. 그 결과 hierarchical clustering기법을 사용하였을 때 65% 이상의 확률로 정답이 상위 5개 군집 내에 존재함을 확인 할 수 있었다. 이로써 상위 5 군집의 대푯값을 뽑아 Molecular Dynamics를 시행함으로 써 정확도와 효율성을 갖춘 binding pose의 예측이 가능해 질 수 있다."
        },
        {
          "rank": 39,
          "score": 0.5868446826934814,
          "doc_id": "JAKO201820765437174",
          "title": "토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구",
          "abstract": "본 연구는 LDA 토픽 모델과 딥 러닝을 적용한 단어 임베딩 기반의 Doc2Vec 기법을 활용하여 자질을 선정하고 자질집합의 크기와 종류 및 분류 알고리즘에 따른 분류 성능의 차이를 평가하였다. 또한 자질집합의 적절한 크기를 확인하고 문헌의 위치에 따라 종류를 다르게 구성하여 분류에 이용할 때 높은 성능을 나타내는 자질집합이 무엇인지 확인하였다. 마지막으로 딥 러닝을 활용한 실험에서는 학습 횟수와 문맥 추론 정보의 유무에 따른 분류 성능을 비교하였다. 실험문헌집단은 PMC에서 제공하는 생의학 학술문헌을 수집하고 질병 범주 체계에 따라 구분하여 Disease-35083을 구축하였다. 연구를 통하여 가장 높은 성능을 나타낸 자질집합의 종류와 크기를 확인하고 학습 시간에 효율성을 나타냄으로써 자질로의 확장 가능성을 가지는 자질집합을 제시하였다. 또한 딥 러닝과 기존 방법 간의 차이점을 비교하고 분류 환경에 따라 적합한 방법을 제안하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201820765437174&target=NART&cn=JAKO201820765437174",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 토픽모델링과 딥 러닝을 활용한 생의학 문헌 자동 분류 기법 연구 본 연구는 LDA 토픽 모델과 딥 러닝을 적용한 단어 임베딩 기반의 Doc2Vec 기법을 활용하여 자질을 선정하고 자질집합의 크기와 종류 및 분류 알고리즘에 따른 분류 성능의 차이를 평가하였다. 또한 자질집합의 적절한 크기를 확인하고 문헌의 위치에 따라 종류를 다르게 구성하여 분류에 이용할 때 높은 성능을 나타내는 자질집합이 무엇인지 확인하였다. 마지막으로 딥 러닝을 활용한 실험에서는 학습 횟수와 문맥 추론 정보의 유무에 따른 분류 성능을 비교하였다. 실험문헌집단은 PMC에서 제공하는 생의학 학술문헌을 수집하고 질병 범주 체계에 따라 구분하여 Disease-35083을 구축하였다. 연구를 통하여 가장 높은 성능을 나타낸 자질집합의 종류와 크기를 확인하고 학습 시간에 효율성을 나타냄으로써 자질로의 확장 가능성을 가지는 자질집합을 제시하였다. 또한 딥 러닝과 기존 방법 간의 차이점을 비교하고 분류 환경에 따라 적합한 방법을 제안하였다."
        },
        {
          "rank": 40,
          "score": 0.5862516164779663,
          "doc_id": "JAKO202108360626662",
          "title": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측",
          "abstract": "본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202108360626662&target=NART&cn=JAKO202108360626662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 딥러닝을 이용한 외해 해양기상자료로부터의 항내파고 예측 본 연구에서는 항내 파고를 신속하고 비교적 정확하게 예측할 수 있는 딥러닝 모델을 구축하였다.다양한 머신러닝 기법들을 외해파랑의 항내로 전파 변형 특성을 감안하여 모델에 적용하였으며 스웰로 인해 하역중단 문제가 심각했던 포항신항을 모델적용 대상지로 선정하였다. 모델의 입력 자료는 외해의 파고, 주기, 파향 그리고 출력 및 예측 자료로는 항내 파고자료로 하여 모델을 학습시켰다. 이때 자료의 전처리 과정으로 항내&#x00B7;외 파랑 시계열자료의 상관성을 감안하여 파향 자료를 분리하는 방법을 적용하고 딥러닝 기법을 이용하여 모델을 학습하였다. 결과적으로 모델을 통해 예측한 값이 항내관측치의 파고 시계열자료를 잘 재현하였으며 모델의 안정성을 크게 향상시켰다."
        },
        {
          "rank": 41,
          "score": 0.5848856568336487,
          "doc_id": "DIKO0014169472",
          "title": "딥러닝 알고리즘에 기반한 기업부도 예측",
          "abstract": "기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014169472&target=NART&cn=DIKO0014169472",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 딥러닝 알고리즘에 기반한 기업부도 예측 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다."
        },
        {
          "rank": 42,
          "score": 0.5846157670021057,
          "doc_id": "DIKO0016741012",
          "title": "머신러닝, 딥러닝을 활용한 질병여부 예측",
          "abstract": "The data is analyzed through machine learning and deep learning with data on heart disease, stroke, and diabetes, which are the top causes of death in Korea, and depression, which ranked first in OECD countries after COVID-19. The algorithms used here are Logistic Regression, Support Vector Classifier (SVC), K-Nearest Neighbor (K-NN), Decision Tree, Gaussian Naive Bayes Classifier, Bernoulli Naive Bayes Classifier, Ridge Classifier, Random Forest Classifier, Ada Boosting Classifier, Extreme Gradient Boosting Analyze using Classifier(XGB), DNN, CNN. In DNN, hyperparameter setting is the optimizer function, which uses Adam, Epoch uses 1000, batch_size 256, Activation Function uses ReLU, Output Activation Function uses Sigmoid, Loss Function uses binary cross entropy In CNN, it is the same as DNN, but Activation Function uses LeakyReLU, Output Activation Function uses Sigmoid, Learning rate is 0.001, Convolution layer uses Conv1d, Kernel size is 2, Polling layer uses Maxpolling, Poll size is set to 2. Accuracy, F1 Score, and ROC_AUC Score are used as evaluation methods, and in deep learning, we check how well training is performed with Lossfucntion.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016741012&target=NART&cn=DIKO0016741012",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝, 딥러닝을 활용한 질병여부 예측 머신러닝, 딥러닝을 활용한 질병여부 예측 머신러닝, 딥러닝을 활용한 질병여부 예측 The data is analyzed through machine learning and deep learning with data on heart disease, stroke, and diabetes, which are the top causes of death in Korea, and depression, which ranked first in OECD countries after COVID-19. The algorithms used here are Logistic Regression, Support Vector Classifier (SVC), K-Nearest Neighbor (K-NN), Decision Tree, Gaussian Naive Bayes Classifier, Bernoulli Naive Bayes Classifier, Ridge Classifier, Random Forest Classifier, Ada Boosting Classifier, Extreme Gradient Boosting Analyze using Classifier(XGB), DNN, CNN. In DNN, hyperparameter setting is the optimizer function, which uses Adam, Epoch uses 1000, batch_size 256, Activation Function uses ReLU, Output Activation Function uses Sigmoid, Loss Function uses binary cross entropy In CNN, it is the same as DNN, but Activation Function uses LeakyReLU, Output Activation Function uses Sigmoid, Learning rate is 0.001, Convolution layer uses Conv1d, Kernel size is 2, Polling layer uses Maxpolling, Poll size is set to 2. Accuracy, F1 Score, and ROC_AUC Score are used as evaluation methods, and in deep learning, we check how well training is performed with Lossfucntion."
        },
        {
          "rank": 43,
          "score": 0.5842975974082947,
          "doc_id": "JAKO201924064455520",
          "title": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용",
          "abstract": "Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201924064455520&target=NART&cn=JAKO201924064455520",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
        },
        {
          "rank": 44,
          "score": 0.5840100646018982,
          "doc_id": "DIKO0014912357",
          "title": "딥러닝 기반 기술융합 예측 방법론",
          "abstract": "오늘날 기업들은 전략적인 관점에서 기술변화를 예측하고, 이를 활용한 기술전략 수립이 반드시 필요하다고 요구된다. 특히 기술융합 현상은 기술혁신을 주도하고 시장과 산업의 변화를 이끈 다고 할 수 있기 때문에, 기술융합을 정량적으로 측정하고 관측하기 위한 연구가 다수 이루어졌다. 선행 연구에서는 계량서지분석을 이용해 기술 구조를 분석하고, 기술네트워크를 통해 기술융합 현상을 분석하는데 그쳤다. 본 연구에서는 미래의 기술융합 구조를 예상할 수 있는 예측 방법론을 제시한다. 링크 예측은 현재 시점의 네트워크를 통해 미래 시점의 네트워크에 추가되거나 제거 될 링크를 예측하는 문제를 의미한다. 본 연구에서는 기술네트워크 형태로 표현 된 기술시스템에 링크 예측을 적용하여 미래 기술융합 관계에 대해 예측하는 것을 목적으로 한다. 특히 딥러닝 기법을 이용한 학습 기반 링크 예측을 수행한다는 특징이 있다. 기존에 링크 예측을 적용해 기술융합 예측을 시도한 연구가 일부 있었으나, 네트워크 내 이웃관계에 의한 토폴로지 유사도를 의사결정 척도로 이용했다는 점에서 한계에 머물렀다. 기술융합 예측이라는 도메인 속성이 고려되지 않았다는 점인데, 본 연구에서는 기존 링크 예측에서 보편적으로 사용되었던 이웃관계에 의한 네트워크 토폴로지 유사도와 인용관계에 의한 유사도를 함께 고려한 기술융합 예측모델을 제시한다. 또한 학습 기반 링크 예측에서는 기술네트워크에 대한 정보를 노드 쌍 조합 단위의 레코드를 갖는 정형화 된 데이터 구조로 변화해 이진분류 문제로 기술융합 예측 문제를 재정의 하였기 때문에, 다양한 교사학습 기반의 기계학습 알고리즘 적용이 가능하다. 본 연구에서는 분류 성능이 우수해 최근 주목받고 있는 딥러닝 기법의 DNN 알고리즘을 사용하여 학습 기반 링크 예측을 수행하고, SVM, 로지스틱회귀(logistic regression), 랜덤포레스트(random foreset)와 같은 보편적인 분류 알고리즘을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014912357&target=NART&cn=DIKO0014912357",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 기술융합 예측 방법론 딥러닝 기반 기술융합 예측 방법론 딥러닝 기반 기술융합 예측 방법론 오늘날 기업들은 전략적인 관점에서 기술변화를 예측하고, 이를 활용한 기술전략 수립이 반드시 필요하다고 요구된다. 특히 기술융합 현상은 기술혁신을 주도하고 시장과 산업의 변화를 이끈 다고 할 수 있기 때문에, 기술융합을 정량적으로 측정하고 관측하기 위한 연구가 다수 이루어졌다. 선행 연구에서는 계량서지분석을 이용해 기술 구조를 분석하고, 기술네트워크를 통해 기술융합 현상을 분석하는데 그쳤다. 본 연구에서는 미래의 기술융합 구조를 예상할 수 있는 예측 방법론을 제시한다. 링크 예측은 현재 시점의 네트워크를 통해 미래 시점의 네트워크에 추가되거나 제거 될 링크를 예측하는 문제를 의미한다. 본 연구에서는 기술네트워크 형태로 표현 된 기술시스템에 링크 예측을 적용하여 미래 기술융합 관계에 대해 예측하는 것을 목적으로 한다. 특히 딥러닝 기법을 이용한 학습 기반 링크 예측을 수행한다는 특징이 있다. 기존에 링크 예측을 적용해 기술융합 예측을 시도한 연구가 일부 있었으나, 네트워크 내 이웃관계에 의한 토폴로지 유사도를 의사결정 척도로 이용했다는 점에서 한계에 머물렀다. 기술융합 예측이라는 도메인 속성이 고려되지 않았다는 점인데, 본 연구에서는 기존 링크 예측에서 보편적으로 사용되었던 이웃관계에 의한 네트워크 토폴로지 유사도와 인용관계에 의한 유사도를 함께 고려한 기술융합 예측모델을 제시한다. 또한 학습 기반 링크 예측에서는 기술네트워크에 대한 정보를 노드 쌍 조합 단위의 레코드를 갖는 정형화 된 데이터 구조로 변화해 이진분류 문제로 기술융합 예측 문제를 재정의 하였기 때문에, 다양한 교사학습 기반의 기계학습 알고리즘 적용이 가능하다. 본 연구에서는 분류 성능이 우수해 최근 주목받고 있는 딥러닝 기법의 DNN 알고리즘을 사용하여 학습 기반 링크 예측을 수행하고, SVM, 로지스틱회귀(logistic regression), 랜덤포레스트(random foreset)와 같은 보편적인 분류 알고리즘을 비교한다."
        },
        {
          "rank": 45,
          "score": 0.5837202668190002,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 46,
          "score": 0.5829570293426514,
          "doc_id": "NART116354539",
          "title": "Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network",
          "abstract": "<P><B>Abstract</B></P>  <P>Alcoholism is a serious disorder that poses a problem for modern society, but the detection of alcoholism has no widely accepted standard tests or procedures. If alcoholism goes undetected at its early stages, it can create havoc in the patient's life. An electroencephalography (EEG) is a method used to measure the brain's electrical activity and can detect alcoholism. EEG signals are complex and multi-channel and thus can be difficult to interpret manually. Several previous works have tried to classify a subject as alcoholic or control (non-alcoholic) based on EEG signals. Such works have mainly used machine learning or statistical techniques along with handcrafted features such as entropy, correlation dimension, Hurst exponent. With the growth in computational power and data volume worldwide, deep learning models have recently been gaining momentum in various fields. However, only a few studies are available on the application of deep learning models for the classification of alcoholism using EEG signals. This paper proposes a deep learning architecture that uses a combination of fast Fourier transform (FFT), a convolution neural network (CNN), long short-term memory (LSTM), and a recently proposed attention mechanism for extracting Spatio-temporal features from multi-channel EEG signals. The proposed architecture can classify a subject as an alcoholic or control with a high degree of accuracy by analyzing EEG signals of that subject and can be used for automating alcoholism detection. The analytical results using the proposed architecture show a 98.83% accuracy, making it better than most state-of-the-art algorithms.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The previous studies used statistical handcrafted features for classification, which requires domain-level knowledge. </LI> <LI>  Existing studies use a few samples, which resulted in less generalized results in most cases. </LI> <LI>  Spatio-temporal EEG signals require architectures that can capture both spatial and temporal features. </LI> <LI>  A combination of FFT-CNN-LSTM-ATTN architecture is proposed to extract Spatio-temporal features. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART116354539&target=NART&cn=NART116354539",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network Detection of alcoholism using EEG signals and a CNN-LSTM-ATTN network <P><B>Abstract</B></P>  <P>Alcoholism is a serious disorder that poses a problem for modern society, but the detection of alcoholism has no widely accepted standard tests or procedures. If alcoholism goes undetected at its early stages, it can create havoc in the patient's life. An electroencephalography (EEG) is a method used to measure the brain's electrical activity and can detect alcoholism. EEG signals are complex and multi-channel and thus can be difficult to interpret manually. Several previous works have tried to classify a subject as alcoholic or control (non-alcoholic) based on EEG signals. Such works have mainly used machine learning or statistical techniques along with handcrafted features such as entropy, correlation dimension, Hurst exponent. With the growth in computational power and data volume worldwide, deep learning models have recently been gaining momentum in various fields. However, only a few studies are available on the application of deep learning models for the classification of alcoholism using EEG signals. This paper proposes a deep learning architecture that uses a combination of fast Fourier transform (FFT), a convolution neural network (CNN), long short-term memory (LSTM), and a recently proposed attention mechanism for extracting Spatio-temporal features from multi-channel EEG signals. The proposed architecture can classify a subject as an alcoholic or control with a high degree of accuracy by analyzing EEG signals of that subject and can be used for automating alcoholism detection. The analytical results using the proposed architecture show a 98.83% accuracy, making it better than most state-of-the-art algorithms.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  The previous studies used statistical handcrafted features for classification, which requires domain-level knowledge. </LI> <LI>  Existing studies use a few samples, which resulted in less generalized results in most cases. </LI> <LI>  Spatio-temporal EEG signals require architectures that can capture both spatial and temporal features. </LI> <LI>  A combination of FFT-CNN-LSTM-ATTN architecture is proposed to extract Spatio-temporal features. </LI> </UL> </P>"
        },
        {
          "rank": 47,
          "score": 0.582460343837738,
          "doc_id": "JAKO202129159550193",
          "title": "딥러닝 및 토픽모델링 기법을 활용한 소셜 미디어의 자살 경향 문헌 판별 및 분석",
          "abstract": "자살은 전 세계 사망 원인 중 4위이며 사회, 경제적 손실이 큰 난제이다. 본 연구는 자살 예방을 위하여 소셜미디어에 나타난 자살 관련 말뭉치를 구축하고 이를 통해 자살 경향 문헌을 분류할 수 있는 딥러닝 자동분류 모델을 만들고자 하였다. 또한, 자살 요인을 분석하기 위해 주제를 자동으로 추출하는 분석 기법인 토픽모델링을 활용하여 자살 관련 말뭉치를 세부 주제로 분류하고자 하였다. 이를 위해 소셜미디어 중 하나인 네이버 지식iN에 나타난 자살 관련 문헌 2,011개를 수집한 후 자살예방교육 매뉴얼을 기준으로 자살 경향 문헌 및 비경향 문헌 여부를 주석 처리하였으며, 이 데이터를 딥러닝 모델(LSTM, BERT, ELECTRA)로 학습시켜 자동분류 모델을 만들었다. 또한, 토픽모델링 기법의 하나인 LDA 기법으로 주제별 문헌을 분류하여 자살 요인을 발견하였고 이를 심층적으로 분석하기 위해 주제별로 동시출현 단어 분석 및 네트워크 시각화를 진행하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129159550193&target=NART&cn=JAKO202129159550193",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 및 토픽모델링 기법을 활용한 소셜 미디어의 자살 경향 문헌 판별 및 분석 딥러닝 및 토픽모델링 기법을 활용한 소셜 미디어의 자살 경향 문헌 판별 및 분석 딥러닝 및 토픽모델링 기법을 활용한 소셜 미디어의 자살 경향 문헌 판별 및 분석 자살은 전 세계 사망 원인 중 4위이며 사회, 경제적 손실이 큰 난제이다. 본 연구는 자살 예방을 위하여 소셜미디어에 나타난 자살 관련 말뭉치를 구축하고 이를 통해 자살 경향 문헌을 분류할 수 있는 딥러닝 자동분류 모델을 만들고자 하였다. 또한, 자살 요인을 분석하기 위해 주제를 자동으로 추출하는 분석 기법인 토픽모델링을 활용하여 자살 관련 말뭉치를 세부 주제로 분류하고자 하였다. 이를 위해 소셜미디어 중 하나인 네이버 지식iN에 나타난 자살 관련 문헌 2,011개를 수집한 후 자살예방교육 매뉴얼을 기준으로 자살 경향 문헌 및 비경향 문헌 여부를 주석 처리하였으며, 이 데이터를 딥러닝 모델(LSTM, BERT, ELECTRA)로 학습시켜 자동분류 모델을 만들었다. 또한, 토픽모델링 기법의 하나인 LDA 기법으로 주제별 문헌을 분류하여 자살 요인을 발견하였고 이를 심층적으로 분석하기 위해 주제별로 동시출현 단어 분석 및 네트워크 시각화를 진행하였다."
        },
        {
          "rank": 48,
          "score": 0.5823045969009399,
          "doc_id": "NART135097894",
          "title": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare",
          "abstract": "<P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART135097894&target=NART&cn=NART135097894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare Revolutionizing Utility of Big Data Analytics in Personalized Cardiovascular Healthcare <P>The term &ldquo;big data analytics (BDA)&rdquo; defines the computational techniques to study complex datasets that are too large for common data processing software, encompassing techniques such as data mining (DM), machine learning (ML), and predictive analytics (PA) to find patterns, correlations, and insights in massive datasets. Cardiovascular diseases (CVDs) are attributed to a combination of various risk factors, including sedentary lifestyle, obesity, diabetes, dyslipidaemia, and hypertension. We searched PubMed and published research using the Google and Cochrane search engines to evaluate existing models of BDA that have been used for CVD prediction models. We critically analyse the pitfalls and advantages of various BDA models using artificial intelligence (AI), machine learning (ML), and artificial neural networks (ANN). BDA with the integration of wide-ranging data sources, such as genomic, proteomic, and lifestyle data, could help understand the complex biological mechanisms behind CVD, including risk stratification in risk-exposed individuals. Predictive modelling is proposed to help in the development of personalized medicines, particularly in pharmacogenomics; understanding genetic variation might help to guide drug selection and dosing, with the consequent improvement in patient outcomes. To summarize, incorporating BDA into cardiovascular research and treatment represents a paradigm shift in our approach to CVD prevention, diagnosis, and management. By leveraging the power of big data, researchers and clinicians can gain deeper insights into disease mechanisms, improve patient care, and ultimately reduce the burden of cardiovascular disease on individuals and healthcare systems.</P>"
        },
        {
          "rank": 49,
          "score": 0.5822633504867554,
          "doc_id": "NPAP12559726",
          "title": "Deep learning and block Go",
          "abstract": "<P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12559726&target=NART&cn=NPAP12559726",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep learning and block Go Deep learning and block Go Deep learning and block Go <P>Google Deepmind AlphaGo successfully defeated a professional nine dan Go player last March. One of the reasons is that they use deep learning to do a pure pattern-matching approach and predict the next move. In this paper, we use deep learning on the game of Block Go. Block Go is a variance of Go. In this paper, firstly we introduce the complexity of Block Go which is between checkers and Othello. Then we apply Deep Convolutional Neural Network (DCNN) on Block Go. Finally, we show that Block Go is a good research topic for deep learning.</P>"
        },
        {
          "rank": 50,
          "score": 0.582134485244751,
          "doc_id": "JAKO202121055483964",
          "title": "딥러닝을 통한 드론의 비정상 진동 예측",
          "abstract": "본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202121055483964&target=NART&cn=JAKO202121055483964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 딥러닝을 통한 드론의 비정상 진동 예측 본 논문에서는 드론의 추락을 예방하기 위해 드론의 프로펠러와 연결된 모터로부터 진동 데이터를 수집하고 순환 신경망(recurrent neural network, RNN)과 long short term memory (LSTM)을 사용하여 드론의 비정상 진동을 예측하는 연구를 진행하였다. 드론의 비정상 진동 데이터를 수집하기 위해 드론의 프로펠러와 연결된 모터에 진동 센서를 부착하여 정상, 바(bar) 손상, 로터(rotor) 손상, 축 휨에 대한 진동 데이터를 수집하고 LSTM과 RNN을 통해 비정상 진동을 예측한 결과의 평균 제곱근 오차 (root mean square error, RMSE) 값을 비교분석 하였다. 시뮬레이션 비교 결과, RNN과 LSTM을 통해 예측한 결과 모두 비정상 진동 패턴을 매우 정확하게 예측하는 것을 확인하였으며 LSTM을 통해 예측한 진동이 RNN을 통해 예측한 진동보다 RMSE값이 평균 15.4% 낮은 것을 확인하였다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}