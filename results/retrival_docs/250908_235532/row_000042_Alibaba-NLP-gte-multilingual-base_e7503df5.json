{
  "id": "row_000042",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:38.075694+09:00",
  "trial_id": "e7503df5",
  "queries": [
    {
      "query": "Could you outline the main points about the role of large-scale machine learning in bridging database systems and commercial applications?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6799874305725098,
          "doc_id": "JAKO202375343265966",
          "title": "인공지능 기술을 활용한 데이터 관리 기술 동향",
          "abstract": "Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202375343265966&target=NART&cn=JAKO202375343265966",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems."
        },
        {
          "rank": 2,
          "score": 0.6586474180221558,
          "doc_id": "JAKO201424635079777",
          "title": "학습 시스템을 위한 빅데이터 처리 환경 구축",
          "abstract": "빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424635079777&target=NART&cn=JAKO201424635079777",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다."
        },
        {
          "rank": 3,
          "score": 0.6495457291603088,
          "doc_id": "JAKO199811921340072",
          "title": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구",
          "abstract": "CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921340072&target=NART&cn=JAKO199811921340072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies."
        },
        {
          "rank": 4,
          "score": 0.6447127461433411,
          "doc_id": "JAKO202302557619339",
          "title": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반",
          "abstract": "최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202302557619339&target=NART&cn=JAKO202302557619339",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다."
        },
        {
          "rank": 5,
          "score": 0.6391399502754211,
          "doc_id": "JAKO201129362563090",
          "title": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교",
          "abstract": "세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201129362563090&target=NART&cn=JAKO201129362563090",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다."
        },
        {
          "rank": 6,
          "score": 0.6384577751159668,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 7,
          "score": 0.6349858045578003,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 8,
          "score": 0.6342097520828247,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 9,
          "score": 0.6329137086868286,
          "doc_id": "JAKO201905653788881",
          "title": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안",
          "abstract": "오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905653788881&target=NART&cn=JAKO201905653788881",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다."
        },
        {
          "rank": 10,
          "score": 0.6315122842788696,
          "doc_id": "NPAP12636301",
          "title": "Application Plan of Big Data and NoSQL",
          "abstract": "오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12636301&target=NART&cn=NPAP12636301",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL 오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다."
        },
        {
          "rank": 11,
          "score": 0.6307165622711182,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 12,
          "score": 0.6291779279708862,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 13,
          "score": 0.6290861368179321,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 14,
          "score": 0.6285274028778076,
          "doc_id": "DIKO0013392225",
          "title": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구",
          "abstract": "오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013392225&target=NART&cn=DIKO0013392225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다."
        },
        {
          "rank": 15,
          "score": 0.6269065737724304,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 16,
          "score": 0.6266061067581177,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 17,
          "score": 0.6253983974456787,
          "doc_id": "ATN0024933735",
          "title": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안",
          "abstract": "Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0024933735&target=NART&cn=ATN0024933735",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner."
        },
        {
          "rank": 18,
          "score": 0.6253819465637207,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 19,
          "score": 0.6251713633537292,
          "doc_id": "JAKO200835054210184",
          "title": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크",
          "abstract": "본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200835054210184&target=NART&cn=JAKO200835054210184",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다."
        },
        {
          "rank": 20,
          "score": 0.6244524717330933,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 21,
          "score": 0.6234651803970337,
          "doc_id": "ATN0037461993",
          "title": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법",
          "abstract": "This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037461993&target=NART&cn=ATN0037461993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis."
        },
        {
          "rank": 22,
          "score": 0.6225441694259644,
          "doc_id": "JAKO200825457812117",
          "title": "SQL 기반 퍼시스턴스 프레임워크",
          "abstract": "기업의 웹 기반 인트라넷 시스템은 객체지향 언어로 개발되고, 데이터의 관리는 RDBMS를 이용하여 구축된다. 두 시스템은 이질적 패러다임에 기인하여 모델의 불일치성을 발생시킨다. 이 문제를 해결하고자 사용되는 ORM 프레임워크는 RDB의 테이블과 객체지향 언어의 객체를 매핑하는 구조로 응용프로그램의 개발이 복잡하고, 변경에 유연하지 못하여 기업형 인트라넷 시스템의 개발 및 유지보수에 어려움을 준다. 본 연구에서는 기존 ORM 프레임워크의 복잡성을 해소하고, 변경에 유연하여 기업의 인트라넷 시스템에 적합한 퍼시스턴스 프레임워크를 제안한다. 제안한 퍼시스턴스 프레임워크는 테이블의 엔티티와 객체를 매핑하는 매핑 메타정보가 불필요하고, 소스코드를 자동 생성하여 개발 및 유지보수의 편의성을 제공하고, 변경에 유연하다. 제안 프레임워크는 Hibernate, iBATIS와의 테스트 결과 iBATIS와는 처리속도가 비슷했으나 iBATIS는 대용량 데이터 처리시 문제를 나타냈으며, Hibernate보다 약 3배 빠른 속도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200825457812117&target=NART&cn=JAKO200825457812117",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SQL 기반 퍼시스턴스 프레임워크 SQL 기반 퍼시스턴스 프레임워크 SQL 기반 퍼시스턴스 프레임워크 기업의 웹 기반 인트라넷 시스템은 객체지향 언어로 개발되고, 데이터의 관리는 RDBMS를 이용하여 구축된다. 두 시스템은 이질적 패러다임에 기인하여 모델의 불일치성을 발생시킨다. 이 문제를 해결하고자 사용되는 ORM 프레임워크는 RDB의 테이블과 객체지향 언어의 객체를 매핑하는 구조로 응용프로그램의 개발이 복잡하고, 변경에 유연하지 못하여 기업형 인트라넷 시스템의 개발 및 유지보수에 어려움을 준다. 본 연구에서는 기존 ORM 프레임워크의 복잡성을 해소하고, 변경에 유연하여 기업의 인트라넷 시스템에 적합한 퍼시스턴스 프레임워크를 제안한다. 제안한 퍼시스턴스 프레임워크는 테이블의 엔티티와 객체를 매핑하는 매핑 메타정보가 불필요하고, 소스코드를 자동 생성하여 개발 및 유지보수의 편의성을 제공하고, 변경에 유연하다. 제안 프레임워크는 Hibernate, iBATIS와의 테스트 결과 iBATIS와는 처리속도가 비슷했으나 iBATIS는 대용량 데이터 처리시 문제를 나타냈으며, Hibernate보다 약 3배 빠른 속도를 보였다."
        },
        {
          "rank": 23,
          "score": 0.6223514080047607,
          "doc_id": "JAKO201224747154192",
          "title": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법",
          "abstract": "최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201224747154192&target=NART&cn=JAKO201224747154192",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다."
        },
        {
          "rank": 24,
          "score": 0.6214367747306824,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 25,
          "score": 0.620995044708252,
          "doc_id": "JAKO201452057196583",
          "title": "빅데이터 지식처리 인공지능 기술동향",
          "abstract": "최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201452057196583&target=NART&cn=JAKO201452057196583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다."
        },
        {
          "rank": 26,
          "score": 0.6203945875167847,
          "doc_id": "JAKO201631642279380",
          "title": "Spark SQL 기반 고도 분석 지원 프레임워크 설계",
          "abstract": "기업의 신속한 의사결정 및 전략적 정책 결정을 위해 빅데이터에 대한 고도 분석이 필수적으로 요구됨에 따라 대량의 데이터를 복수의 노드에 분산하여 처리하는 하둡 또는 스파크와 같은 분산 처리 플랫폼이 주목을 받고 있다. 최근 공개된 Spark SQL은 Spark 환경에서 SQL 기반의 분산 처리 기법을 지원하고 있으나, 기계학습이나 그래프 처리와 같은 반복적 처리가 요구되는 고도 분석 분야에서는 효율적 처리가 불가능한 문제가 있다. 따라서 본 논문은 이러한 문제점을 바탕으로 Spark 환경에서 고도 분석 지원을 위한 SQL 기반의 빅데이터 최적처리 엔진설계와 처리 프레임워크를 제안한다. 복수의 조건과 다수의 조인, 집계, 소팅 연산이 필요한 복합 SQL 질의를 분산/병행적으로 처리할 수 있는 최적화 엔진과 관계형 연산을 지원하는 기계학습 최적화하기 위한 프레임워크를 설계한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201631642279380&target=NART&cn=JAKO201631642279380",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Spark SQL 기반 고도 분석 지원 프레임워크 설계 Spark SQL 기반 고도 분석 지원 프레임워크 설계 Spark SQL 기반 고도 분석 지원 프레임워크 설계 기업의 신속한 의사결정 및 전략적 정책 결정을 위해 빅데이터에 대한 고도 분석이 필수적으로 요구됨에 따라 대량의 데이터를 복수의 노드에 분산하여 처리하는 하둡 또는 스파크와 같은 분산 처리 플랫폼이 주목을 받고 있다. 최근 공개된 Spark SQL은 Spark 환경에서 SQL 기반의 분산 처리 기법을 지원하고 있으나, 기계학습이나 그래프 처리와 같은 반복적 처리가 요구되는 고도 분석 분야에서는 효율적 처리가 불가능한 문제가 있다. 따라서 본 논문은 이러한 문제점을 바탕으로 Spark 환경에서 고도 분석 지원을 위한 SQL 기반의 빅데이터 최적처리 엔진설계와 처리 프레임워크를 제안한다. 복수의 조건과 다수의 조인, 집계, 소팅 연산이 필요한 복합 SQL 질의를 분산/병행적으로 처리할 수 있는 최적화 엔진과 관계형 연산을 지원하는 기계학습 최적화하기 위한 프레임워크를 설계한다."
        },
        {
          "rank": 27,
          "score": 0.620269775390625,
          "doc_id": "JAKO201503340570903",
          "title": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치",
          "abstract": "본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201503340570903&target=NART&cn=JAKO201503340570903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다."
        },
        {
          "rank": 28,
          "score": 0.6199401617050171,
          "doc_id": "JAKO201617338764393",
          "title": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구",
          "abstract": "본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201617338764393&target=NART&cn=JAKO201617338764393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다."
        },
        {
          "rank": 29,
          "score": 0.6187723875045776,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 30,
          "score": 0.6181405782699585,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 31,
          "score": 0.616845428943634,
          "doc_id": "JAKO202307361686821",
          "title": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰",
          "abstract": "Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202307361686821&target=NART&cn=JAKO202307361686821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke."
        },
        {
          "rank": 32,
          "score": 0.616796612739563,
          "doc_id": "JAKO201524236536031",
          "title": "빅데이터를 활용한 효율적인 중소기업 업무 처리 모델",
          "abstract": "최근에 중소기업은 작고 유연한 조직이 지닌 장점과 빅 데이터의 장점을 결합하여 더 나은 가치를 창출하려는 시도가 증가하고 있다. 그러나 현재까지 중소기업은 생산성 향상에만 치중하여 ICT 패러다임 변화에 맞춰 지속가능한 경쟁력 확보가 부족한 실정이다. 본 논문은 저비용으로 새로운 제품 및 서비스 발굴을 위한 고객 니즈 파악, 타겟 마케팅, 고객관리 등에 효과적으로 활용 가능한 효율적인 중소기업 업무 처리 모델을 제안한다. 제안 모델은 중소기업내 생성되는 방대한 빅데이터를 이용하여 기업내 기업간 협업을 위한 신사업 창출에 필요한 경쟁력을 손쉽게 확보할 수 있다. 또한, 제안 모델은 빅데이터를 활용하여 마케팅 정보역량을 강화하고 이를 통해 분석된 정보를 신제품개발, 목표고객 선정, 가격전략, 홍보 및 판촉활동 등 기업경영활동 전반에 활용할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201524236536031&target=NART&cn=JAKO201524236536031",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 효율적인 중소기업 업무 처리 모델 빅데이터를 활용한 효율적인 중소기업 업무 처리 모델 빅데이터를 활용한 효율적인 중소기업 업무 처리 모델 최근에 중소기업은 작고 유연한 조직이 지닌 장점과 빅 데이터의 장점을 결합하여 더 나은 가치를 창출하려는 시도가 증가하고 있다. 그러나 현재까지 중소기업은 생산성 향상에만 치중하여 ICT 패러다임 변화에 맞춰 지속가능한 경쟁력 확보가 부족한 실정이다. 본 논문은 저비용으로 새로운 제품 및 서비스 발굴을 위한 고객 니즈 파악, 타겟 마케팅, 고객관리 등에 효과적으로 활용 가능한 효율적인 중소기업 업무 처리 모델을 제안한다. 제안 모델은 중소기업내 생성되는 방대한 빅데이터를 이용하여 기업내 기업간 협업을 위한 신사업 창출에 필요한 경쟁력을 손쉽게 확보할 수 있다. 또한, 제안 모델은 빅데이터를 활용하여 마케팅 정보역량을 강화하고 이를 통해 분석된 정보를 신제품개발, 목표고객 선정, 가격전략, 홍보 및 판촉활동 등 기업경영활동 전반에 활용할 수 있다."
        },
        {
          "rank": 33,
          "score": 0.6162064671516418,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 34,
          "score": 0.615338921546936,
          "doc_id": "JAKO201419553341501",
          "title": "빅데이터 산업 활성화 전략 연구",
          "abstract": "본 연구는 빅데이터 생태계의 개념 및 구성요소의 역할과 책임을 파악하여 빅데이터 산업이 활성화되기 위해서 필요한 전략을 도출하였다. 빅데이터 생태계의 구성요소는 거버넌스, 데이터 보유자, 서비스 이용자, 서비스 제공자, 인프라 제공자로 5개 구분하였다. 5개의 구성요소 간 역할과 책임을 통해 총 11개의 활성화 전략을 도출하였다. 또한 빅데이터 산업 활성화를 위해 선행연구자들이 주장한 내용을 요약 정리하여 총 12개의 활성화 방안을 제시하였다. 빅데이터 구성요소 간 활성화방안과 선행연구자들이 주장한 내용을 결합하여 본 연구에서 총 13개의 빅데이터 산업의 활성화 전략을 제시하였다. 본 연구에서 제시한 빅데이터 산업 활성화 전략이 빅데이터 사업 및 정책방향과 계획 수립의 기본자료로 활용되기 위하여 빅데이터 산업 활성화에 긍정적인 영향을 제공할 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201419553341501&target=NART&cn=JAKO201419553341501",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 산업 활성화 전략 연구 빅데이터 산업 활성화 전략 연구 빅데이터 산업 활성화 전략 연구 본 연구는 빅데이터 생태계의 개념 및 구성요소의 역할과 책임을 파악하여 빅데이터 산업이 활성화되기 위해서 필요한 전략을 도출하였다. 빅데이터 생태계의 구성요소는 거버넌스, 데이터 보유자, 서비스 이용자, 서비스 제공자, 인프라 제공자로 5개 구분하였다. 5개의 구성요소 간 역할과 책임을 통해 총 11개의 활성화 전략을 도출하였다. 또한 빅데이터 산업 활성화를 위해 선행연구자들이 주장한 내용을 요약 정리하여 총 12개의 활성화 방안을 제시하였다. 빅데이터 구성요소 간 활성화방안과 선행연구자들이 주장한 내용을 결합하여 본 연구에서 총 13개의 빅데이터 산업의 활성화 전략을 제시하였다. 본 연구에서 제시한 빅데이터 산업 활성화 전략이 빅데이터 사업 및 정책방향과 계획 수립의 기본자료로 활용되기 위하여 빅데이터 산업 활성화에 긍정적인 영향을 제공할 것으로 기대한다."
        },
        {
          "rank": 35,
          "score": 0.6144994497299194,
          "doc_id": "JAKO202013363976464",
          "title": "의료 빅데이터 산업 활성화를 위한 정책 동향 고찰",
          "abstract": "오늘날 비약적으로 발달한 의료 기술(Health Technology)은 병원에서 생성되는 데이터 외에도 사물 인터넷 기반의 의료기기를 통해 방대한 양의 데이터를 축적하고 있다. 수집된 데이터는 다양한 가치를 창출할 수 있는 원료가 되지만 우리 사회에는 의료 빅데이터를 활용하는데 근거가 되는 법적&#x00B7;제도적 장치가 미비한 상태다. 이에 본 연구에서는 빅데이터 기반 의료 산업의 활성화 방안을 모색하기 위해 의료 빅데이터의 활용을 저해하는 4가지 주요 요인을 살펴보았으며 그 외 국외 정책 및 기술적 동향을 파악해 국내 의료 빅데이터 활성화를 위한 시사점을 도출하였다. 연구결과 의료 빅데이터의 보안과 활용성 강화를 동시에 만족시키는 규제 체계의 개선 및 빅데이터 거버넌스의 구축이 필요하다는 결론이 도출되었으며 이를 위해 미국과 영국이 채택하고 있는 빅데이터 비식별화 가이드라인을 참고해 규제 체계를 정비할 것을 제안하였다. 향후 본 연구에서 도출한 결론 및 시사점의 구체적 활용 방안을 다룬 연구가 필요할 것으로 보이며 본 연구를 참고해 제도적 미비점을 보완한다면 의료 빅데이터를 유용하게 활용하는데 긍정적인 역할을 할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202013363976464&target=NART&cn=JAKO202013363976464",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 빅데이터 산업 활성화를 위한 정책 동향 고찰 의료 빅데이터 산업 활성화를 위한 정책 동향 고찰 의료 빅데이터 산업 활성화를 위한 정책 동향 고찰 오늘날 비약적으로 발달한 의료 기술(Health Technology)은 병원에서 생성되는 데이터 외에도 사물 인터넷 기반의 의료기기를 통해 방대한 양의 데이터를 축적하고 있다. 수집된 데이터는 다양한 가치를 창출할 수 있는 원료가 되지만 우리 사회에는 의료 빅데이터를 활용하는데 근거가 되는 법적&#x00B7;제도적 장치가 미비한 상태다. 이에 본 연구에서는 빅데이터 기반 의료 산업의 활성화 방안을 모색하기 위해 의료 빅데이터의 활용을 저해하는 4가지 주요 요인을 살펴보았으며 그 외 국외 정책 및 기술적 동향을 파악해 국내 의료 빅데이터 활성화를 위한 시사점을 도출하였다. 연구결과 의료 빅데이터의 보안과 활용성 강화를 동시에 만족시키는 규제 체계의 개선 및 빅데이터 거버넌스의 구축이 필요하다는 결론이 도출되었으며 이를 위해 미국과 영국이 채택하고 있는 빅데이터 비식별화 가이드라인을 참고해 규제 체계를 정비할 것을 제안하였다. 향후 본 연구에서 도출한 결론 및 시사점의 구체적 활용 방안을 다룬 연구가 필요할 것으로 보이며 본 연구를 참고해 제도적 미비점을 보완한다면 의료 빅데이터를 유용하게 활용하는데 긍정적인 역할을 할 것으로 기대된다."
        },
        {
          "rank": 36,
          "score": 0.6128590106964111,
          "doc_id": "NART106279808",
          "title": "Machine learning for site-adaptation and solar radiation forecasting",
          "abstract": "<P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106279808&target=NART&cn=NART106279808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting <P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>"
        },
        {
          "rank": 37,
          "score": 0.6123302578926086,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 38,
          "score": 0.6119066476821899,
          "doc_id": "JAKO202514154005683",
          "title": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구",
          "abstract": "본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514154005683&target=NART&cn=JAKO202514154005683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다."
        },
        {
          "rank": 39,
          "score": 0.6113128662109375,
          "doc_id": "NART124447608",
          "title": "Lifelong Machine Learning Potentials",
          "abstract": "<P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART124447608&target=NART&cn=NART124447608",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials <P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>"
        },
        {
          "rank": 40,
          "score": 0.6106938123703003,
          "doc_id": "JAKO202012758285347",
          "title": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구",
          "abstract": "국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012758285347&target=NART&cn=JAKO202012758285347",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다."
        },
        {
          "rank": 41,
          "score": 0.6095914840698242,
          "doc_id": "DIKO0017154536",
          "title": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템",
          "abstract": "IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017154536&target=NART&cn=DIKO0017154536",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다."
        },
        {
          "rank": 42,
          "score": 0.6094118356704712,
          "doc_id": "JAKO202032362242307",
          "title": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용",
          "abstract": "본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242307&target=NART&cn=JAKO202032362242307",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다."
        },
        {
          "rank": 43,
          "score": 0.6093066334724426,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        },
        {
          "rank": 44,
          "score": 0.6090841293334961,
          "doc_id": "DIKO0017285659",
          "title": "산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로",
          "abstract": "라이다 데이터는 정밀한 3차원 공간 정보를 제공하지만, 데이터 용량이 매우 방대하여 인공지능(AI) 학습과 디지털 산림행정에 바로 적용하는 데에는 한계가 있다. 이에 따라 방대한 라이다 데이터의 문제를 해결하고자, 여러 가지 경량화 기법을 찾고 효율성을 검토하기 위하여 본 연구를 수행하였으며. 복셀 그리드(voxel grid), 무작위 샘플링(random sampling), 옥트리 (octree) 기반 분할, 최원점 샘플링(FPS) 네 가지 방법으로 데이터 용량 감소율과 데이터 보존 정도, 처리 속도 등을 비교하고 분석하였다. 아울러, 라이더 데이터를 활용한 산림행정 지능화 방안으로서 데이터 마이닝, 딥러닝 기반의 다양한 알고리즘을 소개하였다. 각각의 장단점과 산림행정 적용 방안 및 이슈를 분석하였다. 이러한 연구 결과는 향후 디지털 산림행정을 추진하는 데 있어, 데이터 처리 효율과 분석 정확도를 동시에 확보하는 방안으로 활용될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017285659&target=NART&cn=DIKO0017285659",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 라이다 데이터는 정밀한 3차원 공간 정보를 제공하지만, 데이터 용량이 매우 방대하여 인공지능(AI) 학습과 디지털 산림행정에 바로 적용하는 데에는 한계가 있다. 이에 따라 방대한 라이다 데이터의 문제를 해결하고자, 여러 가지 경량화 기법을 찾고 효율성을 검토하기 위하여 본 연구를 수행하였으며. 복셀 그리드(voxel grid), 무작위 샘플링(random sampling), 옥트리 (octree) 기반 분할, 최원점 샘플링(FPS) 네 가지 방법으로 데이터 용량 감소율과 데이터 보존 정도, 처리 속도 등을 비교하고 분석하였다. 아울러, 라이더 데이터를 활용한 산림행정 지능화 방안으로서 데이터 마이닝, 딥러닝 기반의 다양한 알고리즘을 소개하였다. 각각의 장단점과 산림행정 적용 방안 및 이슈를 분석하였다. 이러한 연구 결과는 향후 디지털 산림행정을 추진하는 데 있어, 데이터 처리 효율과 분석 정확도를 동시에 확보하는 방안으로 활용될 수 있다."
        },
        {
          "rank": 45,
          "score": 0.6082602739334106,
          "doc_id": "DIKO0013687737",
          "title": "빅데이터 처리 프로세스의 위험요인에 관한 연구",
          "abstract": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013687737&target=NART&cn=DIKO0013687737",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 빅데이터 처리 프로세스의 위험요인에 관한 연구 최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다."
        },
        {
          "rank": 46,
          "score": 0.6076284646987915,
          "doc_id": "NART06057124",
          "title": "Integration of Machine Learning and Knowledge Acquisition",
          "abstract": "<P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06057124&target=NART&cn=NART06057124",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition <P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>"
        },
        {
          "rank": 47,
          "score": 0.6073818206787109,
          "doc_id": "JAKO201734158606474",
          "title": "제조업의 심층신경망 기계학습(딥러닝)",
          "abstract": "인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734158606474&target=NART&cn=JAKO201734158606474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다."
        },
        {
          "rank": 48,
          "score": 0.6069678068161011,
          "doc_id": "JAKO200818259612116",
          "title": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습",
          "abstract": "본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200818259612116&target=NART&cn=JAKO200818259612116",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다."
        },
        {
          "rank": 49,
          "score": 0.6068372130393982,
          "doc_id": "JAKO201436351075064",
          "title": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구",
          "abstract": "정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201436351075064&target=NART&cn=JAKO201436351075064",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 빅데이터 도입 효과 분석을 통한 빅데이터 성공요인에 관한 연구 정보기술의 발달과 기반하드웨어 기술의 비약적인 발전은 데이터 사용의 폭을 넓혀주었고 이로 인해서 빅데이터 시대라는 새로운 패러다임을 제시하였다. 빅데이터 기술과 그 활용성과는 점차 늘어나는 추세이며 이에 기업들은 데이터의 중요성을 깨닫고 이를 활용하려는 움직임이 활발해지고 있다. 본 연구는 기업에서 빅데이터를 활용함에 있어 빅데이터 기술의 적극적 도입 및 활용을 위한 요인들을 선별해내고 이를 통한 중요도를 검증하고자 수행되었다. 연구모형에 포함된 빅데이터의 특성 요인으로는 예측성, 관리성, 지원성, 경쟁성을 선정하였다. 빅데이터에 대한 경험을 보유한 기업의 실무자를 대상으로 한 설문과 통계를 바탕으로 검증한 결과 관리성 측면이 가장 중요한 성공요인으로 채택되었으며, 본 연구의 결과는 기업에서의 빅데이터 도입 시에 빅데이터의 특성에 대한 좀더 객관적인 이해와 이를 통한 고려사항을 통해 좀더 효율성 있는 사용을 가능하게 정보를 제공하는 것이 가능할 것이다."
        },
        {
          "rank": 50,
          "score": 0.606124997138977,
          "doc_id": "JAKO201835146902109",
          "title": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법",
          "abstract": "인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201835146902109&target=NART&cn=JAKO201835146902109",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다."
        }
      ]
    },
    {
      "query": "What kind of data from database systems is relevant for large-scale machine learning?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7308187484741211,
          "doc_id": "JAKO202375343265966",
          "title": "인공지능 기술을 활용한 데이터 관리 기술 동향",
          "abstract": "Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202375343265966&target=NART&cn=JAKO202375343265966",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems."
        },
        {
          "rank": 2,
          "score": 0.7063572406768799,
          "doc_id": "JAKO201424635079777",
          "title": "학습 시스템을 위한 빅데이터 처리 환경 구축",
          "abstract": "빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424635079777&target=NART&cn=JAKO201424635079777",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다."
        },
        {
          "rank": 3,
          "score": 0.6868827939033508,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 4,
          "score": 0.6772507429122925,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 5,
          "score": 0.6757224202156067,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 6,
          "score": 0.673668384552002,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 7,
          "score": 0.6722866296768188,
          "doc_id": "NPAP12636301",
          "title": "Application Plan of Big Data and NoSQL",
          "abstract": "오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12636301&target=NART&cn=NPAP12636301",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL 오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다."
        },
        {
          "rank": 8,
          "score": 0.6713994145393372,
          "doc_id": "ATN0024933735",
          "title": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안",
          "abstract": "Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0024933735&target=NART&cn=ATN0024933735",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner."
        },
        {
          "rank": 9,
          "score": 0.6698129177093506,
          "doc_id": "DIKO0015936637",
          "title": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구",
          "abstract": "시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015936637&target=NART&cn=DIKO0015936637",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 머신러닝과 딥러닝을 이용한 시계열 빅데이터 예측 연구 시계열 데이터란 시간의 흐름 순서대로 데이터들을 나열한 것으로, 과거의 데이터를 이용하여 미래의 일을 예측하는 것이다. 시계열 데이터의 경우에는 시간에 따른 정보를 포함하고 있어 시간 흐름에 따른 파라미터의 변화량 등을 파악할 수가 있어 다양한 분야에 적용이 가능하다. 과거에서부터 인과관계가 있는 시계열 데이터를 이용하여 다양한 분야에 사용하였다. 이를 통해 단기 예측 혹은 장기 예측을 하여 연구를 지속해왔다. IoT(Internet of Things)와 SNS(Social Network Service)가 등으로 인해 다양한 센서와 다양한 센서로부터 측정된 데이터를 저장하기 위한 기술의 발전으로 데이터의 규모나 복잡성이 커지고 있다. IoT와 다양한 센서로부터 산업에서 측정되는 상당수의 데이터가 시계열 특성을 지내고 있다. 실시간으로 생성되는 데이터를 분석하여 유의미한 미래 예측 분석을 하는 것이 중요하게 되었다.&amp;#xD; 본 논문에서는 헬스케어를 위한 시계열 빅데이터 기반의 예측 연구를 하고자 한다. 헬스케어 분야에서 미리 대처가 가능한 질환에 대해 머신러닝과 딥러닝을 적용하려고 한다. 그에 따라 호흡기 질환과 심정지 예측 연구를 하려고 한다. 그러나 모든 호흡기 질환 예측 혹은 예후 관리 예측은 힘들기 때문에 호흡기 질환에서 큰 영향을 미치는 미세먼지 예측을 하려고 한다. 미세먼지 예측을 통해 호흡기 질환의 악영향을 최소화하기 위해 1시간 이후 미세먼지 수치를 예측하고자 한다. 미세먼지 데이터셋의 경우에는 기상 측정 장비에 의해 주기적으로 측정되는 특징을 가지고 있고, EMR 데이터의 경우에는 의료진에 의해 환자 데이터를 수집하고 전산 시스템에 입력되는 생징후 데이터와, 혈액을 랩 데이터 측정 장비에 의해 측정되는 랩 데이터가 있는 특징을 가지고 있다. 그에 따라 시계열 데이터 연구에 적합하다.&amp;#xD; 한국의 경우 미세먼지를 등급으로 예보하기 때문에 정확한 미세먼지 수치를 파악하기는 힘들다. 기존 미세먼지 예측의 경우에는 미세먼지나, 초미세먼지만을 예측하는 경우가 있다. 특정 나라 내의 소수의 지역의 미세먼지만을 예측한다. 미세먼지 예측을 모델을 개발하기 위해 기상 정보와 대기 정보, 주소 체계, 24절기의 상관관계 분석을 수행하였다. 이를 토대로 한국 내 미세먼지와 초미세먼지를 예측하는 모델을 개발하였다.&amp;#xD; 병원에서 심정지 예측하기 위해 EWS시스템을 사용한다. 그러나 기존의 EWS는 낮은 정밀도와 높은 거짓 알람의 문제점이 존재한다. 심정지 예측을 위해 시계열 데이터를 분석한 결과 병원 데이터의 경우에는 환자별 데이터 측정 주기가 상이한 문제점이 존재한다. 측정 주기가 상이한 경우 시계열 데이터 기반 예측이 어려운 문제점을 갖고 있다. 그에 따라 환자의 데이터 측정 주기를 1시간으로 변경하였고, 결측치는 마지막으로 측정된 값으로 보정을 하였다. 심정지 예측과 관련된 파라미터를 파악하기 위하여 생징후 데이터와 랩 데이터의 상관관계 분석을 수행하였다. 또한 시계열 데이터에서는 Lookback을 통해 과거의 데이터를 고려하는데 고려한 시간에 따른 성능 평가를 하여 심정지 예측을 위한 최적의 Lookback을 확인하였다. 이를 바탕으로 심정지 예측 모델을 개발하였다. 기존 심정지 예측 모델과 성능평가를 한 결과 본 논문에서 제안한 모델이 더 우수한 성능을 보였다. 현재에는 8시간 이내의 심정지 예측만을 제공하나 향후에는 심정지 위험 정보를 수치화하여 의료진들이 고려할 수 있도록 할 예정이다."
        },
        {
          "rank": 10,
          "score": 0.666662871837616,
          "doc_id": "JAKO201129362563090",
          "title": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교",
          "abstract": "세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201129362563090&target=NART&cn=JAKO201129362563090",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다."
        },
        {
          "rank": 11,
          "score": 0.6653404235839844,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 12,
          "score": 0.6600023508071899,
          "doc_id": "DIKO0015069923",
          "title": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템",
          "abstract": "데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015069923&target=NART&cn=DIKO0015069923",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 딥 러닝 모델 최적화 기반 순차 데이터 예측 시스템 데이터 예측 시스템들은 데이터를 예측하기 위해 특정 분야의 데이터를 컴퓨터가 분석하여 규칙을 찾아내고 데이터를 예측하였다. 이러한 방법은 과거 데이터를 분석한 결과로 사람이 규칙을 도출할 수 있어야 데이터를 예측하는 것이 가능하였다. 이에 반해 규칙을 도출할 수 없는 데이터들의 데이터를 예측하는 것은 사람의 능력으로는 한계가 있어 정확도가 낮아지는 문제점이 발생할 수 있다.&amp;#xD; 이를 해결하기 위해 컴퓨터를 활용하여 방대한 데이터를 데이터 예측 프로그램에 학습 데이터로 입력하고 결과로 데이터를 예측하였다. 이러한 방법론을 활용하기 위해서 고성능 컴퓨터로 딥 러닝(Deep Learning) 기술을 적용하여 데이터를 예측하고 있다. 해당 방법론이 활용되고 있는 분야로는 기상 데이터를 분석하여 날씨를 예측하는 날씨 분석과 스포츠 경기의 데이터를 예측하는 것이 대표적이다. &amp;#xD; 딥 러닝 기술은 프로그램이 데이터를 기반으로 학습을 진행하고 진행된 학습을 기반으로 데이터를 처리하는 것이다. 이는 과거에 사람이 직접 데이터를 분석하는 것보다 대규모 데이터를 분석하기에 적합하고 이로 인해 정확도가 올라가는 이점이 있다. 또한 목적에 따라 적합한 딥 러닝 모델을 적용하여 데이터를 예측할 경우 정확도의 기댓값이 높아지는 이점이 있다.&amp;#xD; 현재 딥 러닝 모델 중에서 데이터를 예측하기 위해 사용되는 모델은 신경망 구조를 기반으로 하는 DNN(Deep Neural Network) 모델과 RNN(Recurrent Neural Network) 모델이다. DNN 모델은 학습 데이터 내에서 규칙을 찾아내지 못하더라도 반복 학습을 통해 데이터 예측에 대한 정확도를 올릴 수 있고, RNN은 학습 과정 중에서 은닉층에서 적용될 가중치가 학습을 진행할 수록 변화하여 데이터를 예측하고 이로 인해 정확도를 올릴 수 있다. 이에 반해 DNN은 반복 학습의 횟수가 많아야 정확도가 높아지고 RNN은 가중치 변화의 횟수가 많아져야 정확도가 높아지기 때문에 결국 두 모델들은 학습의 반복이 많아져야 하는 문제점이 있다.&amp;#xD; 본 논문에서는 데이터 예측을 위해 딥 러닝 모델 기반 순차 데이터 예측 시스템을 제안한다. 제안하는 시스템에서 비정형 데이터를 순차 데이터로 정제하기 위해 전처리기를 구현하였다. 전처리기는 딥 러닝 모델에 학습 데이터를 입력하기 전에 데이터들을 정제하는 기능을 수행한다. 데이터는 ‘데이터 : 인덱스’ 구조로 이루어진 데이터 쌍이 되고 이러한 데이터 쌍들의 집합을 딥 러닝 모델에 입력하여 학습을 진행한다.&amp;#xD; 딥 러닝 모델은 DNN 모델, 기본 LSTM 모델, 상태유지 LSTM 모델을 활용하여 시스템을 각각 구축한다. 그리고 각 모델들의 설정 값을 변경하면서 정확도의 변화량을 분석한다. 또한 시퀀스의 길이를 변경해가며 실험을 진행하여 가장 정확도가 높은 데이터 셋과 시퀀스 길이의 비율을 제시한다.&amp;#xD; 딥 러닝 모듈 기반 시스템의 실험을 바탕으로 순차 데이터 예측에 가장 정확도가 높고 효율적인 딥 러닝 모듈을 선정하고 기존 시스템들과 비교 분석을 진행하여 제안하는 시스템의 우수성을 검증한다.&amp;#xD; 제안하는 시스템을 활용할 경우 학습 데이터가 적어도 높은 정확도를 요구하는 분야에서 기존 시스템들에 비해 효율성이 높을 것으로 사료된다.&amp;#xD;"
        },
        {
          "rank": 13,
          "score": 0.6597611308097839,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 14,
          "score": 0.655434250831604,
          "doc_id": "NART69190768",
          "title": "Data, DIKW, Big Data and Data Science",
          "abstract": "In this paper we discuss the relationship between data and DIKW, that the data only evolves to knowledge, which may have some value, but if without the wisdom we still could let the knowledge be really useful to people. Now the big data occupies much attention in some extent for his volume, velocity, and variety. But in practical use the value plays more important role. Finally to judge the value for data not necessary for big, in some cases the small data also may lead to big value. So we appreciate the data science, which may consider more inherent value from data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69190768&target=NART&cn=NART69190768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Data, DIKW, Big Data and Data Science Data, DIKW, Big Data and Data Science Data, DIKW, Big Data and Data Science In this paper we discuss the relationship between data and DIKW, that the data only evolves to knowledge, which may have some value, but if without the wisdom we still could let the knowledge be really useful to people. Now the big data occupies much attention in some extent for his volume, velocity, and variety. But in practical use the value plays more important role. Finally to judge the value for data not necessary for big, in some cases the small data also may lead to big value. So we appreciate the data science, which may consider more inherent value from data."
        },
        {
          "rank": 15,
          "score": 0.654808521270752,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 16,
          "score": 0.6547971367835999,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 17,
          "score": 0.6527870297431946,
          "doc_id": "NPAP12688093",
          "title": "A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis",
          "abstract": "빅데이터 분석은 데이터베이스에 잘 정리된 정형 데이터뿐만 아니라 인터넷, 소셜 네트워크 서비스, 모바일 환경에서 생성되는 웹 문서, 이메일, 소셜 데이터 등 비정형 데이터를 효과적으로 분석하는 기술을 말한다. 대부분의 빅데이터 분석 기술 방법들은 기존 통계학과 전산학에서 사용되던 데이터 마이닝, 기계 학습, 자연 언어 처리, 패턴 인식 등이 이에 해당된다. 글로벌 리서치 기관들은 빅데이터 분석을 2011년 이래로 가장 주목받는 신기술로 지목해오고 있다. 따라서 대부분의 산업에서 기업들은 빅데이터의 적용을 통해 새로운 가치 창출을 위해 노력을 하고 있다. 본 연구에서는 다음 커뮤니케이션의 빅데이터 분석 도구인 소셜 매트릭스를 활용하여 분석하였다. 2018년 5월 19일 시점 1개월 기간을 설정하여 &quot;인공지능&quot; 키워드에 대한 대중들의 인식을 분석하였다. 빅데이터 분석의 결과는 다음과 같다. 첫째, 인공지능에 대한 1위 연관 검색어는 중국(4,122)인 것으로 나타났다. 결과를 바탕으로 연구의 한계와 시사점을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12688093&target=NART&cn=NPAP12688093",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis A Study on Recognition of Artificial Intelligence Utilizing Big Data Analysis 빅데이터 분석은 데이터베이스에 잘 정리된 정형 데이터뿐만 아니라 인터넷, 소셜 네트워크 서비스, 모바일 환경에서 생성되는 웹 문서, 이메일, 소셜 데이터 등 비정형 데이터를 효과적으로 분석하는 기술을 말한다. 대부분의 빅데이터 분석 기술 방법들은 기존 통계학과 전산학에서 사용되던 데이터 마이닝, 기계 학습, 자연 언어 처리, 패턴 인식 등이 이에 해당된다. 글로벌 리서치 기관들은 빅데이터 분석을 2011년 이래로 가장 주목받는 신기술로 지목해오고 있다. 따라서 대부분의 산업에서 기업들은 빅데이터의 적용을 통해 새로운 가치 창출을 위해 노력을 하고 있다. 본 연구에서는 다음 커뮤니케이션의 빅데이터 분석 도구인 소셜 매트릭스를 활용하여 분석하였다. 2018년 5월 19일 시점 1개월 기간을 설정하여 &quot;인공지능&quot; 키워드에 대한 대중들의 인식을 분석하였다. 빅데이터 분석의 결과는 다음과 같다. 첫째, 인공지능에 대한 1위 연관 검색어는 중국(4,122)인 것으로 나타났다. 결과를 바탕으로 연구의 한계와 시사점을 제시하고자 한다."
        },
        {
          "rank": 18,
          "score": 0.6526236534118652,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 19,
          "score": 0.6526217460632324,
          "doc_id": "JAKO200818259612116",
          "title": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습",
          "abstract": "본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200818259612116&target=NART&cn=JAKO200818259612116",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다."
        },
        {
          "rank": 20,
          "score": 0.6526188850402832,
          "doc_id": "JAKO201823952425544",
          "title": "에너지 빅데이터를 수용하는 빅데이터 시스템 개발",
          "abstract": "본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201823952425544&target=NART&cn=JAKO201823952425544",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "에너지 빅데이터를 수용하는 빅데이터 시스템 개발 에너지 빅데이터를 수용하는 빅데이터 시스템 개발 에너지 빅데이터를 수용하는 빅데이터 시스템 개발 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다."
        },
        {
          "rank": 21,
          "score": 0.6524191498756409,
          "doc_id": "JAKO201503340570903",
          "title": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치",
          "abstract": "본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201503340570903&target=NART&cn=JAKO201503340570903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다."
        },
        {
          "rank": 22,
          "score": 0.6513733863830566,
          "doc_id": "DIKO0017154536",
          "title": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템",
          "abstract": "IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017154536&target=NART&cn=DIKO0017154536",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다."
        },
        {
          "rank": 23,
          "score": 0.6505573987960815,
          "doc_id": "NART97302075",
          "title": "Big data processing framework for manufacturing",
          "abstract": "<P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97302075&target=NART&cn=NART97302075",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data processing framework for manufacturing Big data processing framework for manufacturing Big data processing framework for manufacturing <P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>"
        },
        {
          "rank": 24,
          "score": 0.64969801902771,
          "doc_id": "JAKO199811921340072",
          "title": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구",
          "abstract": "CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921340072&target=NART&cn=JAKO199811921340072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies."
        },
        {
          "rank": 25,
          "score": 0.6494871973991394,
          "doc_id": "NART97710485",
          "title": "Big data analytics for personalized medicine",
          "abstract": "<P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97710485&target=NART&cn=NART97710485",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics for personalized medicine Big data analytics for personalized medicine Big data analytics for personalized medicine <P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
        },
        {
          "rank": 26,
          "score": 0.6492104530334473,
          "doc_id": "NART106279808",
          "title": "Machine learning for site-adaptation and solar radiation forecasting",
          "abstract": "<P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106279808&target=NART&cn=NART106279808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting <P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>"
        },
        {
          "rank": 27,
          "score": 0.649007260799408,
          "doc_id": "JAKO201721961719817",
          "title": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법",
          "abstract": "제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721961719817&target=NART&cn=JAKO201721961719817",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다."
        },
        {
          "rank": 28,
          "score": 0.6483073234558105,
          "doc_id": "JAKO201831960581454",
          "title": "빅데이터, 오픈데이터, 마이데이터의 비교 연구",
          "abstract": "지금은 데이터혁명 시대라고 한다. 데이터혁명 시대는 빅데이터로 시작하였고 오픈데이터를 거쳐서 마이데이터로 완성될 것이라 얘기한다. 본 논문에서는 빅데이터, 오픈데이터, 마이데이터를 비교 분석하고, 디지털자원으로서 마이데이터의 역할과 효과를 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201831960581454&target=NART&cn=JAKO201831960581454",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 지금은 데이터혁명 시대라고 한다. 데이터혁명 시대는 빅데이터로 시작하였고 오픈데이터를 거쳐서 마이데이터로 완성될 것이라 얘기한다. 본 논문에서는 빅데이터, 오픈데이터, 마이데이터를 비교 분석하고, 디지털자원으로서 마이데이터의 역할과 효과를 제시하고자 한다."
        },
        {
          "rank": 29,
          "score": 0.647884726524353,
          "doc_id": "ATN0038877162",
          "title": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구",
          "abstract": "Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038877162&target=NART&cn=ATN0038877162",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented."
        },
        {
          "rank": 30,
          "score": 0.6478034853935242,
          "doc_id": "JAKO202032362242307",
          "title": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용",
          "abstract": "본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242307&target=NART&cn=JAKO202032362242307",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 교육종단연구 분석을 위한 빅데이터 플랫폼 개발 및 적용 본 논문에서는 교육종단연구 데이터를 효과적으로 저장&#x00B7;처리&#x00B7;분석하기 위한 데이터 플랫폼을 개발하고, 이를 서울교육종단연구(SELS)에 적용하여 유용성을 확인한다. 플랫폼은 데이터 전처리부와 데이터 분석부로 구성된다. 데이터 전처리부에서는 1) 마스킹 2) 요인화 3) 정규화&#x00B7;이산화 4) 데이터 유도 5) 데이터 웨어하우징 과정을 통해 교육종단연구 데이터 웨어하우스를 생성하게 된다. 데이터 분석부는 OLAP과 데이터 마이닝(DM)으로 구성된다. 먼저, OLAP에서는 측정값 선정, 스키마 설계를 거쳐 OLAP을 수행하게 된다. 이후 DM에서는 변수 선택, 연구모형 선택, 데이터 수정, 인수튜닝, 모형학습, 모형평가 및 해석단계를 거친다. 본 플랫폼에서 전처리 과정을 거쳐 생성된 데이터 웨어하우스는 다양한 연구자들에 의해 공유될 수 있고, 지속적인 연구결과 데이터 셋의 축적이 가능하므로 후속 연구자들은 추가적인 분석을 수월하게 수행할 수 있게 된다. 또한, 정책입안자들도 SELS 데이터 웨어하우스에 직접 접근하여 다차원 분석을 통해 온라인으로 분석할 수 있어 과학적인 의사결정이 가능하게 된다. 본 연구에서는 개발된 플랫폼의 유용성을 입증하기 위해 SELS 데이터를 플랫폼 상에서 구축하고 수학 학업성취도를 측정값으로 선정하여 OLAP 및 DM을 수행하였으며, 측정값에 영향을 주는 다양한 요인을 데이터 마이닝 기법을 사용하여 분석하였다. 이를 통해 데이터 기반 교육정책 시사점을 빠르고 효과적으로 도출할 수 있었다."
        },
        {
          "rank": 31,
          "score": 0.6467230916023254,
          "doc_id": "NPAP13485077",
          "title": "Deep Interpretable Learning for a Rapid Response System",
          "abstract": "In-hospital cardiac arrest is a significant problem for medical systems. Although the traditional early warning systems have been widely applied, they still contain many drawbacks, such as the high false warning rate and low sensitivity. This paper proposed a strategy that involves a deep learning approach based on a novel interpretable deep tabular data learning architecture, named TabNet, for the Rapid Response System. This study has been processed and validated on a dataset collected from two hospitals of Chonnam National University, Korea, in over 10 years. The learning metrics used for the experiment are the area under the receiver operating characteristic curve score (AUROC) and the area under the precision-recall curve score (AUPRC). The experiment on a large real-time dataset shows that our method improves compared to other machine learning-based approaches.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13485077&target=NART&cn=NPAP13485077",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Interpretable Learning for a Rapid Response System Deep Interpretable Learning for a Rapid Response System Deep Interpretable Learning for a Rapid Response System In-hospital cardiac arrest is a significant problem for medical systems. Although the traditional early warning systems have been widely applied, they still contain many drawbacks, such as the high false warning rate and low sensitivity. This paper proposed a strategy that involves a deep learning approach based on a novel interpretable deep tabular data learning architecture, named TabNet, for the Rapid Response System. This study has been processed and validated on a dataset collected from two hospitals of Chonnam National University, Korea, in over 10 years. The learning metrics used for the experiment are the area under the receiver operating characteristic curve score (AUROC) and the area under the precision-recall curve score (AUPRC). The experiment on a large real-time dataset shows that our method improves compared to other machine learning-based approaches."
        },
        {
          "rank": 32,
          "score": 0.6462128758430481,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 33,
          "score": 0.6459271907806396,
          "doc_id": "JAKO202514057605142",
          "title": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구",
          "abstract": "분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514057605142&target=NART&cn=JAKO202514057605142",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다."
        },
        {
          "rank": 34,
          "score": 0.6453142166137695,
          "doc_id": "JAKO201310635656321",
          "title": "빅 데이터의 품질 요소 제안",
          "abstract": "빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201310635656321&target=NART&cn=JAKO201310635656321",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다."
        },
        {
          "rank": 35,
          "score": 0.6453039050102234,
          "doc_id": "ATN0025420772",
          "title": "빅데이터, 오픈데이터, 마이데이터의 비교 연구",
          "abstract": "With the advent of the fourth industrial revolution, data becomes very important resource. Now is called as ‘Data Revolution Age.’ It is said that Data Revolution Age started with Big Data, then accelerated with Open Data, finally completed with My Data. In this paper, we compared Big Data, Open Data, and suggested roles and effects of My Data as a digital resource.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420772&target=NART&cn=ATN0025420772",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 빅데이터, 오픈데이터, 마이데이터의 비교 연구 With the advent of the fourth industrial revolution, data becomes very important resource. Now is called as ‘Data Revolution Age.’ It is said that Data Revolution Age started with Big Data, then accelerated with Open Data, finally completed with My Data. In this paper, we compared Big Data, Open Data, and suggested roles and effects of My Data as a digital resource."
        },
        {
          "rank": 36,
          "score": 0.6452115774154663,
          "doc_id": "JAKO202514154005683",
          "title": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구",
          "abstract": "본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514154005683&target=NART&cn=JAKO202514154005683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다."
        },
        {
          "rank": 37,
          "score": 0.6449759006500244,
          "doc_id": "NART125772135",
          "title": "Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data",
          "abstract": "<P>Big data is quickly becoming a new area where administrative work can be improved. Even so, it is still in the early stages of being used in hospitals in countries with less technology. Therefore, there is an inadequate grasp of the evaluation of big data adoption preparedness in the healthcare sector as data-point-determined insights become crucially useful in healthcare institutions in underdeveloped nations. This process, called &ldquo;digital transformation,&rdquo; has a lot of benefits; for example, it helps healthcare organizations to create more efficient processes, offer different services, give better care, make more money, and cut costs. This paper aims to suggest and assess a conceptual framework that focuses on technological factors and can assist in determining the readiness of healthcare institutions in developing nations to utilize big data. Although the study can offer valuable perspectives on the advantages that can arise from adopting big data in the healthcare sector, it is important to highlight that leveraging big data analytics in healthcare has the potential to enhance the efficiency and effectiveness of healthcare services. This, in turn, can indirectly contribute to sustainability objectives by optimizing the allocation of resources, minimizing waste, and improving patient outcomes. A total of 328 healthcare workers from Malaysia were subjected to experimental testing of the model. The collected data were evaluated using the Smart PLS 3 program and the structural equation model (SEM). The study&rsquo;s findings supported our hypotheses. The results showed that technological factors affected the participants&rsquo; perception of their readiness for big data, which ultimately influenced their interest in utilizing it. By concentrating on big data preparedness in the healthcare industry and ambition to utilize big data, this research provides an important theoretical contribution. Employees who are &ldquo;big data ready&rdquo; would benefit from the study&rsquo;s results, as, through their recognition, said employees are more likely to increase the desire to use big data in Malaysia&rsquo;s healthcare sectors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125772135&target=NART&cn=NART125772135",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data Assessing the Big Data Adoption Readiness Role in Healthcare between Technology Impact Factors and Intention to Adopt Big Data <P>Big data is quickly becoming a new area where administrative work can be improved. Even so, it is still in the early stages of being used in hospitals in countries with less technology. Therefore, there is an inadequate grasp of the evaluation of big data adoption preparedness in the healthcare sector as data-point-determined insights become crucially useful in healthcare institutions in underdeveloped nations. This process, called &ldquo;digital transformation,&rdquo; has a lot of benefits; for example, it helps healthcare organizations to create more efficient processes, offer different services, give better care, make more money, and cut costs. This paper aims to suggest and assess a conceptual framework that focuses on technological factors and can assist in determining the readiness of healthcare institutions in developing nations to utilize big data. Although the study can offer valuable perspectives on the advantages that can arise from adopting big data in the healthcare sector, it is important to highlight that leveraging big data analytics in healthcare has the potential to enhance the efficiency and effectiveness of healthcare services. This, in turn, can indirectly contribute to sustainability objectives by optimizing the allocation of resources, minimizing waste, and improving patient outcomes. A total of 328 healthcare workers from Malaysia were subjected to experimental testing of the model. The collected data were evaluated using the Smart PLS 3 program and the structural equation model (SEM). The study&rsquo;s findings supported our hypotheses. The results showed that technological factors affected the participants&rsquo; perception of their readiness for big data, which ultimately influenced their interest in utilizing it. By concentrating on big data preparedness in the healthcare industry and ambition to utilize big data, this research provides an important theoretical contribution. Employees who are &ldquo;big data ready&rdquo; would benefit from the study&rsquo;s results, as, through their recognition, said employees are more likely to increase the desire to use big data in Malaysia&rsquo;s healthcare sectors.</P>"
        },
        {
          "rank": 38,
          "score": 0.644903838634491,
          "doc_id": "JAKO201713551814199",
          "title": "빅데이터와 U-City 서비스",
          "abstract": "소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201713551814199&target=NART&cn=JAKO201713551814199",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 빅데이터와 U-City 서비스 소셜 네크워크 서비스의 활성화로, 빅데이터가 주목을 받게 된 것은 당연한 귀결이라고 할 수 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 U-City 서비스 유형에 따라 분석하는 것이다. 본 연구 결과, 빅데이터는 외부 정보의 활용보다는 내부 정보의 활용이 근소한 차이로 더 많았다. 또한 구조적 정보의 활용보다는 비구조적 정보의 활용이 더 많았다."
        },
        {
          "rank": 39,
          "score": 0.6443855166435242,
          "doc_id": "JAKO201811041675535",
          "title": "빅데이터 기반 정보 추천 시스템",
          "abstract": "삶의 질의 향상으로 인하여 건강관리는 현대인의 주요 관심 사항이며 자연스럽게 헬스케어 시스템에 대한 요구가 증가하고 있다. 그러나 인터넷 상에는 다양한 의료 관련 정보가 존재할 뿐만 아니라 이 정보들의 신뢰성 또한 가늠하기 힘든 것이 현실이므로, 특정 사용자에게 적합한 맞춤형 웰니스 정보 제공은 어려운 것이 현실이다. 본 연구에서는 빅데이터를 텍스트 마이닝으로 분류하여 사용자 맞춤형 의료정보를 제공함으로서 단순 검색기능이 아닌 사용자에게 적합한 맞춤 서비스를 제공할 수 있는 사용자 중심의 서비스 제공 방법을 제안한다. 효율적인 빅데이터 분석을 위해 하둡 슬레이브 노드를 증가하면서 데이터 처리시간을 실험하였다. 기존 시스템보다 빅데이터 시스템을 구축하는 것이 효율적임을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201811041675535&target=NART&cn=JAKO201811041675535",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 정보 추천 시스템 빅데이터 기반 정보 추천 시스템 빅데이터 기반 정보 추천 시스템 삶의 질의 향상으로 인하여 건강관리는 현대인의 주요 관심 사항이며 자연스럽게 헬스케어 시스템에 대한 요구가 증가하고 있다. 그러나 인터넷 상에는 다양한 의료 관련 정보가 존재할 뿐만 아니라 이 정보들의 신뢰성 또한 가늠하기 힘든 것이 현실이므로, 특정 사용자에게 적합한 맞춤형 웰니스 정보 제공은 어려운 것이 현실이다. 본 연구에서는 빅데이터를 텍스트 마이닝으로 분류하여 사용자 맞춤형 의료정보를 제공함으로서 단순 검색기능이 아닌 사용자에게 적합한 맞춤 서비스를 제공할 수 있는 사용자 중심의 서비스 제공 방법을 제안한다. 효율적인 빅데이터 분석을 위해 하둡 슬레이브 노드를 증가하면서 데이터 처리시간을 실험하였다. 기존 시스템보다 빅데이터 시스템을 구축하는 것이 효율적임을 확인하였다."
        },
        {
          "rank": 40,
          "score": 0.6427904367446899,
          "doc_id": "ATN0037461993",
          "title": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법",
          "abstract": "This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037461993&target=NART&cn=ATN0037461993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis."
        },
        {
          "rank": 41,
          "score": 0.6425292491912842,
          "doc_id": "JAKO201224747154192",
          "title": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법",
          "abstract": "최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201224747154192&target=NART&cn=JAKO201224747154192",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다."
        },
        {
          "rank": 42,
          "score": 0.6415418982505798,
          "doc_id": "ATN0025427128",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025427128&target=NART&cn=ATN0025427128",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice."
        },
        {
          "rank": 43,
          "score": 0.6400023698806763,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 44,
          "score": 0.6397139430046082,
          "doc_id": "DIKO0013392225",
          "title": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구",
          "abstract": "오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013392225&target=NART&cn=DIKO0013392225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다."
        },
        {
          "rank": 45,
          "score": 0.6389670372009277,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 46,
          "score": 0.6371856331825256,
          "doc_id": "ATN0030204222",
          "title": "AHP를 활용한 빅데이터 역량모델 개발 연구",
          "abstract": "Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030204222&target=NART&cn=ATN0030204222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 AHP를 활용한 빅데이터 역량모델 개발 연구 Big Data refers to various types of data that can not be managed by conventional methods and that are generated at a high speed. Big Data is expected to foster new data industries. The Korean government has established a systematic strategy to vitalize the big data industry. The purpose of this study is to develop a Big Data Capability Model that can systematically implement big data strategy and diagnose current big data capability to organizations that want to adopt Big Data. The compability model was constructed through literature research and the importance of competency and item was analyzed through Analytic Hierarchy Process. As the result of analysis, organizational capacity and process for applying Big Data are the most important category. The definition of role, responsibility definition and strategic planning process for data analysis are very important items. This study is expected to serve as a guide to provide priority to companies that are adopting Big Data."
        },
        {
          "rank": 47,
          "score": 0.6369311809539795,
          "doc_id": "JAKO202012758285347",
          "title": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구",
          "abstract": "국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012758285347&target=NART&cn=JAKO202012758285347",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다."
        },
        {
          "rank": 48,
          "score": 0.6369116306304932,
          "doc_id": "JAKO201352057197183",
          "title": "빅데이터 기반 음성언어 처리 기술",
          "abstract": "음성언어 처리 분야는 인간의 자연어 발화를 컴퓨터가 자동으로 이해하고 처리하는 알고리즘을 연구하는 분야로, 자동 통번역, Siri와 같은 음성 대화 시스템, 차세대 인터페이스, 질의 응답 시스템 등 다양한 응용군을 포함한다. 특히, 음성언어 처리 기술은, 최근 빅데이터(big data) 시대를 맞이하여, 방대한 음성/텍스트 정보를 처리하기 위한 필수 기술로 각광받고 있다. 한편, 빅데이터는 그 자체가 거대한 말뭉치 데이터로서 음성언어 처리 기술의 성능을 향상시키는 주된 리소스가 된다. 이에 따라, 최근 빅데이터를 이용하여 음성언어 처리 기술의 성능을 개선시키고자 하는 연구가 활발히 진행되고 있는데, 본고에서는 이들 연구의 배경 및 연구 동향들을 소개하기로 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201352057197183&target=NART&cn=JAKO201352057197183",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 음성언어 처리 기술 빅데이터 기반 음성언어 처리 기술 빅데이터 기반 음성언어 처리 기술 음성언어 처리 분야는 인간의 자연어 발화를 컴퓨터가 자동으로 이해하고 처리하는 알고리즘을 연구하는 분야로, 자동 통번역, Siri와 같은 음성 대화 시스템, 차세대 인터페이스, 질의 응답 시스템 등 다양한 응용군을 포함한다. 특히, 음성언어 처리 기술은, 최근 빅데이터(big data) 시대를 맞이하여, 방대한 음성/텍스트 정보를 처리하기 위한 필수 기술로 각광받고 있다. 한편, 빅데이터는 그 자체가 거대한 말뭉치 데이터로서 음성언어 처리 기술의 성능을 향상시키는 주된 리소스가 된다. 이에 따라, 최근 빅데이터를 이용하여 음성언어 처리 기술의 성능을 개선시키고자 하는 연구가 활발히 진행되고 있는데, 본고에서는 이들 연구의 배경 및 연구 동향들을 소개하기로 한다."
        },
        {
          "rank": 49,
          "score": 0.6365975141525269,
          "doc_id": "JAKO201529539328692",
          "title": "RHadoop을 이용한 빅데이터 분산처리 시스템",
          "abstract": "기하급수적으로 증가하는 대용량 데이터를 저장, 분석하는데 기존 방식으로는 거의 불가능하여 이를 가능케 해 주는 기술이 바로 하둡이다. 최근에 R은 하둡기술을 활용하여 분산처리에 기반한 빅데이터 분석 엔진으로 활용되고 있다. 본 논문에서는 R과 하둡의 통합환경인 RHadoop을 이용하여 실제 데이터와 모의실험 데이터에서 다양한 데이터 크기에 따라 병렬 다중 회귀분석을 구현하고자 한다. 또한, 제안된 RHadoop 플랫폼의 성능을 평가하기 위해 기본 R 패키지의 lm 함수, bigmemory 상에서 유용한 biglm 패키지와 처리 속도를 비교하였다. 실험결과 RHadoop은 데이터 노드가 많을수록 병렬처리로 인해 빠른 처리속도를 보였고 또한 대용량의 데이터에 대해 다른 패키지들보다 빠른 처리속도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201529539328692&target=NART&cn=JAKO201529539328692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RHadoop을 이용한 빅데이터 분산처리 시스템 RHadoop을 이용한 빅데이터 분산처리 시스템 RHadoop을 이용한 빅데이터 분산처리 시스템 기하급수적으로 증가하는 대용량 데이터를 저장, 분석하는데 기존 방식으로는 거의 불가능하여 이를 가능케 해 주는 기술이 바로 하둡이다. 최근에 R은 하둡기술을 활용하여 분산처리에 기반한 빅데이터 분석 엔진으로 활용되고 있다. 본 논문에서는 R과 하둡의 통합환경인 RHadoop을 이용하여 실제 데이터와 모의실험 데이터에서 다양한 데이터 크기에 따라 병렬 다중 회귀분석을 구현하고자 한다. 또한, 제안된 RHadoop 플랫폼의 성능을 평가하기 위해 기본 R 패키지의 lm 함수, bigmemory 상에서 유용한 biglm 패키지와 처리 속도를 비교하였다. 실험결과 RHadoop은 데이터 노드가 많을수록 병렬처리로 인해 빠른 처리속도를 보였고 또한 대용량의 데이터에 대해 다른 패키지들보다 빠른 처리속도를 보였다."
        },
        {
          "rank": 50,
          "score": 0.6364419460296631,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        }
      ]
    },
    {
      "query": "What types of insights or functionalities does large-scale machine learning provide to commercial applications?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6398489475250244,
          "doc_id": "JAKO201536553093556",
          "title": "빅데이터 환경에서 사용자 거래 성향분석을 위한 머신러닝 응용 기법",
          "abstract": "최근 빅데이터 분야에서는 고객의 흥미가 높은 상품이나 과거 구매 내역 등 기존 보유한 데이터를 수집 및 재가공하여 사용자의 거래성향을 분석(상품 추천, 판매 예측 등)하는데 활용하려는 추세이다. 기존 사용자의 성향 관련 연구들은 조사시기와 대상의 범위가 한정적이며 세부 상품에 대한 예측이 어렵고, 실시간성이 없기 때문에 트렌드에 적절한 빠른 판매 전략을 도입하기가 어려운 단점이 존재한다. 본 논문은 기계학습 알고리즘 응용하여 사용자의 거래성향 분석에 활용한다. 기계학습 알고리즘 응용 결과 세부 상품별 추론할 수 있는 다양한 지표를 추출할 수 있음을 증명하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201536553093556&target=NART&cn=JAKO201536553093556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 환경에서 사용자 거래 성향분석을 위한 머신러닝 응용 기법 빅데이터 환경에서 사용자 거래 성향분석을 위한 머신러닝 응용 기법 빅데이터 환경에서 사용자 거래 성향분석을 위한 머신러닝 응용 기법 최근 빅데이터 분야에서는 고객의 흥미가 높은 상품이나 과거 구매 내역 등 기존 보유한 데이터를 수집 및 재가공하여 사용자의 거래성향을 분석(상품 추천, 판매 예측 등)하는데 활용하려는 추세이다. 기존 사용자의 성향 관련 연구들은 조사시기와 대상의 범위가 한정적이며 세부 상품에 대한 예측이 어렵고, 실시간성이 없기 때문에 트렌드에 적절한 빠른 판매 전략을 도입하기가 어려운 단점이 존재한다. 본 논문은 기계학습 알고리즘 응용하여 사용자의 거래성향 분석에 활용한다. 기계학습 알고리즘 응용 결과 세부 상품별 추론할 수 있는 다양한 지표를 추출할 수 있음을 증명하였다."
        },
        {
          "rank": 2,
          "score": 0.6362818479537964,
          "doc_id": "NART118947969",
          "title": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction",
          "abstract": "<P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART118947969&target=NART&cn=NART118947969",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction <P>Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops.</P><P><B>Supplementary Information</B></P><P>The online version contains supplementary material available at 10.1186/s12870-022-03559-z.</P>"
        },
        {
          "rank": 3,
          "score": 0.6360949277877808,
          "doc_id": "JAKO201734158606474",
          "title": "제조업의 심층신경망 기계학습(딥러닝)",
          "abstract": "인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734158606474&target=NART&cn=JAKO201734158606474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다."
        },
        {
          "rank": 4,
          "score": 0.6335394382476807,
          "doc_id": "JAKO201924064455520",
          "title": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용",
          "abstract": "Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201924064455520&target=NART&cn=JAKO201924064455520",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
        },
        {
          "rank": 5,
          "score": 0.6303969025611877,
          "doc_id": "JAKO202302557619339",
          "title": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반",
          "abstract": "최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202302557619339&target=NART&cn=JAKO202302557619339",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다."
        },
        {
          "rank": 6,
          "score": 0.623496413230896,
          "doc_id": "JAKO202307361686821",
          "title": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰",
          "abstract": "Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202307361686821&target=NART&cn=JAKO202307361686821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke."
        },
        {
          "rank": 7,
          "score": 0.621001124382019,
          "doc_id": "DIKO0015372556",
          "title": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용",
          "abstract": "머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015372556&target=NART&cn=DIKO0015372556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 트랜잭션 기반 머신러닝 문제의 자동화된 특성 추출을 위한 딥러닝 활용 머신러닝은 통찰력을 도출하거나 분류 및 예측을 하기 위해, 주어진 데이터를 수학적 모델에 적합시키는 방식으로 정보 기술의 발전과 다양한 스마트 기기의 등장으로 활용 가능한 데이터의 양이 기하급수적으로 증대된 빅데이터 시대에서 편향이 개입되지 않은 패턴 발견으로 높은 예측 성능을 보이고 있다. 이러한 머신러닝 수행 과정에서 해결하고자 하는 문제를 잘 설명할 수 있는 속성을 생성하는 특성공학은 머신러닝 성능에 큰 영향을 미쳐 그 중요성이 지속적으로 강조되어 오고 있다. 하지만, 이러한 중요성에도 불구하고 반복적인 검증 절차와 원천 데이터에 대한 이해 뿐만 아니라 도메인 특성에 대한 깊은 이해를 필요로 함에 따라 여전히 어려운 과업으로 여겨지고 있다. 따라서, 본 연구에서는 이러한 특성공학 과업 중 전문 지식을 요구하며 반복적으로 수행되어야 하는 특성 추출의 복잡성 및 어려움을 해결하고 머신러닝 모델의 성능을 높이기 위한 방법으로 딥러닝 기법의 적용을 제안한다. 다른 머신러닝 기법과 달리 복잡한 비정형 데이터 처리 분야에서 딥러닝 기법이 뛰어난 성능을 보이는 가장 대표적인 이유는 원천 데이터 자체로부터 특성 추출이 가능하다는 점이다. 이러한 딥러닝 기법의 장점을 비즈니스 문제 해결에 적용하기 위하여 본 연구에서는 트랜잭션 데이터로부터 자동적으로 특성을 추출하거나 직접 예측 및 분류가 가능한 딥러닝 기반의 방법들을 제안하고 데이터 특성에 따른 차이를 실험하였다. 특히, 트랜잭션 데이터와 텍스트 데이터의 구조적 유사성에 기반하여 기존의 텍스트 처리에 높은 성능을 보이고 있는 기법을 적용하였으며 트랜잭션 데이터의 특성에 따라 각 방법들의 적합성을 검증하였다. 본 연구를 통해 자동화된 특성추출의 가능성을 탐색할 수 있을 뿐만 아니라 특성 추출 과업 수행 전에 일정 수준 이상의 성능을 보이는 준거 모델의 확보가 가능할 것으로 판단된다. 또한, 해결하고자 하는 비즈니스 문제와 보유하고 있는 데이터 특성에 따라 적합한 딥러닝 모델 선택의 가이드라인을 제시할 수 있으리라 기대된다."
        },
        {
          "rank": 8,
          "score": 0.6176746487617493,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 9,
          "score": 0.6164202690124512,
          "doc_id": "DIKO0017011976",
          "title": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형",
          "abstract": "본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017011976&target=NART&cn=DIKO0017011976",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 대형 언어 모델과 딥러닝을 통합한 리뷰 유용성 예측 모형 본 연구는 온라인 리뷰의 유용성을 예측하기 위한 모델을 제안하며, 이를 위해 대형 언어 모델과 다양한 딥러닝 기법을 통합적으로 활용하였다. 연구의 시작에서는 온라인 리뷰 및 리뷰 유용성에 대한 이론적 배경을 탐구하였으며, 여러 기존 연구들을 통해 리뷰 유용성에 영향을 미치는 요인들을 정리하였다. 특히, 통계기법, 머신러닝, 딥러닝, 그리고 대형 언어 모델을 중심으로 한 기존의 리뷰 유용성 예측 모형들을 비교 및 분석하였다. 이후, KoBERT와 KoGPT2와 같은 한국어 대형 언어 모델을 기반으로 한 리뷰 유용성 예측모형을 구축하였으며, K-NN 알고리즘으로 통합하여 모델의 성능을 향상시켰다. 실증분석 결과, 본 연구에서 제안한 모델은 기존의 모델들에 비해 높은 예측 성능을 보여주었고, 특히 대형 언어 모델의 통합은 리뷰 유용성 예측의 정확도를 크게 향상시켰다. 이러한 결과는 온라인 리뷰의 품질 및 유용성 평가에 큰 도움을 제공할 것으로 기대된다."
        },
        {
          "rank": 10,
          "score": 0.6163629293441772,
          "doc_id": "NART124447608",
          "title": "Lifelong Machine Learning Potentials",
          "abstract": "<P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART124447608&target=NART&cn=NART124447608",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials Lifelong Machine Learning Potentials <P>Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs have been trained from scratch because learning additional data typically requires retraining on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs), which combine structural properties and element information from the periodic table. These eeACSFs are key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pretrained MLP to arrive at a continuously adapting lMLP, because a predefined level of accuracy can be ensured. To extend the applicability of an lMLP to new systems, we apply continual learning strategies to enable autonomous and on-the-fly training on a continuous stream of new data. For the training of deep neural networks, we propose the continual resilient (CoRe) optimizer and incremental learning strategies relying on rehearsal of data, regularization of parameters, and the architecture of the model.</P><BR>[FIG OMISSION]</BR>"
        },
        {
          "rank": 11,
          "score": 0.6154062747955322,
          "doc_id": "JAKO201809863000185",
          "title": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구",
          "abstract": "본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809863000185&target=NART&cn=JAKO201809863000185",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 영상기반의 화재 검출에 효과적인 CNN 심층학습의 커널 특성에 대한 연구 본 논문에서는 보안 감시 카메라 영상을 활용하여 화재 검출을 위한 효과적인 심층학습 방안을 제안한다. AlexNet 모델을 기준으로 효과적인 화재 검출을 위한 커널 크기와 커널 이동 간격의 변화에 따른 분류 성능을 비교 분석한다. 학습을 위한 데이터셋은 정상과 화재 2가지 클래스로 분류한다, 정상 영상에는 구름과 안개 낀 영상을 포함하고, 화재 영상에는 연기와 화염을 각각 포함한다. AlexNet 모델의 첫 번째 계층의 커널 크기와 이동 간격에 따른 분류 성능 분석 결과 커널의 크기는 크고, 이동 간격은 작을수록 화재 분류 성능이 우수한 것을 확인할 수 있다."
        },
        {
          "rank": 12,
          "score": 0.6153166890144348,
          "doc_id": "ATN0038661375",
          "title": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험",
          "abstract": "Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038661375&target=NART&cn=ATN0038661375",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 단백질 기능 예측 모델의 주요 딥러닝 모델 비교 실험 Proteins are the basic unit of all life activities, and understanding them is essential for studying life phenomena. Since the emergenceof the machine learning methodology using artificial neural networks, many researchers have tried to predict the function of proteinsusing only protein sequences. Many combinations of deep learning models have been reported to academia, but the methods are differentand there is no formal methodology, and they are tailored to different data, so there has never been a direct comparative analysis ofwhich algorithms are more suitable for handling protein data. In this paper, the single model performance of each algorithm was comparedand evaluated based on accuracy and speed by applying the same data to CNN, LSTM, and GRU models, which are the most frequentlyused representative algorithms in the convergence research field of predicting protein functions, and the final evaluation scale is presentedas Micro Precision, Recall, and F1-score. The combined models CNN-LSTM and CNN-GRU models also were evaluated in the same way.Through this study, it was confirmed that the performance of LSTM as a single model is good in simple classification problems, overlappingCNN was suitable as a single model in complex classification problems, and the CNN-LSTM was relatively better as a combination model."
        },
        {
          "rank": 13,
          "score": 0.6131747364997864,
          "doc_id": "JAKO201962652079504",
          "title": "심층 강화학습 기술 동향",
          "abstract": "Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201962652079504&target=NART&cn=JAKO201962652079504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습 기술 동향 심층 강화학습 기술 동향 심층 강화학습 기술 동향 Recent trends in deep reinforcement learning (DRL) have revealed the considerable improvements to DRL algorithms in terms of performance, learning stability, and computational efficiency. DRL also enables the scenarios that it covers (e.g., partial observability; cooperation, competition, coexistence, and communications among multiple agents; multi-task; decentralized intelligence) to be vastly expanded. These features have cultivated multi-agent reinforcement learning research. DRL is also expanding its applications from robotics to natural language processing and computer vision into a wide array of fields such as finance, healthcare, chemistry, and even art. In this report, we briefly summarize various DRL techniques and research directions."
        },
        {
          "rank": 14,
          "score": 0.6123328804969788,
          "doc_id": "NART113689464",
          "title": "Predicting Big Data Adoption in Companies With an Explanatory and Predictive Model",
          "abstract": "<P>The purpose of this paper is to identify the factors that affect the intention to use Big Data Applications in companies. Research into Big Data usage intention and adoption is scarce and much less from the perspective of the use of these techniques in companies. That is why this research focuses on analyzing the adoption of Big Data Applications by companies. Further to a review of the literature, it is proposed to use a UTAUT model as a starting model with the update and incorporation of other variables such as resistance to use and perceived risk, and then to perform a neural network to predict this adoption. With respect to this non-parametric technique, we found that the multilayer perceptron model (MLP) for the use of Big Data Applications in companies obtains higher AUC values, and a better confusion matrix. This paper is a pioneering study using this hybrid methodology on the intention to use Big Data Applications. The result of this research has important implications for the theory and practice of adopting Big Data Applications.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART113689464&target=NART&cn=NART113689464",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Predicting Big Data Adoption in Companies With an Explanatory and Predictive Model Predicting Big Data Adoption in Companies With an Explanatory and Predictive Model Predicting Big Data Adoption in Companies With an Explanatory and Predictive Model <P>The purpose of this paper is to identify the factors that affect the intention to use Big Data Applications in companies. Research into Big Data usage intention and adoption is scarce and much less from the perspective of the use of these techniques in companies. That is why this research focuses on analyzing the adoption of Big Data Applications by companies. Further to a review of the literature, it is proposed to use a UTAUT model as a starting model with the update and incorporation of other variables such as resistance to use and perceived risk, and then to perform a neural network to predict this adoption. With respect to this non-parametric technique, we found that the multilayer perceptron model (MLP) for the use of Big Data Applications in companies obtains higher AUC values, and a better confusion matrix. This paper is a pioneering study using this hybrid methodology on the intention to use Big Data Applications. The result of this research has important implications for the theory and practice of adopting Big Data Applications.</P>"
        },
        {
          "rank": 15,
          "score": 0.6108101606369019,
          "doc_id": "JAKO201452057196583",
          "title": "빅데이터 지식처리 인공지능 기술동향",
          "abstract": "최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201452057196583&target=NART&cn=JAKO201452057196583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다."
        },
        {
          "rank": 16,
          "score": 0.6096789836883545,
          "doc_id": "JAKO202131559470407",
          "title": "빅데이터를 활용한 인공지능 주식 예측 분석",
          "abstract": "저금리 시대의 도래로 인해 많은 투자자들이 주식 시장으로 몰리고 있다. 과거의 주식 시장은 사람들이 기업 분석 및 각자의 투자기법을 통해 노동 집약적으로 주식 투자가 이루어졌다면 최근 들어 인공지능 및 데이터를 활용하여 주식 투자가 널리 이용되고 있는 실정이다. 인공지능을 통해 주식 예측의 성공률은 현재 높지 않아 다양한 인공지능 모델을 통해 주식 예측률을 높이는 시도를 하고 있다. 본 연구에서는 다양한 인공지능 모델에 대해 살펴보고 각 모델들간의 장단점 및 예측률을 파악하고자 한다. 이를 위해, 본 연구에서는 주식예측 인공지능 프로그램으로 인공신경망(ANN), 심층 학습 또는 딥 러닝(DNN), k-최근접 이웃 알고리즘(k-NN), 합성곱 신경망(CNN), 순환 신경망(RNN), LSTM에 대해 살펴보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202131559470407&target=NART&cn=JAKO202131559470407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 인공지능 주식 예측 분석 빅데이터를 활용한 인공지능 주식 예측 분석 빅데이터를 활용한 인공지능 주식 예측 분석 저금리 시대의 도래로 인해 많은 투자자들이 주식 시장으로 몰리고 있다. 과거의 주식 시장은 사람들이 기업 분석 및 각자의 투자기법을 통해 노동 집약적으로 주식 투자가 이루어졌다면 최근 들어 인공지능 및 데이터를 활용하여 주식 투자가 널리 이용되고 있는 실정이다. 인공지능을 통해 주식 예측의 성공률은 현재 높지 않아 다양한 인공지능 모델을 통해 주식 예측률을 높이는 시도를 하고 있다. 본 연구에서는 다양한 인공지능 모델에 대해 살펴보고 각 모델들간의 장단점 및 예측률을 파악하고자 한다. 이를 위해, 본 연구에서는 주식예측 인공지능 프로그램으로 인공신경망(ANN), 심층 학습 또는 딥 러닝(DNN), k-최근접 이웃 알고리즘(k-NN), 합성곱 신경망(CNN), 순환 신경망(RNN), LSTM에 대해 살펴보고자 한다."
        },
        {
          "rank": 17,
          "score": 0.6066035628318787,
          "doc_id": "NPAP12884204",
          "title": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches",
          "abstract": "<P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12884204&target=NART&cn=NPAP12884204",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches A Review on Big Data Analytics in Healthcare Using Machine Learning Approaches <P>The rapid expansion of the business intelligence and analytics process has emphasized the importance of how knowledge is aquire and helps to make appropriate decision. The big data in area of healthcare open up new ways for analyze and aquire intelligence from big data. The conventional approaches for management of health data have archive limited success. The traditional approaches are incapable of management and process on big data because of its different characteristics. Following paper shows various techniques for process the big data as machine learning and statistics approaches. Also the paper shows the various tools for storing the big data and its advantages as well as disadvantages for health care big data.</P>"
        },
        {
          "rank": 18,
          "score": 0.6063985228538513,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 19,
          "score": 0.6063397526741028,
          "doc_id": "NART99478101",
          "title": "Building thermal load prediction through shallow machine learning and deep learning",
          "abstract": "<P><B>Abstract</B></P>  <P>Building thermal load prediction informs the optimization of cooling plant and thermal energy storage. Physics-based prediction models of building thermal load are constrained by the model and input complexity. In this study, we developed 12 data-driven models (7 shallow learning, 2 deep learning, and 3 heuristic methods) to predict building thermal load and compared shallow machine learning and deep learning. The 12 prediction models were compared with the measured cooling demand. It was found XGBoost (Extreme Gradient Boost) and LSTM (Long Short Term Memory) provided the most accurate load prediction in the shallow and deep learning category, and both outperformed the best baseline model, which uses the previous day&rsquo;s data for prediction. Then, we discussed how the prediction horizon and input uncertainty would influence the load prediction accuracy. Major conclusions are twofold: first, LSTM performs well in short-term prediction (1 h ahead) but not in long term prediction (24 h ahead), because the sequential information becomes less relevant and accordingly not so useful when the prediction horizon is long. Second, the presence of weather forecast uncertainty deteriorates XGBoost&rsquo;s accuracy and favors LSTM, because the sequential information makes the model more robust to input uncertainty. Training the model with the uncertain rather than accurate weather data could enhance the model&rsquo;s robustness. Our findings have two implications for practice. First, LSTM is recommended for short-term load prediction given that weather forecast uncertainty is unavoidable. Second, XGBoost is recommended for long term prediction, and the model should be trained with the presence of input uncertainty.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Building load prediction informs chiller plant and thermal storage optimization. </LI> <LI>  We used and compared 9 machine learning algorithms and 3 heuristic prediction methods. </LI> <LI>  XGBoost and LSTM are found to be the best shallow and deep learning algorithm. </LI> <LI>  LSTM is better for short term prediction, while XGBoost for long term prediction. </LI> <LI>  It is better to train the model with uncertain rather than accurate weather data. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99478101&target=NART&cn=NART99478101",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Building thermal load prediction through shallow machine learning and deep learning Building thermal load prediction through shallow machine learning and deep learning Building thermal load prediction through shallow machine learning and deep learning <P><B>Abstract</B></P>  <P>Building thermal load prediction informs the optimization of cooling plant and thermal energy storage. Physics-based prediction models of building thermal load are constrained by the model and input complexity. In this study, we developed 12 data-driven models (7 shallow learning, 2 deep learning, and 3 heuristic methods) to predict building thermal load and compared shallow machine learning and deep learning. The 12 prediction models were compared with the measured cooling demand. It was found XGBoost (Extreme Gradient Boost) and LSTM (Long Short Term Memory) provided the most accurate load prediction in the shallow and deep learning category, and both outperformed the best baseline model, which uses the previous day&rsquo;s data for prediction. Then, we discussed how the prediction horizon and input uncertainty would influence the load prediction accuracy. Major conclusions are twofold: first, LSTM performs well in short-term prediction (1 h ahead) but not in long term prediction (24 h ahead), because the sequential information becomes less relevant and accordingly not so useful when the prediction horizon is long. Second, the presence of weather forecast uncertainty deteriorates XGBoost&rsquo;s accuracy and favors LSTM, because the sequential information makes the model more robust to input uncertainty. Training the model with the uncertain rather than accurate weather data could enhance the model&rsquo;s robustness. Our findings have two implications for practice. First, LSTM is recommended for short-term load prediction given that weather forecast uncertainty is unavoidable. Second, XGBoost is recommended for long term prediction, and the model should be trained with the presence of input uncertainty.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Building load prediction informs chiller plant and thermal storage optimization. </LI> <LI>  We used and compared 9 machine learning algorithms and 3 heuristic prediction methods. </LI> <LI>  XGBoost and LSTM are found to be the best shallow and deep learning algorithm. </LI> <LI>  LSTM is better for short term prediction, while XGBoost for long term prediction. </LI> <LI>  It is better to train the model with uncertain rather than accurate weather data. </LI> </UL> </P>"
        },
        {
          "rank": 20,
          "score": 0.6049297451972961,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 21,
          "score": 0.6047788858413696,
          "doc_id": "JAKO201909358629304",
          "title": "머신러닝을 이용한 관중 수요 예측에 관한 연구",
          "abstract": "특정한 이벤트나 콘텐츠를 즐기기 위해 모인 사람들을 관중 또는 관객이라고 하고, 모임의 특성에 따라 다양한 성향을 나타낸다. 그러한 차이점은 있지만, 일반적으로 관중 수는 경영적인 측면과 직결되는 요소로써, 관람료부터 다른 시설의 이용료 등 다양한 수입을 통해 콘텐츠 판매를 위한 안정적인 재정 운영을 가능케 한다. 따라서 관중 수에 대한 예측은 마케팅과 예산 전략 수립에 주요한 요소로 활용될 수 있다. 본 연구에서는 관중 수에 대한 예측을 위한 여러 가지 기존 모델을 검토하고, 그 중에서 효율적인 머신러닝 모델을 제안하고자 한다. 또한 딥러닝과 랜덤포레스트 모델을 혼용하여 일별 관중 수 예측과 비정상적 관중 수 예측에 대한 연구를 진행하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629304&target=NART&cn=JAKO201909358629304",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝을 이용한 관중 수요 예측에 관한 연구 머신러닝을 이용한 관중 수요 예측에 관한 연구 머신러닝을 이용한 관중 수요 예측에 관한 연구 특정한 이벤트나 콘텐츠를 즐기기 위해 모인 사람들을 관중 또는 관객이라고 하고, 모임의 특성에 따라 다양한 성향을 나타낸다. 그러한 차이점은 있지만, 일반적으로 관중 수는 경영적인 측면과 직결되는 요소로써, 관람료부터 다른 시설의 이용료 등 다양한 수입을 통해 콘텐츠 판매를 위한 안정적인 재정 운영을 가능케 한다. 따라서 관중 수에 대한 예측은 마케팅과 예산 전략 수립에 주요한 요소로 활용될 수 있다. 본 연구에서는 관중 수에 대한 예측을 위한 여러 가지 기존 모델을 검토하고, 그 중에서 효율적인 머신러닝 모델을 제안하고자 한다. 또한 딥러닝과 랜덤포레스트 모델을 혼용하여 일별 관중 수 예측과 비정상적 관중 수 예측에 대한 연구를 진행하였다."
        },
        {
          "rank": 22,
          "score": 0.6035778522491455,
          "doc_id": "JAKO202433861648179",
          "title": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교",
          "abstract": "본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202433861648179&target=NART&cn=JAKO202433861648179",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 스켈레톤 데이터에 기반한 동작 분류: 고전적인 머신러닝과 딥러닝 모델 성능 비교 본 연구는 3D 스켈레톤 데이터를 활용하여 머신러닝 및 딥러닝 모델을 통해 동작 인식을 수행하고, 모델 간 분류 성능 차이를 비교 분석하였다. 데이터는 NTU RGB+D 데이터의 정면 촬영 데이터로 40명의 참가자가 수행한 60가지 동작을 분류하였다. 머신러닝 모델로는 선형판별분석(LDA), 다중 클래스 서포트 벡터 머신(SVM), 그리고 랜덤 포레스트(RF)가 있으며, 딥러닝 모델로는 RNN 기반의 HBRNN (hierarchical bidirectional RNN) 모델과 GCN 기반의 SGN (semantics-guided neural network) 모델을 적용하였다. 각 모델의 분류 성능을 평가하기 위해 40명의 참가자별로 교차 검증을 실시하였다. 분석 결과, 모델 간 성능 차이는 동작 유형에 크게 영향을 받았으며, 군집 분석을 통해 각 동작에 대한 분류 성능을 살펴본 결과, 인식이 비교적 쉬운 큰 동작에서는 머신러닝 모델과 딥러닝 모델 간의 성능 차이가 유의미하지 않았고, 비슷한 성능을 나타냈다. 반면, 손뼉치기나 손을 비비는 동작처럼 정면 촬영된 관절 좌표만으로 구별하기 어려운 동작의 경우, 딥러닝 모델이 머신러닝 모델보다 관절의 미세한 움직임을 인식하는 데 더 우수한 성능을 보였다."
        },
        {
          "rank": 23,
          "score": 0.6032172441482544,
          "doc_id": "JAKO202431343310039",
          "title": "의료영상에서 생성형 인공지능과 대형 언어 모델 입문",
          "abstract": "최근 ChatGPT를 포함한 대형 언어 모델의 출현으로 생성형 인공지능은 다양한 분야에 관심을 끌고 있다. 생성형 인공지능은 학습 방법과 데이터에 따라 텍스트, 이미지, 음성 등 다양한 형태의 데이터를 생성할 수 있다. 이에 더해 최근 텍스트와 이미지 등 여러 종류의 데이터를 동시에 처리할 수 있는 기술의 발달로, 다양한 임상정보와 영상정보를 함께 활용해야 하는 의료 환경에서 이러한 멀티모달 생성형 인공지능의 활용 가능성이 높아지고 있다. 본 종설에서는 대형 언어 모델, 이미지 생성 모델, 멀티모달 인공지능에 대한 개념과 종류 등에 대해 알아보고, 연구 사례를 통해 영상의학 분야에서 생성형 인공지능의 활용과 향후 가능성을 알아보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202431343310039&target=NART&cn=JAKO202431343310039",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료영상에서 생성형 인공지능과 대형 언어 모델 입문 의료영상에서 생성형 인공지능과 대형 언어 모델 입문 의료영상에서 생성형 인공지능과 대형 언어 모델 입문 최근 ChatGPT를 포함한 대형 언어 모델의 출현으로 생성형 인공지능은 다양한 분야에 관심을 끌고 있다. 생성형 인공지능은 학습 방법과 데이터에 따라 텍스트, 이미지, 음성 등 다양한 형태의 데이터를 생성할 수 있다. 이에 더해 최근 텍스트와 이미지 등 여러 종류의 데이터를 동시에 처리할 수 있는 기술의 발달로, 다양한 임상정보와 영상정보를 함께 활용해야 하는 의료 환경에서 이러한 멀티모달 생성형 인공지능의 활용 가능성이 높아지고 있다. 본 종설에서는 대형 언어 모델, 이미지 생성 모델, 멀티모달 인공지능에 대한 개념과 종류 등에 대해 알아보고, 연구 사례를 통해 영상의학 분야에서 생성형 인공지능의 활용과 향후 가능성을 알아보고자 한다."
        },
        {
          "rank": 24,
          "score": 0.6009418368339539,
          "doc_id": "NART106279808",
          "title": "Machine learning for site-adaptation and solar radiation forecasting",
          "abstract": "<P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART106279808&target=NART&cn=NART106279808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting Machine learning for site-adaptation and solar radiation forecasting <P><B>Abstract</B></P>  <P>Optimal management for solar energy systems requires quality data to build accurate models for predicting the behavior of solar radiation. Solar irradiance and environmental data are provided by satellite and in-situ measurements. It is usual that satellite measurements present high temporal resolution with limited spatial resolution, and in-situ measurements provide high accuracy but significant missing data. This paper proposes a methodology based on machine learning algorithms that: <I>i)</I> takes the best of both data sources to obtain an improved spatio-temporal resolution, known as site-adaptation; and <I>ii)</I> provides highly accurate forecasting solar-radiation models based on deep learning on the improved data. Through a study case with real data, we show the benefits of using the proposed methodology based on machine and deep learning techniques to integrate data from different sources and to construct precise solar radiation forecasting models in regions where solar energy systems are required. Results show that machine learning models for site-adaptation performed up to 38% better than traditional methods.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Site-adaptation models of solar radiation with machine learning. </LI> <LI>  Machine learning and deep learning for solar radiation forecasting. </LI> <LI>  Improvement of satellite data and ground data. </LI> <LI>  Improvement of spatial-temporal resolution of a database. </LI> </UL> </P>"
        },
        {
          "rank": 25,
          "score": 0.5975062251091003,
          "doc_id": "NPAP13226818",
          "title": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset",
          "abstract": "<P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP13226818&target=NART&cn=NPAP13226818",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset <P>Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round -13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm &#x201C;Multinomial Naive Bayes&#x201D; and deep learning algorithm &#x201C;convolution Long Short Term Memory&#x0027;&#x201D; (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems.</P>"
        },
        {
          "rank": 26,
          "score": 0.5969405174255371,
          "doc_id": "ATN0045840152",
          "title": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구",
          "abstract": "현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0045840152&target=NART&cn=ATN0045840152",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 시계열 이미지 데이터 기반 상품추천을 위한 CNN 모델 성능 비교 연구 현대 사회에서는 정보 기술의 발전으로 인해 전자상거래가 확대되어 소비자가 선호하는 상품과 서비스를 넘쳐나는 정보와 데이터를 효율적으로 취합하여 보여주는 자동 추천 시스템이 중요해졌다. 기존 전자상거래에서 상품추천의 정확성을 높이기 위해서 다양한 기법들이 사용되고 있다. 그 중 다중분류 기반의 상품추천 모델인 RNN을 사용하는 모델에는 고질적인 문제점이 존재한다. RNN은 시계열 분류 태스크에 적합한 딥러닝 모델이지만 기울기 소실 또는 기울기 폭주와 같은 이슈가 발생한다. 이와 같은 이슈를 보완하기 위해 커널(Kernel)을 통해 지역적 패턴을 효과적으로 감지하는 CNN 모델을 사용하기도 한다. 본 연구에서는 시계열 데이터를 GAF, MTF, RP 세 가지의 이미지화 인코딩을 통해 CNN 모델에 학습하여 상품추천 모델을 생성하는 아키텍쳐를 기반으로 추천 모델의 성능을 비교한다. 실험에서는 54만 건의 공개된 트랜잭션 데이터셋을 훈련용과 테스트용으로 분할한다. 분할된 데이터를 시계열 데이터로 구성하고 모델의 입력 이미지의 크기와 동일하게 구성하기 위해 제로패딩을 거친다. 세 가지 이미지화 알고리즘을 통해 생성된 이미지를 AlexNet, VGG16, ResNet50 그리고 MobileNet 모델을 학습시켜 상품추천 정확도를 기존 RNN 추천 모델의 성능과 비교한다. CNN 모델들은 LSTM보다 성능을 향상된 것을 확인할 수 있다. GAF 알고리즘으로 이미지화하고 MobileNet 모델에 학습했을 때 가장 높은 추천 정확도를 도출하였으며 학습 소요 시간도 단축하여 효율성을 향상되었다. 향후 연구로는 상품추천 모델의 성능 향상을 위한 이미지화 알고리즘의 고도화와 시계열 이미지 데이터에 최적화된 CNN 모델 개발을 수행한다."
        },
        {
          "rank": 27,
          "score": 0.5966722369194031,
          "doc_id": "JAKO201909358629507",
          "title": "Lifelong Machine Learning 기반 스팸 메시지 필터링 방법",
          "abstract": "인터넷의 급속한 성장으로 데이터의 송수신의 편리성과 비용이 들지 않는다는 장점 때문에 매일 수백만 건의 무차별적인 광고성 스팸 문자와 메일이 발송되고 있다. 아직은 스팸 단어나 스팸 번호를 차단하는 방법을 주로 사용하지만, 기계 학습이 떠오름에 따라 스팸을 필터링하는 방법에 대해 다양한 방식으로 활발히 연구되고 있다. 그러나 스팸에서만 등장하는 단어나 패턴은 스팸 필터링 시스템에 의해 걸러지지 않기 위해 지속적으로 변화하고 있기 때문에, 기존 기계 학습 메커니즘으로는 새로운 단어와 패턴을 감지, 적응할 수 없다. 최근 이러한 기존 기계 학습의 한계점을 극복하기 위해 기존의 지식을 활용하여 새로운 지식을 지속적으로 학습하도록 하는 Lifelong Learning(이하 LL)의 개념이 대두되었다. 본 논문에서는 문서 분류에 가장 많이 사용되는 나이브 베이즈와 Lifelong Machine Learning(이하 LLML)의 앙상블 기법을 이용한 스팸 메시지 필터링 방법을 제안한다. 우리는 기존 스팸 필터링 시스템에 가장 많이 사용되는 나이브 베이즈와, LLML 모델 중 ELLA를 적용하여 LL의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629507&target=NART&cn=JAKO201909358629507",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Lifelong Machine Learning 기반 스팸 메시지 필터링 방법 Lifelong Machine Learning 기반 스팸 메시지 필터링 방법 Lifelong Machine Learning 기반 스팸 메시지 필터링 방법 인터넷의 급속한 성장으로 데이터의 송수신의 편리성과 비용이 들지 않는다는 장점 때문에 매일 수백만 건의 무차별적인 광고성 스팸 문자와 메일이 발송되고 있다. 아직은 스팸 단어나 스팸 번호를 차단하는 방법을 주로 사용하지만, 기계 학습이 떠오름에 따라 스팸을 필터링하는 방법에 대해 다양한 방식으로 활발히 연구되고 있다. 그러나 스팸에서만 등장하는 단어나 패턴은 스팸 필터링 시스템에 의해 걸러지지 않기 위해 지속적으로 변화하고 있기 때문에, 기존 기계 학습 메커니즘으로는 새로운 단어와 패턴을 감지, 적응할 수 없다. 최근 이러한 기존 기계 학습의 한계점을 극복하기 위해 기존의 지식을 활용하여 새로운 지식을 지속적으로 학습하도록 하는 Lifelong Learning(이하 LL)의 개념이 대두되었다. 본 논문에서는 문서 분류에 가장 많이 사용되는 나이브 베이즈와 Lifelong Machine Learning(이하 LLML)의 앙상블 기법을 이용한 스팸 메시지 필터링 방법을 제안한다. 우리는 기존 스팸 필터링 시스템에 가장 많이 사용되는 나이브 베이즈와, LLML 모델 중 ELLA를 적용하여 LL의 성능을 검증한다."
        },
        {
          "rank": 28,
          "score": 0.5966370105743408,
          "doc_id": "NART06057124",
          "title": "Integration of Machine Learning and Knowledge Acquisition",
          "abstract": "<P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06057124&target=NART&cn=NART06057124",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition <P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>"
        },
        {
          "rank": 29,
          "score": 0.5956887602806091,
          "doc_id": "ATN0027106087",
          "title": "기계학습 방법을 이용한 기업부도의 예측",
          "abstract": "The analysis and management of business failure has been recognized to be important in the area of financial management in the evaluation of firms’ performance and the assessment of their viability. To this end, effective failure-prediction models are needed. This paper describes a new approach to prediction of business failure using the total margin algorithm which is a kind of support vector machine. It will be shown that the proposed method can evaluate the risk of failure better than existing methods through some real data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0027106087&target=NART&cn=ATN0027106087",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습 방법을 이용한 기업부도의 예측 기계학습 방법을 이용한 기업부도의 예측 기계학습 방법을 이용한 기업부도의 예측 The analysis and management of business failure has been recognized to be important in the area of financial management in the evaluation of firms’ performance and the assessment of their viability. To this end, effective failure-prediction models are needed. This paper describes a new approach to prediction of business failure using the total margin algorithm which is a kind of support vector machine. It will be shown that the proposed method can evaluate the risk of failure better than existing methods through some real data."
        },
        {
          "rank": 30,
          "score": 0.5955955982208252,
          "doc_id": "ATN0030112964",
          "title": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석",
          "abstract": "Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030112964&target=NART&cn=ATN0030112964",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 구성 요소들로 본 빅데이터 비즈니스 모델의 특성: 한미 화장품 빅데이터 비즈니스 사례 비교 분석 Big data revolution has changed the management of business as well as the model ofbusiness. The new business model driven by big data characterizes the differences in its value creationand profit realization, compared to traditional business models. This study analyzes Koreaand US cosmetic big data business case to extract the components of big data business modelwhich are discussed in previous literature. As a result, these cases validate the three key constructsof big data business model; data, platform, customer experience. Especially, data plays asignificant role in value creation as well as profit realization. Interestingly enough, US case whichhas a clear profit realization method directly related to big data analysis delivers a moe concretepersonalized customer experience to users."
        },
        {
          "rank": 31,
          "score": 0.5952695608139038,
          "doc_id": "JAKO202130053169360",
          "title": "비정형, 정형 데이터의 이미지 학습을 활용한 시장예측",
          "abstract": "금융 시계열 분석은 현대 사회의 경제적, 사회적으로 매우 중요한 역할을 하며 세계 발전에 영향을 미치는 중요한 과제지만 많은 잡음(noise)과 불확실성 등의 어려움으로 인해 금융 시계열 분석 예측은 어려운 연구 주제이다. 본 논문에서는 비정형 데이터와 정형 데이터를 함께 이미지로 변환하여 시장을 예측 하는 방법(MPIL)을 제안한다. 시장 예측을 위해 n일 기간의 비정형 데이터인 SNS, 뉴스 데이터를 감정분석하고 정형 데이터인 시장 데이터를 GADF 알고리즘으로 이미지 변환하고 이미지 학습을 통해 n+1일의 가격을 예측하는 초단기 시장을 예측한다. MPIL은 평균 정확도 56%로 기존 시장예측에 사용되던 감정분석을 활용하여 LSTM으로 시장을 예측하는 모델 평균 정확도 50%보다 높은 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202130053169360&target=NART&cn=JAKO202130053169360",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비정형, 정형 데이터의 이미지 학습을 활용한 시장예측 비정형, 정형 데이터의 이미지 학습을 활용한 시장예측 비정형, 정형 데이터의 이미지 학습을 활용한 시장예측 금융 시계열 분석은 현대 사회의 경제적, 사회적으로 매우 중요한 역할을 하며 세계 발전에 영향을 미치는 중요한 과제지만 많은 잡음(noise)과 불확실성 등의 어려움으로 인해 금융 시계열 분석 예측은 어려운 연구 주제이다. 본 논문에서는 비정형 데이터와 정형 데이터를 함께 이미지로 변환하여 시장을 예측 하는 방법(MPIL)을 제안한다. 시장 예측을 위해 n일 기간의 비정형 데이터인 SNS, 뉴스 데이터를 감정분석하고 정형 데이터인 시장 데이터를 GADF 알고리즘으로 이미지 변환하고 이미지 학습을 통해 n+1일의 가격을 예측하는 초단기 시장을 예측한다. MPIL은 평균 정확도 56%로 기존 시장예측에 사용되던 감정분석을 활용하여 LSTM으로 시장을 예측하는 모델 평균 정확도 50%보다 높은 정확도를 보였다."
        },
        {
          "rank": 32,
          "score": 0.5948418378829956,
          "doc_id": "JAKO201909358629867",
          "title": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석",
          "abstract": "인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629867&target=NART&cn=JAKO201909358629867",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 CNN-LSTM 조합모델을 이용한 영화리뷰 감성분석 인터넷 기술과 소셜 미디어의 빠른 성장으로 인하여, 구조화되지 않은 문서 표현도 다양한 응용 프로그램에 사용할 수 있게 마이닝 기술이 발전되었다. 그 중 감성분석은 제품이나 서비스에 내재된 사용자의 감성을 탐지할 수 있는 분석방법이기 때문에 지난 몇 년 동안 많은 관심을 받아왔다. 감성분석에서는 주로 텍스트 데이터를 이용하여 사람들의 감성을 사전 정의된 긍정 및 부정의 범주를 할당하여 분석하며, 이때 사전 정의된 레이블을 이용하기 때문에 다양한 방향으로 연구가 진행되고 있다. 초기의 감성분석 연구에서는 쇼핑몰 상품의 리뷰 중심으로 진행되었지만, 최근에는 블로그, 뉴스기사, 날씨 예보, 영화 리뷰, SNS, 주식시장의 동향 등 다양한 분야에 적용되고 있다. 많은 선행연구들이 진행되어 왔으나 대부분 전통적인 단일 기계학습기법에 의존한 감성분류를 시도하였기에 분류 정확도 면에서 한계점이 있었다. 본 연구에서는 전통적인 기계학습기법 대신 대용량 데이터의 처리에 우수한 성능을 보이는 딥러닝 기법과 딥러닝 중 CNN과 LSTM의 조합모델을 이용하여 감성분석의 분류 정확도를 개선하고자 한다. 본 연구에서는 대표적인 영화 리뷰 데이터셋인 IMDB의 리뷰 데이터 셋을 이용하여, 감성분석의 극성분석을 긍정 및 부정으로 범주를 분류하고, 딥러닝과 제안하는 조합모델을 활용하여 극성분석의 예측 정확도를 개선하는 것을 목적으로 한다. 이 과정에서 여러 매개 변수가 존재하기 때문에 그 수치와 정밀도의 관계에 대해 고찰하여 최적의 조합을 찾아 정확도 등 감성분석의 성능 개선을 시도한다. 연구 결과, 딥러닝 기반의 분류 모형이 좋은 분류성과를 보였으며, 특히 본 연구에서 제안하는 CNN-LSTM 조합모델의 성과가 가장 우수한 것으로 나타났다."
        },
        {
          "rank": 33,
          "score": 0.5934209823608398,
          "doc_id": "ART002885478",
          "title": "Detection of fake news using deep learning CNN–RNN based methods",
          "abstract": "Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002885478&target=NART&cn=ART002885478",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Detection of fake news using deep learning CNN–RNN based methods Detection of fake news using deep learning CNN–RNN based methods Detection of fake news using deep learning CNN–RNN based methods Fake news is inaccurate information that is intentionally disseminated for a specific purpose. If allowed to spread, fake news can harm the political and social spheres, so several studies are conducted to detect fake news. This study uses a deep learning method with several architectures such as CNN, Bidirectional LSTM, and ResNet, combined with pre-trained word embedding, trained using four different datasets. Each data goes through a data augmentation process using the back-translation method to reduce data imbalances between classes. The results showed that the Bidirectional LSTM architecture outperformed CNN and ResNet on all tested datasets."
        },
        {
          "rank": 34,
          "score": 0.5927512645721436,
          "doc_id": "JAKO202128557368138",
          "title": "인공지능을 활용한 기계학습 앙상블 모델 개발",
          "abstract": "To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128557368138&target=NART&cn=JAKO202128557368138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database."
        },
        {
          "rank": 35,
          "score": 0.5924022793769836,
          "doc_id": "JAKO202123557618560",
          "title": "공공연구성과 실용화를 위한 데이터 기반의 기술 포트폴리오 분석: 빅데이터 및 인공지능 분야를 중심으로",
          "abstract": "빅데이터 및 인공지능 기술은 4차 산업혁명에 핵심적인 기술이나, 국내 중소&#x00B7;중견 기업의 빅데이터 분석 활용과 복합 인공지능 분야의 기술경쟁력 확보가 미흡한 상황이다. 따라서 빅데이터 및 인공지능 분야의 기술사업화를 통해 산업군 전반의 경쟁력을 강화하는 것이 중요하다. 본 연구에서는 기술 포트폴리오 분석을 통해 공공연구성과 실용화 우선순위를 평가하고자 한다. 우선 공공연구성과 정보에 대해 앙상블 기법을 적용한 딥러닝 모델을 사용하여 과제의 6T 분류 결측값을 개선하였다. 이후 6T 분야별 빅데이터 및 인공지능융합 분야를 대상으로 토픽 모델링을 진행하여 10개의 세부기술분야를 도출하였다. 세부기술분야별 기술사업화 가능성을 판단하기 위해 기술활동성과 기술효율성을 새롭게 정의하고 측정하였다. 두 축을 기반으로 포트폴리오를 4가지의 유형으로 구분하여 기술사업화 최우선 고려 대상, 장기 투자가 필요한 기술분야 등을 제안하였다. '영상 및 이미지 기반의 진단 기술'은 기술활동성 및 기술효율성이 높아 시장의 수요와 사업화 역량 모두 이상적인 수준으로 나타났다. 이처럼 체계적인 산업&#x00B7;기술시장 분석을 통해 공공연구성과 창출 기술의 활용을 활성화할 수 있으며 중소&#x00B7;중견으로의 효율적인 기술 이전 및 사업화 추진이 가능하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202123557618560&target=NART&cn=JAKO202123557618560",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공공연구성과 실용화를 위한 데이터 기반의 기술 포트폴리오 분석: 빅데이터 및 인공지능 분야를 중심으로 공공연구성과 실용화를 위한 데이터 기반의 기술 포트폴리오 분석: 빅데이터 및 인공지능 분야를 중심으로 공공연구성과 실용화를 위한 데이터 기반의 기술 포트폴리오 분석: 빅데이터 및 인공지능 분야를 중심으로 빅데이터 및 인공지능 기술은 4차 산업혁명에 핵심적인 기술이나, 국내 중소&#x00B7;중견 기업의 빅데이터 분석 활용과 복합 인공지능 분야의 기술경쟁력 확보가 미흡한 상황이다. 따라서 빅데이터 및 인공지능 분야의 기술사업화를 통해 산업군 전반의 경쟁력을 강화하는 것이 중요하다. 본 연구에서는 기술 포트폴리오 분석을 통해 공공연구성과 실용화 우선순위를 평가하고자 한다. 우선 공공연구성과 정보에 대해 앙상블 기법을 적용한 딥러닝 모델을 사용하여 과제의 6T 분류 결측값을 개선하였다. 이후 6T 분야별 빅데이터 및 인공지능융합 분야를 대상으로 토픽 모델링을 진행하여 10개의 세부기술분야를 도출하였다. 세부기술분야별 기술사업화 가능성을 판단하기 위해 기술활동성과 기술효율성을 새롭게 정의하고 측정하였다. 두 축을 기반으로 포트폴리오를 4가지의 유형으로 구분하여 기술사업화 최우선 고려 대상, 장기 투자가 필요한 기술분야 등을 제안하였다. '영상 및 이미지 기반의 진단 기술'은 기술활동성 및 기술효율성이 높아 시장의 수요와 사업화 역량 모두 이상적인 수준으로 나타났다. 이처럼 체계적인 산업&#x00B7;기술시장 분석을 통해 공공연구성과 창출 기술의 활용을 활성화할 수 있으며 중소&#x00B7;중견으로의 효율적인 기술 이전 및 사업화 추진이 가능하다."
        },
        {
          "rank": 36,
          "score": 0.5918064117431641,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 37,
          "score": 0.5913799405097961,
          "doc_id": "NART125976684",
          "title": "A deep learning model for online doctor rating prediction",
          "abstract": "<P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART125976684&target=NART&cn=NART125976684",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction A deep learning model for online doctor rating prediction <P><B>Abstract</B><P>Predicting doctor ratings is a critical task in the healthcare industry. A patient usually provides ratings to a few doctors only, leading to the data sparsity issue, which complicates the rating prediction task. The study attempts to improve the prediction methodologies used in the doctor rating prediction systems. The study proposes a novel deep learning (DL) model for online doctor rating prediction based on a hierarchical attention bidirectional long short&#x2010;term memory (ODRP&#x2010;HABiLSTM) network. A hierarchical self&#x2010;attention bidirectional long short&#x2010;term memory (HA&#x2010;BiLSTM) network incorporates a textual review's word and sentence level information. A highway network is used to refine the representations learned by BiLSTM. The resulting latent patient and doctor representations are utilized to predict the online doctor ratings. Experimental findings based on real&#x2010;world doctor reviews from Yelp.com across two medical specialties demonstrate the proposed model's superior performance over state&#x2010;of&#x2010;the&#x2010;art benchmark models. In addition, robustness analysis is used to strengthen the findings.</P></P>"
        },
        {
          "rank": 38,
          "score": 0.5910754203796387,
          "doc_id": "DIKO0012113511",
          "title": "인공신경망을 이용한 판매처 평가 프레임워크",
          "abstract": "인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012113511&target=NART&cn=DIKO0012113511",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망을 이용한 판매처 평가 프레임워크 인공신경망은 분류 예측 문제를 해결하기 위한 다방면의 영역에서 사용되고 있다. 본 연구에서는 기존의 RFM방식에 의한 판매처 평가 프레임워크의 한계점으로 알려진 ‘평가 요소에 대한 배점기준의 모호성으로 인하여 발생하는 결과값의 차이’를 극복하기 위한 대안으로 인공신경망의 SOM기법을 이용한 판매처 평가 프레임워크를 제안하였고 실제 비교 실험을 수행하여 인공신경망을 이용한 판매처 평가 프레임워크가 분석자 개인의 역량에 관계없이 자동화된 방법에 의해  복잡한 데이터 프로세싱의 과정을 단순하게 줄이고도 결과에 있어서 유사한 품질의 판매처분류를 제공 할 수 있다는 가정을 세우고 실험을 통해 그 유효성을 입증하였다.    이를 위해 한국방송통신대학교출판부와 판매처간의 판매데이터를 우리가 제안한 SOM프레임워크에 패턴화하여 입력하고 자동화된 군집화 기법을 이용하여 도출한 판매처 분류 결과와 기존의 RFM 프레임워크의 요소 별 배점을 통한 데이터 프로세싱으로 산출한 결과를 비교 하였는데, 분석 및 검증 결과 인공신경망을 이용한 판매처 평가 프레임워크는 기존의 RFM방식의 판매처 평가 프레임워크와 비교하여 다음과 같은 장점이 있다는 것을 발견하였다.     첫째 인공신경망을 이용한 판매처 평가 프레임워크는 데이터 프로세싱 방법을 자동화할 수 있어서, 기존의 RFM방식의 모호한 배점 기준으로 인해 발생하던 결과값의 차이를 도메인 엑스퍼트의 유무에 상관없이 방지할 수 있었고, 둘째 많은 노력이 소모되던 복잡한 RFM프레임워크의 데이터 프로세싱에 비해 매우 적은 비용과 노력으로도 유사한 품질의 판매처 분류가 가능하다는 것을 증명하였으며, 마지막으로 기존의 방식으로는 시간에 따른 판매흐름의 분석이 불가능하지만 우리가 제안한 프레임워크는 시간에 따른 판매추세도 가늠해 볼 수 있다는 것이다.     이번 실험을 통해 우리는 인공신경망을 이용한 판매처 평가 프레임워크의 유효성을 입증하였고, 분류와 예측의 정확성 측면에서 뛰어난 성능을 보이는 신경망을 통한 규칙 도출 가능성에 대한 또 하나의 사례로서 신경망연구의 외연적 적용범위를 넓힐 수 있었다."
        },
        {
          "rank": 39,
          "score": 0.5908676385879517,
          "doc_id": "NART97710485",
          "title": "Big data analytics for personalized medicine",
          "abstract": "<P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97710485&target=NART&cn=NART97710485",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data analytics for personalized medicine Big data analytics for personalized medicine Big data analytics for personalized medicine <P>Big Data are radically changing biomedical research. The unprecedented advances in automated collection of large-scale molecular and clinical data pose major challenges to data analysis and interpretation, calling for the development of new computational approaches. The creation of powerful systems for the effective use of biomedical Big Data in Personalized Medicine (a.k.a. Precision Medicine) will require significant scientific and technical developments, including infrastructure, engineering, project and financial management. We review here how the evolution of data-driven methods offers the possibility to address many of these problems, guiding the formulation of hypotheses on systems functioning and the generation of mechanistic models, and facilitating the design of clinical procedures in Personalized Medicine.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Big Data are radically transforming Personalized Medicine. </LI> <LI>  Multi-omics, images, device data, and electronic health records represent the main big data types in biomedical research. </LI> <LI>  Cloud computing and HPC are the mainstream infrastructures for the management and analysis of biomedical big data. </LI> <LI>  Multi-view data analysis requires advanced machine learning techniques such as deep learning, and cognitive computing. </LI> </UL> </P>   <P><B>Graphical abstract</B></P>   <P>[DISPLAY OMISSION]</P>"
        },
        {
          "rank": 40,
          "score": 0.5899820327758789,
          "doc_id": "NART119053407",
          "title": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review",
          "abstract": "<P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART119053407&target=NART&cn=NART119053407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review Innovations in Genomics and Big Data Analytics for Personalized Medicine and Health Care: A Review <P>Big data in health care is a fast-growing field and a new paradigm that is transforming case-based studies to large-scale, data-driven research. As big data is dependent on the advancement of new data standards, technology, and relevant research, the future development of big data applications holds foreseeable promise in the modern day health care revolution. Enormously large, rapidly growing collections of biomedical omics-data (genomics, proteomics, transcriptomics, metabolomics, glycomics, etc.) and clinical data create major challenges and opportunities for their analysis and interpretation and open new computational gateways to address these issues. The design of new robust algorithms that are most suitable to properly analyze this big data by taking into account individual variability in genes has enabled the creation of precision (personalized) medicine. We reviewed and highlighted the significance of big data analytics for personalized medicine and health care by focusing mostly on machine learning perspectives on personalized medicine, genomic data models with respect to personalized medicine, the application of data mining algorithms for personalized medicine as well as the challenges we are facing right now in big data analytics.</P>"
        },
        {
          "rank": 41,
          "score": 0.5899158120155334,
          "doc_id": "ART001111579",
          "title": "Solvent manufacturing process monitoring using artificial neural networks",
          "abstract": "Advances in sensors, actuators, and computers and developments in information systems offer unprecedented opportunities to implement highly ambitious automation, control and decision strategies. There are also new challenges and demands for control and automation in modern industrial practices. There is a growing need for an active participation from the information systems in industrial, manufacturing and process industry environments because currently there are many control problems. This paper provides pattern recognition to the monitoring system for solvent manufacturing process and shows performance in real-time response with multiple input signals. Data is learned by a multilayer feedforward network trained by error-backpropagation. The two kinds of test results show that the trained network has the ability to show the current system status with different input data sets.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART001111579&target=NART&cn=ART001111579",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Solvent manufacturing process monitoring using artificial neural networks Solvent manufacturing process monitoring using artificial neural networks Solvent manufacturing process monitoring using artificial neural networks Advances in sensors, actuators, and computers and developments in information systems offer unprecedented opportunities to implement highly ambitious automation, control and decision strategies. There are also new challenges and demands for control and automation in modern industrial practices. There is a growing need for an active participation from the information systems in industrial, manufacturing and process industry environments because currently there are many control problems. This paper provides pattern recognition to the monitoring system for solvent manufacturing process and shows performance in real-time response with multiple input signals. Data is learned by a multilayer feedforward network trained by error-backpropagation. The two kinds of test results show that the trained network has the ability to show the current system status with different input data sets."
        },
        {
          "rank": 42,
          "score": 0.5893243551254272,
          "doc_id": "JAKO202407845906506",
          "title": "프라이버시를 보호하는 분산 기계 학습 연구 동향",
          "abstract": "인공지능 기술은 스마트 시티, 자율 주행, 의료 분야 등 다양한 분야에서 활용 가능성을 높이 평가받고 있으나, 정보주체의 개인정보 및 민감정보의 노출 문제로 모델 활용이 제한되고 있다. 이에 따라 데이터를 중앙 서버에 모아서 학습하지 않고, 보유 데이터셋을 바탕으로 일차적으로 학습을 진행한 후 글로벌 모델을 최종적으로 학습하는 분산 기계 학습의 개념이 등장하였다. 그러나, 분산 기계 학습은 여전히 협력하여 학습을 진행하는 과정에서 데이터 프라이버시 위협이 발생한다. 본 연구는 분산 기계 학습 연구 분야에서 프라이버시를 보호하기 위한 연구를 서버의 존재 유무, 학습 데이터셋의 분포 환경, 참여자의 성능 차이 등 현재까지 제안된 분류 기준들을 바탕으로 유기적으로 분석하여 최신 연구 동향을 파악한다. 특히, 대표적인 분산 기계 학습 기법인 수평적 연합학습, 수직적 연합학습, 스웜 학습에 집중하여 활용된 프라이버시 보호 기법을 살펴본 후 향후 진행되어야 할 연구 방향을 모색한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407845906506&target=NART&cn=JAKO202407845906506",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "프라이버시를 보호하는 분산 기계 학습 연구 동향 프라이버시를 보호하는 분산 기계 학습 연구 동향 프라이버시를 보호하는 분산 기계 학습 연구 동향 인공지능 기술은 스마트 시티, 자율 주행, 의료 분야 등 다양한 분야에서 활용 가능성을 높이 평가받고 있으나, 정보주체의 개인정보 및 민감정보의 노출 문제로 모델 활용이 제한되고 있다. 이에 따라 데이터를 중앙 서버에 모아서 학습하지 않고, 보유 데이터셋을 바탕으로 일차적으로 학습을 진행한 후 글로벌 모델을 최종적으로 학습하는 분산 기계 학습의 개념이 등장하였다. 그러나, 분산 기계 학습은 여전히 협력하여 학습을 진행하는 과정에서 데이터 프라이버시 위협이 발생한다. 본 연구는 분산 기계 학습 연구 분야에서 프라이버시를 보호하기 위한 연구를 서버의 존재 유무, 학습 데이터셋의 분포 환경, 참여자의 성능 차이 등 현재까지 제안된 분류 기준들을 바탕으로 유기적으로 분석하여 최신 연구 동향을 파악한다. 특히, 대표적인 분산 기계 학습 기법인 수평적 연합학습, 수직적 연합학습, 스웜 학습에 집중하여 활용된 프라이버시 보호 기법을 살펴본 후 향후 진행되어야 할 연구 방향을 모색한다."
        },
        {
          "rank": 43,
          "score": 0.5891522169113159,
          "doc_id": "JAKO201620853199880",
          "title": "딥러닝의 모형과 응용사례",
          "abstract": "딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201620853199880&target=NART&cn=JAKO201620853199880",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝의 모형과 응용사례 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다."
        },
        {
          "rank": 44,
          "score": 0.5889660716056824,
          "doc_id": "NART26247392",
          "title": "Learning to score final positions in the game of Go",
          "abstract": "<P><B>Abstract</B></P><P>This article investigates the application of machine-learning techniques for the task of scoring final positions in the game of Go. Neural network classifiers are trained to classify life and death from labelled 9&times;9 game records. The performance is compared to standard classifiers from statistical pattern recognition. A recursive framework for classification is used to improve performance iteratively. Using a maximum of four iterations our cascaded scoring architecture (CSA*) scores 98.9% of the positions correctly. Nearly all incorrectly scored positions are recognised (they can be corrected by a human operator). By providing reliable score information CSA* opens the large source of Go knowledge implicitly available in human game records for automatic extraction. It thus paves the way for a successful application of machine learning in Go.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART26247392&target=NART&cn=NART26247392",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Learning to score final positions in the game of Go Learning to score final positions in the game of Go Learning to score final positions in the game of Go <P><B>Abstract</B></P><P>This article investigates the application of machine-learning techniques for the task of scoring final positions in the game of Go. Neural network classifiers are trained to classify life and death from labelled 9&times;9 game records. The performance is compared to standard classifiers from statistical pattern recognition. A recursive framework for classification is used to improve performance iteratively. Using a maximum of four iterations our cascaded scoring architecture (CSA*) scores 98.9% of the positions correctly. Nearly all incorrectly scored positions are recognised (they can be corrected by a human operator). By providing reliable score information CSA* opens the large source of Go knowledge implicitly available in human game records for automatic extraction. It thus paves the way for a successful application of machine learning in Go.</P>"
        },
        {
          "rank": 45,
          "score": 0.5885754823684692,
          "doc_id": "JAKO201953457807295",
          "title": "경량 딥러닝 기술 동향",
          "abstract": "Considerable accuracy improvements in deep learning have recently been achieved in many applications that require large amounts of computation and expensive memory. However, recent advanced techniques for compacting and accelerating the deep learning model have been developed for deployment in lightweight devices with constrained resources. Lightweight deep learning techniques can be categorized into two schemes: lightweight deep learning algorithms (model simplification and efficient convolutional filters) in nature and transferring models into compact/small ones (model compression and knowledge distillation). In this report, we briefly summarize various lightweight deep learning techniques and possible research directions.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201953457807295&target=NART&cn=JAKO201953457807295",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "경량 딥러닝 기술 동향 경량 딥러닝 기술 동향 경량 딥러닝 기술 동향 Considerable accuracy improvements in deep learning have recently been achieved in many applications that require large amounts of computation and expensive memory. However, recent advanced techniques for compacting and accelerating the deep learning model have been developed for deployment in lightweight devices with constrained resources. Lightweight deep learning techniques can be categorized into two schemes: lightweight deep learning algorithms (model simplification and efficient convolutional filters) in nature and transferring models into compact/small ones (model compression and knowledge distillation). In this report, we briefly summarize various lightweight deep learning techniques and possible research directions."
        },
        {
          "rank": 46,
          "score": 0.5885719060897827,
          "doc_id": "JAKO202020363947235",
          "title": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론",
          "abstract": "최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202020363947235&target=NART&cn=JAKO202020363947235",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 전문성 이식을 통한 딥러닝 기반 전문 이미지 해석 방법론 최근 텍스트와 이미지 딥러닝 기술의 괄목할만한 발전에 힘입어, 두 분야의 접점에 해당하는 이미지 캡셔닝에 대한 관심이 급증하고 있다. 이미지 캡셔닝은 주어진 이미지에 대한 캡션을 자동으로 생성하는 기술로, 이미지 이해와 텍스트 생성을 동시에 다룬다. 다양한 활용 가능성 덕분에 인공지능의 핵심 연구 분야 중 하나로 자리매김하고 있으며, 성능을 다양한 측면에서 향상시키고자 하는 시도가 꾸준히 이루어지고 있다. 하지만 이처럼 이미지 캡셔닝의 성능을 고도화하기 위한 최근의 많은 노력에도 불구하고, 이미지를 일반인이 아닌 분야별 전문가의 시각에서 해석하기 위한 연구는 찾아보기 어렵다. 동일한 이미지에 대해서도 이미지를 접한 사람의 전문 분야에 따라 관심을 갖고 주목하는 부분이 상이할 뿐 아니라, 전문성의 수준에 따라 이를 해석하고 표현하는 방식도 다르다. 이에 본 연구에서는 전문가의 전문성을 활용하여 이미지에 대해 해당 분야에 특화된 캡션을 생성하기 위한 방안을 제안한다. 구체적으로 제안 방법론은 방대한 양의 일반 데이터에 대해 사전 학습을 수행한 후, 소량의 전문 데이터에 대한 전이 학습을 통해 해당 분야의 전문성을 이식한다. 또한 본 연구에서는 이 과정에서 발생하게 되는 관찰간 간섭 문제를 해결하기 위해 '특성 독립 전이 학습' 방안을 제안한다. 제안 방법론의 실현 가능성을 파악하기 위해 MSCOCO의 이미지-캡션 데이터 셋을 활용하여 사전 학습을 수행하고, 미술 치료사의 자문을 토대로 생성한 '이미지-전문 캡션' 데이터를 활용하여 전문성을 이식하는 실험을 수행하였다. 실험 결과 일반 데이터에 대한 학습을 통해 생성된 캡션은 전문적 해석과 무관한 내용을 다수 포함하는 것과 달리, 제안 방법론에 따라 생성된 캡션은 이식된 전문성 관점에서의 캡션을 생성함을 확인하였다. 본 연구는 전문 이미지 해석이라는 새로운 연구 목표를 제안하였고, 이를 위해 전이 학습의 새로운 활용 방안과 특정 도메인에 특화된 캡션을 생성하는 방법을 제시하였다."
        },
        {
          "rank": 47,
          "score": 0.5880531072616577,
          "doc_id": "JAKO201969164870114",
          "title": "의료 인공지능 표준화 동향",
          "abstract": "Based on the accumulation of medical big data, advances in medical artificial intelligence technology facilitate the timely treatment of disease through the reading the medical images and the increase of prediction speed and accuracy of diagnoses. In addition, these advances are expected to spark significant innovations in reducing medical costs and improving care quality. There are already approximately 40 FDA approved products in the US, and more than 10 products with K-FDA approval in Korea. Medical applications and services based on artificial intelligence are expected to spread rapidly in the future. Furthermore, the evolution of medical artificial intelligence technology is expanding the boundaries or limits of various related issues such as reference standards and specifications, ethical and clinical validation issues, and the harmonization of international regulatory systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201969164870114&target=NART&cn=JAKO201969164870114",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료 인공지능 표준화 동향 의료 인공지능 표준화 동향 의료 인공지능 표준화 동향 Based on the accumulation of medical big data, advances in medical artificial intelligence technology facilitate the timely treatment of disease through the reading the medical images and the increase of prediction speed and accuracy of diagnoses. In addition, these advances are expected to spark significant innovations in reducing medical costs and improving care quality. There are already approximately 40 FDA approved products in the US, and more than 10 products with K-FDA approval in Korea. Medical applications and services based on artificial intelligence are expected to spread rapidly in the future. Furthermore, the evolution of medical artificial intelligence technology is expanding the boundaries or limits of various related issues such as reference standards and specifications, ethical and clinical validation issues, and the harmonization of international regulatory systems."
        },
        {
          "rank": 48,
          "score": 0.5865021347999573,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 49,
          "score": 0.5859891176223755,
          "doc_id": "JAKO201974757494930",
          "title": "심층강화학습 라이브러리 기술동향",
          "abstract": "Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201974757494930&target=NART&cn=JAKO201974757494930",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 심층강화학습 라이브러리 기술동향 Reinforcement learning is a type of machine learning paradigm that forces agents to repeat the observation-action-reward process to assess and predict the values of possible future action sequences. This allows the agents to incrementally reinforce the desired behavior for a given observation. Thanks to the recent advancements of deep learning, reinforcement learning has evolved into deep reinforcement learning that introduces promising results in various control and optimization domains, such as games, robotics, autonomous vehicles, computing, industrial control, and so on. In addition to this trend, a number of programming libraries have been developed for importing deep reinforcement learning into a variety of applications. In this article, we briefly review and summarize 10 representative deep reinforcement learning libraries and compare them from a development project perspective."
        },
        {
          "rank": 50,
          "score": 0.585547924041748,
          "doc_id": "JAKO201921957011008",
          "title": "빅데이터를 활용한 패션쇼에 대한 소비자 인식 연구",
          "abstract": "This study examines changes in consumer perceptions of fashion shows, which are critical elements in the apparel industry and a means to represent a brand's image and originality. For this purpose, big data in clothing marketing, text mining, semantic network analysis techniques were applied. This study aims to verify the effectiveness and significance of fashion shows in an effort to give directions for their future utilization. The study was conducted in two major stages. First, data collection with the key word, 'fashion shows,' was conducted across websites, including Naver and Daum between 2015 and 2018. The data collection period was divided into the first- and second-half periods. Next, Textom 3.0 was utilized for data refinement, text mining, and word clouding. The Ucinet 6.0 and NetDraw, were used for semantic network analysis, degree centrality, CONCOR analysis and also visualization. The level of interest in 'models' was found to be the highest among the perception factors related to fashion shows in both periods. In the first-half period, the consumer interests focused on detailed visual stimulants such as model and clothing while in the second-half period, perceptions changed as the value of designers and brands were increasingly recognized over time. The findings of this study can be utilized as a tool to evaluate fashion shows, the apparel industry sectors, and the marketing methods. Additionally, it can also be used as a theoretical framework for big data analysis and as a basis of strategies and research in industrial developments.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201921957011008&target=NART&cn=JAKO201921957011008",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 패션쇼에 대한 소비자 인식 연구 빅데이터를 활용한 패션쇼에 대한 소비자 인식 연구 빅데이터를 활용한 패션쇼에 대한 소비자 인식 연구 This study examines changes in consumer perceptions of fashion shows, which are critical elements in the apparel industry and a means to represent a brand's image and originality. For this purpose, big data in clothing marketing, text mining, semantic network analysis techniques were applied. This study aims to verify the effectiveness and significance of fashion shows in an effort to give directions for their future utilization. The study was conducted in two major stages. First, data collection with the key word, 'fashion shows,' was conducted across websites, including Naver and Daum between 2015 and 2018. The data collection period was divided into the first- and second-half periods. Next, Textom 3.0 was utilized for data refinement, text mining, and word clouding. The Ucinet 6.0 and NetDraw, were used for semantic network analysis, degree centrality, CONCOR analysis and also visualization. The level of interest in 'models' was found to be the highest among the perception factors related to fashion shows in both periods. In the first-half period, the consumer interests focused on detailed visual stimulants such as model and clothing while in the second-half period, perceptions changed as the value of designers and brands were increasingly recognized over time. The findings of this study can be utilized as a tool to evaluate fashion shows, the apparel industry sectors, and the marketing methods. Additionally, it can also be used as a theoretical framework for big data analysis and as a basis of strategies and research in industrial developments."
        }
      ]
    },
    {
      "query": "How does large-scale machine learning facilitate the flow of information or capabilities between database systems and commercial applications?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.6494220495223999,
          "doc_id": "JAKO202375343265966",
          "title": "인공지능 기술을 활용한 데이터 관리 기술 동향",
          "abstract": "Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202375343265966&target=NART&cn=JAKO202375343265966",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 인공지능 기술을 활용한 데이터 관리 기술 동향 Recently, artificial intelligence has been in the spotlight across various fields. Artificial intelligence uses massive amounts of data to train machine learning models and performs various tasks using the trained models. For model training, large, high-quality data sets are essential, and database systems have provided such data. Driven by advances in artificial intelligence, attempts are being made to improve various components of database systems using artificial intelligence. Replacing traditional complex algorithm-based database components with their artificial-intelligence-based counterparts can lead to substantial savings of resources and computation time, thereby improving the system performance and efficiency. We analyze trends in the application of artificial intelligence to database systems."
        },
        {
          "rank": 2,
          "score": 0.6449955701828003,
          "doc_id": "JAKO202302557619339",
          "title": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반",
          "abstract": "최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202302557619339&target=NART&cn=JAKO202302557619339",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 LLM 애플리케이션 아키텍처를 활용한 생성형 AI 서비스 구현: RAG모델과 LangChain 프레임워크 기반 최근 생성형 AI 기술의 발전으로 인해 대형 언어 모델(Large Language Model, LLM)의 활용 및 도입이 확대되고 있는 상황에서 기존 연구들은 기업내부 데이터의 활용에 대한 실제 적용사례나 구현방법을 찾아보기 힘들다. 이에 따라 본 연구에서는 가장 많이 이용되고 있는 LangChain 프레임워크를 이용한 LLM 애플리케이션 아키텍처를 활용하여 생성형 AI 서비스를 구현하는 방법을 제시한다. 이를 위해 LLM의 활용을 중심으로, 정보 부족 문제를 극복하는 다양한 방법을 검토하고 구체적인 해결책을 제시하였다. 이를 위해 파인튜닝이나 직접 문서 정보를 활용하는 방법을 분석하며, 이러한 문제를 해결하기 위한 RAG 모델을 활용한 정보 저장 및 검색 방법에 대해 주요단계에 대해 자세하게 살펴본다. 특히, RAG 모델을 활용하여 정보를 벡터저장소에 저장하고 검색하기 위한 방법으로 유사문맥 추천 및 QA시스템을 활용하였다. 또한 구체적인 작동 방식과 주요한 구현 단계 및 사례를 구현소스 및 사용자 인터페이스까지 제시하여 생성형 AI 기술에 대한 이해를 높였다. 이를 통해 LLM을 활용한 기업내 서비스 구현에 적극적으로 활용할 수 있도록 하는데 의미와 가치가 있다."
        },
        {
          "rank": 3,
          "score": 0.6285102367401123,
          "doc_id": "JAKO201129362563090",
          "title": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교",
          "abstract": "세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201129362563090&target=NART&cn=JAKO201129362563090",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 스타 스키마 조인 처리에 대한 세로-지향 데이터베이스 시스템과 가로-지향 데이터베이스 시스템의 성능 비교 세로-지향 데이터베이스 시스템은 기존의 가로-지향 데이터베이스 시스템과 달리 데이터를 가로(row) 위주가 아닌 세로(column) 위주로 저장한다. 최근에는 데이터 웨어하우스나 의사 결정 시스템 같은 대용량 데이터를 갖는 읽기 위주의 응용들에서 세로-지향데이터베이스의 우수성이 관찰되었다. 본 논문에서는 세로-지향데이터베이스에서의 조인 전략을 구체적으로 분석하고 데이터 웨어하우스 시스템에서 세로-지향 데이터베이스의 우수성을 검증하고자 한다. 두 시스템간의 객관적인 비교를 위해 데이터 웨어하우스 분석 모델인 스타 스키마 벤치마크를 통해 스타스키마조인 질의에 대한 성능분석을 실시하고자 한다. 또한 세로-지향 데이터베이스의 조인 전략으로 조기 실체화(early materialization)와 지연 실체화(late materialization)를 고려하였다. 성능 분석을 통해 스타 스키마 조인 질의처리에 있어 가로-지향 시스템보다는 세로-지향 시스템에서 디스크 I/O 비용이 더 효율적인 결과를 확인할 수 있었다. 세로-지향 데이터베이스 시스템 측면에서는 조기 실체화보다는 지연 실체화 조인전략이 훨씬 우수한 성능을 보였다."
        },
        {
          "rank": 4,
          "score": 0.6264851093292236,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 5,
          "score": 0.6259294748306274,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 6,
          "score": 0.6217913627624512,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 7,
          "score": 0.6206128597259521,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 8,
          "score": 0.6201308369636536,
          "doc_id": "ATN0024933735",
          "title": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안",
          "abstract": "Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0024933735&target=NART&cn=ATN0024933735",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 보건의료 빅데이터 플랫폼에서 LOD를 활용한 데이터 연계 방안 Linked Open Data (LOD) is rated as the best of any kind of data disclosure, and allows you to search related data by linking them in a standard format across the Internet. There is an increasing number of cases in which relevant data are constructed in the LOD form in the global environment, but in the domestic healthcare sector, the disclosure of data in the form of LOD is still at the beginning stage. In this paper, we introduce a case of LOD platform construction that provides services by linking domestic and international related data by LOD method, based on the data of Korean medical research paper data and health care big data linkage platform. Linking all data from each DB into an LOD requires a lot of time and effort, and is basically an infrastructure task that government or public institutions should be in charge of rather than the private sector. In this study, ten domestic and foreign LOD sites were linked with only a portion of each DB, enabling users to link data from various domestic and foreign organizations in a convenient manner."
        },
        {
          "rank": 9,
          "score": 0.6198623180389404,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 10,
          "score": 0.6185503005981445,
          "doc_id": "JAKO200835054210184",
          "title": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크",
          "abstract": "본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200835054210184&target=NART&cn=JAKO200835054210184",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 XMDR 데이터 허브 기반의 Proxy 데이터베이스를 이용한 데이터 상호운용 프레임워크 본 논문에서는 XMDR(eXtended Meta-Data Resistry) 데이터 허브 기반의 Proxy Database를 이용하여 Legacy Database간의 데이터 상호운용이 가능한 프레임워크를 제안한다. 협 업 환경에서는 Legacy Database간의 상호운용을 하는데 있어서 데이터의 구조, 의미, 형식상의 이질적인 문제들이 발생한다. 또한 실시간으로 변화하는 데이터를 종류와 형식에 관계없이 지속적으로 일관성을 유지하기가 어렵다. 본 논문에서는 XMDR 데이터 허브를 이용하여 Legacy DB간의 데이터 통합 및 상호운용에서 발생할 수 있는 이 질적인 문제를 해결한다. Proxy Database를 이용하여 상호운용하고자 하는 데이터들이 종류와 형식에 상관없이 호환이 가능하고, 지속적으로 정확한 정보를 실시간으로 일관성 있게 제공하는 프레임워크를 제안한다."
        },
        {
          "rank": 11,
          "score": 0.6174259185791016,
          "doc_id": "JAKO201503340570903",
          "title": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치",
          "abstract": "본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201503340570903&target=NART&cn=JAKO201503340570903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 의료정보시스템 운영에서 생성되는 의료 빅데이터의 활용가치 본 연구에서는 병원정보시스템에서 분야별로 발생하는 의료 빅데이터 자료를 활용하여 가치있는 의료정보를 생성하고 활용할 수 있는 방안을 마련하고자 한다. 본 연구의 결과는 첫 번째, 의료정보시스템의 진료정보와 각종 검사장비 및 의료영상장비와 연동된 PACS의 발생자료를 통합하고 의료 빅데이터를 분석하여 새로운 의료정보를 생성한다. 이렇게 생성된 의료정보는 감염병 및 질병 예방과 질병의 치료를 위한 다양한 건강정보를 생성하게 된다. 두 번째, 환자의 접수내역과 수납내역 그리고 청구내역들을 통합하여 축적해온 의료 빅데이터를 분석하여 다양한 수익통계정보를 생성한다. 이렇게 생성된 수익통계정보는 의료기관의 운영과 수익분석에 활용하기 위한 다양한 경영정보를 생성하게 된다. 이와 같이 병원정보시스템에서 발생하는 의료정보와 공공기관의 의료정보 그리고 개인건강기록의 자료들이 통합이 되면 의료자료를 활용한 가치있는 보건의료정보를 창출하게 된다."
        },
        {
          "rank": 12,
          "score": 0.6172945499420166,
          "doc_id": "JAKO199811921340072",
          "title": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구",
          "abstract": "CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921340072&target=NART&cn=JAKO199811921340072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 연방 데이터베이스 시스템 기반의 CALS 통합 데이터베이스 구현 연구 CALS IDB (Integrated database) is one of core technologies that embodies the principle of a shared data environment for the life cycle related data in CALS environment. In this study, to successfully share the data, we first classified the data types employed in the CALS environment and then discussed the data heterogeneity issued in data integration processes. To effectively solve this heterogeneity, we proposed the federated database systems as a candidate system especially focusing on the major functions and core element technologies."
        },
        {
          "rank": 13,
          "score": 0.6168594360351562,
          "doc_id": "ATN0030123438",
          "title": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법",
          "abstract": "There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123438&target=NART&cn=ATN0030123438",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 데이터베이스 클러스터 시스템 환경에서의 중첩 질의 분할 처리기법 There is growing need for efficient data analysis to support decision making as the amount of data increases rapidly in most areas of business. For this reason, implementing data warehouse and utilize OLAP analysis are becoming common. However performance of OLAP queries becomes a critical issue, since OLAP queries are usually complex and they include sophisticated analytical tasks. We propose an OLAP queries decomposition and processing technique for a high performance database cluster system called HyperDB."
        },
        {
          "rank": 14,
          "score": 0.6165605783462524,
          "doc_id": "JAKO200765349519201",
          "title": "대규모 분산 파일 시스템 환경의 메타 데이터 관리",
          "abstract": "메타 데이터와 데이터의 처리 경로를 독립시킨 분산 파일 시스템 구조는 입출력 성능향상 및 확장성 용이라는 측면에서 현재 주도적인 아키텍처로 사용되고 있다. 이러한 환경에서 클라이언트 및 데이터 서버의 수가 계속 확장되어 전체 시스템 규모가 페타(peta) 바이트급 이상 처리가 가능한 대규모로 진화될 경우 필연적으로 메타 데이터 서버에 병목 현상이 발생하게 된다. 본 고에서는 이러한 문제를 처리하기 위한 아키텍처로서 메타 데이터 서버들의 클러스터링을 고려하며, 이를 위해 제안된 다양한 기술들의 동작 원리 및 장단점 등을 분석하고 고찰해 보기로 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200765349519201&target=NART&cn=JAKO200765349519201",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 분산 파일 시스템 환경의 메타 데이터 관리 대규모 분산 파일 시스템 환경의 메타 데이터 관리 대규모 분산 파일 시스템 환경의 메타 데이터 관리 메타 데이터와 데이터의 처리 경로를 독립시킨 분산 파일 시스템 구조는 입출력 성능향상 및 확장성 용이라는 측면에서 현재 주도적인 아키텍처로 사용되고 있다. 이러한 환경에서 클라이언트 및 데이터 서버의 수가 계속 확장되어 전체 시스템 규모가 페타(peta) 바이트급 이상 처리가 가능한 대규모로 진화될 경우 필연적으로 메타 데이터 서버에 병목 현상이 발생하게 된다. 본 고에서는 이러한 문제를 처리하기 위한 아키텍처로서 메타 데이터 서버들의 클러스터링을 고려하며, 이를 위해 제안된 다양한 기술들의 동작 원리 및 장단점 등을 분석하고 고찰해 보기로 한다."
        },
        {
          "rank": 15,
          "score": 0.6159911155700684,
          "doc_id": "JAKO201835146902109",
          "title": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법",
          "abstract": "인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201835146902109&target=NART&cn=JAKO201835146902109",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다."
        },
        {
          "rank": 16,
          "score": 0.6155941486358643,
          "doc_id": "JAKO202408283134560",
          "title": "머신러닝&딥러닝 모델을 활용한 댐 일유입량 예측시 융적설을 고려하기 위한 데이터 전처리에 대한 방법 연구",
          "abstract": "댐유입량 예측에 대하여 데이터 기반 머신러닝 및 딥러닝(Machine Learning & Deep Learning, ML&DL) 분석도구들이 공개되어 다양한 분야에서 ML&DL의 적용연구가 활발히 진행되고 있으며, 모델의 자체 성능향상 뿐만 아니라 모델의 특성을 고려한 데이터의 전처리도 댐유입량을 정확하게 예측하게 하는 중요한 모델성능 향상의 요소라고 할 수 있다. 특히 기존 강우자료는 적설량을 열선 설비를 통하여 녹여 강우량으로 환산되어 있으므로, 융적설에 따른 강우와 유입량의 상관관계를 왜곡하게 된다. 따라서 본연구에서는 소양강댐과 같이 융적설의 영향을 받는 댐유역에 대한 댐일유입량 예측시 겨울에 강설량이 적설이 되어 적게 유출되는 현상과, 봄에 융설로 인하여 무강우나 적은 비에도 많은 유출이 일어나는 물리적 현상을 ML&DL모델로 적용하기 위하여 필요한 강우 데이터의 전처리에 대한 연구를 수행 하였다. 강우계열, 유입량계열을 조합하여 3가지 머신러닝(SVM, RF, LGBM)과 2가지 딥러닝(LSTM, TCN) 모델을 구축하고, 최적 하이퍼파라메터 튜닝을 통하여 적합 모델을 적용하고 한 결과, NSE 0.842~0.894로 높은 수준의 예측성능을 나타내었다. 또한 융적설을 반영한 강우보정 데이터를 만들기 위하여 융적설 모의 알고리즘을 개발하고, 이를 통하여 산정된 보정강우를 머신러닝 및 딥러닝 모델에 적용한 결과 NSE 0.841~0.896 으로 융적설 적용전과 비슷한 높은 수준의 예측 성능을 나타내었으나, 융적설 기간에는 조정된 강우로 학습되어 예측되었을 때 실측유입량에 근접하는 모의결과를 나타내었다. 결론적으로, 융적설이 영향을 미치는 유역에서의 데이터 모델 적용시에는 입력자료 구축시 적설 및 융설이 물리적으로 타당한 강우-유출 반응에 적합하도록 전처리과정이 중요함을 밝혔다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202408283134560&target=NART&cn=JAKO202408283134560",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝&딥러닝 모델을 활용한 댐 일유입량 예측시 융적설을 고려하기 위한 데이터 전처리에 대한 방법 연구 머신러닝&딥러닝 모델을 활용한 댐 일유입량 예측시 융적설을 고려하기 위한 데이터 전처리에 대한 방법 연구 머신러닝&딥러닝 모델을 활용한 댐 일유입량 예측시 융적설을 고려하기 위한 데이터 전처리에 대한 방법 연구 댐유입량 예측에 대하여 데이터 기반 머신러닝 및 딥러닝(Machine Learning & Deep Learning, ML&DL) 분석도구들이 공개되어 다양한 분야에서 ML&DL의 적용연구가 활발히 진행되고 있으며, 모델의 자체 성능향상 뿐만 아니라 모델의 특성을 고려한 데이터의 전처리도 댐유입량을 정확하게 예측하게 하는 중요한 모델성능 향상의 요소라고 할 수 있다. 특히 기존 강우자료는 적설량을 열선 설비를 통하여 녹여 강우량으로 환산되어 있으므로, 융적설에 따른 강우와 유입량의 상관관계를 왜곡하게 된다. 따라서 본연구에서는 소양강댐과 같이 융적설의 영향을 받는 댐유역에 대한 댐일유입량 예측시 겨울에 강설량이 적설이 되어 적게 유출되는 현상과, 봄에 융설로 인하여 무강우나 적은 비에도 많은 유출이 일어나는 물리적 현상을 ML&DL모델로 적용하기 위하여 필요한 강우 데이터의 전처리에 대한 연구를 수행 하였다. 강우계열, 유입량계열을 조합하여 3가지 머신러닝(SVM, RF, LGBM)과 2가지 딥러닝(LSTM, TCN) 모델을 구축하고, 최적 하이퍼파라메터 튜닝을 통하여 적합 모델을 적용하고 한 결과, NSE 0.842~0.894로 높은 수준의 예측성능을 나타내었다. 또한 융적설을 반영한 강우보정 데이터를 만들기 위하여 융적설 모의 알고리즘을 개발하고, 이를 통하여 산정된 보정강우를 머신러닝 및 딥러닝 모델에 적용한 결과 NSE 0.841~0.896 으로 융적설 적용전과 비슷한 높은 수준의 예측 성능을 나타내었으나, 융적설 기간에는 조정된 강우로 학습되어 예측되었을 때 실측유입량에 근접하는 모의결과를 나타내었다. 결론적으로, 융적설이 영향을 미치는 유역에서의 데이터 모델 적용시에는 입력자료 구축시 적설 및 융설이 물리적으로 타당한 강우-유출 반응에 적합하도록 전처리과정이 중요함을 밝혔다."
        },
        {
          "rank": 17,
          "score": 0.6153435707092285,
          "doc_id": "JAKO202012758285347",
          "title": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구",
          "abstract": "국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012758285347&target=NART&cn=JAKO202012758285347",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방 빅데이터/인공지능 활성화를 위한 다중메타데이터 저장소 관리시스템(MRMM) 기술 연구 국방부는 감소되는 부대 및 병력자원의 문제해결과 전투력 향상을 위해 4차 산업혁명 기술(빅데이터, AI)의 적극적인 도입을 추진하고 있다. 국방 정보시스템은 업무 영역 및 각군의 특수성에 맞춰 다양하게 개발되어 왔으며, 4차 산업혁명 기술을 적극 활용하기 위해서는 현재 폐쇄적으로 운용하고 있는 국방 데이터 관리체계의 개선이 필요하다. 그러나, 국방 빅데이터 및 인공지능 도입을 위해 전 정보시스템에 데이터 표준을 제정하여 활용하는 것은 보안문제, 각군 업무특성 및 대규모 체계의 표준화 어려움 등으로 제한사항이 있고, 현 국방 데이터 공유체계 제도적으로도 각 체계 상호간 연동 소요를 기반으로 체계간 연동합의를 통해 직접 연동을 통하여 데이터를 제한적으로 공유하고 있는 실정이다. 4차 산업혁명 기술을 적용한 스마트 국방을 구현하기 위해서는 국방 데이터를 공유하여 잘 활용할 수 있는 제도마련이 시급하고, 이를 기술적으로 뒷받침하기 위해 국방상호운용성 관리지침 규정에 따라 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 국방 데이터의 체계적인 표준 관리를 지원하는 다중 데이터 저장소 관리(MRMM) 기술개발이 필요하다. 본 연구에서는 스마트 국방 구현을 위해 가장 기본이 되는 국방 데이터의 도메인 및 코드사전을 생성된 국방 전사 표준과 각 체계별 표준 매핑을 관리하고, 표준간 연계를 통하여 데이터 상호 운용성 증진을 지원하는 다중 데이터 저장소 관리 (MRMM) 기술을 제시하고, 단어의 유사도를 통해 MRMM의 실현 방향성을 구현하였다. MRMM을 바탕으로 전군 DB의 표준화 통합을 좀 더 간편하게 하여 실효성 있는 국방 빅데이터 및 인공지능 데이터 구현환경을 제공하여, 스마트 국방 구현을 위한 막대한 국방예산 절감과 전투력 향상을 위한 전력화 소요기간의 감소를 기대할 수 있다."
        },
        {
          "rank": 18,
          "score": 0.6141382455825806,
          "doc_id": "JAKO201617338764393",
          "title": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구",
          "abstract": "본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201617338764393&target=NART&cn=JAKO201617338764393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다."
        },
        {
          "rank": 19,
          "score": 0.6134001016616821,
          "doc_id": "ART002968156",
          "title": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging",
          "abstract": "The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002968156&target=NART&cn=ART002968156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging Artificial Intelligence and Deep Learning in Musculoskeletal Magnetic Resonance Imaging The application of artificial intelligence (AI) and deep learning (DL) in radiology is rapidly evolving. AI in healthcare has benefits for image recognition, classification, and radiological workflows from a clinical perspective. Additionally, clinical triage AI can be applied to triage systems. This review aims to introduce the concept of DL and discuss its applications in the interpretation of magnetic resonance (MR) images and the DL-based reconstruction of accelerated MR images, with an emphasis on musculoskeletal radiology. The most recent developments and future directions are also discussed briefly."
        },
        {
          "rank": 20,
          "score": 0.6128388047218323,
          "doc_id": "NART06057124",
          "title": "Integration of Machine Learning and Knowledge Acquisition",
          "abstract": "<P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06057124&target=NART&cn=NART06057124",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition Integration of Machine Learning and Knowledge Acquisition <P>&ldquo;Integration of Machine Learning and Knowledge Acquisition&rdquo; may be a surprising title for an ECAI-94 workshop, since most machine learning (ML) systems are intended for knowledge acquisition (KA). So what seems problematic about integrating ML and KA? The answer lies in the difference between the approaches developed by what is referred to as ML and KA research. Apart from sonic major exceptions, such as learning apprentice tools (Mitchell et al., 1989), or libraries like the Machine Learning Toolbox (MLT Consortium, 1993), most ML algorithms have been described without any characterization in terms of real application needs, in terms of what they could be effectively useful for. Although ML methods have been applied to &ldquo;real world&rdquo; problems few general and reusable conclusions have been drawn from these knowledge acquisition experiments. As ML techniques become more and more sophisticated and able to produce various forms of knowledge, the number of possible applications grows. ML methods tend then to be more precisely specified in terms of the domain knowledge initially required, the control knowledge to be set and the nature of the system output (MLT Consortium, 1993; Kodratoff et al., 1994).</P>"
        },
        {
          "rank": 21,
          "score": 0.6119178533554077,
          "doc_id": "JAKO201424635079777",
          "title": "학습 시스템을 위한 빅데이터 처리 환경 구축",
          "abstract": "빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201424635079777&target=NART&cn=JAKO201424635079777",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 학습 시스템을 위한 빅데이터 처리 환경 구축 빅데이터의 병렬분산처리 시스템을 위한 아파치 하둡 환경을 구축하기 위해서는 다수의 컴퓨터를 연결하여 노드를 구성하거나, 하나의 컴퓨터에 다수의 가상 노드 구성을 통해 클라우딩 환경을 구축하여야 한다. 그러나 이러한 시스템을 교육 환경에서 실습용으로 구축하는 것은 복잡한 시스템 구성과 비용적인 측면에서 많은 제약이 따른다. 따라서 빅데이터 처리 분야의 입문자들과 교육기관의 실습용으로 사용할 수 있는 실용적이고 저렴한 학습 시스템의 개발이 시급하다. 본 연구에서는 라즈베리파이 보드를 기반으로 하둡과 NoSQL과 같은 빅데이터 처리 및 분석 실습이 가능한 빅데이터 병렬분산처리 학습시스템을 설계 및 구현하였다. 구현된 빅데이터 병렬분산처리시스템은 교육현장과 빅데이터를 시작하는 입문자들에게 유용한 시스템이 될 것으로 기대된다."
        },
        {
          "rank": 22,
          "score": 0.6118048429489136,
          "doc_id": "JAKO201321353486803",
          "title": "빅데이터 처리 프로세스 및 활용",
          "abstract": "우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201321353486803&target=NART&cn=JAKO201321353486803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 빅데이터 처리 프로세스 및 활용 우리사회는 점점 더 융/복합 현상이 가속화되고, 광범위한 영역으로 확대되고 있다. 이러한 중심축에는 정보통신 기술이 자리잡고 있음은 당연한 일이다. 일례로 정보통신기술과 의료산업의 융합의 결과로 스마트 헬스케어 산업이 등장하였으며, 모든 분야에 정보통신 기술을 접목하고자 하는 노력들이 계속되고 있다. 이로 인해 우리주변에는 수많은 디지털 데이터들이 만들어지고 있다. 또 다른 한편으로는 대중화 되고 있는 스마트폰, 태블릿PC와 카메라, 게임기기등을 통하여 다양한 데이터들이 생성되고 있다. 본 연구에서는 광범위하게 발생하고 있는 빅데이터에 대한 활용 상태를 알아보고 빅데이터 플랫폼의 한 축인 처리 프로세스들에 대해 비교, 분석하였다."
        },
        {
          "rank": 23,
          "score": 0.6112223863601685,
          "doc_id": "JAKO200818259612116",
          "title": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습",
          "abstract": "본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200818259612116&target=NART&cn=JAKO200818259612116",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 대규모 태깅 데이터를 이용한 태깅 온톨로지 학습 본 논문은 대중에 의해 자유롭게 생성된 분류 체계인 폭소노미, 즉 대규모의 태깅 데이터로부터 태깅 온톨로지를 학습하는 방법을 제시하고 있다. 기존 소셜웹 시스템간에는 태깅의 의미에 대해 공통의 합의가 이루어지지 않았기 때문에, 시스템마다 태깅 정보를 표현하기 위해 내부적으로 다른 방법을 쓰고 있으며, 따라서 소프트웨어 에이전트를 이용하여 시스템간의 정보처리를 자동으로 할 수가 없다. 이를 해결하는 방법으로 폭소노미를 위한 태깅 온톨로지가 필요하다. 태깅의 본질적인 속성을 분석하여 태깅 온톨로지를 정의하고, 태깅 데이터의 기계 학습을 통하여 유사 태그와 사용자 그룹 정보를 획득한 후, 태깅 온톨로지를 학습한다. 이의 활용 방안으로 학습된 태깅 온톨로지를 이용하여 모델링한 추천 시스템도 제안한다."
        },
        {
          "rank": 24,
          "score": 0.6106784343719482,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 25,
          "score": 0.6096341013908386,
          "doc_id": "JAKO201006159731627",
          "title": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구",
          "abstract": "정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201006159731627&target=NART&cn=JAKO201006159731627",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다."
        },
        {
          "rank": 26,
          "score": 0.6080172061920166,
          "doc_id": "JAKO201723840540692",
          "title": "빅데이터 통합모형 비교분석",
          "abstract": "빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723840540692&target=NART&cn=JAKO201723840540692",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터 통합모형 비교분석 빅데이터가 4차 산업혁명의 핵심으로 자리하면서 빅데이터 기반 처리 및 분석 능력이 기업의 미래 경쟁력을 좌우할 전망이다. 빅데이터 처리 및 분석을 위한 RHadoop과 RHIPE 모형은 R과 Hadoop의 통합모형으로 지금까지 각각의 모형에 대해서는 연구가 많이 진행되어 왔으나 두 모형간 비교 연구는 거의 이루어 지지 않았다. 본 논문에서는 대용량의 실제 데이터와 모의실험 데이터에서 다중 회귀 (multiple regression)와 로지스틱 회귀 (logistic regression) 추정을 위한 머신러닝 (machine learning) 알고리즘을 MapReduce 프로그램 구현을 통해 RHadoop과 RHIPE 간의 비교 분석하고자 한다. 구축된 분산 클러스터 (distributed cluster) 하에서 두 모형간 성능 실험 결과, RHIPE은 RHadoop에 비해 대체로 빠른 처리속도를 보인 반면에 설치, 사용면에서 어려움을 보였다."
        },
        {
          "rank": 27,
          "score": 0.6078078150749207,
          "doc_id": "JAKO201623954939502",
          "title": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구",
          "abstract": "전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623954939502&target=NART&cn=JAKO201623954939502",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적 환경과 빅데이터 환경의 데이터 자원 관리 비교 연구 전통적인 환경에서 데이터 생명주기는 데이터-정보-지식-지혜 전환과정으로 요약된다. 반면에 빅데이터 환경에서 데이터 생명주기는 데이터-통찰-실행 전환과정으로 요약된다. 이러한 전환과정의 차이점은 데이터 생명주기를 지원하는 데이터 자원 관리에도 변화를 요구한다. 본 논문에서는 전통적인 데이터 자원 관리와 비교하여 빅데이터 환경을 위한 데이터 자원 관리를 연구한다. 특히 빅데이터 자원관리를 위한 주요 구성요소를 제안한다."
        },
        {
          "rank": 28,
          "score": 0.6070847511291504,
          "doc_id": "JAKO201224747154192",
          "title": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법",
          "abstract": "최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201224747154192&target=NART&cn=JAKO201224747154192",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 대규모 데이터베이스 시스템에서 인덱스를 이용한 범위 질의 방법 최근 데이터 양이 폭발적으로 증가함에 따라, 데이터를 저장하고 검색하고 다루기 위한 대규모 데이터베이스 시스템이 등장하였다. 이 환경에서는 일관성과 가용성, 결함 허용 등 다양한 이슈가 존재한다. 이 논문에서는 데이터 관리와 트랜잭션 관리가 분리된 구조를 갖는 대규모 데이터베이스 시스템에서, 효율적인 범위 질의 방법에 대하여 다룬다. 동일한 구조에서 두 모듈의 독립성을 보장하고, 팬텀 문제를 해결하기 위하여 파티션을 이용한 범위 질의 방법에 대한 연구가 있었지만, 범위 질의가 키 값으로 명세되는 경우에만 효율적이었다. 이에 이 논문에서는 키 값이 아닌 다른 속성으로 범위 질의가 주어질 때 효율을 개선할 수 있는 방법을 제안하고자 한다. 제안하는 방법에서는 분리된 두 모듈의 독립성은 보장하며, 부분 인덱스를 사용함으로써 범위 질의를 위한 오버헤드를 줄일 수 있다."
        },
        {
          "rank": 29,
          "score": 0.6062685251235962,
          "doc_id": "DIKO0017285659",
          "title": "산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로",
          "abstract": "라이다 데이터는 정밀한 3차원 공간 정보를 제공하지만, 데이터 용량이 매우 방대하여 인공지능(AI) 학습과 디지털 산림행정에 바로 적용하는 데에는 한계가 있다. 이에 따라 방대한 라이다 데이터의 문제를 해결하고자, 여러 가지 경량화 기법을 찾고 효율성을 검토하기 위하여 본 연구를 수행하였으며. 복셀 그리드(voxel grid), 무작위 샘플링(random sampling), 옥트리 (octree) 기반 분할, 최원점 샘플링(FPS) 네 가지 방법으로 데이터 용량 감소율과 데이터 보존 정도, 처리 속도 등을 비교하고 분석하였다. 아울러, 라이더 데이터를 활용한 산림행정 지능화 방안으로서 데이터 마이닝, 딥러닝 기반의 다양한 알고리즘을 소개하였다. 각각의 장단점과 산림행정 적용 방안 및 이슈를 분석하였다. 이러한 연구 결과는 향후 디지털 산림행정을 추진하는 데 있어, 데이터 처리 효율과 분석 정확도를 동시에 확보하는 방안으로 활용될 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017285659&target=NART&cn=DIKO0017285659",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 산림행정에 인공지능(AI)을 적용하기 위한 데이터 전처리 및 기계학습 방안 연구 : 드론 및 항공 라이다 데이터를 중심으로 라이다 데이터는 정밀한 3차원 공간 정보를 제공하지만, 데이터 용량이 매우 방대하여 인공지능(AI) 학습과 디지털 산림행정에 바로 적용하는 데에는 한계가 있다. 이에 따라 방대한 라이다 데이터의 문제를 해결하고자, 여러 가지 경량화 기법을 찾고 효율성을 검토하기 위하여 본 연구를 수행하였으며. 복셀 그리드(voxel grid), 무작위 샘플링(random sampling), 옥트리 (octree) 기반 분할, 최원점 샘플링(FPS) 네 가지 방법으로 데이터 용량 감소율과 데이터 보존 정도, 처리 속도 등을 비교하고 분석하였다. 아울러, 라이더 데이터를 활용한 산림행정 지능화 방안으로서 데이터 마이닝, 딥러닝 기반의 다양한 알고리즘을 소개하였다. 각각의 장단점과 산림행정 적용 방안 및 이슈를 분석하였다. 이러한 연구 결과는 향후 디지털 산림행정을 추진하는 데 있어, 데이터 처리 효율과 분석 정확도를 동시에 확보하는 방안으로 활용될 수 있다."
        },
        {
          "rank": 30,
          "score": 0.6048150658607483,
          "doc_id": "JAKO201905653788881",
          "title": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안",
          "abstract": "오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905653788881&target=NART&cn=JAKO201905653788881",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 적용 방안 오늘날의 기술 환경에서 대다수의 빅 데이터 기반 애플리케이션 및 솔루션은 스트리밍 데이터의 실시간 처리를 기반으로 한다. 빅 데이터 스트림의 실시간 처리 및 분석은 빅 데이터 기반 애플리케이션 및 솔루션 개발에서 중요한 역할을 한다. 특히 해사 분야 데이터 처리 환경에서도 데이터의 폭발적 증대에 따른 대용량 실시간 데이터를 빠르게 처리 및 분석할 수 있는 기술 개발의 필요성이 가속화되고 있다. 따라서 본 논문에서는 다양한 빅 데이터 처리를 위한 오픈소스 기술 중에 적합한 오픈소스로 NiFi, Kafka, Druid의 특징을 분석하여 한국형 e-Navigation 서비스에서 해사 분야 서비스 분석에 필요한 외부 연계 필요 정보들을 상시 최신 정보로 제공할 수 있도록 실시간 데이터 처리를 위한 개방형 데이터 프레임워크 기술 적용의 기초를 마련하고자 한다."
        },
        {
          "rank": 31,
          "score": 0.6046020984649658,
          "doc_id": "NART69875968",
          "title": "뇌영상 정보추출 응용 분석을 위한 융합 자원관리 시스템",
          "abstract": "<P>&amp;nbsp;&amp;nbsp;최근 많은 과학응용 연구 분야에서 고성능 컴퓨팅 자원뿐만 아니라 고신뢰성 네트워크 자원을 융합하여 사용하고자 하는 요구가 증가하고 있다. 이런 미래 사이버인프라 연구 환경을 구축하기 위해 컴퓨팅 자원과 네트워크 자원을 융합하여 제공할 수 있는 과학기술자원 융합망 구축 사업이 진행되어져 왔다. 이를 통해 응용 연구자는 단순히 공급자가 정해주는 자원 제공을 떠나 스스로 연구 요구사항에 맞게 컴퓨팅 및 네트워크 자원을 할당하여 사용할 수 있다. 본 논문에서는 구축된 과학기술자원 융합망을 기반으로 하여 뇌영상 정보처리에 특화된 통합자원관리시스템을 개발하였다. 이 시스템에서는 뇌영상 처리시 요구되는 알고리즘 및 프로그램을 적용하여 실제 뇌영상 데이터 정보를 분석함으로써 뇌기능 및 연결 구조를 파악하기 위한 대용량 데이터 분석처리가 가능하다. 이는 실제 과학응용 분야에서 요구되는 작업 환경을 적용한 대표적인 사례로 향후, 다양한 과학응용분야에 확장되어 적용되어 질 수 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69875968&target=NART&cn=NART69875968",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "뇌영상 정보추출 응용 분석을 위한 융합 자원관리 시스템 뇌영상 정보추출 응용 분석을 위한 융합 자원관리 시스템 뇌영상 정보추출 응용 분석을 위한 융합 자원관리 시스템 <P>&amp;nbsp;&amp;nbsp;최근 많은 과학응용 연구 분야에서 고성능 컴퓨팅 자원뿐만 아니라 고신뢰성 네트워크 자원을 융합하여 사용하고자 하는 요구가 증가하고 있다. 이런 미래 사이버인프라 연구 환경을 구축하기 위해 컴퓨팅 자원과 네트워크 자원을 융합하여 제공할 수 있는 과학기술자원 융합망 구축 사업이 진행되어져 왔다. 이를 통해 응용 연구자는 단순히 공급자가 정해주는 자원 제공을 떠나 스스로 연구 요구사항에 맞게 컴퓨팅 및 네트워크 자원을 할당하여 사용할 수 있다. 본 논문에서는 구축된 과학기술자원 융합망을 기반으로 하여 뇌영상 정보처리에 특화된 통합자원관리시스템을 개발하였다. 이 시스템에서는 뇌영상 처리시 요구되는 알고리즘 및 프로그램을 적용하여 실제 뇌영상 데이터 정보를 분석함으로써 뇌기능 및 연결 구조를 파악하기 위한 대용량 데이터 분석처리가 가능하다. 이는 실제 과학응용 분야에서 요구되는 작업 환경을 적용한 대표적인 사례로 향후, 다양한 과학응용분야에 확장되어 적용되어 질 수 있다.</P>"
        },
        {
          "rank": 32,
          "score": 0.6041208505630493,
          "doc_id": "JAKO201721961719817",
          "title": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법",
          "abstract": "제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721961719817&target=NART&cn=JAKO201721961719817",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다."
        },
        {
          "rank": 33,
          "score": 0.6039777994155884,
          "doc_id": "ART002483857",
          "title": "Deep Learning in MR Image Processing",
          "abstract": "Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002483857&target=NART&cn=ART002483857",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Deep Learning in MR Image Processing Deep Learning in MR Image Processing Deep Learning in MR Image Processing Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications."
        },
        {
          "rank": 34,
          "score": 0.6030687689781189,
          "doc_id": "JAKO202514154005683",
          "title": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구",
          "abstract": "본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514154005683&target=NART&cn=JAKO202514154005683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 RAG 시스템 성능 평가를 위한 자동 데이터 셋 생성 프레임워크 비교 분석 연구 본 논문은 최근 주목받고 있는 검색 증강 생성(RAG) 시스템의 성능 평가를 위한 테스트 데이터셋 생성 방법을 비교 분석하였다. 대규모 언어 모델(LLM)의 한계를 극복하는 RAG 기술의 필요성과 중요성을 설명하고, 수동 생성 방식과 LLM을 활용한 자동 생성 방식의 특징과 장단점을 정리하였다. 또한 자동화된 데이터셋 구축 프레임워크 중 RAGAS, AutoRAG, DeepEval을 선정하여 의료,금융,법률 문서를 입력으로 각각 100개의 질문-답변 세트를 생성한 후 정확성을 평가하였다. 평가 결과, AutoRAG가 한국어 문장 표현의 자연성과 컨텍스트 기반의 정확성 측면에서 가장 뛰어난 성능을 보였으며, RAGAS는 문서 처리 과정에서 불필요한 정보 포함 등의 오류가 많았고, DeepEval은 한국어 지원 부족으로 인해 성능이 상대적으로 낮았다. 향후 연구에서는 LLM을 활용하여 사용자의 의도와 컨텍스트를 더욱 정확히 반영하는 고급 프롬프팅 기법과 자동화된 데이터 품질 평가 및 개선 전략을 중점적으로 탐색할 계획이다."
        },
        {
          "rank": 35,
          "score": 0.602723240852356,
          "doc_id": "DIKO0013392225",
          "title": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구",
          "abstract": "오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013392225&target=NART&cn=DIKO0013392225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다."
        },
        {
          "rank": 36,
          "score": 0.6016919612884521,
          "doc_id": "JAKO202023258047197",
          "title": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로",
          "abstract": "최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202023258047197&target=NART&cn=JAKO202023258047197",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 보편적 빅데이터와 빅데이터 교육의 방향성 연구 - 빅데이터 전문가의 인식 조사를 기반으로 최근 데이터 관련 법안이 개정되면서 빅데이터의 활용 분야는 점차 확장되고 있으며, 빅데이터 교육에 대한 관심이 증가하고 있다. 그러나 빅데이터를 활용하기 위해서는 높은 수준의 지식과 스킬이 필요하고, 이를 모두 교육하기에는 오랜 시간과 많은 비용이 소요된다. 이에 본 연구를 통해 산업 현장에서 사용되는 광범위한 영역의 빅데이터를 보편적 빅데이터(Universal Big Data)로 정의하고, 대학교 수준에서 보편적 빅데이터를 교육하기 위해서 중점적으로 교육해야 할 지식 영역을 산출하고자 한다. 이를 위해 빅데이터 관련 산업에 종사하는 전문인력을 구분하기 위한 기준을 마련하고, 설문 조사를 통해 빅데이터에 대한 인식을 조사했다. 조사 결과에 의하면 전문가들은 컴퓨터과학에서 의미하는 빅데이터보다 광범위한 범위의 데이터를 빅데이터로 인식하고 있었으며, 빅데이터의 가공 과정에 반드시 빅데이터 처리 프레임워크 또는 고성능 컴퓨터가 필요한 것은 아니라고 인식하고 있었다. 이는 빅데이터를 교육하기 위해서는 컴퓨터과학(공학)적 지식과 스킬보다는 빅데이터의 분석 방법과 응용 방법을 중심으로 교육해야 한다는 것을 의미한다. 분석 결과를 바탕으로 본 논문에서는 보편적 빅데이터 교육을 위한 새로운 패러다임을 제안하고자 한다."
        },
        {
          "rank": 37,
          "score": 0.6016800999641418,
          "doc_id": "JAKO202404861570801",
          "title": "인공지능과 빅데이터가 회계 관행의 발전에 미친 영향: 기회와 과제",
          "abstract": "정보 기술의 급속한 발전에 따라 인공지능과 빅데이터는 효율성, 정확성 및 의사 결정 능력을 향상시켜 금융, 의료 및 물류와 같은 산업을 변화시키고 있다. 회계는 중요한 경제 활동으로서 효과적인 재무 데이터 처리에 크게 의존한다. 인공지능 기술과 빅데이터 분석을 도입함으로써 회계업계는 대형 데이터 세트를 효과적으로 처리하고 위험을 식별하며 재무 결정을 지원하고 데이터 정확성을 높일 수 있다. 이 글은 인공지능과 빅데이터가 회계 분야에 미치는 영향을 중점적으로 탐구하고 그들이 미래에 가져올 수 있는 기회와 도전, 그리고 변화하는 수요에 적응하는 전략을 탐구한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202404861570801&target=NART&cn=JAKO202404861570801",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능과 빅데이터가 회계 관행의 발전에 미친 영향: 기회와 과제 인공지능과 빅데이터가 회계 관행의 발전에 미친 영향: 기회와 과제 인공지능과 빅데이터가 회계 관행의 발전에 미친 영향: 기회와 과제 정보 기술의 급속한 발전에 따라 인공지능과 빅데이터는 효율성, 정확성 및 의사 결정 능력을 향상시켜 금융, 의료 및 물류와 같은 산업을 변화시키고 있다. 회계는 중요한 경제 활동으로서 효과적인 재무 데이터 처리에 크게 의존한다. 인공지능 기술과 빅데이터 분석을 도입함으로써 회계업계는 대형 데이터 세트를 효과적으로 처리하고 위험을 식별하며 재무 결정을 지원하고 데이터 정확성을 높일 수 있다. 이 글은 인공지능과 빅데이터가 회계 분야에 미치는 영향을 중점적으로 탐구하고 그들이 미래에 가져올 수 있는 기회와 도전, 그리고 변화하는 수요에 적응하는 전략을 탐구한다."
        },
        {
          "rank": 38,
          "score": 0.6014989614486694,
          "doc_id": "JAKO201734158606474",
          "title": "제조업의 심층신경망 기계학습(딥러닝)",
          "abstract": "인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734158606474&target=NART&cn=JAKO201734158606474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 제조업의 심층신경망 기계학습(딥러닝) 인공지능 특히 심층신경망기계학습기법(딥러닝)의 제조업분야에서의 이용이 효율적이며 실용적일 수 있다는 인식이 넓게 수용되고 있다 이 보고서는 최근의 신경망기계학습 개발환경을 개관하고 제조업분야에서 활용되고 있는 딥 러닝기술을 개관한다."
        },
        {
          "rank": 39,
          "score": 0.5988951921463013,
          "doc_id": "NART99920153",
          "title": "Big data management in healthcare: Adoption challenges and implications",
          "abstract": "<P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART99920153&target=NART&cn=NART99920153",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications Big data management in healthcare: Adoption challenges and implications <P><B>Abstract</B></P>  <P>The computerized healthcare information system has undergone tremendous advancements in the previous two decades. Medical institutions are paying further attention to the replacement of traditional approaches that can no longer handle the increasing amount of patient data. In recent years, the healthcare information system based on big data has been growing rapidly and is being adapted to medical information to derive important health trends and support timely preventive care. This research aims to evaluate organization-driven barriers in implementing a healthcare information system based on big data. It adopts the analytic network process approach to determine the aspect weight and applies VlseKriterijumska Optimizacija I Kzompromisno Resenje (VIKOR) to conclude a highly appropriate strategy for overcoming such barriers. The proposed model can provide hospital managers with forecasts and implications that facilitate the withdrawal of organizational barriers when adopting the healthcare information system based on big data into their healthcare service system. Results can provide benefits for increasing the effectiveness and quality of the healthcare information system based on big data in the healthcare industry. Therefore, by understanding the sequence of the importance of resistance factors, managers can formulate efficient strategies to solve problems with appropriate priorities.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Barriers to big data development in medical institutions were perceived. </LI> <LI>  A framework of medical big data barriers was constructed. </LI> <LI>  Solid suggestions toward the removal of barriers to big data implementation. </LI> </UL> </P>"
        },
        {
          "rank": 40,
          "score": 0.5985952615737915,
          "doc_id": "JAKO202307361686821",
          "title": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰",
          "abstract": "Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202307361686821&target=NART&cn=JAKO202307361686821",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 허혈성 뇌졸중의 진단, 치료 및 예후 예측에 대한 기계 학습의 응용: 서술적 고찰 Stroke is a leading cause of disability and death. The condition requires prompt diagnosis and treatment. The quality of care provided to patients with stroke can vary depending on the availability of medical resources, which in turn, can affect prognosis. Recently, there has been growing interest in using machine learning (ML) to support stroke diagnosis and treatment decisions based on large medical data sets. Current ML applications in stroke care can be divided into two categories: analysis of neuroimaging data and clinical information-based predictive models. Using ML to analyze neuroimaging data can increase the efficiency and accuracy of diagnoses. Commercial software that uses ML algorithms is already being used in the medical field. Additionally, the accuracy of predictive ML models is improving with the integration of radiomics and clinical data. is expected to be important for improving the quality of care for patients with stroke."
        },
        {
          "rank": 41,
          "score": 0.5982154607772827,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 42,
          "score": 0.598182737827301,
          "doc_id": "JAKO201452057196583",
          "title": "빅데이터 지식처리 인공지능 기술동향",
          "abstract": "최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201452057196583&target=NART&cn=JAKO201452057196583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 빅데이터 지식처리 인공지능 기술동향 최근의 플랫폼 기술동향은 웹 기반 혹은 단순 의사소통이 가능한 모바일 플랫폼에서 빅데이터와 인공지능기술이 접목되면서 심층 질의응답이 가능한 차세대 지능형 지식처리 플랫폼으로의 진화가 진행 중이다. 선진국에서는 국가 차원 혹은 글로벌 기업의 주도하에 대형 장기 프로젝트가 진행 중이다. 국가 주도의 프로젝트로는 미국의 PAL, 유럽의 Human Brain, 일본의 Todai 프로젝트가 대표적인 예이며, 글로벌 기업의 경우는 IBM의 Watson, Google의 Knowledge Graph, Apple의 Sir가 대표적인 예이다. 본고에서는 차세대 지능형 플랫폼의 핵심기술인 인간과 기계의 지식소통을 위한 빅데이터 기반의 지식처리 인공지능 소프트웨어 기술의 개념과 국내외 기술 및 산업, 지식재산권 동향 등을 살펴보고 산업계 활용방안 및 발전방향에 대해 논하고자 한다."
        },
        {
          "rank": 43,
          "score": 0.5974445939064026,
          "doc_id": "JAKO202514057605142",
          "title": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구",
          "abstract": "분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202514057605142&target=NART&cn=JAKO202514057605142",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템 연구 분산 시스템은 대규모 데이터 처리의 한계를 극복하며, 기존 중앙 집중형 시스템의 성능 저하와 자원 비효율 문제를 해결한다. 특히 대규모 로그 분석은 시스템 운영 상태, 성능 최적화 등 다양한 분야에서 활용된다. 하둡은 분산 처리 분야의 주요 도구이며, 맵리듀스는 데이터를 병렬 처리하고, HDFS는 높은 확장성과 내결함성을 제공한다. 이러한 특징 덕분에 하둡은 대규모 로그 데이터의 효율적인 처리 및 분석에 적합하다. 최근 IT 플랫폼들은 대규모 분산 환경에서 운영됨에 따라 로그 데이터의 양이 기하급수적으로 증가한다. 이로 인한 로그의 급격한 증가는 고수준의 빅데이터 분석 기술을 요구하며, CPU와 메모리 사용 시간 및 메모리 사용량 증가, 처리 속도 지연을 야기한다. 이에 본 논문에서는 대규모 로그 데이터 분석을 위한 패턴화 압축 기반 빅데이터 처리 시스템을 제안한다. 제안하는 시스템은 데이터 압축 기술을 활용하여 자원 사용시간 및 사용량을 감소시키고 처리 속도를 향상시킨다. 성능 평가 결과, CPU 사용량은 기존 대비 78.8%, 메모리 사용 시간은 65%, 메모리 사용량 6.2%, 처리 시간은 80% 감소하며 향상된 성능을 보인다. 향후 본 연구를 기반으로 다양한 데이터 구조에서의 패턴화 압축 알고리즘을 적용한 실질적인 검증이 필요하다."
        },
        {
          "rank": 44,
          "score": 0.5973745584487915,
          "doc_id": "JAKO201924064455520",
          "title": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용",
          "abstract": "Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201924064455520&target=NART&cn=JAKO201924064455520",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 트랜잭션 기반 머신러닝에서 특성 추출 자동화를 위한 딥러닝 응용 Machine learning (ML) is a method of fitting given data to a mathematical model to derive insights or to predict. In the age of big data, where the amount of available data increases exponentially due to the development of information technology and smart devices, ML shows high prediction performance due to pattern detection without bias. The feature engineering that generates the features that can explain the problem to be solved in the ML process has a great influence on the performance and its importance is continuously emphasized. Despite this importance, however, it is still considered a difficult task as it requires a thorough understanding of the domain characteristics as well as an understanding of source data and the iterative procedure. Therefore, we propose methods to apply deep learning for solving the complexity and difficulty of feature extraction and improving the performance of ML model. Unlike other techniques, the most common reason for the superior performance of deep learning techniques in complex unstructured data processing is that it is possible to extract features from the source data itself. In order to apply these advantages to the business problems, we propose deep learning based methods that can automatically extract features from transaction data or directly predict and classify target variables. In particular, we applied techniques that show high performance in existing text processing based on the structural similarity between transaction data and text data. And we also verified the suitability of each method according to the characteristics of transaction data. Through our study, it is possible not only to search for the possibility of automated feature extraction but also to obtain a benchmark model that shows a certain level of performance before performing the feature extraction task by a human. In addition, it is expected that it will be able to provide guidelines for choosing a suitable deep learning model based on the business problem and the data characteristics."
        },
        {
          "rank": 45,
          "score": 0.5972479581832886,
          "doc_id": "JAKO201402755362891",
          "title": "다각도 정보융합 방법을 이용한 지능형 에이전트 시스템",
          "abstract": "본 논문에서는 데이터마이닝모듈과 정보융합모듈을 핵심구성요소로 가지는 지능형에이전트 시스템을 설계하고 다각도 정보를 융합하여 진단전문가시스템으로 활용할 수 있는 가능성을 제시한다. 데이터마이닝모듈에서는 퍼지신경망 OFUN-NET에 의하여 다각도의 데이터를 분석하고 퍼지 클러스터 정보를 지식베이스로 구축한다. 정보융합모듈과 응용모듈에서는 가능성정도로 제공되는 진단결과와 불확실 결정상태나 비대칭의 발견과 같은 전문가의 진단에 유용한 정보를 제공해 주고 있다. 또한 DDSM 벤치마크 데이터베이스로부터 획득한 디지털 유방 x선 영상의 BI-RADS 기반 특징데이터를 가지고 실험한 결과는 기존의 방법보다 높은 분류 정확도를 보여주면서 컴퓨터보조진단시스템으로서의 가능성을 보여주고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201402755362891&target=NART&cn=JAKO201402755362891",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다각도 정보융합 방법을 이용한 지능형 에이전트 시스템 다각도 정보융합 방법을 이용한 지능형 에이전트 시스템 다각도 정보융합 방법을 이용한 지능형 에이전트 시스템 본 논문에서는 데이터마이닝모듈과 정보융합모듈을 핵심구성요소로 가지는 지능형에이전트 시스템을 설계하고 다각도 정보를 융합하여 진단전문가시스템으로 활용할 수 있는 가능성을 제시한다. 데이터마이닝모듈에서는 퍼지신경망 OFUN-NET에 의하여 다각도의 데이터를 분석하고 퍼지 클러스터 정보를 지식베이스로 구축한다. 정보융합모듈과 응용모듈에서는 가능성정도로 제공되는 진단결과와 불확실 결정상태나 비대칭의 발견과 같은 전문가의 진단에 유용한 정보를 제공해 주고 있다. 또한 DDSM 벤치마크 데이터베이스로부터 획득한 디지털 유방 x선 영상의 BI-RADS 기반 특징데이터를 가지고 실험한 결과는 기존의 방법보다 높은 분류 정확도를 보여주면서 컴퓨터보조진단시스템으로서의 가능성을 보여주고 있다."
        },
        {
          "rank": 46,
          "score": 0.5968248844146729,
          "doc_id": "JAKO201419553341501",
          "title": "빅데이터 산업 활성화 전략 연구",
          "abstract": "본 연구는 빅데이터 생태계의 개념 및 구성요소의 역할과 책임을 파악하여 빅데이터 산업이 활성화되기 위해서 필요한 전략을 도출하였다. 빅데이터 생태계의 구성요소는 거버넌스, 데이터 보유자, 서비스 이용자, 서비스 제공자, 인프라 제공자로 5개 구분하였다. 5개의 구성요소 간 역할과 책임을 통해 총 11개의 활성화 전략을 도출하였다. 또한 빅데이터 산업 활성화를 위해 선행연구자들이 주장한 내용을 요약 정리하여 총 12개의 활성화 방안을 제시하였다. 빅데이터 구성요소 간 활성화방안과 선행연구자들이 주장한 내용을 결합하여 본 연구에서 총 13개의 빅데이터 산업의 활성화 전략을 제시하였다. 본 연구에서 제시한 빅데이터 산업 활성화 전략이 빅데이터 사업 및 정책방향과 계획 수립의 기본자료로 활용되기 위하여 빅데이터 산업 활성화에 긍정적인 영향을 제공할 것으로 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201419553341501&target=NART&cn=JAKO201419553341501",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 산업 활성화 전략 연구 빅데이터 산업 활성화 전략 연구 빅데이터 산업 활성화 전략 연구 본 연구는 빅데이터 생태계의 개념 및 구성요소의 역할과 책임을 파악하여 빅데이터 산업이 활성화되기 위해서 필요한 전략을 도출하였다. 빅데이터 생태계의 구성요소는 거버넌스, 데이터 보유자, 서비스 이용자, 서비스 제공자, 인프라 제공자로 5개 구분하였다. 5개의 구성요소 간 역할과 책임을 통해 총 11개의 활성화 전략을 도출하였다. 또한 빅데이터 산업 활성화를 위해 선행연구자들이 주장한 내용을 요약 정리하여 총 12개의 활성화 방안을 제시하였다. 빅데이터 구성요소 간 활성화방안과 선행연구자들이 주장한 내용을 결합하여 본 연구에서 총 13개의 빅데이터 산업의 활성화 전략을 제시하였다. 본 연구에서 제시한 빅데이터 산업 활성화 전략이 빅데이터 사업 및 정책방향과 계획 수립의 기본자료로 활용되기 위하여 빅데이터 산업 활성화에 긍정적인 영향을 제공할 것으로 기대한다."
        },
        {
          "rank": 47,
          "score": 0.5966593623161316,
          "doc_id": "JAKO201810038012250",
          "title": "바이오센싱 융합 빅데이터 컴퓨팅 아키텍처",
          "abstract": "생체정보 컴퓨팅은 생체신호 센서와 컴퓨터 정보처리를 융합한 정보시스템에 기초하여 컴퓨팅시스템 뿐만 아니라 빅데이터 시스템에 크게 영향을 미치고 있다. 이러한 생체정보는 지금까지의 텍스트, 이미지, 동영상 등의 전통적인 데이터 형식과는 달리 생체신호의 의미를 부여하는 값은 텍스트 기반으로 표현되고, 중요한 이벤트 순간은 이미지 형식으로 저장하며, 시계열 분석을 통한 데이터 변화 예측 및 분석을 위해서는 동영상 형식 등 비정형데이터를 포함하는 복합적인 데이터 형식을 구성한다. 이러한 복합적인 데이터 구성은 개별 생체정보 응용서비스에서 요구하는 데이터의 특징에 따라 텍스트, 이미지, 영상 형식 등으로 각각 분리되어 요청되거나, 상황에 따라 복잡 데이터 형식을 동시에 요구할 수 있다. 기존 생체정보 컴퓨팅 시스템들은 전통적인 컴퓨팅 구성요소, 컴퓨팅 구조, 데이터 처리 방법 등에 의존하므로 데이터 처리성능, 전송능력, 저장효율성, 시스템안전성 등의 측면에서 많은 비효율성을 내포하고 있다. 본 연구에서는 생체정보 처리 컴퓨팅을 효과적으로 지원하는 생체정보 빅데이터 플랫폼을 구축하기 위해 개선된 바이오센싱 융합 빅데이터 컴퓨팅 아키텍처를 제안한다. 제안 아키텍처는 생체신호관련 데이터의 저장 및 전송 효율성, 컴퓨팅 성능, 시스템 안정성 등을 효과적으로 지원하며, 향후 생체정보 컴퓨팅에 최적화된 시스템 구현 및 생체정보 서비스 구축을 위한 기반을 제공할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810038012250&target=NART&cn=JAKO201810038012250",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "바이오센싱 융합 빅데이터 컴퓨팅 아키텍처 바이오센싱 융합 빅데이터 컴퓨팅 아키텍처 바이오센싱 융합 빅데이터 컴퓨팅 아키텍처 생체정보 컴퓨팅은 생체신호 센서와 컴퓨터 정보처리를 융합한 정보시스템에 기초하여 컴퓨팅시스템 뿐만 아니라 빅데이터 시스템에 크게 영향을 미치고 있다. 이러한 생체정보는 지금까지의 텍스트, 이미지, 동영상 등의 전통적인 데이터 형식과는 달리 생체신호의 의미를 부여하는 값은 텍스트 기반으로 표현되고, 중요한 이벤트 순간은 이미지 형식으로 저장하며, 시계열 분석을 통한 데이터 변화 예측 및 분석을 위해서는 동영상 형식 등 비정형데이터를 포함하는 복합적인 데이터 형식을 구성한다. 이러한 복합적인 데이터 구성은 개별 생체정보 응용서비스에서 요구하는 데이터의 특징에 따라 텍스트, 이미지, 영상 형식 등으로 각각 분리되어 요청되거나, 상황에 따라 복잡 데이터 형식을 동시에 요구할 수 있다. 기존 생체정보 컴퓨팅 시스템들은 전통적인 컴퓨팅 구성요소, 컴퓨팅 구조, 데이터 처리 방법 등에 의존하므로 데이터 처리성능, 전송능력, 저장효율성, 시스템안전성 등의 측면에서 많은 비효율성을 내포하고 있다. 본 연구에서는 생체정보 처리 컴퓨팅을 효과적으로 지원하는 생체정보 빅데이터 플랫폼을 구축하기 위해 개선된 바이오센싱 융합 빅데이터 컴퓨팅 아키텍처를 제안한다. 제안 아키텍처는 생체신호관련 데이터의 저장 및 전송 효율성, 컴퓨팅 성능, 시스템 안정성 등을 효과적으로 지원하며, 향후 생체정보 컴퓨팅에 최적화된 시스템 구현 및 생체정보 서비스 구축을 위한 기반을 제공할 수 있다."
        },
        {
          "rank": 48,
          "score": 0.5965393781661987,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 49,
          "score": 0.5964645743370056,
          "doc_id": "NPAP12636301",
          "title": "Application Plan of Big Data and NoSQL",
          "abstract": "오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12636301&target=NART&cn=NPAP12636301",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL Application Plan of Big Data and NoSQL 오랜 기간 동안, 관계형 데이터베이스는 많은 기업에서 널리 사용되어왔다. 데이터베이스의 표준모형으로서, 데이터 저장과 동시성 제어에서의 뛰어난 영향에도 불구하고, 객체와 관계에서의 불일치에 있어서는 단점이 존재한다. 이러한 배경을 극복하기 위해서, 스키마가 없이도 작동하는 빅 데이터를 위한 새로운 해결책으로 NoSQL이 부각되고 있다. 본 논문에서는 관계형 데이터베이스의 장단점뿐만 아니라, 애플리케이션 데이터베이스와 통합 데이터베이스 간의 비교를 연구하려고 한다. 그리고, 빅데이터를 위한 NoSQL을 정의하고 그 특징을 살펴보겠다."
        },
        {
          "rank": 50,
          "score": 0.5960376262664795,
          "doc_id": "ATN0037461993",
          "title": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법",
          "abstract": "This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037461993&target=NART&cn=ATN0037461993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 이기종 빅데이터 분석을 위한 Spark 기반 join 기법 This paper studies in data virtualization, which logically integrate the distributed heterogeneous databases into a single DBMS, to discuss the implementation method of the data virtualization system for big data analysis. Depending on big data saved in the target heterogeneous DBMS tables are analytical purposes, run the query, but must implement a schema to navigate, inter wherein a large record table join processing is applied to the key. Adopting the system configuration of the Spark base through the join performance comparison test of Spark and Hive in order to achieve the goal, ace editor and tajo sql, by applying such as queries converter, an implementation of the schema browser. Thus, it was possible to ensure the technique of data virtualization system for big data analysis."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}