{
  "id": "row_000002",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:32.305067+09:00",
  "trial_id": "9f960605",
  "queries": [
    {
      "query": "How do artificial neural networks employ weight matrices and vector mappings to relate inputs and outputs in applied linguistics?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7814559936523438,
          "doc_id": "ART002391816",
          "title": "Artificial Intelligence, Language Intelligence, and Mathematics",
          "abstract": "Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002391816&target=NART&cn=ART002391816",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication."
        },
        {
          "rank": 2,
          "score": 0.7529453039169312,
          "doc_id": "ATN0053123228",
          "title": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS",
          "abstract": "<jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0053123228&target=NART&cn=ATN0053123228",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS <jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>"
        },
        {
          "rank": 3,
          "score": 0.6893520951271057,
          "doc_id": "JAKO200211921413494",
          "title": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망",
          "abstract": "본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921413494&target=NART&cn=JAKO200211921413494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.6769601106643677,
          "doc_id": "JAKO202125659009583",
          "title": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석",
          "abstract": "전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659009583&target=NART&cn=JAKO202125659009583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다."
        },
        {
          "rank": 5,
          "score": 0.6678385734558105,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 6,
          "score": 0.6651432514190674,
          "doc_id": "ART002543005",
          "title": "Comparison of Weight Initialization Techniques for Deep Neural Networks",
          "abstract": "Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002543005&target=NART&cn=ART002543005",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration."
        },
        {
          "rank": 7,
          "score": 0.6624540090560913,
          "doc_id": "NART12793683",
          "title": "Approximating vertical vector fields for feedforward neural networks",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART12793683&target=NART&cn=NART12793683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks <P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>"
        },
        {
          "rank": 8,
          "score": 0.6559470891952515,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 9,
          "score": 0.6557213068008423,
          "doc_id": "NART18014750",
          "title": "Neural nets and hidden Markov models: Review and generalizations",
          "abstract": "Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18014750&target=NART&cn=NART18014750",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs)."
        },
        {
          "rank": 10,
          "score": 0.6552073955535889,
          "doc_id": "ATN0030166808",
          "title": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법",
          "abstract": "인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030166808&target=NART&cn=ATN0030166808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다."
        },
        {
          "rank": 11,
          "score": 0.6510911583900452,
          "doc_id": "NART32653959",
          "title": "Integrating support vector machines and neural networks",
          "abstract": "<P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART32653959&target=NART&cn=NART32653959",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating support vector machines and neural networks Integrating support vector machines and neural networks Integrating support vector machines and neural networks <P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>"
        },
        {
          "rank": 12,
          "score": 0.6499476432800293,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 13,
          "score": 0.6491698026657104,
          "doc_id": "JAKO202128557368138",
          "title": "인공지능을 활용한 기계학습 앙상블 모델 개발",
          "abstract": "To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128557368138&target=NART&cn=JAKO202128557368138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database."
        },
        {
          "rank": 14,
          "score": 0.6481402516365051,
          "doc_id": "ART002967567",
          "title": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks",
          "abstract": "Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002967567&target=NART&cn=ART002967567",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation."
        },
        {
          "rank": 15,
          "score": 0.643606424331665,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 16,
          "score": 0.6428570747375488,
          "doc_id": "JAKO200011920771446",
          "title": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축",
          "abstract": "본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771446&target=NART&cn=JAKO200011920771446",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다."
        },
        {
          "rank": 17,
          "score": 0.6428464651107788,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 18,
          "score": 0.6423441171646118,
          "doc_id": "NART07374155",
          "title": "Artificial neural networks as applied to long-term demand forecasting",
          "abstract": "<P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART07374155&target=NART&cn=NART07374155",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting <P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>"
        },
        {
          "rank": 19,
          "score": 0.6403138637542725,
          "doc_id": "DIKO0008264256",
          "title": "부스팅을 이용한 서포트벡터 머신의 분류",
          "abstract": "본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0008264256&target=NART&cn=DIKO0008264256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다."
        },
        {
          "rank": 20,
          "score": 0.640205442905426,
          "doc_id": "JAKO200011920771131",
          "title": "은닉지식 추출을 이용한 신경망회로망 정제",
          "abstract": "신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771131&target=NART&cn=JAKO200011920771131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다."
        },
        {
          "rank": 21,
          "score": 0.6398772597312927,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 22,
          "score": 0.6389762163162231,
          "doc_id": "JAKO201707851605473",
          "title": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표",
          "abstract": "본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201707851605473&target=NART&cn=JAKO201707851605473",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다."
        },
        {
          "rank": 23,
          "score": 0.6379027366638184,
          "doc_id": "JAKO199911921383665",
          "title": "회귀신경망을 이용한 음성인식에 관한 연구",
          "abstract": "본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921383665&target=NART&cn=JAKO199911921383665",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다."
        },
        {
          "rank": 24,
          "score": 0.6354843378067017,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 25,
          "score": 0.6352871656417847,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 26,
          "score": 0.6348820924758911,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 27,
          "score": 0.6340254545211792,
          "doc_id": "NART56157711",
          "title": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식",
          "abstract": "<P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157711&target=NART&cn=NART56157711",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 <P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>"
        },
        {
          "rank": 28,
          "score": 0.6335963606834412,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        },
        {
          "rank": 29,
          "score": 0.6334680318832397,
          "doc_id": "ART002606556",
          "title": "Influence of random topology in artificial neural networks: A survey",
          "abstract": "Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002606556&target=NART&cn=ART002606556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures."
        },
        {
          "rank": 30,
          "score": 0.6328898668289185,
          "doc_id": "NART75359998",
          "title": "Artificial Neural Networks Applied to Image Steganography",
          "abstract": "<P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75359998&target=NART&cn=NART75359998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography <P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>"
        },
        {
          "rank": 31,
          "score": 0.6324948668479919,
          "doc_id": "ART002675389",
          "title": "딥러닝 기반 자연어 처리에서 도메인 지식의 역할",
          "abstract": "Symbolic AI에서는 도메인 지식이 중요시되었다. 규칙 기반 자연어처리에서도 언어학적 지식이 중요한 역할을 담당했다. 확률 기반 자연어처리와 기계학습 기법이 발달하면서 도메인 지식의 역할은 축소되었다. 딥러닝이 대두하면서, 자질 공학과 도메인 지식의 역할은 훨씬 더 축소되었다. 딥러닝 시대에도 여전히 도메인 전문가(언어학자)의 역할이 중요함을 증명하기 위해 한국어 형태소분석기를 개발하였다. 한국어는 형태음소적 교체, 탈락, 축약이 활발하여 분절 과제가 쉽지 않지만, 분절 과제를 분류 문제로 재설정하면 기계학습으로 더 쉽게 해결할 수 있게 된다. 이를 위해서는 분절 이전의 입력의 각 음절과 분절된 출력의 대응하는 문자열 사이의 매핑 관계를 망라적으로 목록화하는 것이 관건이다. 1200만 어절 규모의 세종 형태의미 분석 말뭉치를 통해 이러한 매핑에 200개 유형이 있음을 확인하였다. 이 200개 범주를 바탕으로 LSTM 기반 신경망 모델을 만들어 훈련시켰다. 분절 문제가 해결되면, 분절된 각 토큰에 대한 레이블링은, 영어 등에 대한 선행 연구로 친숙한 연쇄 레이블링 알고리즘으로 쉽게 해결할 수 있다. 이 두 가지 모델과 사전을 결합하여, F1 스코어 98.0%의 성능을 얻을 수 있었다. 이 실험은 딥러닝 시대에도 도메인 지식이 여전히 중요함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002675389&target=NART&cn=ART002675389",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 자연어 처리에서 도메인 지식의 역할 딥러닝 기반 자연어 처리에서 도메인 지식의 역할 딥러닝 기반 자연어 처리에서 도메인 지식의 역할 Symbolic AI에서는 도메인 지식이 중요시되었다. 규칙 기반 자연어처리에서도 언어학적 지식이 중요한 역할을 담당했다. 확률 기반 자연어처리와 기계학습 기법이 발달하면서 도메인 지식의 역할은 축소되었다. 딥러닝이 대두하면서, 자질 공학과 도메인 지식의 역할은 훨씬 더 축소되었다. 딥러닝 시대에도 여전히 도메인 전문가(언어학자)의 역할이 중요함을 증명하기 위해 한국어 형태소분석기를 개발하였다. 한국어는 형태음소적 교체, 탈락, 축약이 활발하여 분절 과제가 쉽지 않지만, 분절 과제를 분류 문제로 재설정하면 기계학습으로 더 쉽게 해결할 수 있게 된다. 이를 위해서는 분절 이전의 입력의 각 음절과 분절된 출력의 대응하는 문자열 사이의 매핑 관계를 망라적으로 목록화하는 것이 관건이다. 1200만 어절 규모의 세종 형태의미 분석 말뭉치를 통해 이러한 매핑에 200개 유형이 있음을 확인하였다. 이 200개 범주를 바탕으로 LSTM 기반 신경망 모델을 만들어 훈련시켰다. 분절 문제가 해결되면, 분절된 각 토큰에 대한 레이블링은, 영어 등에 대한 선행 연구로 친숙한 연쇄 레이블링 알고리즘으로 쉽게 해결할 수 있다. 이 두 가지 모델과 사전을 결합하여, F1 스코어 98.0%의 성능을 얻을 수 있었다. 이 실험은 딥러닝 시대에도 도메인 지식이 여전히 중요함을 보여준다."
        },
        {
          "rank": 32,
          "score": 0.6307704448699951,
          "doc_id": "NART53843256",
          "title": "Neural development of networks for audiovisual speech comprehension",
          "abstract": "<P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53843256&target=NART&cn=NART53843256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension <P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>"
        },
        {
          "rank": 33,
          "score": 0.6304844617843628,
          "doc_id": "JAKO201734964189755",
          "title": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식",
          "abstract": "본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734964189755&target=NART&cn=JAKO201734964189755",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다."
        },
        {
          "rank": 34,
          "score": 0.6294748783111572,
          "doc_id": "NART56157538",
          "title": "확장된 ART 인공 신경망",
          "abstract": "<P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157538&target=NART&cn=NART56157538",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "확장된 ART 인공 신경망 확장된 ART 인공 신경망 확장된 ART 인공 신경망 <P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>"
        },
        {
          "rank": 35,
          "score": 0.6293948292732239,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 36,
          "score": 0.6288651823997498,
          "doc_id": "JAKO201719951669089",
          "title": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링",
          "abstract": "This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201719951669089&target=NART&cn=JAKO201719951669089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method."
        },
        {
          "rank": 37,
          "score": 0.6288609504699707,
          "doc_id": "NART95825020",
          "title": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition",
          "abstract": "<P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95825020&target=NART&cn=NART95825020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition <P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>"
        },
        {
          "rank": 38,
          "score": 0.628754198551178,
          "doc_id": "JAKO201429548810226",
          "title": "불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법",
          "abstract": "필기체 낱글자 인식을 위해서 사용되는 데이터는 일반적으로 다수의 사용자들로부터 수집된 자연언어 문장들을 이용하기 때문에 해당 언어의 언어적 특성에 따라서 낱글자의 종류별 개수 차이가 매우 큰 특징이 있다. 일반적인 기계학습 문제에서 학습데이터의 불균형 문제는 성능을 저하시키는 중요한 요인으로 작용하지만, 필기체 인식에서는 데이터 자체의 높은 분산과 비슷한 모양의 낱글자 등이 성능 저하의 주요인이라 생각하기 때문에 이를 크게 고려하지 않고 있다. 본 논문에서는 이러한 데이터의 불균형 문제를 고려하여 필기체 인식기의 성능을 향상시킬 수 있는 과표본화 기반의 앙상블 학습 기법을 제안한다. 제안한 방법은 데이터의 불균형 문제를 고려하지 않은 방법보다 전체적으로 향상된 성능을 보일 뿐만 아니라 데이터의 개수가 부족한 낱글자들의 분류성능에 있어서도 향상된 결과를 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201429548810226&target=NART&cn=JAKO201429548810226",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 필기체 낱글자 인식을 위해서 사용되는 데이터는 일반적으로 다수의 사용자들로부터 수집된 자연언어 문장들을 이용하기 때문에 해당 언어의 언어적 특성에 따라서 낱글자의 종류별 개수 차이가 매우 큰 특징이 있다. 일반적인 기계학습 문제에서 학습데이터의 불균형 문제는 성능을 저하시키는 중요한 요인으로 작용하지만, 필기체 인식에서는 데이터 자체의 높은 분산과 비슷한 모양의 낱글자 등이 성능 저하의 주요인이라 생각하기 때문에 이를 크게 고려하지 않고 있다. 본 논문에서는 이러한 데이터의 불균형 문제를 고려하여 필기체 인식기의 성능을 향상시킬 수 있는 과표본화 기반의 앙상블 학습 기법을 제안한다. 제안한 방법은 데이터의 불균형 문제를 고려하지 않은 방법보다 전체적으로 향상된 성능을 보일 뿐만 아니라 데이터의 개수가 부족한 낱글자들의 분류성능에 있어서도 향상된 결과를 보여준다."
        },
        {
          "rank": 39,
          "score": 0.6285677552223206,
          "doc_id": "NART56157676",
          "title": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합",
          "abstract": "<P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157676&target=NART&cn=NART56157676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 <P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>"
        },
        {
          "rank": 40,
          "score": 0.6283791065216064,
          "doc_id": "JAKO201006159731627",
          "title": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구",
          "abstract": "정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201006159731627&target=NART&cn=JAKO201006159731627",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다."
        },
        {
          "rank": 41,
          "score": 0.6281463503837585,
          "doc_id": "JAKO201220962918849",
          "title": "수화 패턴 인식을 위한 2단계 신경망 모델",
          "abstract": "본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201220962918849&target=NART&cn=JAKO201220962918849",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다."
        },
        {
          "rank": 42,
          "score": 0.627324640750885,
          "doc_id": "JAKO202213649890315",
          "title": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환",
          "abstract": "스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213649890315&target=NART&cn=JAKO202213649890315",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다."
        },
        {
          "rank": 43,
          "score": 0.6260557174682617,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 44,
          "score": 0.6257791519165039,
          "doc_id": "JAKO202326257774533",
          "title": "트랜스포머 기반 효율적인 자연어 처리 방안 연구",
          "abstract": "현재의 인공지능에서 사용되는 자연어 처리 모델은 거대하여 실시간으로 데이터를 처리하고 분석하는 것은 여러가지 어려움들을 야기하고 있다. 이런 어려움을 해결하기 위한 방법으로 메모리를 적게 사용해 처리의 효율성을 개선하는 방법을 제안하고 제안된 모델의 성능을 확인하였다. 본 논문에서 제안한 모델의 성능평가를 위해 적용한 기법은 BERT[1] 모델의 어텐션 헤드 개수와 임베딩 크기를 작게 조절해 큰 말뭉치를 나눠서 분할 처리 후 출력값의 평균을 통해 결과를 산출하였다. 이 과정에서 입력 데이터의 다양성을 주기위해 매 에폭마다 임의의 오프셋을 문장에 부여하였다. 그리고 모델을 분류가 가능하도록 미세 조정하였다. 말뭉치를 분할 처리한 모델은 그렇지 않은 모델 대비 정확도가 12% 정도 낮았으나, 모델의 파라미터 개수는 56% 정도 절감되는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202326257774533&target=NART&cn=JAKO202326257774533",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜스포머 기반 효율적인 자연어 처리 방안 연구 트랜스포머 기반 효율적인 자연어 처리 방안 연구 트랜스포머 기반 효율적인 자연어 처리 방안 연구 현재의 인공지능에서 사용되는 자연어 처리 모델은 거대하여 실시간으로 데이터를 처리하고 분석하는 것은 여러가지 어려움들을 야기하고 있다. 이런 어려움을 해결하기 위한 방법으로 메모리를 적게 사용해 처리의 효율성을 개선하는 방법을 제안하고 제안된 모델의 성능을 확인하였다. 본 논문에서 제안한 모델의 성능평가를 위해 적용한 기법은 BERT[1] 모델의 어텐션 헤드 개수와 임베딩 크기를 작게 조절해 큰 말뭉치를 나눠서 분할 처리 후 출력값의 평균을 통해 결과를 산출하였다. 이 과정에서 입력 데이터의 다양성을 주기위해 매 에폭마다 임의의 오프셋을 문장에 부여하였다. 그리고 모델을 분류가 가능하도록 미세 조정하였다. 말뭉치를 분할 처리한 모델은 그렇지 않은 모델 대비 정확도가 12% 정도 낮았으나, 모델의 파라미터 개수는 56% 정도 절감되는 것을 확인하였다."
        },
        {
          "rank": 45,
          "score": 0.6251951456069946,
          "doc_id": "JAKO200734515919504",
          "title": "지역 기반 분류기의 앙상블 학습",
          "abstract": "기계학습에서 분류기틀의 집합으로 구성된 앙상블 분류기는 단일 분류기에 비해 정확도가 높다는 것이 입증되어왔다. 본 논문에서는 새로운 앙상블 학습으로서 데이터의 지역 기반 분류기들의 앙상블 학습을 제시하여 기존의 앙상블 학습과의 비교를 통해 성능을 검증하고자 한다. 지역 기반 분류기의 앙상블 학습은 데이터의 분포가 지역에 따라 다르다는 점에 착안하여 학습 데이터를 분할하여 해당하는 지역에 기반을 둔 분류기들을 만들어 나간다. 이렇게 만들어진 분류기들로부터 지역에 따라 가중치를 둔 투표를 적용하여 앙상블 방법을 이끌어낸다. 본 논문에서 제시한 앙상블 분류기의 성능평가를 위해 단일 분류기와 기존의 앙상블 분류기인 배깅과 부스팅 등을 UCI Machine Learning Repository에 있는 11개의 데이터 셋으로 정확도 비교를 하였다. 그 결과 새로운 앙상블 방법이 기본 분류기로 나이브 베이즈와 SVM을 사용했을 때 다른 방법보다 좋은 성능을 보이는 것을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200734515919504&target=NART&cn=JAKO200734515919504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지역 기반 분류기의 앙상블 학습 지역 기반 분류기의 앙상블 학습 지역 기반 분류기의 앙상블 학습 기계학습에서 분류기틀의 집합으로 구성된 앙상블 분류기는 단일 분류기에 비해 정확도가 높다는 것이 입증되어왔다. 본 논문에서는 새로운 앙상블 학습으로서 데이터의 지역 기반 분류기들의 앙상블 학습을 제시하여 기존의 앙상블 학습과의 비교를 통해 성능을 검증하고자 한다. 지역 기반 분류기의 앙상블 학습은 데이터의 분포가 지역에 따라 다르다는 점에 착안하여 학습 데이터를 분할하여 해당하는 지역에 기반을 둔 분류기들을 만들어 나간다. 이렇게 만들어진 분류기들로부터 지역에 따라 가중치를 둔 투표를 적용하여 앙상블 방법을 이끌어낸다. 본 논문에서 제시한 앙상블 분류기의 성능평가를 위해 단일 분류기와 기존의 앙상블 분류기인 배깅과 부스팅 등을 UCI Machine Learning Repository에 있는 11개의 데이터 셋으로 정확도 비교를 하였다. 그 결과 새로운 앙상블 방법이 기본 분류기로 나이브 베이즈와 SVM을 사용했을 때 다른 방법보다 좋은 성능을 보이는 것을 알 수 있었다."
        },
        {
          "rank": 46,
          "score": 0.6244461536407471,
          "doc_id": "NPAP07942137",
          "title": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP07942137&target=NART&cn=NPAP07942137",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 47,
          "score": 0.6242095828056335,
          "doc_id": "NART17510385",
          "title": "Hidden-articulator Markov models for speech recognition",
          "abstract": "<P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART17510385&target=NART&cn=NART17510385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition <P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>"
        },
        {
          "rank": 48,
          "score": 0.6241765022277832,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 49,
          "score": 0.6241329312324524,
          "doc_id": "DIKO0014782182",
          "title": "서포트 벡터 머신을 활용한 데이터 분류",
          "abstract": "현대 사회에서는 데이터가 무궁무진하게 많이 생성된다. 예를 들어 사소한 현상에서부터 큰 현상까지 인간이 인지하고 관측가능하다면 이것은 데이터가 된다. 이러한 데이터를 분석하는 것은 매우 어렵지만, 매우 중요한 부분이다. 데이터 분석중에 분류는 아주 기초적인 방법이지만, 그 효과는 확실하다. 분류의 기준을 우리가 가지고 있다면, 이후에 그러한 데이터를 분석할 때 그 기준을 만족하느냐 만족하지 못하느냐만으로도 복잡한 데이터의 양상에서 데이터의 의미를 어느정도는 알 수 있게 된다. 그 분류의 기준을 수학적으로 타당하게 설정한다면 그 기준이 데이터 분석에서 활용가능한 방법이 되게 할 수 있다. 그러한 수학적인 분류 방법에서도 가장 많이 활용되는 방법이 서포트 벡터 머신이다. 본 논문에서는 다양한 서포트 벡터 머신의 종류에 대해서 연구하는 것을 목적으로 한다. 서포트벡터머신의 여러가지 방법중에 각각의 차이점을 분석하고, 어떠한 이유에서 데이터를 분석할 때에 서포트 벡터 머신을 사용하는지 알아볼 것이다. 그리고 더 효율적으로 서포트 벡터 머신을 사용할 수 있는 방법에 대해서 알아본다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014782182&target=NART&cn=DIKO0014782182",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 머신을 활용한 데이터 분류 서포트 벡터 머신을 활용한 데이터 분류 서포트 벡터 머신을 활용한 데이터 분류 현대 사회에서는 데이터가 무궁무진하게 많이 생성된다. 예를 들어 사소한 현상에서부터 큰 현상까지 인간이 인지하고 관측가능하다면 이것은 데이터가 된다. 이러한 데이터를 분석하는 것은 매우 어렵지만, 매우 중요한 부분이다. 데이터 분석중에 분류는 아주 기초적인 방법이지만, 그 효과는 확실하다. 분류의 기준을 우리가 가지고 있다면, 이후에 그러한 데이터를 분석할 때 그 기준을 만족하느냐 만족하지 못하느냐만으로도 복잡한 데이터의 양상에서 데이터의 의미를 어느정도는 알 수 있게 된다. 그 분류의 기준을 수학적으로 타당하게 설정한다면 그 기준이 데이터 분석에서 활용가능한 방법이 되게 할 수 있다. 그러한 수학적인 분류 방법에서도 가장 많이 활용되는 방법이 서포트 벡터 머신이다. 본 논문에서는 다양한 서포트 벡터 머신의 종류에 대해서 연구하는 것을 목적으로 한다. 서포트벡터머신의 여러가지 방법중에 각각의 차이점을 분석하고, 어떠한 이유에서 데이터를 분석할 때에 서포트 벡터 머신을 사용하는지 알아볼 것이다. 그리고 더 효율적으로 서포트 벡터 머신을 사용할 수 있는 방법에 대해서 알아본다."
        },
        {
          "rank": 50,
          "score": 0.6227890849113464,
          "doc_id": "NART13812249",
          "title": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination",
          "abstract": "<P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13812249&target=NART&cn=NART13812249",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination <P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>"
        }
      ]
    },
    {
      "query": "What is the role of weight matrices in artificial neural networks?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7582634687423706,
          "doc_id": "ART002543005",
          "title": "Comparison of Weight Initialization Techniques for Deep Neural Networks",
          "abstract": "Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002543005&target=NART&cn=ART002543005",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration."
        },
        {
          "rank": 2,
          "score": 0.7182132005691528,
          "doc_id": "ART002391816",
          "title": "Artificial Intelligence, Language Intelligence, and Mathematics",
          "abstract": "Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002391816&target=NART&cn=ART002391816",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication."
        },
        {
          "rank": 3,
          "score": 0.7091643810272217,
          "doc_id": "ATN0053123228",
          "title": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS",
          "abstract": "<jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0053123228&target=NART&cn=ATN0053123228",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS <jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>"
        },
        {
          "rank": 4,
          "score": 0.6991252303123474,
          "doc_id": "ART002967567",
          "title": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks",
          "abstract": "Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002967567&target=NART&cn=ART002967567",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation."
        },
        {
          "rank": 5,
          "score": 0.6871311664581299,
          "doc_id": "JAKO200211921413494",
          "title": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망",
          "abstract": "본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921413494&target=NART&cn=JAKO200211921413494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다."
        },
        {
          "rank": 6,
          "score": 0.6852056980133057,
          "doc_id": "NART75359998",
          "title": "Artificial Neural Networks Applied to Image Steganography",
          "abstract": "<P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75359998&target=NART&cn=NART75359998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography <P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>"
        },
        {
          "rank": 7,
          "score": 0.6807183027267456,
          "doc_id": "ART002606556",
          "title": "Influence of random topology in artificial neural networks: A survey",
          "abstract": "Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002606556&target=NART&cn=ART002606556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures."
        },
        {
          "rank": 8,
          "score": 0.6794003248214722,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 9,
          "score": 0.6689138412475586,
          "doc_id": "NART07374155",
          "title": "Artificial neural networks as applied to long-term demand forecasting",
          "abstract": "<P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART07374155&target=NART&cn=NART07374155",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting <P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>"
        },
        {
          "rank": 10,
          "score": 0.6639864444732666,
          "doc_id": "JAKO202128557368138",
          "title": "인공지능을 활용한 기계학습 앙상블 모델 개발",
          "abstract": "To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128557368138&target=NART&cn=JAKO202128557368138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database."
        },
        {
          "rank": 11,
          "score": 0.6607947945594788,
          "doc_id": "NART13812249",
          "title": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination",
          "abstract": "<P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13812249&target=NART&cn=NART13812249",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination <P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>"
        },
        {
          "rank": 12,
          "score": 0.6571534872055054,
          "doc_id": "NART66524993",
          "title": "Artificial neural networks",
          "abstract": "<P>Examines the following questions associated with artificial neural networks: why people are interested in artificial neural networks; what artificial neural networks are, from the point of view of electronic circuits, and how they work; how they can be programmed and made to solve particular problems; and whether interesting problems can actually be put on such networks. The author then describes the current state of artificial neural network technology and the resulting challenges to people working on electronic devices.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART66524993&target=NART&cn=NART66524993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks Artificial neural networks Artificial neural networks <P>Examines the following questions associated with artificial neural networks: why people are interested in artificial neural networks; what artificial neural networks are, from the point of view of electronic circuits, and how they work; how they can be programmed and made to solve particular problems; and whether interesting problems can actually be put on such networks. The author then describes the current state of artificial neural network technology and the resulting challenges to people working on electronic devices.</P>"
        },
        {
          "rank": 13,
          "score": 0.6551923751831055,
          "doc_id": "NART133898062",
          "title": "Hidden Markov Neural Networks",
          "abstract": "<P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133898062&target=NART&cn=NART133898062",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Neural Networks Hidden Markov Neural Networks Hidden Markov Neural Networks <P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>"
        },
        {
          "rank": 14,
          "score": 0.6528763771057129,
          "doc_id": "JAKO202213649890315",
          "title": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환",
          "abstract": "스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213649890315&target=NART&cn=JAKO202213649890315",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다."
        },
        {
          "rank": 15,
          "score": 0.6496350169181824,
          "doc_id": "JAKO200011920771446",
          "title": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축",
          "abstract": "본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771446&target=NART&cn=JAKO200011920771446",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다."
        },
        {
          "rank": 16,
          "score": 0.6485612392425537,
          "doc_id": "NART32653959",
          "title": "Integrating support vector machines and neural networks",
          "abstract": "<P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART32653959&target=NART&cn=NART32653959",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating support vector machines and neural networks Integrating support vector machines and neural networks Integrating support vector machines and neural networks <P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>"
        },
        {
          "rank": 17,
          "score": 0.6483250856399536,
          "doc_id": "NART19532808",
          "title": "Artificial neural networks applied to financial forecasting",
          "abstract": "A neural network application in the financial forecasting is presented. Next week's change in S&amp;P 500 stock index is the predicted output based on the weekly changes in the 14 indicators. A methodology for pre-processing of the data was devised and successfully implemented. The backpropagation simulator was used to predict the expected sales.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART19532808&target=NART&cn=NART19532808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks applied to financial forecasting Artificial neural networks applied to financial forecasting Artificial neural networks applied to financial forecasting A neural network application in the financial forecasting is presented. Next week's change in S&amp;P 500 stock index is the predicted output based on the weekly changes in the 14 indicators. A methodology for pre-processing of the data was devised and successfully implemented. The backpropagation simulator was used to predict the expected sales."
        },
        {
          "rank": 18,
          "score": 0.6452014446258545,
          "doc_id": "ATN0027036789",
          "title": "인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발",
          "abstract": "A MSH(Mine Subsidence Hazard) index has been developed to estimate the subsidence possibility of an abandoned mine by means of an artificial neural network (ANN) and an interaction matrix. For this, 19 influence factors of mine subsidence were determined through a literature study, and the influence factors for 287 subsidence points at 38 abandoned mines were selected first, of which 108 points (34 abandoned mines) having high data quality were used for learning of ANN. Each influence factor of which range is widely distributed was classified into seven ranges to use it as a learning data of ANN. Interaction matrixes were constructed by an ANN analysis, and a MSH index for each subsidence point was calculated from influence factors as well as influence weights that are from the interaction matrix. The result shows that MSH index ranges between 37 and 66. The average of MSH index for Non-coal mines is 54, which is 13% higher than the one for coal mines of which average MSH index is 47.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0027036789&target=NART&cn=ATN0027036789",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 A MSH(Mine Subsidence Hazard) index has been developed to estimate the subsidence possibility of an abandoned mine by means of an artificial neural network (ANN) and an interaction matrix. For this, 19 influence factors of mine subsidence were determined through a literature study, and the influence factors for 287 subsidence points at 38 abandoned mines were selected first, of which 108 points (34 abandoned mines) having high data quality were used for learning of ANN. Each influence factor of which range is widely distributed was classified into seven ranges to use it as a learning data of ANN. Interaction matrixes were constructed by an ANN analysis, and a MSH index for each subsidence point was calculated from influence factors as well as influence weights that are from the interaction matrix. The result shows that MSH index ranges between 37 and 66. The average of MSH index for Non-coal mines is 54, which is 13% higher than the one for coal mines of which average MSH index is 47."
        },
        {
          "rank": 19,
          "score": 0.6370934844017029,
          "doc_id": "ATN0026857341",
          "title": "인공신경망 모델의 가중치와 편의를 이용한 테트라포드의 안정수 계산 방법",
          "abstract": "Tetrapod is one of the most widely used concrete armor units for rubble mound breakwaters. The calculation of the stability number of Tetrapods is necessary to determine the optimal weight of Tetrapods. Many empirical formulas have been developed to calculate the stability number of Tetrapods, from the Hudson formula in 1950s to the recent one developed by Suh and Kang. They were developed by using the regression analysis to determine the coefficients of an assumed formula using the experimental data. Recently, software engineering (or machine learning) methods are introduced as a large amount of experimental data becomes available, e.g. artificial neural network (ANN) models for rock armors. However, these methods are seldom used probably because they did not significantly improve the accuracy compared with the empirical formula and/or the engineers are not familiar with them. In this study, we propose an explicit method to calculate the stability number of Tetrapods using the weights and biases of an ANN model. This method can be used by an engineer who has basic knowledge of matrix operation without requiring knowledge of ANN, and it is more accurate than previous empirical formulas.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0026857341&target=NART&cn=ATN0026857341",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망 모델의 가중치와 편의를 이용한 테트라포드의 안정수 계산 방법 인공신경망 모델의 가중치와 편의를 이용한 테트라포드의 안정수 계산 방법 인공신경망 모델의 가중치와 편의를 이용한 테트라포드의 안정수 계산 방법 Tetrapod is one of the most widely used concrete armor units for rubble mound breakwaters. The calculation of the stability number of Tetrapods is necessary to determine the optimal weight of Tetrapods. Many empirical formulas have been developed to calculate the stability number of Tetrapods, from the Hudson formula in 1950s to the recent one developed by Suh and Kang. They were developed by using the regression analysis to determine the coefficients of an assumed formula using the experimental data. Recently, software engineering (or machine learning) methods are introduced as a large amount of experimental data becomes available, e.g. artificial neural network (ANN) models for rock armors. However, these methods are seldom used probably because they did not significantly improve the accuracy compared with the empirical formula and/or the engineers are not familiar with them. In this study, we propose an explicit method to calculate the stability number of Tetrapods using the weights and biases of an ANN model. This method can be used by an engineer who has basic knowledge of matrix operation without requiring knowledge of ANN, and it is more accurate than previous empirical formulas."
        },
        {
          "rank": 20,
          "score": 0.6368754506111145,
          "doc_id": "DIKO0008264256",
          "title": "부스팅을 이용한 서포트벡터 머신의 분류",
          "abstract": "본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0008264256&target=NART&cn=DIKO0008264256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다."
        },
        {
          "rank": 21,
          "score": 0.6359759569168091,
          "doc_id": "JAKO202109651162667",
          "title": "신경망기법을 활용한 선박 가치평가 모델 개발",
          "abstract": "본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202109651162667&target=NART&cn=JAKO202109651162667",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 신경망기법을 활용한 선박 가치평가 모델 개발 본 연구의 목적은 Neural Network Regression 모델을 활용하여 선박의 가치평가 모델을 개발하는 것이다. 가치평가의 대상은 중고 VLCC선이며, 선행연구를 통해 선박의 가치 변화를 유발하는 주요 요인들을 선별하여 변수를 설정하고, 2000년 1월부터 2020년 8월까지의 해당 데이터를 확보하였다. 변수의 안정성을 판단하기 위해 다중 공선성 검사를 수행하여 최종적으로 6개의 독립변수와 1개의 종속변수를 선정하고 연구 구조를 설계하였다. 이를 바탕으로 Linear Regression, Neural Network Regression, Random Forest Algorithm을 활용하여 총 9개의 시뮬레이션 모델을 설계하였다. 또한 각 모델간의 비교검증을 통해 평가결과의 정확성을 제고시켰다. 평가 결과, VLCC실제값과의 비교를 통해 2층으로 구성된 Hidden Layer의 Neural Network Regression 모델이 가장 정확도가 높은 것으로 나타났다. 본 연구의 시사점은 첫째, 기존 정형화된 평가기법에서 벗어나 기계학습기반 모델을 선박가치평가에 적용하였다는 점이다. 둘째, 해운시장 변화요인을 동태적 관점에서 분석하고 예측함으로써 연구결과의 객관성을 제고시켰다고 할 수 있다."
        },
        {
          "rank": 22,
          "score": 0.632978081703186,
          "doc_id": "ART002897789",
          "title": "Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork",
          "abstract": "In this study, a modified Artificial Neural Network (ANN) and Support Vector Regression (SVR) with three different optimization algorithms (Genetic, Salp Swarm and Grasshopper) were used to establish an accurate and easy-to-use module to predict the lateral pressure exerted by fresh concrete on formwork based on three main inputs, namely mix proportions (cement content, w/c, coarse aggregates, fine aggregates and admixture agent), casting rate, and height of specimens. The data have been obtained from 30 previously piloted experimental studies (resulted 113 samples). Achieved results for the model including all the input data provide the most excellent prediction of the exerted lateral pressure. Additionally, having different magnitudes of powder volume, aggregate volume and fluid content in the mix exposes different rising and descending in the lateral pressure outcomes. The results indicate that each model has its own advantages and disadvantages; however, the root mean square error values of the SVR models are lower than that of the ANN model. Additionally, the proposed models have been validated and all of them can accurately predict the lateral pressure of fresh concrete on the panel of the formwork.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002897789&target=NART&cn=ART002897789",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork In this study, a modified Artificial Neural Network (ANN) and Support Vector Regression (SVR) with three different optimization algorithms (Genetic, Salp Swarm and Grasshopper) were used to establish an accurate and easy-to-use module to predict the lateral pressure exerted by fresh concrete on formwork based on three main inputs, namely mix proportions (cement content, w/c, coarse aggregates, fine aggregates and admixture agent), casting rate, and height of specimens. The data have been obtained from 30 previously piloted experimental studies (resulted 113 samples). Achieved results for the model including all the input data provide the most excellent prediction of the exerted lateral pressure. Additionally, having different magnitudes of powder volume, aggregate volume and fluid content in the mix exposes different rising and descending in the lateral pressure outcomes. The results indicate that each model has its own advantages and disadvantages; however, the root mean square error values of the SVR models are lower than that of the ANN model. Additionally, the proposed models have been validated and all of them can accurately predict the lateral pressure of fresh concrete on the panel of the formwork."
        },
        {
          "rank": 23,
          "score": 0.6323232650756836,
          "doc_id": "NART11140616",
          "title": "Artificial neural networks applied for studying metallic complexes",
          "abstract": "<P>Metallic complexes of multimetal and multiligand systems are complicated for calculating equilibrium concentrations in solutions. An artificial neural network has been developed for studying Al<SUP>3+</SUP> and EDTA complexes in solution with an initial concentration of 0.01 mol L<SUP>&minus;1</SUP> for these species. In this system there are 20 compounds and may exist 18 simultaneous reactions. The neural network has been trained and the simulated data of different concentrations as a function of pH are predicted with an accuracy of about 1% for all species simultaneously. A general analytical formula is presented, which directly relates all the concentrations as a function of pH. The analysis showed that predictions closer to the boundary of the input and output data are quantitative while out of these limits these are not even qualitative. &copy; 2001 John Wiley &amp; Sons, Inc. J Comput Chem 22: 1691&ndash;1701, 2001</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART11140616&target=NART&cn=NART11140616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks applied for studying metallic complexes Artificial neural networks applied for studying metallic complexes Artificial neural networks applied for studying metallic complexes <P>Metallic complexes of multimetal and multiligand systems are complicated for calculating equilibrium concentrations in solutions. An artificial neural network has been developed for studying Al<SUP>3+</SUP> and EDTA complexes in solution with an initial concentration of 0.01 mol L<SUP>&minus;1</SUP> for these species. In this system there are 20 compounds and may exist 18 simultaneous reactions. The neural network has been trained and the simulated data of different concentrations as a function of pH are predicted with an accuracy of about 1% for all species simultaneously. A general analytical formula is presented, which directly relates all the concentrations as a function of pH. The analysis showed that predictions closer to the boundary of the input and output data are quantitative while out of these limits these are not even qualitative. &copy; 2001 John Wiley &amp; Sons, Inc. J Comput Chem 22: 1691&ndash;1701, 2001</P>"
        },
        {
          "rank": 24,
          "score": 0.6305211186408997,
          "doc_id": "JAKO200708410645481",
          "title": "효율적인 신경망 부싱모델을 위한 신경망 구성 최적화",
          "abstract": "A bushing component of a vehicle suspension system is tested to capture the nonlinear behavior of rubber bushing element using the MTS 3-axes rubber test machine. The results of the tests are used to model the artificial neural network bushing model. The performances from the neural network model usually are dependent on the structure of the neural network. In this paper, maximum error, peak error, root mean square error, and error-to-signal ratio are employed to evaluate the performances of the neural network bushing model. A simple simulation is carried out to show the usefulness of the developed procedure.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200708410645481&target=NART&cn=JAKO200708410645481",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 A bushing component of a vehicle suspension system is tested to capture the nonlinear behavior of rubber bushing element using the MTS 3-axes rubber test machine. The results of the tests are used to model the artificial neural network bushing model. The performances from the neural network model usually are dependent on the structure of the neural network. In this paper, maximum error, peak error, root mean square error, and error-to-signal ratio are employed to evaluate the performances of the neural network bushing model. A simple simulation is carried out to show the usefulness of the developed procedure."
        },
        {
          "rank": 25,
          "score": 0.6300758719444275,
          "doc_id": "ART001904385",
          "title": "Artificial neural networks and aggregate consumption patterns in New Zealand",
          "abstract": "This study engineers a household sector where individuals process macroeconomic information to reproduce consumption spending patterns in New Zealand. To do this, heterogeneous artificial neural networks (ANNs) are trained to forecast changes in per worker consumption. In contrast to existing literature, results suggest that there exists a trained ANN that significantly outperforms a linear econometric model at out-of-sample forecasting. To improve the accuracy of ANNs using only in-sample information, methods for combining private knowledge into social knowledge are explored. For one type of ANN, relying on an expert is beneficial. For most ANN structures, weighting an individual's forecast according to how frequently that individual's ANN is a top performer during in-sample training produces more accurate social forecasts. By focusing only on recent periods, considering the severity of an individual's errors in weighting their forecast is also beneficial. Possible avenues for incorporating ANN structures into artificial social simulation models of consumption are discussed.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART001904385&target=NART&cn=ART001904385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks and aggregate consumption patterns in New Zealand Artificial neural networks and aggregate consumption patterns in New Zealand Artificial neural networks and aggregate consumption patterns in New Zealand This study engineers a household sector where individuals process macroeconomic information to reproduce consumption spending patterns in New Zealand. To do this, heterogeneous artificial neural networks (ANNs) are trained to forecast changes in per worker consumption. In contrast to existing literature, results suggest that there exists a trained ANN that significantly outperforms a linear econometric model at out-of-sample forecasting. To improve the accuracy of ANNs using only in-sample information, methods for combining private knowledge into social knowledge are explored. For one type of ANN, relying on an expert is beneficial. For most ANN structures, weighting an individual's forecast according to how frequently that individual's ANN is a top performer during in-sample training produces more accurate social forecasts. By focusing only on recent periods, considering the severity of an individual's errors in weighting their forecast is also beneficial. Possible avenues for incorporating ANN structures into artificial social simulation models of consumption are discussed."
        },
        {
          "rank": 26,
          "score": 0.6295053362846375,
          "doc_id": "ATN0026985104",
          "title": "영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구",
          "abstract": "In this paper, it is realized an image filter for a noise elimination using a recurrent neural networks with fuzzy. The proposed fuzzy neural networks structure is to converge weights and the number of iteration for a certain value by using basically recurrent neural networks structure and is simplified computation and complexity of mathematics by applying the hybrid fuzzy membership function operator.In this paper, the proposed method, the recurrent neural networks applying fuzzy which is collected a certain value, has been proved improving average 0.38dB than the conventional method, the generalied recurrent neural networks, by using PSNR. Also, a result image of the proposed method was similar to the original image than a result image of the conventional method by comparing to visual images.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0026985104&target=NART&cn=ATN0026985104",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 In this paper, it is realized an image filter for a noise elimination using a recurrent neural networks with fuzzy. The proposed fuzzy neural networks structure is to converge weights and the number of iteration for a certain value by using basically recurrent neural networks structure and is simplified computation and complexity of mathematics by applying the hybrid fuzzy membership function operator.In this paper, the proposed method, the recurrent neural networks applying fuzzy which is collected a certain value, has been proved improving average 0.38dB than the conventional method, the generalied recurrent neural networks, by using PSNR. Also, a result image of the proposed method was similar to the original image than a result image of the conventional method by comparing to visual images."
        },
        {
          "rank": 27,
          "score": 0.6277081966400146,
          "doc_id": "NART123156091",
          "title": "Artificial Neural Networks Applied in Civil Engineering",
          "abstract": "<P>In recent years, artificial neural networks (ANN) and artificial intelligence (AI), in general, have garnered significant attention with respect to their applications in several scientific fields, varying from big data management to medical diagnosis [...]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123156091&target=NART&cn=NART123156091",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied in Civil Engineering Artificial Neural Networks Applied in Civil Engineering Artificial Neural Networks Applied in Civil Engineering <P>In recent years, artificial neural networks (ANN) and artificial intelligence (AI), in general, have garnered significant attention with respect to their applications in several scientific fields, varying from big data management to medical diagnosis [...]</P>"
        },
        {
          "rank": 28,
          "score": 0.6275575160980225,
          "doc_id": "ATN0030166808",
          "title": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법",
          "abstract": "인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030166808&target=NART&cn=ATN0030166808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다."
        },
        {
          "rank": 29,
          "score": 0.6265969276428223,
          "doc_id": "NART78799808",
          "title": "Associative Learning Should Go Deep",
          "abstract": "<P>Conditioning, how animals learn to associate two or more events, is one of the most influential paradigms in learning theory. It is nevertheless unclear how current models of associative learning can accommodate complex phenomena without ad hoc representational assumptions. We propose to embrace deep neural networks to negotiate this problem.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78799808&target=NART&cn=NART78799808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Associative Learning Should Go Deep Associative Learning Should Go Deep Associative Learning Should Go Deep <P>Conditioning, how animals learn to associate two or more events, is one of the most influential paradigms in learning theory. It is nevertheless unclear how current models of associative learning can accommodate complex phenomena without ad hoc representational assumptions. We propose to embrace deep neural networks to negotiate this problem.</P>"
        },
        {
          "rank": 30,
          "score": 0.623294472694397,
          "doc_id": "JAKO200011920771131",
          "title": "은닉지식 추출을 이용한 신경망회로망 정제",
          "abstract": "신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771131&target=NART&cn=JAKO200011920771131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다."
        },
        {
          "rank": 31,
          "score": 0.6232729554176331,
          "doc_id": "NART56157538",
          "title": "확장된 ART 인공 신경망",
          "abstract": "<P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157538&target=NART&cn=NART56157538",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "확장된 ART 인공 신경망 확장된 ART 인공 신경망 확장된 ART 인공 신경망 <P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>"
        },
        {
          "rank": 32,
          "score": 0.6232462525367737,
          "doc_id": "JAKO200831852745707",
          "title": "점진적 특징 가중치 기법을 이용한 나이브 베이즈 문서분류기의 성능 개선",
          "abstract": "실제 운용 환경에서 자동문서분류시스템의 성공을 위해서 충분하지 못한 학습문서의 문제와 특징 공간들에 대한 사전지식이 없는 상황을 해결하는 것이 관건이다. 이런 맥락에서 많은 자동문서분류 시스템의 구축을 위해 나이브 베이즈 문서분류 알고리즘을 사용한다. 이는 기존 학습된 분류모델과 특징 공간을 점진적으로 갱신함으로써 분류모델을 향상시키는 것이 매우 용이하기 때문이다. 본 논문에서는 특징 가중치를 이용하여 문서분류기의 성능을 향상시키는 기법을 제안한다. 기본 아이디어는 문서분류 모델의 인자로서 특징들의 분포뿐만 아니라 각 특징들의 중요도를 반영하는 것이다. 속성 선택을 미리 수행하여 학습모델을 만드는 것이 아니라, 속성 중요도를 나이브 베이즈 학습 모델에 포함시킴으로써 보다 정확한 모델을 생성할 수 있다. 또한 동적 환경에서 점진적인 특징 가중치 부여를 위해 기존의 특징 갱신 기법을 확장한 알고리즘도 제안한다. 본 논문에서 제안된 기법을 평가하기 위해서 Reuters-21578과 20Newsgroup 문서집합 이용한 실험을 실시하여, 제안된 기법이 전통적인 나이브 베이즈 분류기의 성능을 크게 향상시킴을 증명한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200831852745707&target=NART&cn=JAKO200831852745707",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "점진적 특징 가중치 기법을 이용한 나이브 베이즈 문서분류기의 성능 개선 점진적 특징 가중치 기법을 이용한 나이브 베이즈 문서분류기의 성능 개선 점진적 특징 가중치 기법을 이용한 나이브 베이즈 문서분류기의 성능 개선 실제 운용 환경에서 자동문서분류시스템의 성공을 위해서 충분하지 못한 학습문서의 문제와 특징 공간들에 대한 사전지식이 없는 상황을 해결하는 것이 관건이다. 이런 맥락에서 많은 자동문서분류 시스템의 구축을 위해 나이브 베이즈 문서분류 알고리즘을 사용한다. 이는 기존 학습된 분류모델과 특징 공간을 점진적으로 갱신함으로써 분류모델을 향상시키는 것이 매우 용이하기 때문이다. 본 논문에서는 특징 가중치를 이용하여 문서분류기의 성능을 향상시키는 기법을 제안한다. 기본 아이디어는 문서분류 모델의 인자로서 특징들의 분포뿐만 아니라 각 특징들의 중요도를 반영하는 것이다. 속성 선택을 미리 수행하여 학습모델을 만드는 것이 아니라, 속성 중요도를 나이브 베이즈 학습 모델에 포함시킴으로써 보다 정확한 모델을 생성할 수 있다. 또한 동적 환경에서 점진적인 특징 가중치 부여를 위해 기존의 특징 갱신 기법을 확장한 알고리즘도 제안한다. 본 논문에서 제안된 기법을 평가하기 위해서 Reuters-21578과 20Newsgroup 문서집합 이용한 실험을 실시하여, 제안된 기법이 전통적인 나이브 베이즈 분류기의 성능을 크게 향상시킴을 증명한다."
        },
        {
          "rank": 33,
          "score": 0.6227189898490906,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 34,
          "score": 0.6224428415298462,
          "doc_id": "NART64726780",
          "title": "MATRIX MANIPULATIONS USING ARTIFICIAL NEURAL NETWORKS",
          "abstract": "<P>A new neural network approach for matrix computations is presented. The idea is to construct a feed-forward neural network (FNN) and then train it by matching a desired set of patterns. The solution of the problem is the converged weight of the FNN. Accordingly, unlike the conventional FNN research that concentrates on external properties (mappings) of the networks, this study concentrates on the internal properties (weights) of the network. The present network is linear and its weights are usually strongly constrained; hence, a complicated overlapped network needs to be constructed. It should be noticed, however, that the present approach depends highly on the training algorithm of the FNN. Unfortunately, the available training methods such as the, the original Back-propagation (BP) algorithm, encounter many deficiencies when applied to matrix algebra problems, including slow convergence due to improper choice of learning rates (LR). Thus, this study focused on the development of new efficient and accurate FNN training methods. One improvement suggested to alleviate the problem of LR choice is the use of a line search with steepest descent method, namely, bracketing with golden section method. This provides an optimal LR as training progresses. Another improvement proposed in this study is the use of conjugate gradient (CG) methods to speed up the training process of the neural network. The computational feasibility of these methods is assessed on two matrix problems; namely, the LU-decomposition of both band and square ill-conditioned unsymmetric matrices and the inversion of square ill-conditioned unsymmetric matrices. In this paper, only the first one is reported.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART64726780&target=NART&cn=NART64726780",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "MATRIX MANIPULATIONS USING ARTIFICIAL NEURAL NETWORKS MATRIX MANIPULATIONS USING ARTIFICIAL NEURAL NETWORKS MATRIX MANIPULATIONS USING ARTIFICIAL NEURAL NETWORKS <P>A new neural network approach for matrix computations is presented. The idea is to construct a feed-forward neural network (FNN) and then train it by matching a desired set of patterns. The solution of the problem is the converged weight of the FNN. Accordingly, unlike the conventional FNN research that concentrates on external properties (mappings) of the networks, this study concentrates on the internal properties (weights) of the network. The present network is linear and its weights are usually strongly constrained; hence, a complicated overlapped network needs to be constructed. It should be noticed, however, that the present approach depends highly on the training algorithm of the FNN. Unfortunately, the available training methods such as the, the original Back-propagation (BP) algorithm, encounter many deficiencies when applied to matrix algebra problems, including slow convergence due to improper choice of learning rates (LR). Thus, this study focused on the development of new efficient and accurate FNN training methods. One improvement suggested to alleviate the problem of LR choice is the use of a line search with steepest descent method, namely, bracketing with golden section method. This provides an optimal LR as training progresses. Another improvement proposed in this study is the use of conjugate gradient (CG) methods to speed up the training process of the neural network. The computational feasibility of these methods is assessed on two matrix problems; namely, the LU-decomposition of both band and square ill-conditioned unsymmetric matrices and the inversion of square ill-conditioned unsymmetric matrices. In this paper, only the first one is reported.</P>"
        },
        {
          "rank": 35,
          "score": 0.6201702356338501,
          "doc_id": "JAKO201726163354280",
          "title": "WFSO 알고리즘을 이용한 인공 신경망과 합성곱 신경망의 학습",
          "abstract": "본 논문에서는 최적화 알고리즘으로 개발된 WFSO(Water Flowing and Shaking Optimization) 알고리즘을 사용한 인공신경망 과합성공 신경망의 학습 방법을 제안한다. 최적화 알고리즘은 다수의 후보 해를 기반으로 탐색해 나가기 때문에 일반적으로 속도가 느린 단점이 있으나 지역 최소값에 거의 빠지지 않고 병렬화가 용이하며 미분 불가능한 활성화함수를 갖는 인공신경망 학습도 가능하고 구조와 가중치를 동시에 최적화 할 수 있는 장점이 있다. 본 논문에서는 WFSO 알고리즘을 인공신경망 학습에 적용하는 방법을 설명하고 다층 인공신경망과 합성곱 신경망에서 오류역전파 알고리즘과 성능을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201726163354280&target=NART&cn=JAKO201726163354280",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "WFSO 알고리즘을 이용한 인공 신경망과 합성곱 신경망의 학습 WFSO 알고리즘을 이용한 인공 신경망과 합성곱 신경망의 학습 WFSO 알고리즘을 이용한 인공 신경망과 합성곱 신경망의 학습 본 논문에서는 최적화 알고리즘으로 개발된 WFSO(Water Flowing and Shaking Optimization) 알고리즘을 사용한 인공신경망 과합성공 신경망의 학습 방법을 제안한다. 최적화 알고리즘은 다수의 후보 해를 기반으로 탐색해 나가기 때문에 일반적으로 속도가 느린 단점이 있으나 지역 최소값에 거의 빠지지 않고 병렬화가 용이하며 미분 불가능한 활성화함수를 갖는 인공신경망 학습도 가능하고 구조와 가중치를 동시에 최적화 할 수 있는 장점이 있다. 본 논문에서는 WFSO 알고리즘을 인공신경망 학습에 적용하는 방법을 설명하고 다층 인공신경망과 합성곱 신경망에서 오류역전파 알고리즘과 성능을 비교한다."
        },
        {
          "rank": 36,
          "score": 0.6195927858352661,
          "doc_id": "NART12793683",
          "title": "Approximating vertical vector fields for feedforward neural networks",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART12793683&target=NART&cn=NART12793683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks <P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>"
        },
        {
          "rank": 37,
          "score": 0.6185997128486633,
          "doc_id": "NART104818649",
          "title": "Self-Net: Lifelong Learning via Continual Self-Modeling",
          "abstract": "<P>Learning a set of tasks over time, also known as continual learning (CL), is one of the most challenging problems in artificial intelligence. While recent approaches achieve some degree of CL in deep neural networks, they either (1) store a new network (or an equivalent number of parameters) for each new task, (2) store training data from previous tasks, or (3) restrict the network's ability to learn new tasks. To address these issues, we propose a novel framework, Self-Net, that uses an autoencoder to learn a set of low-dimensional representations of the weights learned for different tasks. We demonstrate that these low-dimensional vectors can then be used to generate high-fidelity recollections of the original weights. Self-Net can incorporate new tasks over time with little retraining, minimal loss in performance for older tasks, and without storing prior training data. We show that our technique achieves over 10X storage compression in a continual fashion, and that it outperforms state-of-the-art approaches on numerous datasets, including continual versions of MNIST, CIFAR10, CIFAR100, Atari, and task-incremental CORe50. To the best of our knowledge, we are the first to use autoencoders to sequentially encode sets of network weights to enable continual learning.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART104818649&target=NART&cn=NART104818649",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Self-Net: Lifelong Learning via Continual Self-Modeling Self-Net: Lifelong Learning via Continual Self-Modeling Self-Net: Lifelong Learning via Continual Self-Modeling <P>Learning a set of tasks over time, also known as continual learning (CL), is one of the most challenging problems in artificial intelligence. While recent approaches achieve some degree of CL in deep neural networks, they either (1) store a new network (or an equivalent number of parameters) for each new task, (2) store training data from previous tasks, or (3) restrict the network's ability to learn new tasks. To address these issues, we propose a novel framework, Self-Net, that uses an autoencoder to learn a set of low-dimensional representations of the weights learned for different tasks. We demonstrate that these low-dimensional vectors can then be used to generate high-fidelity recollections of the original weights. Self-Net can incorporate new tasks over time with little retraining, minimal loss in performance for older tasks, and without storing prior training data. We show that our technique achieves over 10X storage compression in a continual fashion, and that it outperforms state-of-the-art approaches on numerous datasets, including continual versions of MNIST, CIFAR10, CIFAR100, Atari, and task-incremental CORe50. To the best of our knowledge, we are the first to use autoencoders to sequentially encode sets of network weights to enable continual learning.</P>"
        },
        {
          "rank": 38,
          "score": 0.6176767945289612,
          "doc_id": "ATN0037688802",
          "title": "인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색",
          "abstract": "Artificial neural network technology is a field of computer technology that seeks to mechanically realize human sensory processing and internal changes, and has sufficient relevance to neuroscience, character and moral education. Assuming that character education is an effort to guide the human inner side in a desirable direction, artificial neural networks are excellent as an experimental tool to explain such thought processes and characteristics. Therefore, this study seeks to find implications related to character education and explain the phenomenon based on the operating principle of AI artificial neural network technology. Recently, AI research tends to focus on connectionist intelligence, such as deep neural networks, rather than traditional symbolism. This paper also attempts to explain the unique behavioral characteristics of deep neural networks in relation to important elements of character education in accordance with this trend of the times. As a specific element of implications, “Overfitting: Resolving the concentrated learning ability”, “Activation function; Ensuring individuality and diversity of learners” and “Analog processing: balance between learner's reason and emotion”. As in this paper, efforts to find the implications of personality education from the perspective of AI artificial neural networks have meaning as a tool for fusion with other subjects and broaden the extension of AI information education.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037688802&target=NART&cn=ATN0037688802",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 Artificial neural network technology is a field of computer technology that seeks to mechanically realize human sensory processing and internal changes, and has sufficient relevance to neuroscience, character and moral education. Assuming that character education is an effort to guide the human inner side in a desirable direction, artificial neural networks are excellent as an experimental tool to explain such thought processes and characteristics. Therefore, this study seeks to find implications related to character education and explain the phenomenon based on the operating principle of AI artificial neural network technology. Recently, AI research tends to focus on connectionist intelligence, such as deep neural networks, rather than traditional symbolism. This paper also attempts to explain the unique behavioral characteristics of deep neural networks in relation to important elements of character education in accordance with this trend of the times. As a specific element of implications, “Overfitting: Resolving the concentrated learning ability”, “Activation function; Ensuring individuality and diversity of learners” and “Analog processing: balance between learner's reason and emotion”. As in this paper, efforts to find the implications of personality education from the perspective of AI artificial neural networks have meaning as a tool for fusion with other subjects and broaden the extension of AI information education."
        },
        {
          "rank": 39,
          "score": 0.6175795197486877,
          "doc_id": "JAKO202331137845623",
          "title": "활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법",
          "abstract": "본 논문에서는 딥러닝 분야에서 사용되는 신경망 모델, 그중에서도 다중 계층 퍼셉트론 모델에 사용되는 지수함수 기반의 활성화 함수를 근사 함수로 대체하고, 근사 함수에 마스킹을 적용함으로써 신경망 모델의 추론 과정의 전력 분석 저항성을 높이는 방법을 제안한다. 이미 학습된 값을 사용하여 연산하는 인공 신경망의 추론 과정은 그 특성상 가중치나 편향 등의 내부 정보가 부채널 공격에 노출될 위험성이 있다. 다만 신경망 모델의 활성화 함수 계층에서는 매우 다양한 함수를 사용하고, 특히 지수함수 기반의 활성화 함수에는 마스킹 기법 등 통상적인 부채널 대응기법을 적용하기가 어렵다. 따라서 본 연구에서는 지수함수 기반의 활성화 함수를 단순한 형태로 근사하여도 모델의 치명적인 성능 저하가 일어나지 않음을 보이고, 근사 함수에 마스킹을 적용함으로써 전력 분석으로부터 안전한 순방향 신경망 모델을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202331137845623&target=NART&cn=JAKO202331137845623",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 본 논문에서는 딥러닝 분야에서 사용되는 신경망 모델, 그중에서도 다중 계층 퍼셉트론 모델에 사용되는 지수함수 기반의 활성화 함수를 근사 함수로 대체하고, 근사 함수에 마스킹을 적용함으로써 신경망 모델의 추론 과정의 전력 분석 저항성을 높이는 방법을 제안한다. 이미 학습된 값을 사용하여 연산하는 인공 신경망의 추론 과정은 그 특성상 가중치나 편향 등의 내부 정보가 부채널 공격에 노출될 위험성이 있다. 다만 신경망 모델의 활성화 함수 계층에서는 매우 다양한 함수를 사용하고, 특히 지수함수 기반의 활성화 함수에는 마스킹 기법 등 통상적인 부채널 대응기법을 적용하기가 어렵다. 따라서 본 연구에서는 지수함수 기반의 활성화 함수를 단순한 형태로 근사하여도 모델의 치명적인 성능 저하가 일어나지 않음을 보이고, 근사 함수에 마스킹을 적용함으로써 전력 분석으로부터 안전한 순방향 신경망 모델을 제안하고자 한다."
        },
        {
          "rank": 40,
          "score": 0.6175016164779663,
          "doc_id": "ATN0037469990",
          "title": "특징 벡터의 effectiveness 요소 기반의 가중치 SVM 분류기 연구",
          "abstract": "In this paper, we proposed a new SVM model for classification based on analysis of weight and effectiveness of a certain feature vector. The standard SVM approach used a concept of minimization of geometric soft margin between input feature vector and classification function. Although the classical approach builds a classification function to pro-vide efficient decision boundary, this model is easily affected by outliers because each support vector cannot reflect structural or distributional properties of input data. To overcome defects of the classical SVM approach, a new model is derived from weighting scheme based on geometrical relation of nearby feature vectors and data distribution of input feature vectors. The proposed model was verified by using the effectiveness factor that helps to build classification function to provide effective global decision boundary. We evaluated our weighted SVM model using effectiveness factor for multi-class classification and achieved higher accuracy than classical SVM model using the MNIST dataset.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037469990&target=NART&cn=ATN0037469990",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "특징 벡터의 effectiveness 요소 기반의 가중치 SVM 분류기 연구 특징 벡터의 effectiveness 요소 기반의 가중치 SVM 분류기 연구 특징 벡터의 effectiveness 요소 기반의 가중치 SVM 분류기 연구 In this paper, we proposed a new SVM model for classification based on analysis of weight and effectiveness of a certain feature vector. The standard SVM approach used a concept of minimization of geometric soft margin between input feature vector and classification function. Although the classical approach builds a classification function to pro-vide efficient decision boundary, this model is easily affected by outliers because each support vector cannot reflect structural or distributional properties of input data. To overcome defects of the classical SVM approach, a new model is derived from weighting scheme based on geometrical relation of nearby feature vectors and data distribution of input feature vectors. The proposed model was verified by using the effectiveness factor that helps to build classification function to provide effective global decision boundary. We evaluated our weighted SVM model using effectiveness factor for multi-class classification and achieved higher accuracy than classical SVM model using the MNIST dataset."
        },
        {
          "rank": 41,
          "score": 0.6166390776634216,
          "doc_id": "DIKO0012049012",
          "title": "입자 군집 최적화 및 Type-2 퍼지 신경회로망을 이용한 패턴인식에 관한 연구",
          "abstract": "다항식기반 신경회로망(Polynomial neural networks)은 이미 기존의 다른 연구 및 논문에서도 분류기로서의 유용함이 많이 알려져 있다. 본 연구에서는 패턴인식을 목적으로 한 다항식 RBF 신경회로망(Polynomial Radial Basis Function Neural Network; P-RBFNN)과 이것의 확장형이라 할 수 있는 Interval Type-2 퍼지 신경회로망 (Interval Type-2 Fuzzy Neural Network; IT2 P-RBFNNS)을 설계하여 패턴분류기로서의 성능을 실험한다. P-RBFNN 모델은 ‘If-then' 형식으로 기술되는 퍼지 규칙에 의하여 조건부, 결론부, 추론부, 세 가지의 기능적 모듈로 표현된다. 조건부는 FCM 클러스터링을 사용하여 입력 공간을 분할하고, 결론부는 분할된 로컬 영역을 상수 및 다항식 함수로 표현한다. 추론부에서는 네트워크의 최종 출력을 퍼지추론에 의하여 나타낸다. 퍼지 추론에 의해 P-RBFNN의 최종출력식은 출력 공간상에 비선형 판별 함수(nonliner discernment function)를 생성하여 분류기로서의 성능을 높인다. IT2 P-RBFNN은 P-RBFNN의 확장된 구조라 할 수 있다. Input layer, Fuzzyification layer, Inference layer의 3개의 층으로 구분하며 기본연산 과정은 P-RBFNN과 비슷하다고 할 수 있다. Type-2 FCM클러스터링은 두 개의 퍼지화 계수를 사용하여 Type-2 퍼지 집합을 표현한다. Interval Type-2 Fuzzy Set을 Fuzzification layer의 활성 함수로 사용하고 Type-2 퍼지 집합에 따른 각각의 연결가충치를 계산하여 평균을 구함으로써 최종 출력을 얻는다. 이렇게 설계된 IT2 P-RBFNN은 노이즈에 좀 더 강한 특성을 보인다. 또한 입자 군집 최적화(Particle Swarm Optimization; PSO) 알고리즘을 이용하여 FCM클러스터링의 퍼지화 계수(Fuzzification Coefficient)를 최적화한다. 제안된 분류기모델은 모의 데이터 집합, 기계 학습 데이터, 얼굴 이미지 데이터를 사용하여 분류기로서의 성능을 평가한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012049012&target=NART&cn=DIKO0012049012",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "입자 군집 최적화 및 Type-2 퍼지 신경회로망을 이용한 패턴인식에 관한 연구 입자 군집 최적화 및 Type-2 퍼지 신경회로망을 이용한 패턴인식에 관한 연구 입자 군집 최적화 및 Type-2 퍼지 신경회로망을 이용한 패턴인식에 관한 연구 다항식기반 신경회로망(Polynomial neural networks)은 이미 기존의 다른 연구 및 논문에서도 분류기로서의 유용함이 많이 알려져 있다. 본 연구에서는 패턴인식을 목적으로 한 다항식 RBF 신경회로망(Polynomial Radial Basis Function Neural Network; P-RBFNN)과 이것의 확장형이라 할 수 있는 Interval Type-2 퍼지 신경회로망 (Interval Type-2 Fuzzy Neural Network; IT2 P-RBFNNS)을 설계하여 패턴분류기로서의 성능을 실험한다. P-RBFNN 모델은 ‘If-then' 형식으로 기술되는 퍼지 규칙에 의하여 조건부, 결론부, 추론부, 세 가지의 기능적 모듈로 표현된다. 조건부는 FCM 클러스터링을 사용하여 입력 공간을 분할하고, 결론부는 분할된 로컬 영역을 상수 및 다항식 함수로 표현한다. 추론부에서는 네트워크의 최종 출력을 퍼지추론에 의하여 나타낸다. 퍼지 추론에 의해 P-RBFNN의 최종출력식은 출력 공간상에 비선형 판별 함수(nonliner discernment function)를 생성하여 분류기로서의 성능을 높인다. IT2 P-RBFNN은 P-RBFNN의 확장된 구조라 할 수 있다. Input layer, Fuzzyification layer, Inference layer의 3개의 층으로 구분하며 기본연산 과정은 P-RBFNN과 비슷하다고 할 수 있다. Type-2 FCM클러스터링은 두 개의 퍼지화 계수를 사용하여 Type-2 퍼지 집합을 표현한다. Interval Type-2 Fuzzy Set을 Fuzzification layer의 활성 함수로 사용하고 Type-2 퍼지 집합에 따른 각각의 연결가충치를 계산하여 평균을 구함으로써 최종 출력을 얻는다. 이렇게 설계된 IT2 P-RBFNN은 노이즈에 좀 더 강한 특성을 보인다. 또한 입자 군집 최적화(Particle Swarm Optimization; PSO) 알고리즘을 이용하여 FCM클러스터링의 퍼지화 계수(Fuzzification Coefficient)를 최적화한다. 제안된 분류기모델은 모의 데이터 집합, 기계 학습 데이터, 얼굴 이미지 데이터를 사용하여 분류기로서의 성능을 평가한다."
        },
        {
          "rank": 42,
          "score": 0.6163397431373596,
          "doc_id": "ART002356179",
          "title": "Intelligent intrusion detection systems using artificial neural networks",
          "abstract": "This paper presents a novel approach to detection of malicious network traffic using artificial neural networks suitable for use in deep packet inspection based intrusion detection systems. Experimental results using a range of typical benign network traffic data (images, dynamic link library files, and a selection of other miscellaneous files such as logs, music files, and word processing documents) and malicious shell code files sourced from the online exploit and vulnerability repository exploitdb [1], have shown that the proposed artificial neural network architecture is able to distinguish between benign and malicious network traffic accurately.The proposed artificial neural network architecture obtains an average accuracy of 98%, an average area under the receiver operator characteristic curve of 0.98, and an average false positive rate of less than 2% in repeated 10-fold cross-validation. This shows that the proposed classification technique is robust, accurate, and precise. The novel approach to malicious network traffic detection proposed in this paper has the potential to significantly enhance the utility of intrusion detection systems applied to both conventional network traffic analysis and network traffic analysis for cyber–physical systems such as smart-grids.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002356179&target=NART&cn=ART002356179",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Intelligent intrusion detection systems using artificial neural networks Intelligent intrusion detection systems using artificial neural networks Intelligent intrusion detection systems using artificial neural networks This paper presents a novel approach to detection of malicious network traffic using artificial neural networks suitable for use in deep packet inspection based intrusion detection systems. Experimental results using a range of typical benign network traffic data (images, dynamic link library files, and a selection of other miscellaneous files such as logs, music files, and word processing documents) and malicious shell code files sourced from the online exploit and vulnerability repository exploitdb [1], have shown that the proposed artificial neural network architecture is able to distinguish between benign and malicious network traffic accurately.The proposed artificial neural network architecture obtains an average accuracy of 98%, an average area under the receiver operator characteristic curve of 0.98, and an average false positive rate of less than 2% in repeated 10-fold cross-validation. This shows that the proposed classification technique is robust, accurate, and precise. The novel approach to malicious network traffic detection proposed in this paper has the potential to significantly enhance the utility of intrusion detection systems applied to both conventional network traffic analysis and network traffic analysis for cyber–physical systems such as smart-grids."
        },
        {
          "rank": 43,
          "score": 0.6157113313674927,
          "doc_id": "NART37979687",
          "title": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network",
          "abstract": "<P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART37979687&target=NART&cn=NART37979687",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network <P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>"
        },
        {
          "rank": 44,
          "score": 0.6153839826583862,
          "doc_id": "JAKO202125659009583",
          "title": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석",
          "abstract": "전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659009583&target=NART&cn=JAKO202125659009583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다."
        },
        {
          "rank": 45,
          "score": 0.6146426200866699,
          "doc_id": "JAKO202311540154298",
          "title": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색",
          "abstract": "본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202311540154298&target=NART&cn=JAKO202311540154298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다."
        },
        {
          "rank": 46,
          "score": 0.6141316890716553,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 47,
          "score": 0.6141039133071899,
          "doc_id": "NART104701803",
          "title": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go",
          "abstract": "<P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART104701803&target=NART&cn=NART104701803",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go Improved Feature Learning: A Maximum-Average-Out Deep Neural Network for the Game Go <P>Computer game-playing programs based on deep reinforcement learning have surpassed the performance of even the best human players. However, the huge analysis space of such neural networks and their numerous parameters require extensive computing power. Hence, in this study, we aimed to increase the network learning efficiency by modifying the neural network structure, which should reduce the number of learning iterations and the required computing power. A convolutional neural network with a maximum-average-out (MAO) unit structure based on piecewise function thinking is proposed, through which features can be effectively learned and the expression ability of hidden layer features can be enhanced. To verify the performance of the MAO structure, we compared it with the ResNet18 network by applying them both to the framework of AlphaGo Zero, which was developed for playing the game Go. The two network structures were trained from scratch using a low-cost server environment. MAO unit won eight out of ten games against the ResNet18 network. The superior performance of the MAO unit compared with the ResNet18 network is significant for the further development of game algorithms that require less computing power than those currently in use.</P>"
        },
        {
          "rank": 48,
          "score": 0.6138943433761597,
          "doc_id": "JAKO201926358474432",
          "title": "CNN의 깊은 특징과 전이학습을 사용한 보행자 분류",
          "abstract": "자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는 HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고 있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여 보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning)을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한 결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61%로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다. 그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금 낮았지만 고정특징추출 기법보다는 높았다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201926358474432&target=NART&cn=JAKO201926358474432",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 CNN의 깊은 특징과 전이학습을 사용한 보행자 분류 자율주행 시스템에서, 카메라에 포착된 영상을 통하여 보행자를 분류하는 기능은 보행자 안전을 위하여 매우 중요하다. 기존에는 HOG(Histogram of Oriented Gradients)나 SIFT(Scale-Invariant Feature Transform) 등으로 보행자의 특징을 추출한 후 SVM(Support Vector Machine)으로 분류하는 기술을 사용했었으나, 보행자 특징을 위와 같이 수동(handcrafted)으로 추출하는 것은 많은 한계점을 가지고 있다. 따라서 본 논문에서는 CNN(Convolutional Neural Network)의 깊은 특징(deep features)과 전이학습(transfer learning)을 사용하여 보행자를 안정적이고 효과적으로 분류하는 방법을 제시한다. 본 논문은 2가지 대표적인 전이학습 기법인 고정특징추출(fixed feature extractor) 기법과 미세조정(fine-tuning) 기법을 모두 사용하여 실험하였고, 특히 미세조정 기법에서는 3가지 다른 크기로 레이어를 전이구간과 비전이구간으로 구분한 후, 비전이구간에 속한 레이어들에 대해서만 가중치를 조정하는 설정(M-Fine: Modified Fine-tuning)을 새롭게 추가하였다. 5가지 CNN모델(VGGNet, DenseNet, Inception V3, Xception, MobileNet)과 INRIA Person데이터 세트로 실험한 결과, HOG나 SIFT 같은 수동적인 특징보다 CNN의 깊은 특징이 더 좋은 성능을 보여주었고, Xception의 정확도(임계치 = 0.5)가 99.61%로 가장 높았다. Xception과 유사한 성능을 내면서도 80% 적은 파라메터를 학습한 MobileNet이 효율성 측면에서는 가장 뛰어났다. 그리고 3가지 전이학습 기법중 미세조정 기법의 성능이 가장 우수하였고, M-Fine 기법의 성능은 미세조정 기법과 대등하거나 조금 낮았지만 고정특징추출 기법보다는 높았다."
        },
        {
          "rank": 49,
          "score": 0.6134750843048096,
          "doc_id": "NPAP12270893",
          "title": "Speech Recognition in Noisy Environments with Convolutional Neural Networks",
          "abstract": "<P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12270893&target=NART&cn=NPAP12270893",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks <P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>"
        },
        {
          "rank": 50,
          "score": 0.6122061014175415,
          "doc_id": "ART001111579",
          "title": "Solvent manufacturing process monitoring using artificial neural networks",
          "abstract": "Advances in sensors, actuators, and computers and developments in information systems offer unprecedented opportunities to implement highly ambitious automation, control and decision strategies. There are also new challenges and demands for control and automation in modern industrial practices. There is a growing need for an active participation from the information systems in industrial, manufacturing and process industry environments because currently there are many control problems. This paper provides pattern recognition to the monitoring system for solvent manufacturing process and shows performance in real-time response with multiple input signals. Data is learned by a multilayer feedforward network trained by error-backpropagation. The two kinds of test results show that the trained network has the ability to show the current system status with different input data sets.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART001111579&target=NART&cn=ART001111579",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Solvent manufacturing process monitoring using artificial neural networks Solvent manufacturing process monitoring using artificial neural networks Solvent manufacturing process monitoring using artificial neural networks Advances in sensors, actuators, and computers and developments in information systems offer unprecedented opportunities to implement highly ambitious automation, control and decision strategies. There are also new challenges and demands for control and automation in modern industrial practices. There is a growing need for an active participation from the information systems in industrial, manufacturing and process industry environments because currently there are many control problems. This paper provides pattern recognition to the monitoring system for solvent manufacturing process and shows performance in real-time response with multiple input signals. Data is learned by a multilayer feedforward network trained by error-backpropagation. The two kinds of test results show that the trained network has the ability to show the current system status with different input data sets."
        }
      ]
    },
    {
      "query": "What is the role of vector mappings in artificial neural networks?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7293607592582703,
          "doc_id": "NART12793683",
          "title": "Approximating vertical vector fields for feedforward neural networks",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART12793683&target=NART&cn=NART12793683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks <P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>"
        },
        {
          "rank": 2,
          "score": 0.7004973292350769,
          "doc_id": "ART002391816",
          "title": "Artificial Intelligence, Language Intelligence, and Mathematics",
          "abstract": "Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002391816&target=NART&cn=ART002391816",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication."
        },
        {
          "rank": 3,
          "score": 0.6675662994384766,
          "doc_id": "ART002967567",
          "title": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks",
          "abstract": "Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002967567&target=NART&cn=ART002967567",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation."
        },
        {
          "rank": 4,
          "score": 0.6645625829696655,
          "doc_id": "ART002606556",
          "title": "Influence of random topology in artificial neural networks: A survey",
          "abstract": "Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002606556&target=NART&cn=ART002606556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures."
        },
        {
          "rank": 5,
          "score": 0.664074182510376,
          "doc_id": "NART75359998",
          "title": "Artificial Neural Networks Applied to Image Steganography",
          "abstract": "<P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75359998&target=NART&cn=NART75359998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography <P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>"
        },
        {
          "rank": 6,
          "score": 0.6628864407539368,
          "doc_id": "ATN0053123228",
          "title": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS",
          "abstract": "<jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0053123228&target=NART&cn=ATN0053123228",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS <jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>"
        },
        {
          "rank": 7,
          "score": 0.6592288017272949,
          "doc_id": "NART07757458",
          "title": "Slowness vector correction for teleseismic events with artificial neural networks",
          "abstract": "<P><B>Abstract</B></P><P>The slowness anomalies cause serious location errors. The objective of this study is to create a mapping from observed slowness values to corrected values, which will provide more accurate locations. Artificial neural networks (ANNs) are efficient tools for mapping one multidimensional space to another. ANNs have been applied to compute slowness vector corrections for teleseismic events. Separate databases were used for training, testing and validating the networks. The training data set consisted of 2218 events in the period 1988&#x2013;1992. An independent test database consisted of 1091 events from the year 1993 and the first half of 1994. The observed slowness vectors were computed using a three-station array of short period stations, KEF, SUF and KAF, in central Finland. The type of neural network was multi-layer perceptron. To improve the learning capability of the networks, a set of region-dependent extra inputs, resembling bias inputs, were added to the input layer. Several nets of different sizes were tested. The smallest net with only two hidden nodes gave best results. The median of error of the validation database dropped from 523 to 138 km. The median of error after correction is smaller than achieved with the method previously used with these stations. Due to the good interpolation capability of the neural net, the corrections decreased the location error even on areas which had no previous events in the training database. The method can be applied to slowness vector correction at any type of station or array, which produces slowness and azimuth values, if the mapping from the observed slowness values to calculated values is unambiguous.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART07757458&target=NART&cn=NART07757458",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Slowness vector correction for teleseismic events with artificial neural networks Slowness vector correction for teleseismic events with artificial neural networks Slowness vector correction for teleseismic events with artificial neural networks <P><B>Abstract</B></P><P>The slowness anomalies cause serious location errors. The objective of this study is to create a mapping from observed slowness values to corrected values, which will provide more accurate locations. Artificial neural networks (ANNs) are efficient tools for mapping one multidimensional space to another. ANNs have been applied to compute slowness vector corrections for teleseismic events. Separate databases were used for training, testing and validating the networks. The training data set consisted of 2218 events in the period 1988&#x2013;1992. An independent test database consisted of 1091 events from the year 1993 and the first half of 1994. The observed slowness vectors were computed using a three-station array of short period stations, KEF, SUF and KAF, in central Finland. The type of neural network was multi-layer perceptron. To improve the learning capability of the networks, a set of region-dependent extra inputs, resembling bias inputs, were added to the input layer. Several nets of different sizes were tested. The smallest net with only two hidden nodes gave best results. The median of error of the validation database dropped from 523 to 138 km. The median of error after correction is smaller than achieved with the method previously used with these stations. Due to the good interpolation capability of the neural net, the corrections decreased the location error even on areas which had no previous events in the training database. The method can be applied to slowness vector correction at any type of station or array, which produces slowness and azimuth values, if the mapping from the observed slowness values to calculated values is unambiguous.</P>"
        },
        {
          "rank": 8,
          "score": 0.6586645245552063,
          "doc_id": "JAKO200211921413494",
          "title": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망",
          "abstract": "본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921413494&target=NART&cn=JAKO200211921413494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다."
        },
        {
          "rank": 9,
          "score": 0.6585249304771423,
          "doc_id": "NART32653959",
          "title": "Integrating support vector machines and neural networks",
          "abstract": "<P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART32653959&target=NART&cn=NART32653959",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating support vector machines and neural networks Integrating support vector machines and neural networks Integrating support vector machines and neural networks <P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>"
        },
        {
          "rank": 10,
          "score": 0.6524955630302429,
          "doc_id": "JAKO200311921891113",
          "title": "서포트 벡터 기계에서 잡음 영향의 효과적 조절",
          "abstract": "서포트 벡터 기계(Support Vector Machines, SVMs)에서의 일반화 오차의 경계는 훈련점들과 분리 초평면 사이의 최소의 거리에 의존한다. 특히, 소프트 마진 알고리즘은 목표 마진과 slack 벡터의 놈들에 의하여 경계가 결정된다. 이 논문에서는, 자료들에 있어서 잡음들에 의한 오염들을 직접적으로 고려하는 새로운 소프트 마진 알고리즘을 공식화하였다. 그리고, 수치적 예제를 통하여, 제안된 방법과 기존의 소프트 마진 알고리즘을 비교하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311921891113&target=NART&cn=JAKO200311921891113",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 기계에서 잡음 영향의 효과적 조절 서포트 벡터 기계에서 잡음 영향의 효과적 조절 서포트 벡터 기계에서 잡음 영향의 효과적 조절 서포트 벡터 기계(Support Vector Machines, SVMs)에서의 일반화 오차의 경계는 훈련점들과 분리 초평면 사이의 최소의 거리에 의존한다. 특히, 소프트 마진 알고리즘은 목표 마진과 slack 벡터의 놈들에 의하여 경계가 결정된다. 이 논문에서는, 자료들에 있어서 잡음들에 의한 오염들을 직접적으로 고려하는 새로운 소프트 마진 알고리즘을 공식화하였다. 그리고, 수치적 예제를 통하여, 제안된 방법과 기존의 소프트 마진 알고리즘을 비교하였다."
        },
        {
          "rank": 11,
          "score": 0.6477030515670776,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 12,
          "score": 0.646178126335144,
          "doc_id": "DIKO0008264256",
          "title": "부스팅을 이용한 서포트벡터 머신의 분류",
          "abstract": "본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0008264256&target=NART&cn=DIKO0008264256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다."
        },
        {
          "rank": 13,
          "score": 0.6400554180145264,
          "doc_id": "JAKO200504704352464",
          "title": "퍼지 원 클래스 서포트 벡터 머신",
          "abstract": "OC-SVM(One Class Support Vector Machine)은 주어진 전체 데이터의 분포를 측정하는 대신에. 데이터 분포의 서포트(support)를 측정하는 기술로서 주어진 데이터를 가장 잘 설명할 수 있는 최적의 서포트 벡터(support vector)를 구하는 기술이다. OC-SVM은 데이터 분포의 표현에 아주 뛰어난 접근 방법이지만, 사람의 주관적인 중요도를 반영하는 것은 힘들다. 본 논문에서는 각 데이터에 퍼지 맴버쉽(fuzzy membership)을 적용하여 기존의 OC-SVM에 사용자의 주관적인 중요도를 표현할 수 있는 FOC-SVM(Fuzzy One class Support Vector Machine)을 유도 하였다. FOC-SVM은 데이터들을 동등하게 다루는 것이 아니라, 데이터 객체의 중요도에 따라 데이터를 다룬다. 즉, 덜 중요한 데이터의 특징 벡터는 OC-SVM의 처리과정에 덜 기여하도록 하기 위하여, 객체의 중요도에 따라 특징 벡터의 크기를 조정하였다. 이를 증명하기 위하여 가상의 데이터를 가지고 실험을 하였고, 실험 결과는 예측된 결과를 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200504704352464&target=NART&cn=JAKO200504704352464",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "퍼지 원 클래스 서포트 벡터 머신 퍼지 원 클래스 서포트 벡터 머신 퍼지 원 클래스 서포트 벡터 머신 OC-SVM(One Class Support Vector Machine)은 주어진 전체 데이터의 분포를 측정하는 대신에. 데이터 분포의 서포트(support)를 측정하는 기술로서 주어진 데이터를 가장 잘 설명할 수 있는 최적의 서포트 벡터(support vector)를 구하는 기술이다. OC-SVM은 데이터 분포의 표현에 아주 뛰어난 접근 방법이지만, 사람의 주관적인 중요도를 반영하는 것은 힘들다. 본 논문에서는 각 데이터에 퍼지 맴버쉽(fuzzy membership)을 적용하여 기존의 OC-SVM에 사용자의 주관적인 중요도를 표현할 수 있는 FOC-SVM(Fuzzy One class Support Vector Machine)을 유도 하였다. FOC-SVM은 데이터들을 동등하게 다루는 것이 아니라, 데이터 객체의 중요도에 따라 데이터를 다룬다. 즉, 덜 중요한 데이터의 특징 벡터는 OC-SVM의 처리과정에 덜 기여하도록 하기 위하여, 객체의 중요도에 따라 특징 벡터의 크기를 조정하였다. 이를 증명하기 위하여 가상의 데이터를 가지고 실험을 하였고, 실험 결과는 예측된 결과를 보여 주었다."
        },
        {
          "rank": 14,
          "score": 0.6350191831588745,
          "doc_id": "JAKO202128557368138",
          "title": "인공지능을 활용한 기계학습 앙상블 모델 개발",
          "abstract": "To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128557368138&target=NART&cn=JAKO202128557368138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database."
        },
        {
          "rank": 15,
          "score": 0.6346647143363953,
          "doc_id": "JAKO200011920771131",
          "title": "은닉지식 추출을 이용한 신경망회로망 정제",
          "abstract": "신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771131&target=NART&cn=JAKO200011920771131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다."
        },
        {
          "rank": 16,
          "score": 0.6338180303573608,
          "doc_id": "DIKO0014782182",
          "title": "서포트 벡터 머신을 활용한 데이터 분류",
          "abstract": "현대 사회에서는 데이터가 무궁무진하게 많이 생성된다. 예를 들어 사소한 현상에서부터 큰 현상까지 인간이 인지하고 관측가능하다면 이것은 데이터가 된다. 이러한 데이터를 분석하는 것은 매우 어렵지만, 매우 중요한 부분이다. 데이터 분석중에 분류는 아주 기초적인 방법이지만, 그 효과는 확실하다. 분류의 기준을 우리가 가지고 있다면, 이후에 그러한 데이터를 분석할 때 그 기준을 만족하느냐 만족하지 못하느냐만으로도 복잡한 데이터의 양상에서 데이터의 의미를 어느정도는 알 수 있게 된다. 그 분류의 기준을 수학적으로 타당하게 설정한다면 그 기준이 데이터 분석에서 활용가능한 방법이 되게 할 수 있다. 그러한 수학적인 분류 방법에서도 가장 많이 활용되는 방법이 서포트 벡터 머신이다. 본 논문에서는 다양한 서포트 벡터 머신의 종류에 대해서 연구하는 것을 목적으로 한다. 서포트벡터머신의 여러가지 방법중에 각각의 차이점을 분석하고, 어떠한 이유에서 데이터를 분석할 때에 서포트 벡터 머신을 사용하는지 알아볼 것이다. 그리고 더 효율적으로 서포트 벡터 머신을 사용할 수 있는 방법에 대해서 알아본다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014782182&target=NART&cn=DIKO0014782182",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 머신을 활용한 데이터 분류 서포트 벡터 머신을 활용한 데이터 분류 서포트 벡터 머신을 활용한 데이터 분류 현대 사회에서는 데이터가 무궁무진하게 많이 생성된다. 예를 들어 사소한 현상에서부터 큰 현상까지 인간이 인지하고 관측가능하다면 이것은 데이터가 된다. 이러한 데이터를 분석하는 것은 매우 어렵지만, 매우 중요한 부분이다. 데이터 분석중에 분류는 아주 기초적인 방법이지만, 그 효과는 확실하다. 분류의 기준을 우리가 가지고 있다면, 이후에 그러한 데이터를 분석할 때 그 기준을 만족하느냐 만족하지 못하느냐만으로도 복잡한 데이터의 양상에서 데이터의 의미를 어느정도는 알 수 있게 된다. 그 분류의 기준을 수학적으로 타당하게 설정한다면 그 기준이 데이터 분석에서 활용가능한 방법이 되게 할 수 있다. 그러한 수학적인 분류 방법에서도 가장 많이 활용되는 방법이 서포트 벡터 머신이다. 본 논문에서는 다양한 서포트 벡터 머신의 종류에 대해서 연구하는 것을 목적으로 한다. 서포트벡터머신의 여러가지 방법중에 각각의 차이점을 분석하고, 어떠한 이유에서 데이터를 분석할 때에 서포트 벡터 머신을 사용하는지 알아볼 것이다. 그리고 더 효율적으로 서포트 벡터 머신을 사용할 수 있는 방법에 대해서 알아본다."
        },
        {
          "rank": 17,
          "score": 0.6322006583213806,
          "doc_id": "NART07374155",
          "title": "Artificial neural networks as applied to long-term demand forecasting",
          "abstract": "<P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART07374155&target=NART&cn=NART07374155",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting <P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>"
        },
        {
          "rank": 18,
          "score": 0.6320480704307556,
          "doc_id": "JAKO200011920771446",
          "title": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축",
          "abstract": "본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771446&target=NART&cn=JAKO200011920771446",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다."
        },
        {
          "rank": 19,
          "score": 0.6312655210494995,
          "doc_id": "ATN0030166808",
          "title": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법",
          "abstract": "인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030166808&target=NART&cn=ATN0030166808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다."
        },
        {
          "rank": 20,
          "score": 0.629204273223877,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 21,
          "score": 0.6277367472648621,
          "doc_id": "ART002543005",
          "title": "Comparison of Weight Initialization Techniques for Deep Neural Networks",
          "abstract": "Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002543005&target=NART&cn=ART002543005",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration."
        },
        {
          "rank": 22,
          "score": 0.625572681427002,
          "doc_id": "JAKO202331137845623",
          "title": "활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법",
          "abstract": "본 논문에서는 딥러닝 분야에서 사용되는 신경망 모델, 그중에서도 다중 계층 퍼셉트론 모델에 사용되는 지수함수 기반의 활성화 함수를 근사 함수로 대체하고, 근사 함수에 마스킹을 적용함으로써 신경망 모델의 추론 과정의 전력 분석 저항성을 높이는 방법을 제안한다. 이미 학습된 값을 사용하여 연산하는 인공 신경망의 추론 과정은 그 특성상 가중치나 편향 등의 내부 정보가 부채널 공격에 노출될 위험성이 있다. 다만 신경망 모델의 활성화 함수 계층에서는 매우 다양한 함수를 사용하고, 특히 지수함수 기반의 활성화 함수에는 마스킹 기법 등 통상적인 부채널 대응기법을 적용하기가 어렵다. 따라서 본 연구에서는 지수함수 기반의 활성화 함수를 단순한 형태로 근사하여도 모델의 치명적인 성능 저하가 일어나지 않음을 보이고, 근사 함수에 마스킹을 적용함으로써 전력 분석으로부터 안전한 순방향 신경망 모델을 제안하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202331137845623&target=NART&cn=JAKO202331137845623",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 활성화 함수 근사를 통한 지수함수 기반 신경망 마스킹 기법 본 논문에서는 딥러닝 분야에서 사용되는 신경망 모델, 그중에서도 다중 계층 퍼셉트론 모델에 사용되는 지수함수 기반의 활성화 함수를 근사 함수로 대체하고, 근사 함수에 마스킹을 적용함으로써 신경망 모델의 추론 과정의 전력 분석 저항성을 높이는 방법을 제안한다. 이미 학습된 값을 사용하여 연산하는 인공 신경망의 추론 과정은 그 특성상 가중치나 편향 등의 내부 정보가 부채널 공격에 노출될 위험성이 있다. 다만 신경망 모델의 활성화 함수 계층에서는 매우 다양한 함수를 사용하고, 특히 지수함수 기반의 활성화 함수에는 마스킹 기법 등 통상적인 부채널 대응기법을 적용하기가 어렵다. 따라서 본 연구에서는 지수함수 기반의 활성화 함수를 단순한 형태로 근사하여도 모델의 치명적인 성능 저하가 일어나지 않음을 보이고, 근사 함수에 마스킹을 적용함으로써 전력 분석으로부터 안전한 순방향 신경망 모델을 제안하고자 한다."
        },
        {
          "rank": 23,
          "score": 0.6221826076507568,
          "doc_id": "NART56157538",
          "title": "확장된 ART 인공 신경망",
          "abstract": "<P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157538&target=NART&cn=NART56157538",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "확장된 ART 인공 신경망 확장된 ART 인공 신경망 확장된 ART 인공 신경망 <P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>"
        },
        {
          "rank": 24,
          "score": 0.6212377548217773,
          "doc_id": "NART66524993",
          "title": "Artificial neural networks",
          "abstract": "<P>Examines the following questions associated with artificial neural networks: why people are interested in artificial neural networks; what artificial neural networks are, from the point of view of electronic circuits, and how they work; how they can be programmed and made to solve particular problems; and whether interesting problems can actually be put on such networks. The author then describes the current state of artificial neural network technology and the resulting challenges to people working on electronic devices.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART66524993&target=NART&cn=NART66524993",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks Artificial neural networks Artificial neural networks <P>Examines the following questions associated with artificial neural networks: why people are interested in artificial neural networks; what artificial neural networks are, from the point of view of electronic circuits, and how they work; how they can be programmed and made to solve particular problems; and whether interesting problems can actually be put on such networks. The author then describes the current state of artificial neural network technology and the resulting challenges to people working on electronic devices.</P>"
        },
        {
          "rank": 25,
          "score": 0.6208605170249939,
          "doc_id": "JAKO200734513395422",
          "title": "선형 활성화 함수를 이용한 개선된 퍼지 단층 퍼셉트론",
          "abstract": "기존의 단층 퍼셉트론은 출력 노드가 선형 분리 가능한 패턴들만을 분류할 수 있고 XOR과 같은 비선형 문제에 대해서는 분류할 수 없는 단점이 있다. 퍼지 단층 퍼셉트론은 퍼지 소속 함수(Fuzzy Membership Function)를 적용하여 단층 구조로 XOR 문제와 같은 고전적인 문제를 개선하였다. 그러나 퍼지 단층 퍼셉트론은 기존의 단층 퍼셉트론과 마찬가지로 결정 경계선이 진동하는 경우가 생기며 초기 가중치의 범위와 학습률에 따라 수렴성이 매우 낮아지는 단점이 있다. 따라서 본 논문에서는 바이어스항을 도입하여 결정 경계선이 진동하는 것을 방지하여 수렴성을 개선시키고 선형 활성화 함수를 제안하고 학습률과 모멘텀 개념을 도입 한 개선된 델타규칙을 적용함으로써 학습 시간을 단축시키는 개선된 퍼지 단층 퍼셉트론 알고리즘을 제안한다. 제안된 방법과 퍼지 단층 퍼셉트론간의 학습 성능을 분석하기 위하여 인공 신경망에서 벤치마크로 사용되는 XOR 문제와 패턴 분류에 적용하여 Epoch 수와 수렴성을 비교한 결과, 제안된 방법이 기존의 퍼지 단층 퍼셉트론보다 학습 시간이 적게 소요되고 수렴성이 개선된 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200734513395422&target=NART&cn=JAKO200734513395422",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "선형 활성화 함수를 이용한 개선된 퍼지 단층 퍼셉트론 선형 활성화 함수를 이용한 개선된 퍼지 단층 퍼셉트론 선형 활성화 함수를 이용한 개선된 퍼지 단층 퍼셉트론 기존의 단층 퍼셉트론은 출력 노드가 선형 분리 가능한 패턴들만을 분류할 수 있고 XOR과 같은 비선형 문제에 대해서는 분류할 수 없는 단점이 있다. 퍼지 단층 퍼셉트론은 퍼지 소속 함수(Fuzzy Membership Function)를 적용하여 단층 구조로 XOR 문제와 같은 고전적인 문제를 개선하였다. 그러나 퍼지 단층 퍼셉트론은 기존의 단층 퍼셉트론과 마찬가지로 결정 경계선이 진동하는 경우가 생기며 초기 가중치의 범위와 학습률에 따라 수렴성이 매우 낮아지는 단점이 있다. 따라서 본 논문에서는 바이어스항을 도입하여 결정 경계선이 진동하는 것을 방지하여 수렴성을 개선시키고 선형 활성화 함수를 제안하고 학습률과 모멘텀 개념을 도입 한 개선된 델타규칙을 적용함으로써 학습 시간을 단축시키는 개선된 퍼지 단층 퍼셉트론 알고리즘을 제안한다. 제안된 방법과 퍼지 단층 퍼셉트론간의 학습 성능을 분석하기 위하여 인공 신경망에서 벤치마크로 사용되는 XOR 문제와 패턴 분류에 적용하여 Epoch 수와 수렴성을 비교한 결과, 제안된 방법이 기존의 퍼지 단층 퍼셉트론보다 학습 시간이 적게 소요되고 수렴성이 개선된 것을 확인하였다."
        },
        {
          "rank": 26,
          "score": 0.618777334690094,
          "doc_id": "JAKO200708410645481",
          "title": "효율적인 신경망 부싱모델을 위한 신경망 구성 최적화",
          "abstract": "A bushing component of a vehicle suspension system is tested to capture the nonlinear behavior of rubber bushing element using the MTS 3-axes rubber test machine. The results of the tests are used to model the artificial neural network bushing model. The performances from the neural network model usually are dependent on the structure of the neural network. In this paper, maximum error, peak error, root mean square error, and error-to-signal ratio are employed to evaluate the performances of the neural network bushing model. A simple simulation is carried out to show the usefulness of the developed procedure.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200708410645481&target=NART&cn=JAKO200708410645481",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 효율적인 신경망 부싱모델을 위한 신경망 구성 최적화 A bushing component of a vehicle suspension system is tested to capture the nonlinear behavior of rubber bushing element using the MTS 3-axes rubber test machine. The results of the tests are used to model the artificial neural network bushing model. The performances from the neural network model usually are dependent on the structure of the neural network. In this paper, maximum error, peak error, root mean square error, and error-to-signal ratio are employed to evaluate the performances of the neural network bushing model. A simple simulation is carried out to show the usefulness of the developed procedure."
        },
        {
          "rank": 27,
          "score": 0.6181096434593201,
          "doc_id": "JAKO200614222986747",
          "title": "가변적 비디오 트랙을 위한 임계형 신경망 모델",
          "abstract": "본 논문은 가변적 비디오 트랙을 위한 모델링 방법을 제시한다. 가변적인 비디오 트랙은 간헐적인 버스트 및 긴 구간 상관관계의 특성을 갖는다고 잘 알려져 있다. 이러한 데이터를 분석하기 위해서, 에러 임계값으로부터 구한 보조적인 선형 구조를 갖는 신경망 구조 모델 구축을 한다. 모델링 결과 테스트를 위해서, 흔돈 비선형 함수와 지수 랜덤 노이즈를 결합한 가변적 비디오 트랙을 발생하였다. 발생된 데이터를 모델링한 결과, 전통적인 신경망 모델에 비해서 제시된 모델이 보다 정확한 모델링 결과를 보여 주었다. 그러나 또한 제시된 모델에 ARは을 결합한 결과가 제시된 모델 단독인 경우에 비해서 더욱 발생된 데이터의 통계적 특성에 근접함을 발견했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200614222986747&target=NART&cn=JAKO200614222986747",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가변적 비디오 트랙을 위한 임계형 신경망 모델 가변적 비디오 트랙을 위한 임계형 신경망 모델 가변적 비디오 트랙을 위한 임계형 신경망 모델 본 논문은 가변적 비디오 트랙을 위한 모델링 방법을 제시한다. 가변적인 비디오 트랙은 간헐적인 버스트 및 긴 구간 상관관계의 특성을 갖는다고 잘 알려져 있다. 이러한 데이터를 분석하기 위해서, 에러 임계값으로부터 구한 보조적인 선형 구조를 갖는 신경망 구조 모델 구축을 한다. 모델링 결과 테스트를 위해서, 흔돈 비선형 함수와 지수 랜덤 노이즈를 결합한 가변적 비디오 트랙을 발생하였다. 발생된 데이터를 모델링한 결과, 전통적인 신경망 모델에 비해서 제시된 모델이 보다 정확한 모델링 결과를 보여 주었다. 그러나 또한 제시된 모델에 ARは을 결합한 결과가 제시된 모델 단독인 경우에 비해서 더욱 발생된 데이터의 통계적 특성에 근접함을 발견했다."
        },
        {
          "rank": 28,
          "score": 0.6177551746368408,
          "doc_id": "NART78799808",
          "title": "Associative Learning Should Go Deep",
          "abstract": "<P>Conditioning, how animals learn to associate two or more events, is one of the most influential paradigms in learning theory. It is nevertheless unclear how current models of associative learning can accommodate complex phenomena without ad hoc representational assumptions. We propose to embrace deep neural networks to negotiate this problem.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78799808&target=NART&cn=NART78799808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Associative Learning Should Go Deep Associative Learning Should Go Deep Associative Learning Should Go Deep <P>Conditioning, how animals learn to associate two or more events, is one of the most influential paradigms in learning theory. It is nevertheless unclear how current models of associative learning can accommodate complex phenomena without ad hoc representational assumptions. We propose to embrace deep neural networks to negotiate this problem.</P>"
        },
        {
          "rank": 29,
          "score": 0.6147050261497498,
          "doc_id": "NART53843256",
          "title": "Neural development of networks for audiovisual speech comprehension",
          "abstract": "<P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53843256&target=NART&cn=NART53843256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension <P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>"
        },
        {
          "rank": 30,
          "score": 0.6131024360656738,
          "doc_id": "ATN0027036789",
          "title": "인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발",
          "abstract": "A MSH(Mine Subsidence Hazard) index has been developed to estimate the subsidence possibility of an abandoned mine by means of an artificial neural network (ANN) and an interaction matrix. For this, 19 influence factors of mine subsidence were determined through a literature study, and the influence factors for 287 subsidence points at 38 abandoned mines were selected first, of which 108 points (34 abandoned mines) having high data quality were used for learning of ANN. Each influence factor of which range is widely distributed was classified into seven ranges to use it as a learning data of ANN. Interaction matrixes were constructed by an ANN analysis, and a MSH index for each subsidence point was calculated from influence factors as well as influence weights that are from the interaction matrix. The result shows that MSH index ranges between 37 and 66. The average of MSH index for Non-coal mines is 54, which is 13% higher than the one for coal mines of which average MSH index is 47.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0027036789&target=NART&cn=ATN0027036789",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 인공신경망과 상관도 행렬을 이용한 폐광지역 지반침하 위험도지수 개발 A MSH(Mine Subsidence Hazard) index has been developed to estimate the subsidence possibility of an abandoned mine by means of an artificial neural network (ANN) and an interaction matrix. For this, 19 influence factors of mine subsidence were determined through a literature study, and the influence factors for 287 subsidence points at 38 abandoned mines were selected first, of which 108 points (34 abandoned mines) having high data quality were used for learning of ANN. Each influence factor of which range is widely distributed was classified into seven ranges to use it as a learning data of ANN. Interaction matrixes were constructed by an ANN analysis, and a MSH index for each subsidence point was calculated from influence factors as well as influence weights that are from the interaction matrix. The result shows that MSH index ranges between 37 and 66. The average of MSH index for Non-coal mines is 54, which is 13% higher than the one for coal mines of which average MSH index is 47."
        },
        {
          "rank": 31,
          "score": 0.6128827333450317,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 32,
          "score": 0.6115041375160217,
          "doc_id": "NART133898062",
          "title": "Hidden Markov Neural Networks",
          "abstract": "<P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133898062&target=NART&cn=NART133898062",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Neural Networks Hidden Markov Neural Networks Hidden Markov Neural Networks <P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>"
        },
        {
          "rank": 33,
          "score": 0.6114640235900879,
          "doc_id": "JAKO202311540154298",
          "title": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색",
          "abstract": "본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202311540154298&target=NART&cn=JAKO202311540154298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다."
        },
        {
          "rank": 34,
          "score": 0.6110620498657227,
          "doc_id": "NART19532808",
          "title": "Artificial neural networks applied to financial forecasting",
          "abstract": "A neural network application in the financial forecasting is presented. Next week's change in S&amp;P 500 stock index is the predicted output based on the weekly changes in the 14 indicators. A methodology for pre-processing of the data was devised and successfully implemented. The backpropagation simulator was used to predict the expected sales.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART19532808&target=NART&cn=NART19532808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks applied to financial forecasting Artificial neural networks applied to financial forecasting Artificial neural networks applied to financial forecasting A neural network application in the financial forecasting is presented. Next week's change in S&amp;P 500 stock index is the predicted output based on the weekly changes in the 14 indicators. A methodology for pre-processing of the data was devised and successfully implemented. The backpropagation simulator was used to predict the expected sales."
        },
        {
          "rank": 35,
          "score": 0.6087325811386108,
          "doc_id": "JAKO200735822449370",
          "title": "함수 근사화를 위한 방사 기저함수 네트워크의 전역 최적화 기법",
          "abstract": "본 논문에서는 방사 기저함수 네트워크의 파라미터를 전 영역에서 최적화하는 학습 알고리즘을 제안한다. 기존의 학습 알고리즘들은 지역 최적화만을 수행하기 때문에 성능의 한계가 있고 최종 결과가 초기 네트워크 파라미터 값에 크게 의존하는 단점이 있다. 본 논문에서 제안하는 하이브리드 모의 담금질 기법은 모의 담금질 기법의 전 영역 탐색 능력과 경사 기반 학습 알고리즘의 지역 최적화 능력을 조합하여 전 파라미터 영역에서 해를 찾을 수 있도록 한다. 제안하는 기법을 함수 근사화 문제에 적용하여 기존의 학습 알고리즘에 비해 더 좋은 학습 및 일반화 성능을 보이는 네트워크 파라미터를 찾을 수 있으며, 초기 파라미터 값의 영향을 크게 줄일 수 있음을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200735822449370&target=NART&cn=JAKO200735822449370",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "함수 근사화를 위한 방사 기저함수 네트워크의 전역 최적화 기법 함수 근사화를 위한 방사 기저함수 네트워크의 전역 최적화 기법 함수 근사화를 위한 방사 기저함수 네트워크의 전역 최적화 기법 본 논문에서는 방사 기저함수 네트워크의 파라미터를 전 영역에서 최적화하는 학습 알고리즘을 제안한다. 기존의 학습 알고리즘들은 지역 최적화만을 수행하기 때문에 성능의 한계가 있고 최종 결과가 초기 네트워크 파라미터 값에 크게 의존하는 단점이 있다. 본 논문에서 제안하는 하이브리드 모의 담금질 기법은 모의 담금질 기법의 전 영역 탐색 능력과 경사 기반 학습 알고리즘의 지역 최적화 능력을 조합하여 전 파라미터 영역에서 해를 찾을 수 있도록 한다. 제안하는 기법을 함수 근사화 문제에 적용하여 기존의 학습 알고리즘에 비해 더 좋은 학습 및 일반화 성능을 보이는 네트워크 파라미터를 찾을 수 있으며, 초기 파라미터 값의 영향을 크게 줄일 수 있음을 보인다."
        },
        {
          "rank": 36,
          "score": 0.6072214841842651,
          "doc_id": "JAKO199900842577131",
          "title": "다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화",
          "abstract": "이 논문에서는 오차 역전파 학습 알고리듬의 학습 속도를 향상시키기 위한 새로운 학습 방법을 제안한다. 제안하고자 하는 방법은 시그모이드 형태를 갖는 신경회로망의 활성화 함수(activation function) 자체에 고차항(higher order)을 적절히 이용하여 초기 학습 단계에서 발생할 수 있는 조기 포화(premature saturation) 현상을 계산량의 큰 증가 없이 효과적으로 대처할 수 있다. 고차항을 이용함으로써 은닉층 활성화 함수의 도합수가 작은 값으로 감소함에 따라 신경망의 연결 강도를 학습시키는 학습율은 적응적으로 큰 값을 갖게 된다. 또한, 은닉층에 고차항을 이용하는 제안한 방법에 모멘텀(momentum) 학습 알고리듬을 결합하는 새로운 hybrid 학습 방법을 제안한다. 컴퓨터 모의 실험을 통해 제안하고자 하는 학습 방법과 기존의 방법들과의 학습 속도 성능을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199900842577131&target=NART&cn=JAKO199900842577131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 이 논문에서는 오차 역전파 학습 알고리듬의 학습 속도를 향상시키기 위한 새로운 학습 방법을 제안한다. 제안하고자 하는 방법은 시그모이드 형태를 갖는 신경회로망의 활성화 함수(activation function) 자체에 고차항(higher order)을 적절히 이용하여 초기 학습 단계에서 발생할 수 있는 조기 포화(premature saturation) 현상을 계산량의 큰 증가 없이 효과적으로 대처할 수 있다. 고차항을 이용함으로써 은닉층 활성화 함수의 도합수가 작은 값으로 감소함에 따라 신경망의 연결 강도를 학습시키는 학습율은 적응적으로 큰 값을 갖게 된다. 또한, 은닉층에 고차항을 이용하는 제안한 방법에 모멘텀(momentum) 학습 알고리듬을 결합하는 새로운 hybrid 학습 방법을 제안한다. 컴퓨터 모의 실험을 통해 제안하고자 하는 학습 방법과 기존의 방법들과의 학습 속도 성능을 비교한다."
        },
        {
          "rank": 37,
          "score": 0.6072141528129578,
          "doc_id": "NART123156091",
          "title": "Artificial Neural Networks Applied in Civil Engineering",
          "abstract": "<P>In recent years, artificial neural networks (ANN) and artificial intelligence (AI), in general, have garnered significant attention with respect to their applications in several scientific fields, varying from big data management to medical diagnosis [...]</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123156091&target=NART&cn=NART123156091",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied in Civil Engineering Artificial Neural Networks Applied in Civil Engineering Artificial Neural Networks Applied in Civil Engineering <P>In recent years, artificial neural networks (ANN) and artificial intelligence (AI), in general, have garnered significant attention with respect to their applications in several scientific fields, varying from big data management to medical diagnosis [...]</P>"
        },
        {
          "rank": 38,
          "score": 0.6059263944625854,
          "doc_id": "ART002897789",
          "title": "Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork",
          "abstract": "In this study, a modified Artificial Neural Network (ANN) and Support Vector Regression (SVR) with three different optimization algorithms (Genetic, Salp Swarm and Grasshopper) were used to establish an accurate and easy-to-use module to predict the lateral pressure exerted by fresh concrete on formwork based on three main inputs, namely mix proportions (cement content, w/c, coarse aggregates, fine aggregates and admixture agent), casting rate, and height of specimens. The data have been obtained from 30 previously piloted experimental studies (resulted 113 samples). Achieved results for the model including all the input data provide the most excellent prediction of the exerted lateral pressure. Additionally, having different magnitudes of powder volume, aggregate volume and fluid content in the mix exposes different rising and descending in the lateral pressure outcomes. The results indicate that each model has its own advantages and disadvantages; however, the root mean square error values of the SVR models are lower than that of the ANN model. Additionally, the proposed models have been validated and all of them can accurately predict the lateral pressure of fresh concrete on the panel of the formwork.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002897789&target=NART&cn=ART002897789",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork Modified Artificial Neural Networks and Support Vector Regression to Predict Lateral Pressure Exerted by Fresh Concrete on Formwork In this study, a modified Artificial Neural Network (ANN) and Support Vector Regression (SVR) with three different optimization algorithms (Genetic, Salp Swarm and Grasshopper) were used to establish an accurate and easy-to-use module to predict the lateral pressure exerted by fresh concrete on formwork based on three main inputs, namely mix proportions (cement content, w/c, coarse aggregates, fine aggregates and admixture agent), casting rate, and height of specimens. The data have been obtained from 30 previously piloted experimental studies (resulted 113 samples). Achieved results for the model including all the input data provide the most excellent prediction of the exerted lateral pressure. Additionally, having different magnitudes of powder volume, aggregate volume and fluid content in the mix exposes different rising and descending in the lateral pressure outcomes. The results indicate that each model has its own advantages and disadvantages; however, the root mean square error values of the SVR models are lower than that of the ANN model. Additionally, the proposed models have been validated and all of them can accurately predict the lateral pressure of fresh concrete on the panel of the formwork."
        },
        {
          "rank": 39,
          "score": 0.605582594871521,
          "doc_id": "JAKO201708733756156",
          "title": "서포트 벡터 머신을 이용한 완도 인근해역 추천항로 개선안에 관한 연구",
          "abstract": "항로 설정은 통항 선박들의 안전을 위해 교통 흐름을 반영할 필요가 있으며, 선박들이 항로를 잘 준수하는지 지속적인 경과 분석이 필요하다. 본 연구에서는 완도항 인근해역 추천항로의 문제점을 도출하고 이에 대한 개선안을 제시하였다. 효율적인 항로 중앙선을 설정하기 위해 선박 항적을 기반으로 서포트 벡터 머신을 이용하였다. 추천항로 중앙선을 기준으로 우측으로 항해해야 하므로 통항 선박들의 항적이 2개의 군집으로 분할된다. 서포트 벡터 머신은 패턴 인식 등 많은 분야에서 이용되고 있으며, 특히 이진 분류 기능이 뛰어나다. 연구 결과 장죽수도 방향의 2.4 NM 추천항로 구간에서 동진하는 상선은 약 79.5%가 추천항로를 준수하지 않는 것으로 나타나 선박 충돌 사고 위험이 상존하는 것을 확인하였다. 추천항로를 현 위치에서 북쪽으로 약 300 m 재설정할 경우, 동진하는 상선은 항로를 역주행할 비율이 79.5%에서 30.9%로 낮아지는 것으로 나타났다. 본 연구에서 적용한 서포트 벡터 머신은 선박 항적을 두 군집으로 분류가 가능하므로 항로 중앙선을 효과적으로 설정하는데 응용할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201708733756156&target=NART&cn=JAKO201708733756156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 머신을 이용한 완도 인근해역 추천항로 개선안에 관한 연구 서포트 벡터 머신을 이용한 완도 인근해역 추천항로 개선안에 관한 연구 서포트 벡터 머신을 이용한 완도 인근해역 추천항로 개선안에 관한 연구 항로 설정은 통항 선박들의 안전을 위해 교통 흐름을 반영할 필요가 있으며, 선박들이 항로를 잘 준수하는지 지속적인 경과 분석이 필요하다. 본 연구에서는 완도항 인근해역 추천항로의 문제점을 도출하고 이에 대한 개선안을 제시하였다. 효율적인 항로 중앙선을 설정하기 위해 선박 항적을 기반으로 서포트 벡터 머신을 이용하였다. 추천항로 중앙선을 기준으로 우측으로 항해해야 하므로 통항 선박들의 항적이 2개의 군집으로 분할된다. 서포트 벡터 머신은 패턴 인식 등 많은 분야에서 이용되고 있으며, 특히 이진 분류 기능이 뛰어나다. 연구 결과 장죽수도 방향의 2.4 NM 추천항로 구간에서 동진하는 상선은 약 79.5%가 추천항로를 준수하지 않는 것으로 나타나 선박 충돌 사고 위험이 상존하는 것을 확인하였다. 추천항로를 현 위치에서 북쪽으로 약 300 m 재설정할 경우, 동진하는 상선은 항로를 역주행할 비율이 79.5%에서 30.9%로 낮아지는 것으로 나타났다. 본 연구에서 적용한 서포트 벡터 머신은 선박 항적을 두 군집으로 분류가 가능하므로 항로 중앙선을 효과적으로 설정하는데 응용할 수 있을 것으로 기대된다."
        },
        {
          "rank": 40,
          "score": 0.6026716828346252,
          "doc_id": "JAKO201208438434752",
          "title": "부도 예측을 위한 앙상블 분류기 개발",
          "abstract": "분류기의 앙상블 학습은 여러 개의 서로 다른 분류기들의 조합을 통해 만들어진다. 앙상블 학습은 기계학습 분야에서 많은 관심을 끌고 있는 중요한 연구주제이며 대부분의 경우에 있어서 앙상블 모형은 개별 기저 분류기보다 더 좋은 성과를 내는 것으로 알려져 있다. 본 연구는 부도 예측 모형의 성능개선에 관한 연구이다. 이를 위해 본 연구에서는 단일 모형으로 그 우수성을 인정받고 있는 SVM을 기저 분류기로 사용하는 앙상블 모형에 대해 고찰하였다. SVM 모형의 성능 개선을 위해 bagging과 random subspace 모형을 부도 예측 문제에 적용해 보았으며 bagging 모형과 random subspace 모형의 성과 개선을 위해 bagging과 random subspace의 통합 모형을 제안하였다. 제안한 모형의 성과를 검증하기 위해 실제 기업의 부도 예측 데이터를 사용하여 실험하였고, 실험 결과 본 연구에서 제안한 새로운 형태의 통합 모형이 가장 좋은 성과를 보임을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201208438434752&target=NART&cn=JAKO201208438434752",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부도 예측을 위한 앙상블 분류기 개발 부도 예측을 위한 앙상블 분류기 개발 부도 예측을 위한 앙상블 분류기 개발 분류기의 앙상블 학습은 여러 개의 서로 다른 분류기들의 조합을 통해 만들어진다. 앙상블 학습은 기계학습 분야에서 많은 관심을 끌고 있는 중요한 연구주제이며 대부분의 경우에 있어서 앙상블 모형은 개별 기저 분류기보다 더 좋은 성과를 내는 것으로 알려져 있다. 본 연구는 부도 예측 모형의 성능개선에 관한 연구이다. 이를 위해 본 연구에서는 단일 모형으로 그 우수성을 인정받고 있는 SVM을 기저 분류기로 사용하는 앙상블 모형에 대해 고찰하였다. SVM 모형의 성능 개선을 위해 bagging과 random subspace 모형을 부도 예측 문제에 적용해 보았으며 bagging 모형과 random subspace 모형의 성과 개선을 위해 bagging과 random subspace의 통합 모형을 제안하였다. 제안한 모형의 성과를 검증하기 위해 실제 기업의 부도 예측 데이터를 사용하여 실험하였고, 실험 결과 본 연구에서 제안한 새로운 형태의 통합 모형이 가장 좋은 성과를 보임을 알 수 있었다."
        },
        {
          "rank": 41,
          "score": 0.6020989418029785,
          "doc_id": "ATN0037688802",
          "title": "인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색",
          "abstract": "Artificial neural network technology is a field of computer technology that seeks to mechanically realize human sensory processing and internal changes, and has sufficient relevance to neuroscience, character and moral education. Assuming that character education is an effort to guide the human inner side in a desirable direction, artificial neural networks are excellent as an experimental tool to explain such thought processes and characteristics. Therefore, this study seeks to find implications related to character education and explain the phenomenon based on the operating principle of AI artificial neural network technology. Recently, AI research tends to focus on connectionist intelligence, such as deep neural networks, rather than traditional symbolism. This paper also attempts to explain the unique behavioral characteristics of deep neural networks in relation to important elements of character education in accordance with this trend of the times. As a specific element of implications, “Overfitting: Resolving the concentrated learning ability”, “Activation function; Ensuring individuality and diversity of learners” and “Analog processing: balance between learner's reason and emotion”. As in this paper, efforts to find the implications of personality education from the perspective of AI artificial neural networks have meaning as a tool for fusion with other subjects and broaden the extension of AI information education.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037688802&target=NART&cn=ATN0037688802",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 인공 신경망 기술로 살펴보는 인성 교육의 함의점 모색 Artificial neural network technology is a field of computer technology that seeks to mechanically realize human sensory processing and internal changes, and has sufficient relevance to neuroscience, character and moral education. Assuming that character education is an effort to guide the human inner side in a desirable direction, artificial neural networks are excellent as an experimental tool to explain such thought processes and characteristics. Therefore, this study seeks to find implications related to character education and explain the phenomenon based on the operating principle of AI artificial neural network technology. Recently, AI research tends to focus on connectionist intelligence, such as deep neural networks, rather than traditional symbolism. This paper also attempts to explain the unique behavioral characteristics of deep neural networks in relation to important elements of character education in accordance with this trend of the times. As a specific element of implications, “Overfitting: Resolving the concentrated learning ability”, “Activation function; Ensuring individuality and diversity of learners” and “Analog processing: balance between learner's reason and emotion”. As in this paper, efforts to find the implications of personality education from the perspective of AI artificial neural networks have meaning as a tool for fusion with other subjects and broaden the extension of AI information education."
        },
        {
          "rank": 42,
          "score": 0.6015801429748535,
          "doc_id": "NART23878411",
          "title": "Artificial Neural Networks applied to landslide susceptibility assessment",
          "abstract": "<P><B>Abstract</B></P><P>Landslide hazard mapping is often performed through the identification and analysis of hillslope instability factors, usually managed as thematic data within geographic information systems (GIS). In heuristic approaches, these factors are rated by the attribution of scores based on the assumed role played by each of them in controlling the development of a sliding process. Other more refined methods, based on the principle that the present and the past are keys to the future, have also been developed, thus allowing less subjective analyses in which landslide susceptibility is assessed by statistical relationships between past landslide events and hillslope instability factors. The objective of this research is to define a method with the ability to forecast landslide susceptibility through the application of Artificial Neural Networks (ANNs). The Riomaggiore catchment, a subwatershed of the Reno River basin located in the Northern Apennines (Italy), was chosen as an ideal test site, as it is representative of many of the geomorphological settings within this region.</P><P>In the present application, two different ANNs, used in classification problems, were set up and applied: one belonging to the category of Multi-Layered Perceptron (MLP) and the other to the Probabilistic Neural Network (PNN) family. The hillslope factors that have been taken into account in the analysis were the following: (a) lithology, (b) slope angle, (c), profile curvature, (d) land cover and (e) upslope contributing area. These factors have been classified on nominal scales, and their intersection allowed 3342 homogeneous domains (Unique Condition Unit, UCU) to be singled out, which correspond to the terrain units utilized in this analysis. The model vector used to train the ANNs is a subset of that derived from the production of Unique Condition Units and consists of 3342 records organized in input and output variable vectors. In particular, the hillslope factors, once classified on nominal scales as binary numbers, represent the 19 input variables, while the presence/absence of a landslide in a given terrain unit is assumed to be the output variable. The comparison between the most up-to-date landslide inventory of the Riomaggiore catchment and the hazardous areas, as predicted by the ANNs, showed satisfactory results (with a slight preference for the MLP). For this reason, this is an encouraging preliminary approach towards a systematic introduction of ANN-based statistical methods in landslide hazard assessment and mapping.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART23878411&target=NART&cn=NART23878411",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks applied to landslide susceptibility assessment Artificial Neural Networks applied to landslide susceptibility assessment Artificial Neural Networks applied to landslide susceptibility assessment <P><B>Abstract</B></P><P>Landslide hazard mapping is often performed through the identification and analysis of hillslope instability factors, usually managed as thematic data within geographic information systems (GIS). In heuristic approaches, these factors are rated by the attribution of scores based on the assumed role played by each of them in controlling the development of a sliding process. Other more refined methods, based on the principle that the present and the past are keys to the future, have also been developed, thus allowing less subjective analyses in which landslide susceptibility is assessed by statistical relationships between past landslide events and hillslope instability factors. The objective of this research is to define a method with the ability to forecast landslide susceptibility through the application of Artificial Neural Networks (ANNs). The Riomaggiore catchment, a subwatershed of the Reno River basin located in the Northern Apennines (Italy), was chosen as an ideal test site, as it is representative of many of the geomorphological settings within this region.</P><P>In the present application, two different ANNs, used in classification problems, were set up and applied: one belonging to the category of Multi-Layered Perceptron (MLP) and the other to the Probabilistic Neural Network (PNN) family. The hillslope factors that have been taken into account in the analysis were the following: (a) lithology, (b) slope angle, (c), profile curvature, (d) land cover and (e) upslope contributing area. These factors have been classified on nominal scales, and their intersection allowed 3342 homogeneous domains (Unique Condition Unit, UCU) to be singled out, which correspond to the terrain units utilized in this analysis. The model vector used to train the ANNs is a subset of that derived from the production of Unique Condition Units and consists of 3342 records organized in input and output variable vectors. In particular, the hillslope factors, once classified on nominal scales as binary numbers, represent the 19 input variables, while the presence/absence of a landslide in a given terrain unit is assumed to be the output variable. The comparison between the most up-to-date landslide inventory of the Riomaggiore catchment and the hazardous areas, as predicted by the ANNs, showed satisfactory results (with a slight preference for the MLP). For this reason, this is an encouraging preliminary approach towards a systematic introduction of ANN-based statistical methods in landslide hazard assessment and mapping.</P>"
        },
        {
          "rank": 43,
          "score": 0.6008052825927734,
          "doc_id": "JAKO202125659009583",
          "title": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석",
          "abstract": "전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659009583&target=NART&cn=JAKO202125659009583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다."
        },
        {
          "rank": 44,
          "score": 0.6007953882217407,
          "doc_id": "JAKO200727500210663",
          "title": "신경망을 이용한 영역 행위 예측",
          "abstract": "목적 지향 대화에서 사용자의 의도는 화행과 개념열의 쌍으로 구성된 영역행위로 표현될 수 있다. 사용자 발화에 대한 영역행위 예측은 음성 인식 오류를 보정하는데 유용하며, 시스템 발화에 대한 영역행위 예측은 유연한 응답 생성에 유용하다. 본 논문에서는 신경망을 이용하여 영역행위를 예측하는 모델을 제안한다. 제안 모델은 대화 이력 벡터와 현재 영역행위를 신경망의 입력으로 사용하여 다음 영역행위를 예측한다. 실험 결과, 제안 모델은 화행 예측과 개념열 예측에서 각각 80.02%, 82.09%의 정확률을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200727500210663&target=NART&cn=JAKO200727500210663",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망을 이용한 영역 행위 예측 신경망을 이용한 영역 행위 예측 신경망을 이용한 영역 행위 예측 목적 지향 대화에서 사용자의 의도는 화행과 개념열의 쌍으로 구성된 영역행위로 표현될 수 있다. 사용자 발화에 대한 영역행위 예측은 음성 인식 오류를 보정하는데 유용하며, 시스템 발화에 대한 영역행위 예측은 유연한 응답 생성에 유용하다. 본 논문에서는 신경망을 이용하여 영역행위를 예측하는 모델을 제안한다. 제안 모델은 대화 이력 벡터와 현재 영역행위를 신경망의 입력으로 사용하여 다음 영역행위를 예측한다. 실험 결과, 제안 모델은 화행 예측과 개념열 예측에서 각각 80.02%, 82.09%의 정확률을 보였다."
        },
        {
          "rank": 45,
          "score": 0.6005167961120605,
          "doc_id": "JAKO202400657610149",
          "title": "서포트 벡터 머신을 활용한 일래스틱 평면 형태데이터의 선형공간 속 분류 연구",
          "abstract": "본 논문에서는 컴퓨터 비전, 의학 이미징과 같은 다양한 응용 분야에서 활용되는 형태데이터에 대하여 서포트 벡터 머신 기반의 분류 모형을 제안하고 다른 통계적 모형들과의 분류 성능을 비교한다. 형태를 함수형 데이터로 표현했을 때, 위치이동, 크기조절, 회전, 재매개변수화와 같은 변동 요인에 불변하는 형태 거리를 가지고 분석하기 위하여 최근 활발히 연구되어지고 있는 일래스틱 형태 분석을 기반으로 한다. 이 분석 틀은 형태를 표현하는 곡선을 제곱근속도함수로 변환하여 곡선의 본래 공간인 리마니안 다양체를 단위 초구로 재구성할 수 있다. 초구 위에 변환된 표본 형태데이터의 평균을 중심으로 탄젠트 공간을 만들고, 그 위로 사영시킨 유클리디안 벡터를 통해 서포트 벡터 머신 방법들로 분류한다. 폰 미제스-피셔 혼합분포를 이용하여 생성한 모의실험 형태데이터와 조류 형태를 분석하는 실제 데이터를 통해 제안한 서포트 벡터 머신 방법과 다른 통계적 분류 모형들을 적용하고 그 성능을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202400657610149&target=NART&cn=JAKO202400657610149",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 머신을 활용한 일래스틱 평면 형태데이터의 선형공간 속 분류 연구 서포트 벡터 머신을 활용한 일래스틱 평면 형태데이터의 선형공간 속 분류 연구 서포트 벡터 머신을 활용한 일래스틱 평면 형태데이터의 선형공간 속 분류 연구 본 논문에서는 컴퓨터 비전, 의학 이미징과 같은 다양한 응용 분야에서 활용되는 형태데이터에 대하여 서포트 벡터 머신 기반의 분류 모형을 제안하고 다른 통계적 모형들과의 분류 성능을 비교한다. 형태를 함수형 데이터로 표현했을 때, 위치이동, 크기조절, 회전, 재매개변수화와 같은 변동 요인에 불변하는 형태 거리를 가지고 분석하기 위하여 최근 활발히 연구되어지고 있는 일래스틱 형태 분석을 기반으로 한다. 이 분석 틀은 형태를 표현하는 곡선을 제곱근속도함수로 변환하여 곡선의 본래 공간인 리마니안 다양체를 단위 초구로 재구성할 수 있다. 초구 위에 변환된 표본 형태데이터의 평균을 중심으로 탄젠트 공간을 만들고, 그 위로 사영시킨 유클리디안 벡터를 통해 서포트 벡터 머신 방법들로 분류한다. 폰 미제스-피셔 혼합분포를 이용하여 생성한 모의실험 형태데이터와 조류 형태를 분석하는 실제 데이터를 통해 제안한 서포트 벡터 머신 방법과 다른 통계적 분류 모형들을 적용하고 그 성능을 비교한다."
        },
        {
          "rank": 46,
          "score": 0.6003634333610535,
          "doc_id": "JAKO201619036407823",
          "title": "서포트 벡터 머신을 이용한 차량도어의 개폐 보조력 예측",
          "abstract": "본 논문에서는 차량이 주차된 지형의 조건에 따라 적용되는 도어 개폐 보조력 예측 모델을 제시하였다. 경사도, 사용자의 힘 등의 조건에 따른 개폐력 설정을 위하여 작동 보조력에 대한 학습 모델을 구현하여 비교하였고, 예측 모델의 학습을 위하여 축소모형을 제작하여 실험을 통해 학습데이터를 얻을 수 있는 실험 모델을 구성하였다. 실제 보상력 데이터를 학습, 반영하여 적정 값을 도출할 수 있는 학습 알고리즘을 개발하고, 이를 적용할 수 있는 시스템을 개발하였다. 학습 방법 중에서 인공신경망(Artificial Neural Network, ANN)과 서포트 벡터 머신(Support Vector Machine, SVM) 알고리즘을 적용하여 비교 검증하였다. 실제 측정값과 비교 검증한 결과, 차량의 도어 개폐 보조력 예측을 위해서 서포트 벡터 머신의 상대적으로 높은 적용성을 확인할 수 있었으며, 이 예측 모델을 활용하여 경사, 사용자의 힘에 따라 도어 개폐 구동 모터가 보상해야 할 적정한 힘을 예측하여 시간에 따라 구동함으로써 사용자가 평지와 같은 힘으로 문을 제어할 수 있는 시스템 구성을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201619036407823&target=NART&cn=JAKO201619036407823",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "서포트 벡터 머신을 이용한 차량도어의 개폐 보조력 예측 서포트 벡터 머신을 이용한 차량도어의 개폐 보조력 예측 서포트 벡터 머신을 이용한 차량도어의 개폐 보조력 예측 본 논문에서는 차량이 주차된 지형의 조건에 따라 적용되는 도어 개폐 보조력 예측 모델을 제시하였다. 경사도, 사용자의 힘 등의 조건에 따른 개폐력 설정을 위하여 작동 보조력에 대한 학습 모델을 구현하여 비교하였고, 예측 모델의 학습을 위하여 축소모형을 제작하여 실험을 통해 학습데이터를 얻을 수 있는 실험 모델을 구성하였다. 실제 보상력 데이터를 학습, 반영하여 적정 값을 도출할 수 있는 학습 알고리즘을 개발하고, 이를 적용할 수 있는 시스템을 개발하였다. 학습 방법 중에서 인공신경망(Artificial Neural Network, ANN)과 서포트 벡터 머신(Support Vector Machine, SVM) 알고리즘을 적용하여 비교 검증하였다. 실제 측정값과 비교 검증한 결과, 차량의 도어 개폐 보조력 예측을 위해서 서포트 벡터 머신의 상대적으로 높은 적용성을 확인할 수 있었으며, 이 예측 모델을 활용하여 경사, 사용자의 힘에 따라 도어 개폐 구동 모터가 보상해야 할 적정한 힘을 예측하여 시간에 따라 구동함으로써 사용자가 평지와 같은 힘으로 문을 제어할 수 있는 시스템 구성을 제시하였다."
        },
        {
          "rank": 47,
          "score": 0.5990181565284729,
          "doc_id": "JAKO200311922141107",
          "title": "강화학습의 학습 가속을 위한 함수 근사 방법",
          "abstract": "강화학습은 제어, 스케쥴링 등 많은 응용분야에서 성공적인 학습 결과를 얻었다. 기본적인 강화학습 알고리즘인 Q-Learning, TD(λ), SARSA 등의 학습 속도의 개선과 기억장소 등의 문제를 해결하기 위해서 여러 함수 근사방법(function approximation methods)이 연구되었다. 대부분의 함수 근사 방법들은 가정을 통하여 강화학습의 일부 특성을 제거하고 사전지식과 사전처리가 필요하다. 예로 Fuzzy Q-Learning은 퍼지 변수를 정의하기 위한 사전 처리가 필요하고, 국소 최소 자승법은 훈련 예제집합을 이용한다. 본 논문에서는 온-라인 퍼지 클러스터링을 이용한 함수 근사 방법인 Fuzzy Q-Map을 제안하다. Fuzzy Q-Map은 사전 지식이 최소한으로 주어진 환경에서, 온라인으로 주어지는 상태를 거리에 따른 소속도(membership degree)를 이용하여 분류하고 행동을 예측한다. Fuzzy Q-Map과 다른 함수 근사 방법인 CMAC와 LWR을 마운틴 카 문제에 적용하여 실험 한 결과 Fuzzy Q-Map은 훈련예제를 사용하지 않는 CMAC보다는 빠르게 최고 예측율에 도달하였고, 훈련 예제를 사용한 LWR보다는 낮은 예측율을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922141107&target=NART&cn=JAKO200311922141107",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "강화학습의 학습 가속을 위한 함수 근사 방법 강화학습의 학습 가속을 위한 함수 근사 방법 강화학습의 학습 가속을 위한 함수 근사 방법 강화학습은 제어, 스케쥴링 등 많은 응용분야에서 성공적인 학습 결과를 얻었다. 기본적인 강화학습 알고리즘인 Q-Learning, TD(λ), SARSA 등의 학습 속도의 개선과 기억장소 등의 문제를 해결하기 위해서 여러 함수 근사방법(function approximation methods)이 연구되었다. 대부분의 함수 근사 방법들은 가정을 통하여 강화학습의 일부 특성을 제거하고 사전지식과 사전처리가 필요하다. 예로 Fuzzy Q-Learning은 퍼지 변수를 정의하기 위한 사전 처리가 필요하고, 국소 최소 자승법은 훈련 예제집합을 이용한다. 본 논문에서는 온-라인 퍼지 클러스터링을 이용한 함수 근사 방법인 Fuzzy Q-Map을 제안하다. Fuzzy Q-Map은 사전 지식이 최소한으로 주어진 환경에서, 온라인으로 주어지는 상태를 거리에 따른 소속도(membership degree)를 이용하여 분류하고 행동을 예측한다. Fuzzy Q-Map과 다른 함수 근사 방법인 CMAC와 LWR을 마운틴 카 문제에 적용하여 실험 한 결과 Fuzzy Q-Map은 훈련예제를 사용하지 않는 CMAC보다는 빠르게 최고 예측율에 도달하였고, 훈련 예제를 사용한 LWR보다는 낮은 예측율을 보였다."
        },
        {
          "rank": 48,
          "score": 0.5989242792129517,
          "doc_id": "JAKO201220962918849",
          "title": "수화 패턴 인식을 위한 2단계 신경망 모델",
          "abstract": "본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201220962918849&target=NART&cn=JAKO201220962918849",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다."
        },
        {
          "rank": 49,
          "score": 0.5983206033706665,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 50,
          "score": 0.5977659821510315,
          "doc_id": "JAKO200907653004097",
          "title": "얼굴 등록자 인증을 위한 클래스 구별 특징 벡터 기반 서포트 벡터 머신",
          "abstract": "얼굴 등록자 인증은 얼굴 인식을 기반으로 인증하고자 하는 사람이 등록자인지, 아닌지를 판별하는 것으로, 기본적으로 2클래스 분류 문제이다. 서포트 벡터 머신(Support Vector Machine, 이하 SVM)은 2 클래스 분류 문제에 효과적인 것으로 잘 알려져 있다. 얼굴 등록자 인증의 분류에 사용되었던 기존의 SVM들은 각 클래스 (등록자 클래스, 미등록자 클래스) 구성원의 얼굴 이미지로부터 추출된 이미지 특징 벡터를 이용하여 훈련되고 인증된다. 이렇게 훈련 세트 구성원들의 이미지 특징 벡터들로 훈련된 SVM은 인증시의 얼굴 이미지가 SVM 훈련 세트의 얼굴 이미지들의 조명, 자세, 표정들과 다른 인증 환경의 경우나 등록자의 가입 및 탈퇴 등으로 등록 클래스나 미등록 클래스의 구성과 크기에 변동이 생기는 인증 환경의 경우에, 강인한 성능을 보이기 어려웠다. 본 논문에서는 강인한 얼굴 등록자 인증을 위하여, 효과적인 클래스 구별 특징 벡터 기반 SVM을 제안한다. 훈련과 인증에 사용되는 특징 벡터는 2개의 클래스를 잘 구별할 수 있는 특성을 반영하도록 선택되었기 때문에 이를 이용하여 훈련된 제안된 SVM은 등록자 클래스 구성의 변화 및 얼굴 이미지에 있어서의 조명, 얼굴 자세, 얼굴 표정의 변화에 덜 영향을 받는다. 실험을 통해 제안된 SVM에 기반을 둔 얼굴 등록자 인증 방법이 기존 SVM에 기반을 둔 방법보다 성능이 더 나으며, 등록자 클래스 구성의 변화에도 강인함을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200907653004097&target=NART&cn=JAKO200907653004097",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "얼굴 등록자 인증을 위한 클래스 구별 특징 벡터 기반 서포트 벡터 머신 얼굴 등록자 인증을 위한 클래스 구별 특징 벡터 기반 서포트 벡터 머신 얼굴 등록자 인증을 위한 클래스 구별 특징 벡터 기반 서포트 벡터 머신 얼굴 등록자 인증은 얼굴 인식을 기반으로 인증하고자 하는 사람이 등록자인지, 아닌지를 판별하는 것으로, 기본적으로 2클래스 분류 문제이다. 서포트 벡터 머신(Support Vector Machine, 이하 SVM)은 2 클래스 분류 문제에 효과적인 것으로 잘 알려져 있다. 얼굴 등록자 인증의 분류에 사용되었던 기존의 SVM들은 각 클래스 (등록자 클래스, 미등록자 클래스) 구성원의 얼굴 이미지로부터 추출된 이미지 특징 벡터를 이용하여 훈련되고 인증된다. 이렇게 훈련 세트 구성원들의 이미지 특징 벡터들로 훈련된 SVM은 인증시의 얼굴 이미지가 SVM 훈련 세트의 얼굴 이미지들의 조명, 자세, 표정들과 다른 인증 환경의 경우나 등록자의 가입 및 탈퇴 등으로 등록 클래스나 미등록 클래스의 구성과 크기에 변동이 생기는 인증 환경의 경우에, 강인한 성능을 보이기 어려웠다. 본 논문에서는 강인한 얼굴 등록자 인증을 위하여, 효과적인 클래스 구별 특징 벡터 기반 SVM을 제안한다. 훈련과 인증에 사용되는 특징 벡터는 2개의 클래스를 잘 구별할 수 있는 특성을 반영하도록 선택되었기 때문에 이를 이용하여 훈련된 제안된 SVM은 등록자 클래스 구성의 변화 및 얼굴 이미지에 있어서의 조명, 얼굴 자세, 얼굴 표정의 변화에 덜 영향을 받는다. 실험을 통해 제안된 SVM에 기반을 둔 얼굴 등록자 인증 방법이 기존 SVM에 기반을 둔 방법보다 성능이 더 나으며, 등록자 클래스 구성의 변화에도 강인함을 보였다."
        }
      ]
    },
    {
      "query": "How do artificial neural networks utilize weight matrices and vector mappings to relate inputs and outputs in applied linguistics?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.7827852964401245,
          "doc_id": "ART002391816",
          "title": "Artificial Intelligence, Language Intelligence, and Mathematics",
          "abstract": "Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002391816&target=NART&cn=ART002391816",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial Intelligence, Language Intelligence, and Mathematics Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication."
        },
        {
          "rank": 2,
          "score": 0.757412314414978,
          "doc_id": "ATN0053123228",
          "title": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS",
          "abstract": "<jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0053123228&target=NART&cn=ATN0053123228",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS ARTIFICIAL NEURAL NETWORKS IN MACHINE LINGUISTICS <jats:p>Artificial neural networks (ANN) have revolutionized natural language processing (NLP) and have fundamentally changed the approach to solving linguistic problems. Due to their ability to learn from large amounts of data, ANNs demonstrate high performance</jats:p>"
        },
        {
          "rank": 3,
          "score": 0.6867194771766663,
          "doc_id": "JAKO200211921413494",
          "title": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망",
          "abstract": "본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921413494&target=NART&cn=JAKO200211921413494",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 비선형 함수 학습 근사화를 위한 퍼지 개념을 이용한 웨이브렛 신경망 본 논문에서는 퍼지와 웨이브렛 변환의 다해상도 분해(MRA)를 가진 퍼지 개념을 이용한 웨이브렛 신경망을 제안하고, 또한 이 시스템을 이용하여 임의의 비선형 함수 학습 근사화를 개선하고자 한다. 여기에서 퍼지 개념은 벨(bell)형 퍼지 소속함수를 사용하였다. 그리고 웨이브렛의 구성은 단일 크기를 가지고 있으며, 퍼지 개념을 이용한 웨이브렛 신경망의 학습을 위해 역전파 알고리즘을 사용하였다. 웨이브렛 변환의 다해상도 분해, 벨형 퍼지 소속 함수 그리고 학습을 위한 역전파 알고리즘을 이용한 이 구조는 기존의 알고리즘보다 근사화 성능이 개선됨을 모의 실험을 통하여 1차원, 2차원 함수에서 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.6757840514183044,
          "doc_id": "JAKO202125659009583",
          "title": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석",
          "abstract": "전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125659009583&target=NART&cn=JAKO202125659009583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 딥러닝을 이용한 기형도 시의 핵심 이미지 분석 전후방 단어들의 인접 여부 혹은 후방 단어들의 순서를 학습할 수 있는 통계 기법인 SVD, 딥러닝 기법인 CBOW, LSTM으로 단어벡터를 구할 수 있다. 이렇게 학습된 단어벡터를 기형도의 시에 적용하여 핵심 이미지를 대표하는 단어들과 유사도 높은 단어를 구해서 분석해 보았다. 시적 이미지와 어울리지 않는 단어들이 연산되기도 하지만 그 단어가 사용된 시적 맥락에서는 기준 단어와 유사한 이미지를 표현하고 있음을 알 수 있었다. 이러한 단어벡터를 활용하면 핵심 이미지를 대표하는 단어들의 관계와 유사한 관계의 다른 단어들도 유추할 수 있다. 따라서 통계 기법인 SVD 및 딥러닝 기법인 CBOW와 LSTM으로 구한 단어벡터의 유사도 및 유추 연산을 통해 대상 시를 다양하고 심도 깊게 분석할 수 있다."
        },
        {
          "rank": 5,
          "score": 0.668110191822052,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 6,
          "score": 0.6633047461509705,
          "doc_id": "ART002543005",
          "title": "Comparison of Weight Initialization Techniques for Deep Neural Networks",
          "abstract": "Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002543005&target=NART&cn=ART002543005",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Comparison of Weight Initialization Techniques for Deep Neural Networks Neural networks have been reborn as a Deep Learning thanks to big data, improved processor, and some modification of training methods. Neural networks used to initialize weights in a stupid way, and to choose wrong type activation functions of non-linearity. Weight initialization contributes as a significant factor on the final quality of a network as well as its convergence rate. This paper discusses different approaches to weight initialization. MNIST dataset is used for experiments for comparing their results to find out the best technique that can be employed to achieve higher accuracy in relatively lower duration."
        },
        {
          "rank": 7,
          "score": 0.6628748178482056,
          "doc_id": "NART12793683",
          "title": "Approximating vertical vector fields for feedforward neural networks",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART12793683&target=NART&cn=NART12793683",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks Approximating vertical vector fields for feedforward neural networks <P><B>Abstract</B></P><P>In this paper, we investigate the problem of approximating a vertical vector field for a given nonlinear mapping. Our primary interest lies with artificial neural networks of feedforward type, although the method could easily be applied to other nonlinear mappings. We calculate a Lie group approximation of the vertical vector field.</P>"
        },
        {
          "rank": 8,
          "score": 0.6567813754081726,
          "doc_id": "NART18014750",
          "title": "Neural nets and hidden Markov models: Review and generalizations",
          "abstract": "Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18014750&target=NART&cn=NART18014750",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs)."
        },
        {
          "rank": 9,
          "score": 0.6535032987594604,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 10,
          "score": 0.6518399715423584,
          "doc_id": "ATN0030166808",
          "title": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법",
          "abstract": "인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030166808&target=NART&cn=ATN0030166808",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망에서 은닉 유닛 명확화를 이용한 효율적인 규칙추출 방법 인공 신경망은 최근 다양한 분야에서 뛰어난 성능을 보여주고 있다. 하지만 인공 신경망이 학습한 지식이 정확히 어떤 내용인지를 사람이 파악하기 어렵다는 문제점이 존재하는데, 이를 해결하기 위한 방법 중 하나로 학습된 인공 신경망에서 규칙을 추출하는 방법들이 연구되고 있다. 본 연구에서는 학습된 인공 신경망으로부터 규칙을 추출하는 방법 중 하나인 ordered-attribute search(OAS) 알고리즘을 사용하여 인공 신경망으로부터 규칙을 추출해보고, 추출된 규칙을 개선하기 위해 규칙들을 분석하였다. 그 결과로 은닉 층의 출력값 분포가 OAS 알고리즘을 이용해 추출된 규칙의 정확도에 영향을 주는 것을 파악하였고, 은닉 유닛 명확화 기법을 통해 은닉 층 출력값을 이진화하여 효율적인 규칙을 추출할 수 있음을 제시하였다."
        },
        {
          "rank": 11,
          "score": 0.6497377753257751,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 12,
          "score": 0.6495898365974426,
          "doc_id": "NART32653959",
          "title": "Integrating support vector machines and neural networks",
          "abstract": "<P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART32653959&target=NART&cn=NART32653959",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Integrating support vector machines and neural networks Integrating support vector machines and neural networks Integrating support vector machines and neural networks <P><B>Abstract</B></P><P>Support vector machines (SVMs) are a powerful technique developed in the last decade to effectively tackle classification and regression problems. In this paper we describe how support vector machines and artificial neural networks can be integrated in order to classify objects correctly. This technique has been successfully applied to the problem of determining the quality of tiles. Using an optical reader system, some features are automatically extracted, then a subset of the features is determined and the tiles are classified based on this subset.</P>"
        },
        {
          "rank": 13,
          "score": 0.648346483707428,
          "doc_id": "ART002967567",
          "title": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks",
          "abstract": "Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002967567&target=NART&cn=ART002967567",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Straightforward Clarification for Fundamental Algorithms of Artificial Neural Networks Artificial neural networks (ANNs) have revolutionized the field of science in the last few decades. Unlike classical machine learning (ML) algorithms, which require human effort to craft well-structured features, an ANN automatically extracts complex patterns as features and passes them into ML to perform various downstream tasks, such as classification and segmentation. Hence, ANNs have made most classical ML algorithms obsolete for many tasks. In addition, deep learning-based models, such as convolutional neural networks, recurrent neural networks, graph neural networks, and generative adversarial neural networks, accelerate artificial intelligence (AI) applications. Therefore, it is essential for novices in ML to understand the basic functionality of ANN to pursue deep learning-related algorithms. Considering this importance, this paper explains the major functionalities of ANN algorithms, such as loss function and backpropagation."
        },
        {
          "rank": 14,
          "score": 0.6470967531204224,
          "doc_id": "JAKO202128557368138",
          "title": "인공지능을 활용한 기계학습 앙상블 모델 개발",
          "abstract": "To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202128557368138&target=NART&cn=JAKO202128557368138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 인공지능을 활용한 기계학습 앙상블 모델 개발 To predict mechanical properties of secondary hardening martensitic steels, a machine learning ensemble model was established. Based on ANN(Artificial Neural Network) architecture, some kinds of methods was considered to optimize the model. In particular, interaction features, which can reflect interactions between chemical compositions and processing conditions of real alloy system, was considered by means of feature engineering, and then K-Fold cross validation coupled with bagging ensemble were investigated to reduce R2_score and a factor indicating average learning errors owing to biased experimental database."
        },
        {
          "rank": 15,
          "score": 0.6443426609039307,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 16,
          "score": 0.6428488492965698,
          "doc_id": "NART07374155",
          "title": "Artificial neural networks as applied to long-term demand forecasting",
          "abstract": "<P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART07374155&target=NART&cn=NART07374155",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting Artificial neural networks as applied to long-term demand forecasting <P><B>Abstract</B></P><P>This paper reports on the application of Artificial Neural Networks (ANN) to long-term load forecasting. The ANN model is used to forecast the energy requirements of an electric utility. It is then compared to time series models. The comparison reveals that the ANN produces results that are close to the actual data. The ANN model is then used to forecast the annual peak demand of a Middle Eastern utility up to the year 2006. The results compare favorably with the utility&#x2019;s forecast.</P>"
        },
        {
          "rank": 17,
          "score": 0.6408742666244507,
          "doc_id": "JAKO200011920771446",
          "title": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축",
          "abstract": "본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771446&target=NART&cn=JAKO200011920771446",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다."
        },
        {
          "rank": 18,
          "score": 0.6406937837600708,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 19,
          "score": 0.638673722743988,
          "doc_id": "JAKO199911921383665",
          "title": "회귀신경망을 이용한 음성인식에 관한 연구",
          "abstract": "본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921383665&target=NART&cn=JAKO199911921383665",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다."
        },
        {
          "rank": 20,
          "score": 0.6385462284088135,
          "doc_id": "JAKO200011920771131",
          "title": "은닉지식 추출을 이용한 신경망회로망 정제",
          "abstract": "신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771131&target=NART&cn=JAKO200011920771131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 은닉지식 추출을 이용한 신경망회로망 정제 신경회로망 구조의 정제(精製)는 회로망의 일반화능력이나 효율성의 관점에서 중요한 문제이다. 본 논문에서는 feed-forward neural networks로부터 은닉지식을 추출하는 방법을 사용하여 네트워크 재구성을 통한 정제방법을 제안한다. 먼저, 효율적인 if-then rule 추출방법을 제시하고 그 추출된 룰들을 사용하여 룰기반 네트워크로 변환하는 과정을 보여준다. 생성된 룰기반 네트워크 fully connected network에 비하여 상당히 축소된 연결 복잡도를 가지게 되며 일반적으로 더 우수한 일반화능력을 가지게 된다. 본 연구는 도메인 지식이 없이 데이타만 사용하여 어떻게 정제된 룰기반 신경망회로를 생성하고 있는가를 보여준다. 도메인 데이타들에 대한 실험결과도 제시하였다."
        },
        {
          "rank": 21,
          "score": 0.6383131146430969,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 22,
          "score": 0.6382537484169006,
          "doc_id": "JAKO201707851605473",
          "title": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표",
          "abstract": "본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201707851605473&target=NART&cn=JAKO201707851605473",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다."
        },
        {
          "rank": 23,
          "score": 0.6381742358207703,
          "doc_id": "DIKO0008264256",
          "title": "부스팅을 이용한 서포트벡터 머신의 분류",
          "abstract": "본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0008264256&target=NART&cn=DIKO0008264256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 부스팅을 이용한 서포트벡터 머신의 분류 본 논문은 기존의 기계학습(Machine Learning)에서 주로 사용되어져 왔던 신경망 (Neural Network)의 일반화에 대한 문제점과 학습 수행에 중대한 영향을 미치는 모수 선택과정에서 경험에 의존한 문제점을 해결할 수 있는 서포트벡터 머신(Support Vector Machine)을 소개한다. 그리고 서포트벡터 머신에서 해를 구하기 위해 사용되는 알고리즘인 QP(Quadratic Programming)의 문제점을 해결하기 위해 개발된 커널-애더트론(Kernel Adatron)알고리즘 소개한다. 또한 주어진 학습 알고리즘의 정확도를 향상시키기 위한 부스팅(Boosting)알고리즘을 소개하고, 서포트벡터 머신과 부스팅을 결합한 알고리즘을 제안하고, 이 제안된 알고리즘의 우수성을 실제자료와 모의실험을 통하여 확인하였다."
        },
        {
          "rank": 24,
          "score": 0.6357513666152954,
          "doc_id": "ART002606556",
          "title": "Influence of random topology in artificial neural networks: A survey",
          "abstract": "Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002606556&target=NART&cn=ART002606556",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Influence of random topology in artificial neural networks: A survey Due to the fully-connected complex structure of Artificial Neural Networks (ANNs), systems based on ANN may consume much computational time, energy and space. Therefore, intense research has been recently centered on changing the topology and design of ANNs to obtain high performance. To explore the influence of network structure on ANNs complex systems topologies have been applied in these networks to have more efficient and less complex structures while they are more similar to biological systems at the same time. In this paper, the methodology and results of some recent papers are summarized and discussed in which the authors investigated the efficacy of random complex networks on the performance of Hopfield associative memory and multi-layer ANNs compared with ANNs with small-world, scale-free and regular structures."
        },
        {
          "rank": 25,
          "score": 0.6347057819366455,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 26,
          "score": 0.6341137290000916,
          "doc_id": "NART53843256",
          "title": "Neural development of networks for audiovisual speech comprehension",
          "abstract": "<P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53843256&target=NART&cn=NART53843256",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension Neural development of networks for audiovisual speech comprehension <P><B>Abstract</B></P><P>Everyday conversation is both an auditory and a visual phenomenon. While visual speech information enhances comprehension for the listener, evidence suggests that the ability to benefit from this information improves with development. A number of brain regions have been implicated in audiovisual speech comprehension, but the extent to which the neurobiological substrate in the child compares to the adult is unknown. In particular, developmental differences in the network for audiovisual speech comprehension could manifest through the incorporation of additional brain regions, or through different patterns of effective connectivity. In the present study we used functional magnetic resonance imaging and structural equation modeling (SEM) to characterize the developmental changes in network interactions for audiovisual speech comprehension. The brain response was recorded while children 8- to 11-years-old and adults passively listened to stories under audiovisual (AV) and auditory-only (A) conditions. Results showed that in children and adults, AV comprehension activated the same fronto-temporo-parietal network of regions known for their contribution to speech production and perception. However, the SEM network analysis revealed age-related differences in the functional interactions among these regions. In particular, the influence of the posterior inferior frontal gyrus/ventral premotor cortex on supramarginal gyrus differed across age groups during AV, but not A speech. This functional pathway might be important for relating motor and sensory information used by the listener to identify speech sounds. Further, its development might reflect changes in the mechanisms that relate visual speech information to articulatory speech representations through experience producing and perceiving speech.</P>"
        },
        {
          "rank": 27,
          "score": 0.6331676244735718,
          "doc_id": "ART002675389",
          "title": "딥러닝 기반 자연어 처리에서 도메인 지식의 역할",
          "abstract": "Symbolic AI에서는 도메인 지식이 중요시되었다. 규칙 기반 자연어처리에서도 언어학적 지식이 중요한 역할을 담당했다. 확률 기반 자연어처리와 기계학습 기법이 발달하면서 도메인 지식의 역할은 축소되었다. 딥러닝이 대두하면서, 자질 공학과 도메인 지식의 역할은 훨씬 더 축소되었다. 딥러닝 시대에도 여전히 도메인 전문가(언어학자)의 역할이 중요함을 증명하기 위해 한국어 형태소분석기를 개발하였다. 한국어는 형태음소적 교체, 탈락, 축약이 활발하여 분절 과제가 쉽지 않지만, 분절 과제를 분류 문제로 재설정하면 기계학습으로 더 쉽게 해결할 수 있게 된다. 이를 위해서는 분절 이전의 입력의 각 음절과 분절된 출력의 대응하는 문자열 사이의 매핑 관계를 망라적으로 목록화하는 것이 관건이다. 1200만 어절 규모의 세종 형태의미 분석 말뭉치를 통해 이러한 매핑에 200개 유형이 있음을 확인하였다. 이 200개 범주를 바탕으로 LSTM 기반 신경망 모델을 만들어 훈련시켰다. 분절 문제가 해결되면, 분절된 각 토큰에 대한 레이블링은, 영어 등에 대한 선행 연구로 친숙한 연쇄 레이블링 알고리즘으로 쉽게 해결할 수 있다. 이 두 가지 모델과 사전을 결합하여, F1 스코어 98.0%의 성능을 얻을 수 있었다. 이 실험은 딥러닝 시대에도 도메인 지식이 여전히 중요함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002675389&target=NART&cn=ART002675389",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝 기반 자연어 처리에서 도메인 지식의 역할 딥러닝 기반 자연어 처리에서 도메인 지식의 역할 딥러닝 기반 자연어 처리에서 도메인 지식의 역할 Symbolic AI에서는 도메인 지식이 중요시되었다. 규칙 기반 자연어처리에서도 언어학적 지식이 중요한 역할을 담당했다. 확률 기반 자연어처리와 기계학습 기법이 발달하면서 도메인 지식의 역할은 축소되었다. 딥러닝이 대두하면서, 자질 공학과 도메인 지식의 역할은 훨씬 더 축소되었다. 딥러닝 시대에도 여전히 도메인 전문가(언어학자)의 역할이 중요함을 증명하기 위해 한국어 형태소분석기를 개발하였다. 한국어는 형태음소적 교체, 탈락, 축약이 활발하여 분절 과제가 쉽지 않지만, 분절 과제를 분류 문제로 재설정하면 기계학습으로 더 쉽게 해결할 수 있게 된다. 이를 위해서는 분절 이전의 입력의 각 음절과 분절된 출력의 대응하는 문자열 사이의 매핑 관계를 망라적으로 목록화하는 것이 관건이다. 1200만 어절 규모의 세종 형태의미 분석 말뭉치를 통해 이러한 매핑에 200개 유형이 있음을 확인하였다. 이 200개 범주를 바탕으로 LSTM 기반 신경망 모델을 만들어 훈련시켰다. 분절 문제가 해결되면, 분절된 각 토큰에 대한 레이블링은, 영어 등에 대한 선행 연구로 친숙한 연쇄 레이블링 알고리즘으로 쉽게 해결할 수 있다. 이 두 가지 모델과 사전을 결합하여, F1 스코어 98.0%의 성능을 얻을 수 있었다. 이 실험은 딥러닝 시대에도 도메인 지식이 여전히 중요함을 보여준다."
        },
        {
          "rank": 28,
          "score": 0.6331013441085815,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 29,
          "score": 0.6330766677856445,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 30,
          "score": 0.631494402885437,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        },
        {
          "rank": 31,
          "score": 0.6311557292938232,
          "doc_id": "NART56157711",
          "title": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식",
          "abstract": "<P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157711&target=NART&cn=NART56157711",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 <P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>"
        },
        {
          "rank": 32,
          "score": 0.6310458183288574,
          "doc_id": "NART75359998",
          "title": "Artificial Neural Networks Applied to Image Steganography",
          "abstract": "<P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75359998&target=NART&cn=NART75359998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography <P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>"
        },
        {
          "rank": 33,
          "score": 0.6299959421157837,
          "doc_id": "JAKO201734964189755",
          "title": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식",
          "abstract": "본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734964189755&target=NART&cn=JAKO201734964189755",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다."
        },
        {
          "rank": 34,
          "score": 0.6297661066055298,
          "doc_id": "NART56157538",
          "title": "확장된 ART 인공 신경망",
          "abstract": "<P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157538&target=NART&cn=NART56157538",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "확장된 ART 인공 신경망 확장된 ART 인공 신경망 확장된 ART 인공 신경망 <P> 본 논문에서는 임의의 순서의 입력 패턴에 대해서도 실시간에 안정된 인식 영역을 스스로 만들어 가는 자율적인 적응 인공 신경망 모델인 ART의 결점을 찾아서 수학적인 분석과 컴퓨터 시뮬레이션을 통해서 그 해결 방안을 모색하였다. 그리고 새로운 확장된 인공 신경망 모델(EART)을 제시하였다.  자율적인 적응학습방법을 사용하는 이 모델은 Grossberg가 주창한 ART의 모든 특성을 만족시켜 준다. 그리고 일정하게 감소하거나 증가하는 순서로 들어오는 입력 패턴에 대해서도 안정된 인식을 할 수 있다. 특히 입력 패턴의 학습이 완료된 후에 유사성을 비교해서 리세트 시스템을 동작하도록 하는 ART와는 달리, 연속적인 리세트 형태로 이루어져 있기 때문에, 학습을 하는 동안에 바로 리세트 시스템을 동작하도록 함으로써 전체 학습시간을 단축시킬 수 있다. 마지막으로 LLTM 기술을 이용하여 어느 정도의 화상개념을 구체화했다.</P>"
        },
        {
          "rank": 35,
          "score": 0.6292771100997925,
          "doc_id": "JAKO201006159731627",
          "title": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구",
          "abstract": "정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201006159731627&target=NART&cn=JAKO201006159731627",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 나이브베이즈 분류모델과 협업필터링 기반 지능형 학술논문 추천시스템 연구 정보기술과 인터넷의 발달로 학술정보가 폭발적으로 증가하고 있다. 정보 과잉으로 인해 연구자들은 필요한 정보를 찾거나 필터링하는데 더 많은 시간과 노력을 투입하고 있다. 이용자들이 원하는 정보를 예측하여 관심 가질만한 정보를 선별하여 추천하는 시스템을 전문가시스템, 데이터마이닝, 정보검색 등 다양한 분야에서 오래 전부터 연구하여 왔다. 최근에는 콘텐츠기반추천시스템과 협업필터링을 결합하거나 다른 분야 모델을 접목한 하이브리드 추천시스템으로 발전하고 있다. 본 연구에서는 기존 추천시스템 문제를 해결하고 대규모 정보센터나 도서관에서 학술논문을 효율적이고 지능적으로 추천하기 위해 협업필터링과 나이브베이즈모델을 결합한 새로운 방식의 추천시스템을 제시하였다. 즉, 협업필터링 방식으로 과도한 특성화(Over-specialization) 문제를 해결하고, 나이브베이즈모델을 통해 평가정보나 이용정보가 부족한 신규콘텐츠 추천문제를 해소하였다. 본 모델을 검증하기 위해 한국과학기술정보연구원 NDSL에서 제공하는 식품과 전기 분야 학술논문에 적용하여 실험하였다. 현재 NDSL 이용자 4명에게 피드백을 받은 결과 추천논문에 상당히 만족하는 것으로 나타났다."
        },
        {
          "rank": 36,
          "score": 0.6289083361625671,
          "doc_id": "NART56157676",
          "title": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합",
          "abstract": "<P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157676&target=NART&cn=NART56157676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 <P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>"
        },
        {
          "rank": 37,
          "score": 0.6288880109786987,
          "doc_id": "NART95825020",
          "title": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition",
          "abstract": "<P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95825020&target=NART&cn=NART95825020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition <P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>"
        },
        {
          "rank": 38,
          "score": 0.6278766393661499,
          "doc_id": "JAKO201429548810226",
          "title": "불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법",
          "abstract": "필기체 낱글자 인식을 위해서 사용되는 데이터는 일반적으로 다수의 사용자들로부터 수집된 자연언어 문장들을 이용하기 때문에 해당 언어의 언어적 특성에 따라서 낱글자의 종류별 개수 차이가 매우 큰 특징이 있다. 일반적인 기계학습 문제에서 학습데이터의 불균형 문제는 성능을 저하시키는 중요한 요인으로 작용하지만, 필기체 인식에서는 데이터 자체의 높은 분산과 비슷한 모양의 낱글자 등이 성능 저하의 주요인이라 생각하기 때문에 이를 크게 고려하지 않고 있다. 본 논문에서는 이러한 데이터의 불균형 문제를 고려하여 필기체 인식기의 성능을 향상시킬 수 있는 과표본화 기반의 앙상블 학습 기법을 제안한다. 제안한 방법은 데이터의 불균형 문제를 고려하지 않은 방법보다 전체적으로 향상된 성능을 보일 뿐만 아니라 데이터의 개수가 부족한 낱글자들의 분류성능에 있어서도 향상된 결과를 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201429548810226&target=NART&cn=JAKO201429548810226",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 불균형 데이터 처리를 위한 과표본화 기반 앙상블 학습 기법 필기체 낱글자 인식을 위해서 사용되는 데이터는 일반적으로 다수의 사용자들로부터 수집된 자연언어 문장들을 이용하기 때문에 해당 언어의 언어적 특성에 따라서 낱글자의 종류별 개수 차이가 매우 큰 특징이 있다. 일반적인 기계학습 문제에서 학습데이터의 불균형 문제는 성능을 저하시키는 중요한 요인으로 작용하지만, 필기체 인식에서는 데이터 자체의 높은 분산과 비슷한 모양의 낱글자 등이 성능 저하의 주요인이라 생각하기 때문에 이를 크게 고려하지 않고 있다. 본 논문에서는 이러한 데이터의 불균형 문제를 고려하여 필기체 인식기의 성능을 향상시킬 수 있는 과표본화 기반의 앙상블 학습 기법을 제안한다. 제안한 방법은 데이터의 불균형 문제를 고려하지 않은 방법보다 전체적으로 향상된 성능을 보일 뿐만 아니라 데이터의 개수가 부족한 낱글자들의 분류성능에 있어서도 향상된 결과를 보여준다."
        },
        {
          "rank": 39,
          "score": 0.6271670460700989,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 40,
          "score": 0.6268808245658875,
          "doc_id": "JAKO202213649890315",
          "title": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환",
          "abstract": "스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213649890315&target=NART&cn=JAKO202213649890315",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망 추론을 위한 심층 신경망 가중치 변환 스파이킹 신경망은 실제 두뇌 뉴런의 작동원리를 적용한 신경망으로, 뉴런의 생물학적 메커니즘으로 인해 기존 신경망보다 학습과 추론에 소모되는 전력이 적다. 최근 딥러닝 모델이 거대해지며 운용에 소모되는 비용 또한 기하급수적으로 증가함에 따라 스파이킹 신경망은 합성곱, 순환 신경망을 잇는 3세대 신경망으로 주목받으며 관련 연구가 활발히 진행되고 있다. 그러나 스파이킹 신경망 모델을 산업에 적용하기 위해서는 아직 선행되어야 할 연구가 많이 남아있고, 새로운 모델을 적용하기 위한 모델 재학습 문제 역시 해결해야 한다. 본 논문에서는 기존의 학습된 딥러닝 모델의 가중치를 추출하여 스파이킹 신경망 모델의 가중치로 변환하는 것으로 모델 재학습 비용을 최소화하는 방법을 제안한다. 또한, 변환된 가중치를 사용한 추론 결과와 기존 모델의 결과를 비교해 가중치 변환이 올바르게 작동함을 보인다."
        },
        {
          "rank": 41,
          "score": 0.6265085935592651,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 42,
          "score": 0.6263177394866943,
          "doc_id": "JAKO201719951669089",
          "title": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링",
          "abstract": "This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201719951669089&target=NART&cn=JAKO201719951669089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method."
        },
        {
          "rank": 43,
          "score": 0.6259693503379822,
          "doc_id": "JAKO201220962918849",
          "title": "수화 패턴 인식을 위한 2단계 신경망 모델",
          "abstract": "본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201220962918849&target=NART&cn=JAKO201220962918849",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 수화 패턴 인식을 위한 2단계 신경망 모델 본 논문에서는 착용식 추적장치나 표식 등의 보조 도구를 사용하지 않는 환경의 동영상 데이터로부터 수화 패턴을 인식하는 방법론에 관하여 고찰한다. 시스템 설계 및 구현에 관한 주제로서 특징점의 추출기법, 특징데이터의 표현기법 및 패턴 분류기법에 관한 방법론을 제시하고 그 유용성을 고찰한다. 일련의 동영상으로 표현되는 수화패턴에 대하여 특징점의 공간적 위치에 대한 변이 뿐만 아니라 시간차원의 변화를 고려한 특징데이터의 표현방법을 제시하며, 방대한 데이터에 의한 분류기의 크기 문제와 계산량의 문제를 개선하기 위하여 효과적으로 특징수를 줄일 수 있는 특징추출 방법을 소개한다. 패턴 분류과정에서 점진적 학습(incremental learning)이 가능한 신경망 모델을 제시하고 그 동작특성 및 학습효과를 분석한다. 또한 학습된 분류모델로부터 특징과 패턴 클래스 간의 상대적 연관성 척도를 정의하고, 이로부터 효과적인 특징을 선별하여 성능저하 없이 분류기의 규모를 최적화 할 수 있음을 보인다. 제안된 내용에 대하여 여섯 가지 수화패턴을 대상으로 적용한 실험을 통하여 유용성을 평가한다."
        },
        {
          "rank": 44,
          "score": 0.6253347396850586,
          "doc_id": "JAKO200734515919504",
          "title": "지역 기반 분류기의 앙상블 학습",
          "abstract": "기계학습에서 분류기틀의 집합으로 구성된 앙상블 분류기는 단일 분류기에 비해 정확도가 높다는 것이 입증되어왔다. 본 논문에서는 새로운 앙상블 학습으로서 데이터의 지역 기반 분류기들의 앙상블 학습을 제시하여 기존의 앙상블 학습과의 비교를 통해 성능을 검증하고자 한다. 지역 기반 분류기의 앙상블 학습은 데이터의 분포가 지역에 따라 다르다는 점에 착안하여 학습 데이터를 분할하여 해당하는 지역에 기반을 둔 분류기들을 만들어 나간다. 이렇게 만들어진 분류기들로부터 지역에 따라 가중치를 둔 투표를 적용하여 앙상블 방법을 이끌어낸다. 본 논문에서 제시한 앙상블 분류기의 성능평가를 위해 단일 분류기와 기존의 앙상블 분류기인 배깅과 부스팅 등을 UCI Machine Learning Repository에 있는 11개의 데이터 셋으로 정확도 비교를 하였다. 그 결과 새로운 앙상블 방법이 기본 분류기로 나이브 베이즈와 SVM을 사용했을 때 다른 방법보다 좋은 성능을 보이는 것을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200734515919504&target=NART&cn=JAKO200734515919504",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "지역 기반 분류기의 앙상블 학습 지역 기반 분류기의 앙상블 학습 지역 기반 분류기의 앙상블 학습 기계학습에서 분류기틀의 집합으로 구성된 앙상블 분류기는 단일 분류기에 비해 정확도가 높다는 것이 입증되어왔다. 본 논문에서는 새로운 앙상블 학습으로서 데이터의 지역 기반 분류기들의 앙상블 학습을 제시하여 기존의 앙상블 학습과의 비교를 통해 성능을 검증하고자 한다. 지역 기반 분류기의 앙상블 학습은 데이터의 분포가 지역에 따라 다르다는 점에 착안하여 학습 데이터를 분할하여 해당하는 지역에 기반을 둔 분류기들을 만들어 나간다. 이렇게 만들어진 분류기들로부터 지역에 따라 가중치를 둔 투표를 적용하여 앙상블 방법을 이끌어낸다. 본 논문에서 제시한 앙상블 분류기의 성능평가를 위해 단일 분류기와 기존의 앙상블 분류기인 배깅과 부스팅 등을 UCI Machine Learning Repository에 있는 11개의 데이터 셋으로 정확도 비교를 하였다. 그 결과 새로운 앙상블 방법이 기본 분류기로 나이브 베이즈와 SVM을 사용했을 때 다른 방법보다 좋은 성능을 보이는 것을 알 수 있었다."
        },
        {
          "rank": 45,
          "score": 0.6245473027229309,
          "doc_id": "NART13812249",
          "title": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination",
          "abstract": "<P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13812249&target=NART&cn=NART13812249",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination An intelligent sales forecasting system through integration of artificial neural networks and fuzzy neural networks with fuzzy weight elimination <P><B>Abstract</B></P><P>Sales forecasting plays a very prominent role in business strategy. Numerous investigations addressing this problem have generally employed statistical methods, such as regression or autoregressive and moving average (ARMA). However, sales forecasting is very complicated owing to influence by internal and external environments. Recently, artificial neural networks (ANNs) have also been applied in sales forecasting since their promising performances in the areas of control and pattern recognition. However, further improvement is still necessary since unique circumstances, e.g. promotion, cause a sudden change in the sales pattern. Thus, this study utilizes a proposed fuzzy neural network (FNN), which is able to eliminate the unimportant weights, for the sake of learning fuzzy IF&#x2013;THEN rules obtained from the marketing experts with respect to promotion. The result from FNN is further integrated with the time series data through an ANN. Both the simulated and real-world problem results show that FNN with weight elimination can have lower training error compared with the regular FNN. Besides, real-world problem results also indicate that the proposed estimation system outperforms the conventional statistical method and single ANN in accuracy.</P>"
        },
        {
          "rank": 46,
          "score": 0.6243926882743835,
          "doc_id": "JAKO202326257774533",
          "title": "트랜스포머 기반 효율적인 자연어 처리 방안 연구",
          "abstract": "현재의 인공지능에서 사용되는 자연어 처리 모델은 거대하여 실시간으로 데이터를 처리하고 분석하는 것은 여러가지 어려움들을 야기하고 있다. 이런 어려움을 해결하기 위한 방법으로 메모리를 적게 사용해 처리의 효율성을 개선하는 방법을 제안하고 제안된 모델의 성능을 확인하였다. 본 논문에서 제안한 모델의 성능평가를 위해 적용한 기법은 BERT[1] 모델의 어텐션 헤드 개수와 임베딩 크기를 작게 조절해 큰 말뭉치를 나눠서 분할 처리 후 출력값의 평균을 통해 결과를 산출하였다. 이 과정에서 입력 데이터의 다양성을 주기위해 매 에폭마다 임의의 오프셋을 문장에 부여하였다. 그리고 모델을 분류가 가능하도록 미세 조정하였다. 말뭉치를 분할 처리한 모델은 그렇지 않은 모델 대비 정확도가 12% 정도 낮았으나, 모델의 파라미터 개수는 56% 정도 절감되는 것을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202326257774533&target=NART&cn=JAKO202326257774533",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "트랜스포머 기반 효율적인 자연어 처리 방안 연구 트랜스포머 기반 효율적인 자연어 처리 방안 연구 트랜스포머 기반 효율적인 자연어 처리 방안 연구 현재의 인공지능에서 사용되는 자연어 처리 모델은 거대하여 실시간으로 데이터를 처리하고 분석하는 것은 여러가지 어려움들을 야기하고 있다. 이런 어려움을 해결하기 위한 방법으로 메모리를 적게 사용해 처리의 효율성을 개선하는 방법을 제안하고 제안된 모델의 성능을 확인하였다. 본 논문에서 제안한 모델의 성능평가를 위해 적용한 기법은 BERT[1] 모델의 어텐션 헤드 개수와 임베딩 크기를 작게 조절해 큰 말뭉치를 나눠서 분할 처리 후 출력값의 평균을 통해 결과를 산출하였다. 이 과정에서 입력 데이터의 다양성을 주기위해 매 에폭마다 임의의 오프셋을 문장에 부여하였다. 그리고 모델을 분류가 가능하도록 미세 조정하였다. 말뭉치를 분할 처리한 모델은 그렇지 않은 모델 대비 정확도가 12% 정도 낮았으나, 모델의 파라미터 개수는 56% 정도 절감되는 것을 확인하였다."
        },
        {
          "rank": 47,
          "score": 0.6238468289375305,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 48,
          "score": 0.6236415505409241,
          "doc_id": "NPAP07942137",
          "title": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP07942137&target=NART&cn=NPAP07942137",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 49,
          "score": 0.6232012510299683,
          "doc_id": "DIKO0007842188",
          "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
          "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
        },
        {
          "rank": 50,
          "score": 0.6229351758956909,
          "doc_id": "NART17510385",
          "title": "Hidden-articulator Markov models for speech recognition",
          "abstract": "<P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART17510385&target=NART&cn=NART17510385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition <P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>"
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}