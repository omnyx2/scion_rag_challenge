{
  "id": "row_000003",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:32.434746+09:00",
  "trial_id": "a57c73f2",
  "queries": [
    {
      "query": "What approach and results characterize the system that learns TurKontrol’s POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8459355235099792,
          "doc_id": "NART120023140",
          "title": "Artificial Intelligence for Artificial Artificial Intelligence",
          "abstract": "<P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120023140&target=NART&cn=NART120023140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence <P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>"
        },
        {
          "rank": 2,
          "score": 0.8086855411529541,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART66567138&target=NART&cn=NART66567138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost."
        },
        {
          "rank": 3,
          "score": 0.7450080513954163,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69625850&target=NART&cn=NART69625850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>"
        },
        {
          "rank": 4,
          "score": 0.73335862159729,
          "doc_id": "NART108676444",
          "title": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP)",
          "abstract": "<P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108676444&target=NART&cn=NART108676444",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) <P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>"
        },
        {
          "rank": 5,
          "score": 0.7197081446647644,
          "doc_id": "NART95314903",
          "title": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots",
          "abstract": "<P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95314903&target=NART&cn=NART95314903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>"
        },
        {
          "rank": 6,
          "score": 0.7175913453102112,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77197564&target=NART&cn=NART77197564",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants."
        },
        {
          "rank": 7,
          "score": 0.7143677473068237,
          "doc_id": "JAKO201222653563471",
          "title": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법",
          "abstract": "최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201222653563471&target=NART&cn=JAKO201222653563471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다."
        },
        {
          "rank": 8,
          "score": 0.7130173444747925,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART127620540&target=NART&cn=NART127620540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>"
        },
        {
          "rank": 9,
          "score": 0.711937427520752,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75736850&target=NART&cn=NART75736850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>"
        },
        {
          "rank": 10,
          "score": 0.6938424706459045,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART92832666&target=NART&cn=NART92832666",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>"
        },
        {
          "rank": 11,
          "score": 0.6922528743743896,
          "doc_id": "NART70754548",
          "title": "Amazon Mechanical Turk and the commodification of labour",
          "abstract": "<P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70754548&target=NART&cn=NART70754548",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour <P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>"
        },
        {
          "rank": 12,
          "score": 0.6873599290847778,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202411139606539&target=NART&cn=JAKO202411139606539",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다."
        },
        {
          "rank": 13,
          "score": 0.6868321895599365,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123803221&target=NART&cn=NART123803221",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>"
        },
        {
          "rank": 14,
          "score": 0.6805345416069031,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART88129314&target=NART&cn=NART88129314",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>"
        },
        {
          "rank": 15,
          "score": 0.6753079891204834,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103944733&target=NART&cn=NART103944733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>"
        },
        {
          "rank": 16,
          "score": 0.671816349029541,
          "doc_id": "NART134452383",
          "title": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk",
          "abstract": "<P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART134452383&target=NART&cn=NART134452383",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk <P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>"
        },
        {
          "rank": 17,
          "score": 0.6640565395355225,
          "doc_id": "NART53030850",
          "title": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems",
          "abstract": "This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53030850&target=NART&cn=NART53030850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems."
        },
        {
          "rank": 18,
          "score": 0.6611911654472351,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 19,
          "score": 0.6593266129493713,
          "doc_id": "NART77258550",
          "title": "Real-time recommendation algorithms for crowdsourcing systems",
          "abstract": "Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77258550&target=NART&cn=NART77258550",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms."
        },
        {
          "rank": 20,
          "score": 0.6591039896011353,
          "doc_id": "NART77727471",
          "title": "Robotic manipulation of multiple objects as a POMDP",
          "abstract": "This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77727471&target=NART&cn=NART77727471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience."
        },
        {
          "rank": 21,
          "score": 0.6517467498779297,
          "doc_id": "NART108498824",
          "title": "Hierarchical POMDP planning for object manipulation in clutter",
          "abstract": "<P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108498824&target=NART&cn=NART108498824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter <P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>"
        },
        {
          "rank": 22,
          "score": 0.6517136096954346,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73604379&target=NART&cn=NART73604379",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>"
        },
        {
          "rank": 23,
          "score": 0.6504757404327393,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73267731&target=NART&cn=NART73267731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>"
        },
        {
          "rank": 24,
          "score": 0.649384617805481,
          "doc_id": "NART68279824",
          "title": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces",
          "abstract": "Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART68279824&target=NART&cn=NART68279824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance."
        },
        {
          "rank": 25,
          "score": 0.6488375663757324,
          "doc_id": "JAKO202033759655983",
          "title": "공 던지기 로봇의 정책 예측 심층 강화학습",
          "abstract": "Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202033759655983&target=NART&cn=JAKO202033759655983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate."
        },
        {
          "rank": 26,
          "score": 0.6485549807548523,
          "doc_id": "ATN0037493744",
          "title": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템",
          "abstract": "Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037493744&target=NART&cn=ATN0037493744",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features."
        },
        {
          "rank": 27,
          "score": 0.6456483006477356,
          "doc_id": "JAKO200617033460433",
          "title": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법",
          "abstract": "본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200617033460433&target=NART&cn=JAKO200617033460433",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다."
        },
        {
          "rank": 28,
          "score": 0.6429119110107422,
          "doc_id": "NART48526876",
          "title": "Prioritizing Point-Based POMDP Solvers",
          "abstract": "<P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART48526876&target=NART&cn=NART48526876",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers <P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>"
        },
        {
          "rank": 29,
          "score": 0.6395876407623291,
          "doc_id": "DIKO0012506219",
          "title": "POMDP 기반의 Market-Making 전략 시스템",
          "abstract": "본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012506219&target=NART&cn=DIKO0012506219",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다."
        },
        {
          "rank": 30,
          "score": 0.6390164494514465,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70960968&target=NART&cn=NART70960968",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed."
        },
        {
          "rank": 31,
          "score": 0.637479841709137,
          "doc_id": "NART75854774",
          "title": "Massively parallel motion planning algorithms under uncertainty using POMDP",
          "abstract": "<P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75854774&target=NART&cn=NART75854774",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP <P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>"
        },
        {
          "rank": 32,
          "score": 0.6353300213813782,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 33,
          "score": 0.6339514255523682,
          "doc_id": "JAKO202417657635096",
          "title": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험",
          "abstract": "행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202417657635096&target=NART&cn=JAKO202417657635096",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다."
        },
        {
          "rank": 34,
          "score": 0.6333988308906555,
          "doc_id": "NART51683398",
          "title": "Sampling Based Approximate Algorithm for POMDP",
          "abstract": "Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART51683398&target=NART&cn=NART51683398",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms."
        },
        {
          "rank": 35,
          "score": 0.6330422163009644,
          "doc_id": "JAKO201417638008069",
          "title": "POMDP 기반 사용자-로봇 인터랙션 행동 모델",
          "abstract": "This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201417638008069&target=NART&cn=JAKO201417638008069",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world."
        },
        {
          "rank": 36,
          "score": 0.631550133228302,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78755911&target=NART&cn=NART78755911",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>"
        },
        {
          "rank": 37,
          "score": 0.6313252449035645,
          "doc_id": "ART003204610",
          "title": "CNN-LSTM Based Malicious Code Detection",
          "abstract": "This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003204610&target=NART&cn=ART003204610",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability."
        },
        {
          "rank": 38,
          "score": 0.6307064294815063,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 39,
          "score": 0.6255834102630615,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 40,
          "score": 0.6241590976715088,
          "doc_id": "JAKO202106153173640",
          "title": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구",
          "abstract": "컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153173640&target=NART&cn=JAKO202106153173640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다."
        },
        {
          "rank": 41,
          "score": 0.623550534248352,
          "doc_id": "NART77437325",
          "title": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns",
          "abstract": "Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77437325&target=NART&cn=NART77437325",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences."
        },
        {
          "rank": 42,
          "score": 0.6219239234924316,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 43,
          "score": 0.621781587600708,
          "doc_id": "JAKO202012764215284",
          "title": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측",
          "abstract": "청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012764215284&target=NART&cn=JAKO202012764215284",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다."
        },
        {
          "rank": 44,
          "score": 0.6193881034851074,
          "doc_id": "JAKO201911263062209",
          "title": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론",
          "abstract": "Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911263062209&target=NART&cn=JAKO201911263062209",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics."
        },
        {
          "rank": 45,
          "score": 0.6187252998352051,
          "doc_id": "JAKO201905959996575",
          "title": "MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM",
          "abstract": "A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905959996575&target=NART&cn=JAKO201905959996575",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection."
        },
        {
          "rank": 46,
          "score": 0.618143618106842,
          "doc_id": "JAKO202519750403920",
          "title": "모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법",
          "abstract": "본 논문에서는 모바일 로봇의 실내 자율 주행을 위해 심층강화학습 기반 알고리즘을 제안한다. 제안하는 방법은 off-policy 방식의 Soft Actor Critic(SAC) 알고리즘과 두 가지 경험 재사용 기법인 Prioritized Experience Replay(PER) 및 Hindsight Experience Replay(HER)을 결합하여 학습 효율성과 안정성을 향상시키는 것을 목표로 한다. 특히, 정책의 수렴 정도가 낮은 초기 시점부터 정책이 어느정도 수렴된 시점까지 학습 시점에 따라 경험 재사용 기법의 적용을 달리하여 정책 수렴의 안정성과 속도를 개선한다. 제안한 방법은 Gazebo 시뮬레이션 환경에서 동적 장애물이 추가된 환경에 대해 기존 SAC 알고리즘과 비교하여 성능을 평가하였으며, 목표 지점과 로봇 경로는 ROS(Robot Operation System)의 RVIZ 툴을 사용하여 시각화하였다. 실험 결과를 통해 제안하는 기법의 유효성을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202519750403920&target=NART&cn=JAKO202519750403920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 본 논문에서는 모바일 로봇의 실내 자율 주행을 위해 심층강화학습 기반 알고리즘을 제안한다. 제안하는 방법은 off-policy 방식의 Soft Actor Critic(SAC) 알고리즘과 두 가지 경험 재사용 기법인 Prioritized Experience Replay(PER) 및 Hindsight Experience Replay(HER)을 결합하여 학습 효율성과 안정성을 향상시키는 것을 목표로 한다. 특히, 정책의 수렴 정도가 낮은 초기 시점부터 정책이 어느정도 수렴된 시점까지 학습 시점에 따라 경험 재사용 기법의 적용을 달리하여 정책 수렴의 안정성과 속도를 개선한다. 제안한 방법은 Gazebo 시뮬레이션 환경에서 동적 장애물이 추가된 환경에 대해 기존 SAC 알고리즘과 비교하여 성능을 평가하였으며, 목표 지점과 로봇 경로는 ROS(Robot Operation System)의 RVIZ 툴을 사용하여 시각화하였다. 실험 결과를 통해 제안하는 기법의 유효성을 검증한다."
        },
        {
          "rank": 47,
          "score": 0.6168954372406006,
          "doc_id": "JAKO201909358629233",
          "title": "CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트",
          "abstract": "본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629233&target=NART&cn=JAKO201909358629233",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다."
        },
        {
          "rank": 48,
          "score": 0.6166747212409973,
          "doc_id": "JAKO202519561208274",
          "title": "프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구",
          "abstract": "본 연구는 대화형 인공지능 모델인 ChatGPT와 프롬프트 엔지니어링(Prompt Engineering) 기법을 활용하여, 자연어 기반 지시문만으로 토픽 모델링 분석을 수행할 수 있는 방법론을 제안한다. 기존의 토픽 모델링은 LDA 등 통계 기반 알고리즘을 활용함으로써 높은 수준의 프로그래밍 이해와 복잡한 모델 설정이 요구된다는 한계가 있다. 그러나 본 연구는 프롬프트 엔지니어링 기법을 활용한 '데이터 사이언티스트' 역할 부여, 자연어 기반의 구조화한 토픽 모델링 분석 절차 정의함으로써 GPT에 전문성을 부여하였다. 그 결과, 기존 자동화 모델에서 구현하기 어려웠던 도매인 전문성과 문맥 기반 해석에 따라 실제 뉴스 데이터를 대상으로 토픽 수 결정, 모델 선택, 시각화, 일관성 있는 분석 등 전 과정을 자동화하는 접근을 실험적으로 제시하였다. 분석과정에서 자동 생성된 파이썬 코드는 별도의 개발 환경에서 재 실행함으로써 GPT 생성 코드의 정확성과 신뢰성을 검증하였다. 또한 ChatGPT의 [지식] 기능을 통해 검증된 외부 문서 정보를 불러와 분석의 객관성을 확보함으로써 GPT 환각(Hallucination)현상을 방지하였다. 본 연구의 GPT모델은 한글 형태소 분석, BERTopic와 같은 딥러닝 기반 토픽 모델링, OpenAPI 연동 등과 같은 ChatGPT 운영 환경에 일부 제약이 있었다. 그러나 ChatGPT 프롬프트 기반 데이터 분석 자동화의 가능성과 ChatGPT의 실무적 활용 확장을 위한 기초 연구로서 의의를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202519561208274&target=NART&cn=JAKO202519561208274",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 본 연구는 대화형 인공지능 모델인 ChatGPT와 프롬프트 엔지니어링(Prompt Engineering) 기법을 활용하여, 자연어 기반 지시문만으로 토픽 모델링 분석을 수행할 수 있는 방법론을 제안한다. 기존의 토픽 모델링은 LDA 등 통계 기반 알고리즘을 활용함으로써 높은 수준의 프로그래밍 이해와 복잡한 모델 설정이 요구된다는 한계가 있다. 그러나 본 연구는 프롬프트 엔지니어링 기법을 활용한 '데이터 사이언티스트' 역할 부여, 자연어 기반의 구조화한 토픽 모델링 분석 절차 정의함으로써 GPT에 전문성을 부여하였다. 그 결과, 기존 자동화 모델에서 구현하기 어려웠던 도매인 전문성과 문맥 기반 해석에 따라 실제 뉴스 데이터를 대상으로 토픽 수 결정, 모델 선택, 시각화, 일관성 있는 분석 등 전 과정을 자동화하는 접근을 실험적으로 제시하였다. 분석과정에서 자동 생성된 파이썬 코드는 별도의 개발 환경에서 재 실행함으로써 GPT 생성 코드의 정확성과 신뢰성을 검증하였다. 또한 ChatGPT의 [지식] 기능을 통해 검증된 외부 문서 정보를 불러와 분석의 객관성을 확보함으로써 GPT 환각(Hallucination)현상을 방지하였다. 본 연구의 GPT모델은 한글 형태소 분석, BERTopic와 같은 딥러닝 기반 토픽 모델링, OpenAPI 연동 등과 같은 ChatGPT 운영 환경에 일부 제약이 있었다. 그러나 ChatGPT 프롬프트 기반 데이터 분석 자동화의 가능성과 ChatGPT의 실무적 활용 확장을 위한 기초 연구로서 의의를 가진다."
        },
        {
          "rank": 49,
          "score": 0.6164829730987549,
          "doc_id": "DIKO0017198883",
          "title": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating",
          "abstract": "전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017198883&target=NART&cn=DIKO0017198883",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating 전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다."
        },
        {
          "rank": 50,
          "score": 0.6161913871765137,
          "doc_id": "NART77437322",
          "title": "Crowdsourcing and brand control",
          "abstract": "Crowdsourcing is the deliberate use of crowds to solve problems, create new products, and improve consumer experiences. When used by brands, crowdsourcing engages consumers by asking them to be part of a deliberate call to action. Crowdsourcing provides interesting and dynamic marketing opportunities for brands, given the consumer engagement it entails. This conceptual study examines the literature on crowdsourcing and brand community, and makes a series of propositions regarding this rich marketing arena. Herein, we discuss managerial implications of the relationship between crowdsourcing and brand community dynamics and propose a typology for brands to better assess customer bases and market realities.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77437322&target=NART&cn=NART77437322",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing and brand control Crowdsourcing and brand control Crowdsourcing and brand control Crowdsourcing is the deliberate use of crowds to solve problems, create new products, and improve consumer experiences. When used by brands, crowdsourcing engages consumers by asking them to be part of a deliberate call to action. Crowdsourcing provides interesting and dynamic marketing opportunities for brands, given the consumer engagement it entails. This conceptual study examines the literature on crowdsourcing and brand community, and makes a series of propositions regarding this rich marketing arena. Herein, we discuss managerial implications of the relationship between crowdsourcing and brand community dynamics and propose a typology for brands to better assess customer bases and market realities."
        }
      ]
    },
    {
      "query": "What approach does the system use to learn TurKontrol’s POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8365156650543213,
          "doc_id": "NART120023140",
          "title": "Artificial Intelligence for Artificial Artificial Intelligence",
          "abstract": "<P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120023140&target=NART&cn=NART120023140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence <P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>"
        },
        {
          "rank": 2,
          "score": 0.7991546392440796,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART66567138&target=NART&cn=NART66567138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost."
        },
        {
          "rank": 3,
          "score": 0.7442933320999146,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69625850&target=NART&cn=NART69625850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>"
        },
        {
          "rank": 4,
          "score": 0.7268987894058228,
          "doc_id": "NART108676444",
          "title": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP)",
          "abstract": "<P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108676444&target=NART&cn=NART108676444",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) <P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>"
        },
        {
          "rank": 5,
          "score": 0.7159260511398315,
          "doc_id": "JAKO201222653563471",
          "title": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법",
          "abstract": "최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201222653563471&target=NART&cn=JAKO201222653563471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다."
        },
        {
          "rank": 6,
          "score": 0.7125508189201355,
          "doc_id": "NART95314903",
          "title": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots",
          "abstract": "<P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95314903&target=NART&cn=NART95314903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>"
        },
        {
          "rank": 7,
          "score": 0.7119227647781372,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77197564&target=NART&cn=NART77197564",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants."
        },
        {
          "rank": 8,
          "score": 0.7054990530014038,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART127620540&target=NART&cn=NART127620540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>"
        },
        {
          "rank": 9,
          "score": 0.7011294364929199,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75736850&target=NART&cn=NART75736850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>"
        },
        {
          "rank": 10,
          "score": 0.6899298429489136,
          "doc_id": "NART70754548",
          "title": "Amazon Mechanical Turk and the commodification of labour",
          "abstract": "<P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70754548&target=NART&cn=NART70754548",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour <P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>"
        },
        {
          "rank": 11,
          "score": 0.6797451972961426,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART92832666&target=NART&cn=NART92832666",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>"
        },
        {
          "rank": 12,
          "score": 0.6780394911766052,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202411139606539&target=NART&cn=JAKO202411139606539",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다."
        },
        {
          "rank": 13,
          "score": 0.676859974861145,
          "doc_id": "NART134452383",
          "title": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk",
          "abstract": "<P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART134452383&target=NART&cn=NART134452383",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk <P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>"
        },
        {
          "rank": 14,
          "score": 0.6761408448219299,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART88129314&target=NART&cn=NART88129314",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>"
        },
        {
          "rank": 15,
          "score": 0.6731347441673279,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123803221&target=NART&cn=NART123803221",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>"
        },
        {
          "rank": 16,
          "score": 0.6664564609527588,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103944733&target=NART&cn=NART103944733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>"
        },
        {
          "rank": 17,
          "score": 0.6652840375900269,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 18,
          "score": 0.6584944725036621,
          "doc_id": "NART53030850",
          "title": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems",
          "abstract": "This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53030850&target=NART&cn=NART53030850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems."
        },
        {
          "rank": 19,
          "score": 0.6553842425346375,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73604379&target=NART&cn=NART73604379",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>"
        },
        {
          "rank": 20,
          "score": 0.652670681476593,
          "doc_id": "NART77258550",
          "title": "Real-time recommendation algorithms for crowdsourcing systems",
          "abstract": "Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77258550&target=NART&cn=NART77258550",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms."
        },
        {
          "rank": 21,
          "score": 0.651309609413147,
          "doc_id": "NART77727471",
          "title": "Robotic manipulation of multiple objects as a POMDP",
          "abstract": "This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77727471&target=NART&cn=NART77727471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience."
        },
        {
          "rank": 22,
          "score": 0.6495604515075684,
          "doc_id": "NART108498824",
          "title": "Hierarchical POMDP planning for object manipulation in clutter",
          "abstract": "<P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108498824&target=NART&cn=NART108498824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter <P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>"
        },
        {
          "rank": 23,
          "score": 0.6460622549057007,
          "doc_id": "ATN0037493744",
          "title": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템",
          "abstract": "Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037493744&target=NART&cn=ATN0037493744",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features."
        },
        {
          "rank": 24,
          "score": 0.6460191011428833,
          "doc_id": "JAKO200617033460433",
          "title": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법",
          "abstract": "본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200617033460433&target=NART&cn=JAKO200617033460433",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다."
        },
        {
          "rank": 25,
          "score": 0.6453734040260315,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 26,
          "score": 0.6440168619155884,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73267731&target=NART&cn=NART73267731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>"
        },
        {
          "rank": 27,
          "score": 0.6398295760154724,
          "doc_id": "JAKO201417638008069",
          "title": "POMDP 기반 사용자-로봇 인터랙션 행동 모델",
          "abstract": "This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201417638008069&target=NART&cn=JAKO201417638008069",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world."
        },
        {
          "rank": 28,
          "score": 0.6391780376434326,
          "doc_id": "NART51683398",
          "title": "Sampling Based Approximate Algorithm for POMDP",
          "abstract": "Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART51683398&target=NART&cn=NART51683398",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms."
        },
        {
          "rank": 29,
          "score": 0.6389219164848328,
          "doc_id": "JAKO202033759655983",
          "title": "공 던지기 로봇의 정책 예측 심층 강화학습",
          "abstract": "Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202033759655983&target=NART&cn=JAKO202033759655983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate."
        },
        {
          "rank": 30,
          "score": 0.638581395149231,
          "doc_id": "DIKO0012506219",
          "title": "POMDP 기반의 Market-Making 전략 시스템",
          "abstract": "본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012506219&target=NART&cn=DIKO0012506219",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다."
        },
        {
          "rank": 31,
          "score": 0.6354130506515503,
          "doc_id": "NART68279824",
          "title": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces",
          "abstract": "Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART68279824&target=NART&cn=NART68279824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance."
        },
        {
          "rank": 32,
          "score": 0.6346088647842407,
          "doc_id": "NART75854774",
          "title": "Massively parallel motion planning algorithms under uncertainty using POMDP",
          "abstract": "<P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75854774&target=NART&cn=NART75854774",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP <P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>"
        },
        {
          "rank": 33,
          "score": 0.6309145092964172,
          "doc_id": "NART48526876",
          "title": "Prioritizing Point-Based POMDP Solvers",
          "abstract": "<P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART48526876&target=NART&cn=NART48526876",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers <P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>"
        },
        {
          "rank": 34,
          "score": 0.6280820369720459,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70960968&target=NART&cn=NART70960968",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed."
        },
        {
          "rank": 35,
          "score": 0.6274692416191101,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 36,
          "score": 0.6274051070213318,
          "doc_id": "JAKO202106153173640",
          "title": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구",
          "abstract": "컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153173640&target=NART&cn=JAKO202106153173640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다."
        },
        {
          "rank": 37,
          "score": 0.6232494115829468,
          "doc_id": "JAKO202417657635096",
          "title": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험",
          "abstract": "행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202417657635096&target=NART&cn=JAKO202417657635096",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다."
        },
        {
          "rank": 38,
          "score": 0.6219202280044556,
          "doc_id": "JAKO202519750403920",
          "title": "모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법",
          "abstract": "본 논문에서는 모바일 로봇의 실내 자율 주행을 위해 심층강화학습 기반 알고리즘을 제안한다. 제안하는 방법은 off-policy 방식의 Soft Actor Critic(SAC) 알고리즘과 두 가지 경험 재사용 기법인 Prioritized Experience Replay(PER) 및 Hindsight Experience Replay(HER)을 결합하여 학습 효율성과 안정성을 향상시키는 것을 목표로 한다. 특히, 정책의 수렴 정도가 낮은 초기 시점부터 정책이 어느정도 수렴된 시점까지 학습 시점에 따라 경험 재사용 기법의 적용을 달리하여 정책 수렴의 안정성과 속도를 개선한다. 제안한 방법은 Gazebo 시뮬레이션 환경에서 동적 장애물이 추가된 환경에 대해 기존 SAC 알고리즘과 비교하여 성능을 평가하였으며, 목표 지점과 로봇 경로는 ROS(Robot Operation System)의 RVIZ 툴을 사용하여 시각화하였다. 실험 결과를 통해 제안하는 기법의 유효성을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202519750403920&target=NART&cn=JAKO202519750403920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 모바일 로봇의 실내 자율주행을 위한 심층 강화학습 기법 본 논문에서는 모바일 로봇의 실내 자율 주행을 위해 심층강화학습 기반 알고리즘을 제안한다. 제안하는 방법은 off-policy 방식의 Soft Actor Critic(SAC) 알고리즘과 두 가지 경험 재사용 기법인 Prioritized Experience Replay(PER) 및 Hindsight Experience Replay(HER)을 결합하여 학습 효율성과 안정성을 향상시키는 것을 목표로 한다. 특히, 정책의 수렴 정도가 낮은 초기 시점부터 정책이 어느정도 수렴된 시점까지 학습 시점에 따라 경험 재사용 기법의 적용을 달리하여 정책 수렴의 안정성과 속도를 개선한다. 제안한 방법은 Gazebo 시뮬레이션 환경에서 동적 장애물이 추가된 환경에 대해 기존 SAC 알고리즘과 비교하여 성능을 평가하였으며, 목표 지점과 로봇 경로는 ROS(Robot Operation System)의 RVIZ 툴을 사용하여 시각화하였다. 실험 결과를 통해 제안하는 기법의 유효성을 검증한다."
        },
        {
          "rank": 39,
          "score": 0.6208345293998718,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 40,
          "score": 0.6189720034599304,
          "doc_id": "JAKO201905959996575",
          "title": "MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM",
          "abstract": "A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201905959996575&target=NART&cn=JAKO201905959996575",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM MALICIOUS URL RECOGNITION AND DETECTION USING ATTENTION-BASED CNN-LSTM A malicious Uniform Resource Locator (URL) recognition and detection method based on the combination of Attention mechanism with Convolutional Neural Network and Long Short-Term Memory Network (Attention-Based CNN-LSTM), is proposed. Firstly, the WHOIS check method is used to extract and filter features, including the URL texture information, the URL string statistical information of attributes and the WHOIS information, and the features are subsequently encoded and pre-processed followed by inputting them to the constructed Convolutional Neural Network (CNN) convolution layer to extract local features. Secondly, in accordance with the weights from the Attention mechanism, the generated local features are input into the Long-Short Term Memory (LSTM) model, and subsequently pooled to calculate the global features of the URLs. Finally, the URLs are detected and classified by the SoftMax function using global features. The results demonstrate that compared with the existing methods, the Attention-based CNN-LSTM mechanism has higher accuracy for malicious URL detection."
        },
        {
          "rank": 41,
          "score": 0.6183314323425293,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 42,
          "score": 0.6174589991569519,
          "doc_id": "NART77437325",
          "title": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns",
          "abstract": "Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77437325&target=NART&cn=NART77437325",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences."
        },
        {
          "rank": 43,
          "score": 0.6168566942214966,
          "doc_id": "ART003204610",
          "title": "CNN-LSTM Based Malicious Code Detection",
          "abstract": "This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003204610&target=NART&cn=ART003204610",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability."
        },
        {
          "rank": 44,
          "score": 0.6165754795074463,
          "doc_id": "JAKO202519561208274",
          "title": "프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구",
          "abstract": "본 연구는 대화형 인공지능 모델인 ChatGPT와 프롬프트 엔지니어링(Prompt Engineering) 기법을 활용하여, 자연어 기반 지시문만으로 토픽 모델링 분석을 수행할 수 있는 방법론을 제안한다. 기존의 토픽 모델링은 LDA 등 통계 기반 알고리즘을 활용함으로써 높은 수준의 프로그래밍 이해와 복잡한 모델 설정이 요구된다는 한계가 있다. 그러나 본 연구는 프롬프트 엔지니어링 기법을 활용한 '데이터 사이언티스트' 역할 부여, 자연어 기반의 구조화한 토픽 모델링 분석 절차 정의함으로써 GPT에 전문성을 부여하였다. 그 결과, 기존 자동화 모델에서 구현하기 어려웠던 도매인 전문성과 문맥 기반 해석에 따라 실제 뉴스 데이터를 대상으로 토픽 수 결정, 모델 선택, 시각화, 일관성 있는 분석 등 전 과정을 자동화하는 접근을 실험적으로 제시하였다. 분석과정에서 자동 생성된 파이썬 코드는 별도의 개발 환경에서 재 실행함으로써 GPT 생성 코드의 정확성과 신뢰성을 검증하였다. 또한 ChatGPT의 [지식] 기능을 통해 검증된 외부 문서 정보를 불러와 분석의 객관성을 확보함으로써 GPT 환각(Hallucination)현상을 방지하였다. 본 연구의 GPT모델은 한글 형태소 분석, BERTopic와 같은 딥러닝 기반 토픽 모델링, OpenAPI 연동 등과 같은 ChatGPT 운영 환경에 일부 제약이 있었다. 그러나 ChatGPT 프롬프트 기반 데이터 분석 자동화의 가능성과 ChatGPT의 실무적 활용 확장을 위한 기초 연구로서 의의를 가진다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202519561208274&target=NART&cn=JAKO202519561208274",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 프롬프트 엔지니어링 기반 ChatGPT의 토픽 모델링 자동화 구현 연구 본 연구는 대화형 인공지능 모델인 ChatGPT와 프롬프트 엔지니어링(Prompt Engineering) 기법을 활용하여, 자연어 기반 지시문만으로 토픽 모델링 분석을 수행할 수 있는 방법론을 제안한다. 기존의 토픽 모델링은 LDA 등 통계 기반 알고리즘을 활용함으로써 높은 수준의 프로그래밍 이해와 복잡한 모델 설정이 요구된다는 한계가 있다. 그러나 본 연구는 프롬프트 엔지니어링 기법을 활용한 '데이터 사이언티스트' 역할 부여, 자연어 기반의 구조화한 토픽 모델링 분석 절차 정의함으로써 GPT에 전문성을 부여하였다. 그 결과, 기존 자동화 모델에서 구현하기 어려웠던 도매인 전문성과 문맥 기반 해석에 따라 실제 뉴스 데이터를 대상으로 토픽 수 결정, 모델 선택, 시각화, 일관성 있는 분석 등 전 과정을 자동화하는 접근을 실험적으로 제시하였다. 분석과정에서 자동 생성된 파이썬 코드는 별도의 개발 환경에서 재 실행함으로써 GPT 생성 코드의 정확성과 신뢰성을 검증하였다. 또한 ChatGPT의 [지식] 기능을 통해 검증된 외부 문서 정보를 불러와 분석의 객관성을 확보함으로써 GPT 환각(Hallucination)현상을 방지하였다. 본 연구의 GPT모델은 한글 형태소 분석, BERTopic와 같은 딥러닝 기반 토픽 모델링, OpenAPI 연동 등과 같은 ChatGPT 운영 환경에 일부 제약이 있었다. 그러나 ChatGPT 프롬프트 기반 데이터 분석 자동화의 가능성과 ChatGPT의 실무적 활용 확장을 위한 기초 연구로서 의의를 가진다."
        },
        {
          "rank": 45,
          "score": 0.6165090799331665,
          "doc_id": "NART39451414",
          "title": "Real-time POMDP algorithm based on belief states space compression",
          "abstract": "Solving belief state space for partially observable Markov decision processes （POMDP） is an NP-difficult problem. Therefore, a belief state space compression（BSSC） algorithm is proposed, which compacts belief state space from high dimension to low dimension. State transition function, observation functionand reward function are compressed by using dynamic Bayesian network to reduce the solving dimension and realize real-time decision. The test data show that the BSSC algorithm can quickly solve optimal policy and optimal value function in the real-time environment.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART39451414&target=NART&cn=NART39451414",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Real-time POMDP algorithm based on belief states space compression Real-time POMDP algorithm based on belief states space compression Real-time POMDP algorithm based on belief states space compression Solving belief state space for partially observable Markov decision processes （POMDP） is an NP-difficult problem. Therefore, a belief state space compression（BSSC） algorithm is proposed, which compacts belief state space from high dimension to low dimension. State transition function, observation functionand reward function are compressed by using dynamic Bayesian network to reduce the solving dimension and realize real-time decision. The test data show that the BSSC algorithm can quickly solve optimal policy and optimal value function in the real-time environment."
        },
        {
          "rank": 46,
          "score": 0.6155230402946472,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78755911&target=NART&cn=NART78755911",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>"
        },
        {
          "rank": 47,
          "score": 0.6139984726905823,
          "doc_id": "DIKO0016950566",
          "title": "심층 강화학습을 활용한 로봇 경로 계획",
          "abstract": "강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016950566&target=NART&cn=DIKO0016950566",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 심층 강화학습을 활용한 로봇 경로 계획 강화학습이란 주어진 작업에 맞는 환경과 에이전트가 상호 작용하며 하는 행동에 따라 받는 보상을 기반으로 한 에피소드동안 누적 보상합이 최대가 되는 최적의 행동을 에이전트가 학습하는 분야이다. 에이전트는 수많은 시행착오를 거치며 학습에 필요한 데이터들을 기억하고 누적 보상합이 최대화 하는 행동을 하도록 학습한다. 따라서 환경과 에이전트만 있다면 다양한 분야에서 강화 학습은 사용가능하다. 본 논문에서는 이를 로봇의 경로 계획에 사용한 두개의 심층 강화 학습 방법을 제안한다. 첫째로 두 개의 로봇 팔 매니퓰레이터를 사용하여 움직이는 장애물이 있는 환경에서의 경로 계획을 보여준다. 심층 강화 학습의 SAC(Soft Actor Critic) 알고리즘을 사용하여 에이전트를 학습 시키고 움직이는 장애물의 위치 정보를 이용하기위해 딥 러닝의 LSTM(Long Short-Term Memory)을 사용하여 움직이는 장애물의 미래 위치를 추정하여 심층 강화 학습의 상태 데이터로 같이 사용한다. 두번째로 UGV(Unmanned Ground Vehicle)와 UAV(Unmanned Aerial Vehicle)의 협업을 통해 심층 강화 학습을 이용한 경로 계획 방법을 제안한다. 심층 강화 학습의 Rainbow DQN 알고리즘을 개선하여 사용한다. 미지의 환경에서 경로 계획을 진행 할 경우 환경에 대한 정보를 모르는 UGV가 경로 계획을 하기 위한 정보를 얻기 위하여 UAV를 통해 환경에 대한 정보를 얻고 이를 이용하여 UGV가 경로 계획을 진행한다."
        },
        {
          "rank": 48,
          "score": 0.612479567527771,
          "doc_id": "NART77437322",
          "title": "Crowdsourcing and brand control",
          "abstract": "Crowdsourcing is the deliberate use of crowds to solve problems, create new products, and improve consumer experiences. When used by brands, crowdsourcing engages consumers by asking them to be part of a deliberate call to action. Crowdsourcing provides interesting and dynamic marketing opportunities for brands, given the consumer engagement it entails. This conceptual study examines the literature on crowdsourcing and brand community, and makes a series of propositions regarding this rich marketing arena. Herein, we discuss managerial implications of the relationship between crowdsourcing and brand community dynamics and propose a typology for brands to better assess customer bases and market realities.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77437322&target=NART&cn=NART77437322",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing and brand control Crowdsourcing and brand control Crowdsourcing and brand control Crowdsourcing is the deliberate use of crowds to solve problems, create new products, and improve consumer experiences. When used by brands, crowdsourcing engages consumers by asking them to be part of a deliberate call to action. Crowdsourcing provides interesting and dynamic marketing opportunities for brands, given the consumer engagement it entails. This conceptual study examines the literature on crowdsourcing and brand community, and makes a series of propositions regarding this rich marketing arena. Herein, we discuss managerial implications of the relationship between crowdsourcing and brand community dynamics and propose a typology for brands to better assess customer bases and market realities."
        },
        {
          "rank": 49,
          "score": 0.6120370626449585,
          "doc_id": "JAKO201911263062209",
          "title": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론",
          "abstract": "Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911263062209&target=NART&cn=JAKO201911263062209",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics."
        },
        {
          "rank": 50,
          "score": 0.6120238304138184,
          "doc_id": "JAKO202012764215284",
          "title": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측",
          "abstract": "청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012764215284&target=NART&cn=JAKO202012764215284",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다."
        }
      ]
    },
    {
      "query": "What results characterize the system that learns TurKontrol’s POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8467158079147339,
          "doc_id": "NART120023140",
          "title": "Artificial Intelligence for Artificial Artificial Intelligence",
          "abstract": "<P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART120023140&target=NART&cn=NART120023140",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence Artificial Intelligence for Artificial Artificial Intelligence <P> Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. </P>"
        },
        {
          "rank": 2,
          "score": 0.8061032295227051,
          "doc_id": "NART66567138",
          "title": "POMDP-based control of workflows for crowdsourcing",
          "abstract": "Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART66567138&target=NART&cn=NART66567138",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing POMDP-based control of workflows for crowdsourcing Crowdsourcing, outsourcing of tasks to a crowd of unknown people (''workers'') in an open call, is rapidly rising in popularity. It is already being heavily used by numerous employers (''requesters'') for solving a wide variety of tasks, such as audio transcription, content screening, and labeling training data for machine learning. However, quality control of such tasks continues to be a key challenge because of the high variability in worker quality. In this paper we show the value of decision-theoretic techniques for the problem of optimizing workflows used in crowdsourcing. In particular, we design AI agents that use Bayesian network learning and inference in combination with Partially-Observable Markov Decision Processes (POMDPs) for obtaining excellent cost-quality tradeoffs. We use these techniques for three distinct crowdsourcing scenarios: (1) control of voting to answer a binary-choice question, (2) control of an iterative improvement workflow, and (3) control of switching between alternate workflows for a task. In each scenario, we design a Bayes net model that relates worker competency, task difficulty and worker response quality. We also design a POMDP for each task, whose solution provides the dynamic control policy. We demonstrate the usefulness of our models and agents in live experiments on Amazon Mechanical Turk. We consistently achieve superior quality results than non-adaptive controllers, while incurring equal or less cost."
        },
        {
          "rank": 3,
          "score": 0.7522146701812744,
          "doc_id": "NART69625850",
          "title": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool",
          "abstract": "<P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART69625850&target=NART&cn=NART69625850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool Inside the Turk : Understanding Mechanical Turk as a Participant Pool <P>Mechanical Turk (MTurk), an online labor market created by Amazon, has recently become popular among social scientists as a source of survey and experimental data. The workers who populate this market have been assessed on dimensions that are universally relevant to understanding whether, why, and when they should be recruited as research participants. We discuss the characteristics of MTurk as a participant pool for psychology and other social sciences, highlighting the traits of the MTurk samples, why people become MTurk workers and research participants, and how data quality on MTurk compares to that from other pools and depends on controllable and uncontrollable factors.</P>"
        },
        {
          "rank": 4,
          "score": 0.737086296081543,
          "doc_id": "NART108676444",
          "title": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP)",
          "abstract": "<P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108676444&target=NART&cn=NART108676444",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP) <P>Selecting appropriate tutoring help actions that account for both a student&rsquo;s content mastery and engagement level is essential for effective human tutors, indicating the critical need for these skills in autonomous tutors. In this work, we formulate the robot-student tutoring help action selection problem as the Assistive Tutor partially observable Markov decision process (AT-POMDP). We designed the AT-POMDP and derived its parameters based on data from a prior robot-student tutoring study. The policy that results from solving the AT-POMDP allows a robot tutor to decide upon the optimal tutoring help action to give a student, while maintaining a belief of the student&rsquo;s mastery of the material and engagement with the task. This approach is validated through a between-subjects field study, which involved 4th grade students (n=28) interacting with a social robot solving long division problems over five sessions. Students who received help from a robot using the AT-POMDP policy demonstrated significantly greater learning gains than students who received help from a robot with a fixed help action selection policy. Our results demonstrate that this robust computational framework can be used effectively to deliver diverse and personalized tutoring support over time for students.</P>"
        },
        {
          "rank": 5,
          "score": 0.731204628944397,
          "doc_id": "NART127620540",
          "title": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations",
          "abstract": "<P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART127620540&target=NART&cn=NART127620540",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations Mechanical Turk Versus Student Samples: Comparisons and Recommendations <P>Mechanical Turk and other online crowdsourcing markets (OCMs) have become a go-to data source across scientific disciplines. In 2014 Steelman and colleagues investigated how Mechanical Turk data compared with student samples and consumer panels. They found the data to be comparable and reliable for academic research. In the nearly 10 years since its publication, the use of Mechanical Turk in research has grown substantially. To understand whether their results still hold, we conducted a partial replication to determine how Mechanical Turk workers continue to compare with students using UTAUT 2 as our theoretical model and virtual-reality headsets as the focal IT artifact. Our findings generally align with Steelman et al. (2014) and confirm that Mechanical Turk continues to offer a suitable alternative to student samples. This study reveals consistent results between the student and OCM samples, indicating the potential for interchangeability. The OCM samples are primarily male, while the student sample is majority female, following current US academic trends. All samples are significantly different in age, and only the US OCM and non-US OCM samples are similar in education. The path coefficients from the non-US OCM sample differ significantly from those from other OCM samples; the path coefficients derived from the student sample do not differ significantly from any OCM sample. While sample differences exist, as expected, many are addressable post hoc if anticipated and designed for during data collection. From our findings and the extant literature, we summarize recommendations for researchers and review teams.</P>"
        },
        {
          "rank": 6,
          "score": 0.7305763363838196,
          "doc_id": "NART77197564",
          "title": "Online recruitment and testing of infants with Mechanical Turk",
          "abstract": "Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77197564&target=NART&cn=NART77197564",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Online recruitment and testing of infants with Mechanical Turk Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users' webcams we recorded how long infants aged 5 to 8months attended while viewing children's television programs. We found that infants (N=57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants."
        },
        {
          "rank": 7,
          "score": 0.7297760248184204,
          "doc_id": "NART75736850",
          "title": "Mechanical Turk upends social sciences",
          "abstract": "<P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75736850&target=NART&cn=NART75736850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Mechanical Turk upends social sciences Mechanical Turk upends social sciences Mechanical Turk upends social sciences <P>In May, 23,000 people voluntarily took part in thousands of social science experiments without ever visiting a lab. All they did was log on to Amazon Mechanical Turk (MTurk), an online crowdsourcing service run by the Seattle, Washington&#x2013;based company better known for its massive internet-based retail business. Those research subjects completed 230,000 tasks on their computers in 3.3 million minutes&#x2014;more than 6 years of effort in total. The prodigious output demonstrates the popularity of an online platform that scientists had only begun to exploit 5 years ago. But the growing use of MTurk has raised concerns, as researchers discussed at the Association for Psychological Science meeting in Chicago, Illinois, last month. Some worry that they are becoming too dependent on a commercial platform. Others question whether the research volunteers are paid fairly and treated ethically. And looming over it all are questions about who these anonymous volunteers actually are, and concerns that they are less numerous and diverse than researchers hope.</P>"
        },
        {
          "rank": 8,
          "score": 0.7194415926933289,
          "doc_id": "NART95314903",
          "title": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots",
          "abstract": "<P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95314903&target=NART&cn=NART95314903",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots <P><B>Abstract</B></P>  <P>In this work we present <I>&alpha;</I>POMDP: a User-Adaptive Decision-Making technique for social robots. This technique is based on the classical POMDP formulation which we extend with novel aspects inspired by Reward Shaping and Model-Based Reinforcement Learning. Our technique innovates in two main ways: by applying a novel set of rewarding schemes based on the state of the user and by employing a novel execution loop that enables the system to learn the impact of its actions on the user on-the-fly. Our technique has been tested with multiple POMDP solvers and reward formulations in simulations and with real users through the GrowMu social robot. Results show that our technique is able to correctly decide which actions to take, maintaining the user in positive states which interacting with the robot and methodically exploring and learning their characteristics, activities and behaviors.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  aPOMDP controls an agent&rsquo;s actions to maintain the user in maximum value states. </LI> <LI>  Three reward functions based on state value and entropy are proposed and compared. </LI> <LI>  Online learning of the transition matrix T is done through a knowledge update step. </LI> <LI>  User stays in most valuable states up to 71% of the time, lowering T entropy to 0.7. </LI> <LI>  User tests show that the technique is transferable to real scenarios with robots. </LI> </UL> </P>"
        },
        {
          "rank": 9,
          "score": 0.7128536701202393,
          "doc_id": "NART92832666",
          "title": "Using Amazon Mechanical Turk for linguistic research",
          "abstract": "<P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART92832666&target=NART&cn=NART92832666",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research Using Amazon Mechanical Turk for linguistic research <P>Amazon?s Mechanical Turk service makes linguistic experimentation quick, easy, and inexpensive. However, researchers have not been certain about its reliability. In a series of experiments, this paper compares data collected via Mechanical Turk to those obtained using more traditional methods One set of experiments measured the predictability of words in sentences using the Cloze sentence completion task (Taylor, 1953). The correlation between traditional and Turk Cloze scores is high (rho=0.823) and both data sets perform similarly against alternative measures of contextual predictability. Five other experiments on the semantic relatedness of verbs and phrasal verbs (how much is ?lift? part of ?lift up?) manipulate the presence of the sentence context and the composition of the experimental list. The results indicate that Turk data correlate well between experiments and with data from traditional methods (rho up to 0.9), and they show high inter-rater consistency and agreement. We conclude that Mechanical Turk is a reliable source of data for complex linguistic tasks in heavy use by psycholinguists. The paper provides suggestions for best practices in data collection and scrubbing.</P>"
        },
        {
          "rank": 10,
          "score": 0.7049505710601807,
          "doc_id": "JAKO202411139606539",
          "title": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이",
          "abstract": "온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202411139606539&target=NART&cn=JAKO202411139606539",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 Amazon Mechanical Turk 마스터, 일반 참가자, 오프라인 참가자 집단의 기억 수행 차이 온라인 크라우드소싱 플랫폼인 Amazon Mechanical Turk(MTurk)은 뛰어난 과제 수행 기록을 가진 참가자들에게 마스터 등급을 부여한다. 그러나 MTurk의 마스터 참가자와 일반 참가자를 비교한 선행 연구들은 두 집단이 실제로 수행의 차이를 보이는가에 대해 일관되지 않은 결과를 보고했다. 또한 선행 연구들은 대부분 설문 조사 방식을 사용했으며 MTurk의 마스터와 일반 참가자의 인지 과제 수행 능력을 비교한 연구는 부족한 상황이다. 본 연구는 시각 기억 재인 과제를 사용하여 MTurk 마스터 및 일반 참가자와 오프라인에서 모집한 대학생 참가자 집단의 수행을 비교했다. 연구 결과, MTurk 마스터 참가자와 오프라인 참가자는 동일한 수준의 기억 수행을 보였다. 그러나 MTurk 일반 참가자의 기억 과제 수행은 마스터와 오프라인 참가자 집단의 결과와 차이를 보였다. 각 집단에서 기억 과제 정확률이 낮은 참가자를 제외한 후에도 동일한 결과가 나타났다. 이러한 결과는 온라인에서 참가자 집단을 적절히 선발하면 기존의 오프라인 실험 결과를 잘 재현할 수 있음을 보여준다. 동시에 본 연구의 결과는 온라인 크라우드소싱 플랫폼의 참가자 집단이 균일하지 않으며, 집단 선정 방식에 따라 연구의 결과가 다르게 나타날 수 있음을 시사한다."
        },
        {
          "rank": 11,
          "score": 0.7043347358703613,
          "doc_id": "JAKO201222653563471",
          "title": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법",
          "abstract": "최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201222653563471&target=NART&cn=JAKO201222653563471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법 최근 무인항공기의 제작 기술이 발전함에 따라, 농업, 재해 관측용 등의 민간 용도 뿐만 아니라 정찰 및 공격 등의 군사적 목적으로 다수의 무인기를 사용하는 다양한 시도가 진행되고 있다. 그러나 다수의 무인기를 사용할 때에 각 무인기를 사람이 직접 제어하는 데에는 어려움이 많으므로, 주어진 목표를 달성하기 위해서 자율적으로 협력하며 효과적인 행동을 수행하는 알고리즘의 개발이 필수적이다. 이러한 문제는 순차적 의사결정 문제로 생각할 수 있으며, 마코프 의사결정 과정(Markov Decision Processes; MDPs)과 이를 부분적 혹은 부정확한 관찰값을 다룰 수 있도록 확장한 부분관찰 마코프 의사결정 과정(Partially Observable MDPs; POMDPs) 등의 대표적인 의사결정이론 모델을 이용하여 복잡하고 불확실한 환경에서의 의사결정 문제를 통계적으로 다룰 수 있다. 본 논문에서는 복수의 무인기를 이용할 때 동적 임무 할당 및 정찰 임무 문제를 POMDP를 이용하여 효율적으로 최적화할 수 있음을 보이고, 센서의 관찰값에 오차가 발생할 수 있는 경우, MDP에 비해 POMDP를 이용할 때 더 좋은 성능을 얻을 수 있음을 보인다. 또한 실제 쿼드콥터(quadcopter)를 이용하여 POMDP 정책이 실제 환경에서도 잘 동작함을 시뮬레이션을 통해 입증하였다."
        },
        {
          "rank": 12,
          "score": 0.7000491619110107,
          "doc_id": "NART123803221",
          "title": "Running experiments on Amazon Mechanical Turk",
          "abstract": "<P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART123803221&target=NART&cn=NART123803221",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk Running experiments on Amazon Mechanical Turk <P><B>Abstract</B><P>Although Mechanical Turk has recently become popular among social scientists as a source of experimental data, doubts may linger about the quality of data provided by subjects recruited from online labor markets. We address these potential concerns by presenting new demographic data about the Mechanical Turk subject population, reviewing the strengths of Mechanical Turk relative to other online and offline methods of recruiting subjects, and comparing the magnitude of effects obtained using Mechanical Turk and traditional subject pools. We further discuss some additional benefits such as the possibility of longitudinal, cross cultural and prescreening designs, and offer some advice on how to best manage a common subject pool.</P></P>"
        },
        {
          "rank": 13,
          "score": 0.693526029586792,
          "doc_id": "NART103944733",
          "title": "The Language Demographics of Amazon Mechanical Turk",
          "abstract": "<P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART103944733&target=NART&cn=NART103944733",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk The Language Demographics of Amazon Mechanical Turk <P> We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying. We validate workers&rsquo; self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages. Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it. Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk. We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. </P>"
        },
        {
          "rank": 14,
          "score": 0.6923538446426392,
          "doc_id": "NART70754548",
          "title": "Amazon Mechanical Turk and the commodification of labour",
          "abstract": "<P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70754548&target=NART&cn=NART70754548",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour Amazon Mechanical Turk and the commodification of labour <P>Crowd employment platforms enable firms to source labour and expertise by leveraging Internet technology. Rather than offshoring jobs to low&#8208;cost geographies, functions once performed by internal employees can be outsourced to an undefined pool of digital labour using a virtual network. This enables firms to shift costs and offload risk as they access a flexible, scalable workforce that sits outside the traditional boundaries of labour laws and regulations. The micro&#8208;tasks of &lsquo;clickwork&rsquo; are tedious, repetitive and poorly paid, with remuneration often well below minimum wage. This article will present an analysis of one of the most popular crowdsourcing sites&mdash;Mechanical Turk&mdash;to illuminate how Amazon's platform enables an array of companies to access digital labour at low cost and without any of the associated social protection or moral obligation.</P>"
        },
        {
          "rank": 15,
          "score": 0.6906245350837708,
          "doc_id": "NART88129314",
          "title": "Using Mechanical Turk to Study Clinical Populations",
          "abstract": "<P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART88129314&target=NART&cn=NART88129314",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations Using Mechanical Turk to Study Clinical Populations <P> Although participants with psychiatric symptoms, specific risk factors, or rare demographic characteristics can be difficult to identify and recruit for participation in research, participants with these characteristics are crucial for research in the social, behavioral, and clinical sciences. Online research in general and crowdsourcing software in particular may offer a solution. However, no research to date has examined the utility of crowdsourcing software for conducting research on psychopathology. In the current study, we examined the prevalence of several psychiatric disorders and related problems, as well as the reliability and validity of participant reports on these domains, among users of Amazon&rsquo;s Mechanical Turk. Findings suggest that crowdsourcing software offers several advantages for clinical research while providing insight into potential problems, such as misrepresentation, that researchers should address when collecting data online. </P>"
        },
        {
          "rank": 16,
          "score": 0.6811765432357788,
          "doc_id": "NART134452383",
          "title": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk",
          "abstract": "<P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART134452383&target=NART&cn=NART134452383",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk &raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk <P>This article centers Amazon Mechanical Turk (MTurk) workers to examine their alienation, as they complete monotonous and repetitive microtasks from behind their screens. Confronted with various &raquo;virtual assembly lines&laquo; that produce data across the globe, their labor can be further used for machine learning specifically and Artificial Intelligence more generally. Engaging with these workers and their labor is central to general contemporary and future technological developments bound to bring their own repercussions with them - including the growing and central role of algorithms in managing the world of work.</P>"
        },
        {
          "rank": 17,
          "score": 0.668110728263855,
          "doc_id": "NART73267731",
          "title": "The (Non) Religion of Mechanical Turk Workers",
          "abstract": "<P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73267731&target=NART&cn=NART73267731",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers The (Non) Religion of Mechanical Turk Workers <P>Social science researchers have increasingly come to utilize Amazon's Mechanical Turk (MTurk) to obtain adult, opt&#8208;in samples for use with experiments. Based on the demographic characteristics of MTurk samples, studies have provided some support for the representativeness of MTurk. Others have warranted caution based on demographic characteristics and comparisons of reliability. Yet, what is missing is an examination of the most glaring demographic difference in MTurk&mdash;religion. We compare five MTurk samples with a student convenience sample and the 2012 General Social Survey, finding that MTurk samples have a consistent bias toward nonreligion. MTurk surveys significantly overrepresent seculars and underrepresent Catholics and evangelical Protestants. We then compare the religiosity of religious identifiers across samples as well as relationships between religiosity and partisanship, finding many similarities and a few important differences from the general population.</P>"
        },
        {
          "rank": 18,
          "score": 0.662880003452301,
          "doc_id": "NART77258550",
          "title": "Real-time recommendation algorithms for crowdsourcing systems",
          "abstract": "Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77258550&target=NART&cn=NART77258550",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Real-time recommendation algorithms for crowdsourcing systems Crowdsourcing has become a promising paradigm for solving tasks that are beyond the capabilities of machines alone via outsourcing tasks to online crowds of people. Both requesters and workers in crowdsourcing systems confront a flood of data coming along with the vast amount of tasks. Fast, on-the-fly recommendation of tasks to workers and workers to requesters is becoming critical for crowdsourcing systems. Traditional recommendation algorithms such as collaborative filtering no longer work satisfactorily because of the unprecedented data flow and the on-the-fly nature of the tasks in crowdsourcing systems. A pressing need for real-time recommendations has emerged in crowdsourcing systems: on the one hand, workers want effective recommendation of the top-k most suitable tasks with regard to their skills and preferences, and on the other hand, requesters want reliable recommendation of the top-k best workers for their tasks in terms of workers' qualifications and accountability. In this article, we propose two real-time recommendation algorithms for crowdsourcing systems: (1) TOP-K-T that computes the top-k most suitable tasks for a given worker and (2) TOP-K-W that computes the top-k best workers to a requester with regard to a given task. Experimental study has shown the efficacy of both algorithms."
        },
        {
          "rank": 19,
          "score": 0.6601259708404541,
          "doc_id": "NART68279824",
          "title": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces",
          "abstract": "Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART68279824&target=NART&cn=NART68279824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Leveraging non-expert crowdsourcing workers for improper task detection in crowdsourcing marketplaces Controlling the quality of tasks, i.e., propriety of posted jobs, is a major challenge in crowdsourcing marketplaces. Most existing crowdsourcing services prohibit requesters from posting illegal or objectionable tasks. Operators in marketplaces have to monitor tasks continuously to find such improper ones; however, it is very expensive to manually investigate each task. In this paper, we present the results of our trial study on automatic detection of improper tasks to support the monitoring of activities by marketplace operators. We performed experiments using real task data from a commercial crowdsourcing marketplace and showed that the classifier trained by the operators' judgments achieves a high performance in detecting improper tasks. By analyzing the estimated classifier, we observed several effective features for detecting improper tasks, such as the words appeared in the task information, the amount of money that each worker will receive for the task, and the type of worker qualification option set for a task. In addition, to reduce the annotation costs of the operators and improve classification performance, we considered the use of crowdsourcing for task annotation. We hired a group of crowdsourcing (non-expert) workers to monitor posted tasks and use their judgments to train the classifier. We were able to confirm that applying quality control techniques is beneficial for handling the variability in worker reliability and that it improved the performance of the classifier. Finally, our results showed that the use of non-expert judgments of crowdsourcing workers in combination with expert judgments improves the performance of detecting improper crowdsourcing tasks, and that the use of crowdsourced labels allows a reduction in the required number of expert judgments by 25% while maintaining the level of detection performance."
        },
        {
          "rank": 20,
          "score": 0.6598766446113586,
          "doc_id": "NART53030850",
          "title": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems",
          "abstract": "This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART53030850&target=NART&cn=NART53030850",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems This paper describes a statistically motivated framework for performing real-time dialogue state updates and policy learning in a spoken dialogue system. The framework is based on the partially observable Markov decision process (POMDP), which provides a well-founded, statistical model of spoken dialogue management. However, exact belief state updates in a POMDP model are computationally intractable so approximate methods must be used. This paper presents a tractable method based on the loopy belief propagation algorithm. Various simplifications are made, which improve the efficiency significantly compared to the original algorithm as well as compared to other POMDP-based dialogue state updating approaches. A second contribution of this paper is a method for learning in spoken dialogue systems which uses a component-based policy with the episodic Natural Actor Critic algorithm. The framework proposed in this paper was tested on both simulations and in a user trial. Both indicated that using Bayesian updates of the dialogue state significantly outperforms traditional definitions of the dialogue state. Policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the Bayesian update of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems."
        },
        {
          "rank": 21,
          "score": 0.6581252813339233,
          "doc_id": "NART77727471",
          "title": "Robotic manipulation of multiple objects as a POMDP",
          "abstract": "This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77727471&target=NART&cn=NART77727471",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP Robotic manipulation of multiple objects as a POMDP This paper investigates manipulation of multiple unknown objects in a crowded environment. Because of incomplete knowledge due to unknown objects and occlusions in visual observations, object observations are imperfect and action success is uncertain, making planning challenging. We model the problem as a partially observable Markov decision process (POMDP), which allows a general reward based optimization objective and takes uncertainty in temporal evolution and partial observations into account. In addition to occlusion dependent observation and action success probabilities, our POMDP model also automatically adapts object specific action success probabilities. To cope with the changing system dynamics and performance constraints, we present a new online POMDP method based on particle filtering that produces compact policies. The approach is validated both in simulation and in physical experiments in a scenario of moving dirty dishes into a dishwasher. The results indicate that: 1) a greedy heuristic manipulation approach is not sufficient, multi-object manipulation requires multi-step POMDP planning, and 2) on-line planning is beneficial since it allows the adaptation of the system dynamics model based on actual experience."
        },
        {
          "rank": 22,
          "score": 0.6575192213058472,
          "doc_id": "ART003173264",
          "title": "Optimizing smart city planning: A deep reinforcement learning framework",
          "abstract": "We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003173264&target=NART&cn=ART003173264",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework Optimizing smart city planning: A deep reinforcement learning framework We introduce a deep reinforcement learning-based approach for smart city planning, designed to determine the optimal timing for constructing various smart city components such as apartments, base stations, and hospitals over a specified development period. Utilizing the Dueling Deep Q-Network (DQN), the proposed method aims to maximize the city’s population while maintaining a predetermined happiness level of residents in the smart city. This optimization is achieved through strategic construction of smart city components, considering that both the total population and happiness levels are influenced by the interplay between housing, communication, transportation, and healthcare infrastructures, as well as the population ratio. Specifically, we present two distinct formulations of the Markov Decision Process (MDP) for smart city planning to illustrate the practicality of applying reinforcement learning across different scenarios."
        },
        {
          "rank": 23,
          "score": 0.656048059463501,
          "doc_id": "JAKO202033759655983",
          "title": "공 던지기 로봇의 정책 예측 심층 강화학습",
          "abstract": "Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202033759655983&target=NART&cn=JAKO202033759655983",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 공 던지기 로봇의 정책 예측 심층 강화학습 Robot's throwing control is difficult to accurately calculate because of air resistance and rotational inertia, etc. This complexity can be solved by using machine learning. Reinforcement learning using reward function puts limit on adapting to new environment for robots. Therefore, this paper applied deep reinforcement learning using neural network without reward function. Throwing is evaluated as a success or failure. AI network learns by taking the target position and control policy as input and yielding the evaluation as output. Then, the task is carried out by predicting the success probability according to the target location and control policy and searching the policy with the highest probability. Repeating this task can result in performance improvements as data accumulates. And this model can even predict tasks that were not previously attempted which means it is an universally applicable learning model for any new environment. According to the data results from 520 experiments, this learning model guarantees 75% success rate."
        },
        {
          "rank": 24,
          "score": 0.6527199745178223,
          "doc_id": "NART73604379",
          "title": "Conducting behavioral research on Amazon’s Mechanical Turk",
          "abstract": "<P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART73604379&target=NART&cn=NART73604379",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk Conducting behavioral research on Amazon’s Mechanical Turk <P>Amazon&#039;s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.</P>"
        },
        {
          "rank": 25,
          "score": 0.6520376205444336,
          "doc_id": "NART78755911",
          "title": "Using Mechanical Turk for research on cancer survivors",
          "abstract": "<P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART78755911&target=NART&cn=NART78755911",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors Using Mechanical Turk for research on cancer survivors <P><B>Abstract</B></P><P><B>Objective</B></P><P>The successful recruitment and study of cancer survivors within psycho&#8208;oncology research can be challenging, time&#8208;consuming, and expensive, particularly for key subgroups such as young adult cancer survivors. Online crowdsourcing platforms offer a potential solution that has not yet been investigated with regard to cancer populations. The current study assessed the presence of cancer survivors on Amazon's Mechanical Turk (MTurk) and the feasibility of using MTurk as an efficient, cost&#8208;effective, and reliable psycho&#8208;oncology recruitment and research platform.</P><P><B>Methods</B></P><P>During a <4&#8208;month period, cancer survivors living in the United States were recruited on MTurk to complete two assessments, spaced 1 week apart, relating to psychosocial and cancer&#8208;related functioning. The reliability and validity of responses were investigated.</P><P><B>Results</B></P><P>Within a <4&#8208;month period, 464 self&#8208;identified cancer survivors on MTurk consented to and completed an online assessment. The vast majority (79.09%) provided reliable and valid study data according to multiple indices. The sample was highly diverse in terms of U.S. geography, socioeconomic status, and cancer type, and reflected a particularly strong presence of distressed and young adult cancer survivors (median age = 36 years). A majority of participants (58.19%) responded to a second survey sent one week later.</P><P><B>Conclusions</B></P><P>Online crowdsourcing represents a feasible, efficient, and cost&#8208;effective recruitment and research platform for cancer survivors, particularly for young adult cancer survivors and those with significant distress. We discuss remaining challenges and future recommendations. Copyright &copy; 2016 John Wiley &amp; Sons, Ltd.</P>"
        },
        {
          "rank": 26,
          "score": 0.6504067182540894,
          "doc_id": "NART70960968",
          "title": "A reliability analysis of Mechanical Turk data",
          "abstract": "Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70960968&target=NART&cn=NART70960968",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data A reliability analysis of Mechanical Turk data Amazon's Mechanical Turk (MTurk) provides researchers with access to a diverse set of people who can serve as research participants, making the process of data collection a streamlined and cost-effective one. While a small number of studies are often cited to support the use of this methodology, there remains a need for additional analyses of the quality of the research data. In the present study, MTurk-based responses for a personality scale were found to be significantly less reliable than scores previously reported for a community sample. While score reliability was not affected by the length of the survey or the payment rates, the presence of an item asking respondents to affirm that they were attentive and honest was associated with more reliable responses. Best practices for MTurk-based research and continuing research needs are addressed."
        },
        {
          "rank": 27,
          "score": 0.6485852003097534,
          "doc_id": "ATN0037493744",
          "title": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템",
          "abstract": "Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037493744&target=NART&cn=ATN0037493744",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 digo: 생산성 향상을 위한 딥러닝 실험 관리 시스템 Recently, advanced service using artificial intelligence has become a necessity, not an option. As a result, research on artificial intelligence has been accelerated, drawing attention to methods for efficient artificial intelligence research. A typical method is to use tools to effectively manage experiments in the course of the study. Existing deep learning studies have been inefficient due to collaboration based on fragmentary work methods and repetitive tasks for optimizing learning results. To improve these problems, this work designs and implements Digo (a combination of words that represent repetitive deep learning research as a compound word of dig and go), a collaborative-based deep learning experiment management tool that can provide a convenient and productive research environment, focusing on deep learning among artificial intelligence. Experiments and surveys were conducted on machine learning researchers to validate the performance of deep learning experimental management tools, and to confirm the convenience of hyperparameter automatic optimization and learning result visualization features."
        },
        {
          "rank": 28,
          "score": 0.6462038159370422,
          "doc_id": "NART108498824",
          "title": "Hierarchical POMDP planning for object manipulation in clutter",
          "abstract": "<P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART108498824&target=NART&cn=NART108498824",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter Hierarchical POMDP planning for object manipulation in clutter <P><B>Abstract</B></P>  <P>Object manipulation planning in clutter suffers from perception uncertainties due to occlusion, as well as action constraints required by collision avoidance. Partially observable Markov decision process (POMDP) provides a general model for planning under uncertainties. But a manipulation task usually have a large action space, which not only makes task planning intractable but also brings significant motion planning effort to check action feasibility. In this work, a new kind of hierarchical POMDP is presented for object manipulation tasks, in which a brief abstract POMDP is extracted and utilized together with the original POMDP. And a hierarchical belief tree search algorithm is proposed for efficient online planning, which constructs fewer belief nodes by building part of the tree with the abstract POMDP and invokes motion planning fewer times by determining action feasibility with observation function of the abstract POMDP. A learning mechanism is also designed in case there are unknown probabilities in transition and observation functions. This planning framework is demonstrated with an object fetching task and the performance is empirically validated by simulations and experiments.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  We propose a hierarchical POMDP including an original POMDP and an abstract POMDP. </LI> <LI>  We design a mechanism to learn unknown probabilities in the abstract POMDP. </LI> <LI>  We link action feasibility to observation function to avoid motion planning. </LI> <LI>  We search a hierarchical belief tree for online planning with high efficiency. </LI> <LI>  We conduct various simulations and experiments to validate the proposed method. </LI> </UL> </P>"
        },
        {
          "rank": 29,
          "score": 0.6385859251022339,
          "doc_id": "JAKO200617033460433",
          "title": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법",
          "abstract": "본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200617033460433&target=NART&cn=JAKO200617033460433",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법 본 논문에서는 Localized Aptive QoS 라우팅을 위해 POMDP(Partially Observable Markov Decision Processes)와 Exploration Bonus 기법을 사용하는 방법을 제안하였다. 또한, POMDP 문제를 해결하기 위해 Dynamic Programming을 사용하여 최적의 행동을 찾는 연산이 매우 복잡하고 어렵기 때문에 CEA(Certainty Equivalency Approximation) 기법을 통한 기댓값 사용으로 문제를 단순하였으며, Exploration Bonus 방식을 사용해 현재 경로보다 나은 경로를 탐색하고자 하였다. 이를 위해 다중 경로 탐색 알고리즘(SEMA)을 제안했다. 더욱이 탐색의 횟수와 간격을 정의하기 위해 <TEX>$\\phi$</TEX>와 k 성능 파라미터들을 사용하여 이들을 통해 탐색의 횟수 변화를 통한 서비스 성공률과 성공 시 사용된 평균 홉 수에 대한 성능을 살펴보았다. 결과적으로 <TEX>$\\phi$</TEX> 값이 증가함에 따라 현재의 경로보다 더 나은 경로를 찾게 되며, k 값이 증가할수록 탐색이 증가함을 볼 수 있다."
        },
        {
          "rank": 30,
          "score": 0.6377626657485962,
          "doc_id": "JAKO202417657635096",
          "title": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험",
          "abstract": "행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202417657635096&target=NART&cn=JAKO202417657635096",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터 환경에서 컷오프-투표 분류기를 활용한 빅데이터 예측모형의 실험 행정 빅데이터를 활용하는 예측 모형을 운영하기 위해서는 정책의 변화 및 변동성 심한 데이터의 특성이 고려가 되어야만 한다. 이런 상황을 고려하여 본 연구에서는 Cut-off Voting Classifier(CVC) 알고리즘을 제안한다. 제안하는 알고리즘은 여러개의 약 분류기를 활용하여 적중률이 급격하게 하락하는 것을 방지하는 알고리즘이다. 본 연구에서는 제안하는 알고리즘을 실험을 통해 성능을 검증한다. 성능검증 결과 급격하게 예측모형 적중률이 하락하는 상황에서도 안정적으로 예측률을 유지한다는 것을 입증할 수 있었다."
        },
        {
          "rank": 31,
          "score": 0.6365759372711182,
          "doc_id": "NART48526876",
          "title": "Prioritizing Point-Based POMDP Solvers",
          "abstract": "<P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART48526876&target=NART&cn=NART48526876",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers Prioritizing Point-Based POMDP Solvers <P>Scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.</P>"
        },
        {
          "rank": 32,
          "score": 0.6361570954322815,
          "doc_id": "ART003204610",
          "title": "CNN-LSTM Based Malicious Code Detection",
          "abstract": "This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003204610&target=NART&cn=ART003204610",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection CNN-LSTM Based Malicious Code Detection This paper proposes a hybrid CNN-LSTM model for malicious code detection, combining static and dynamic analysis. CNN extracts spatial features from grayscale images of malware binaries, while LSTM captures temporal behavior from system call sequences. The model achieves high accuracy (94.6%) and F1-score (93.2%) on public datasets, outperforming traditional and single-stream deep learning methods. Its dual-channel design enables comprehensive feature representation, enhancing robustness against obfuscation and behavioral variation. The approach demonstrates strong potential for practical deployment in intelligent malicious code detection systems. Future work will explore attention mechanisms and graph-based modeling to improve detection precision and interpretability."
        },
        {
          "rank": 33,
          "score": 0.6355035901069641,
          "doc_id": "NART75854774",
          "title": "Massively parallel motion planning algorithms under uncertainty using POMDP",
          "abstract": "<P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75854774&target=NART&cn=NART75854774",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP Massively parallel motion planning algorithms under uncertainty using POMDP <P>We present new parallel algorithms that solve continuous-state partially observable Markov decision process (POMDP) problems using the GPU (gPOMDP) and a hybrid of the GPU and CPU (hPOMDP). We choose the Monte Carlo value iteration (MCVI) method as our base algorithm and parallelize this algorithm using the multi-level parallel formulation of MCVI. For each parallel level, we propose efficient algorithms to utilize the massive data parallelism available on modern GPUs. Our GPU-based method uses the two workload distribution techniques, compute/data interleaving and workload balancing, in order to obtain the maximum parallel performance at the highest level. Here we also present a CPU-GPU hybrid method that takes advantage of both CPU and GPU parallelism in order to solve highly complex POMDP planning problems. The CPU is responsible for data preparation, while the GPU performs Monte Cacrlo simulations; these operations are performed concurrently using the compute/data overlap technique between the CPU and GPU. To the best of the authors' knowledge, our algorithms are the first parallel algorithms that efficiently execute POMDP in a massively parallel fashion utilizing the GPU or a hybrid of the GPU and CPU. Our algorithms outperform the existing CPU-based algorithm by a factor of 75-99 based on the chosen benchmark.</P>"
        },
        {
          "rank": 34,
          "score": 0.632605791091919,
          "doc_id": "JAKO201417638008069",
          "title": "POMDP 기반 사용자-로봇 인터랙션 행동 모델",
          "abstract": "This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201417638008069&target=NART&cn=JAKO201417638008069",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 POMDP 기반 사용자-로봇 인터랙션 행동 모델 This paper presents the interactive behavior modeling method based on POMDP (Partially Observable Markov Decision Process) for HRI (Human-Robot Interaction). HRI seems similar to conversational interaction in point of interaction between human and a robot. The POMDP has been popularly used in conversational interaction system. The POMDP can efficiently handle uncertainty of observable variables in conversational interaction system. In this paper, the input variables of the proposed conversational HRI system in POMDP are the input information of sensors and the log of used service. The output variables of system are the name of robot behaviors. The robot behavior presents the motion occurred from LED, LCD, Motor, sound. The suggested conversational POMDP-based HRI system was applied to an emotional robot KIBOT. In the result of human-KIBOT interaction, this system shows the flexible robot behavior in real world."
        },
        {
          "rank": 35,
          "score": 0.6322644352912903,
          "doc_id": "JAKO202012764215284",
          "title": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측",
          "abstract": "청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202012764215284&target=NART&cn=JAKO202012764215284",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 국민청원 주제 분석 및 딥러닝 기반 답변 가능 청원 예측 청와대 국민 청원 사이트가 개설된 이래로 많은 관심을 받고 있다. 본 논문에서는 국민 청원의 주제를 분석하고 딥러닝을 활용하여 답변 가능한 청원을 예측하는 모델을 제안하였다. 먼저, 추천순으로 1,500개의 청원글을 수집하였고, K-means 클러스터링을 적용하여 청원글을 군집하여 대주제를 정의하고, 보다 구체적인 세부 주제를 정의하기 위히여 토픽 모델링을 실시하였다. 다음으로는 LSTM을 활용한 답변 가능한 청원 예측 모델을 생성하여, 20만의 청원동의를 얻는 청원을 예측하기 위한 모델을 개발하였다. 이를 위해 글의 주제와 본문뿐만 아니라 글의 길이, 카테고리, 특정 품사의 비율이 영향을 미칠 수 있는지를 살펴보았다. 그 결과, 본문과 함께 글의 길이, 카테고리, 체언, 용언, 독립언, 수식언의 품사의 비율을 변수로 추가한 모델의 f1-score가 0.9 이상으로 글의 제목과 본문을 변수로 하는 모델보다 예측력이 높음을 알 수 있었다."
        },
        {
          "rank": 36,
          "score": 0.6322367191314697,
          "doc_id": "NART121336460",
          "title": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples",
          "abstract": "<P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART121336460&target=NART&cn=NART121336460",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples Traditional and Modern Convenience Samples: An Investigation of College Student, Mechanical Turk, and Mechanical Turk College Student Samples <P> Two of the most popular populations for convenience sampling used in the psychological sciences are college students and Mechanical Turk (MTurk) workers. College students represent a traditional type of convenience sample, whereas MTurk workers provide a more modern source of data. However, little research has examined how these populations differ from each other in salient characteristics. Additionally, no research to date has investigated how MTurk college students (a traditional sample collected using modern methods) compare to either population. The current study examined 1,248 participants comprising three samples: MTurk noncollege workers ( n = 533), MTurk college students ( n = 385), and traditional college students ( n = 330). We compared the samples on demographic characteristics, study completion time, attention, and individual difference variables (i.e., personality, social desirability, need for cognition, personal values, and social attitudes). We examined the individual difference variables in terms of mean responses, internal consistency estimates, and subscale intercorrelations. Results indicated the samples were distinct from each other in terms of all variables assessed; in addition, adding demographic characteristics as covariates to the analyses of individual difference variables did not effectively account for sample differences. We conclude that research using convenience samples should take these differences into account. </P>"
        },
        {
          "rank": 37,
          "score": 0.6291996240615845,
          "doc_id": "DIKO0012506219",
          "title": "POMDP 기반의 Market-Making 전략 시스템",
          "abstract": "본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0012506219&target=NART&cn=DIKO0012506219",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 POMDP 기반의 Market-Making 전략 시스템 본 연구에서는 POMDP 체계하에서 적응하고 학습 가능한 market-making 전략 시스템을 제안한다. Market-making은 매수자와 매도자 사이의 거래를 중개하면서 매수/매도 스프레드를 이용해 수익을 내는 거래 방법이다. Market-maker는 적절한 재고 위험 관리 전략이 없다면 시장의 매수/매도 체결 비중이 불균형한 시장에서 큰 재고 위험에 직면할 수 있다. POMDP 모델은 agent가 환경의 state를 완전히 관측할 수 없는 상황에서 장기 기간 동안 누적 이익을 최대화 하도록 학습시키는 기술이다. 시장의 역학 구조에 대한 세밀한 가정을 하지 않고 과거의 데이터와 경험으로부터 학습한다. Agent는 수익의 최대화, 재고 위험의 최소화 등과 같이 다중의 목표를 달성할 수 있다. 시뮬레이션 결과는 산출된 market-making 전략이 수익 산출과 재고 위험 관리에 있어 통계적으로 유의한 성능을 내고 있음을 보여 준다."
        },
        {
          "rank": 38,
          "score": 0.6283783912658691,
          "doc_id": "DIKO0017198883",
          "title": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating",
          "abstract": "전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017198883&target=NART&cn=DIKO0017198883",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating Multi-Modal Review Helpfulness Prediction Considering the Consistency Between Review Text and Rating 전자상거래 환경에서 온라인 리뷰는 소비자들의 구매 의사결정 과정에서 핵심적인 역할을 수행하며, 방대한 리뷰 중에서 유용한 리뷰를 효율적으로 탐색하는 것은 소비자와 전자상거래 플랫폼 모두에게 중요한 과제가 되고 있다. 기존 연구들은 리뷰 텍스트와 평점 간의 일관성을 분석하여 유용성을 예측하려는 다양한 시도를 해왔으며, 이러한 연구는 소비자 신뢰도를 높이고 유용성을 향상시키는 데 기여해왔다. 그러나 시각적 정보인 리뷰 이미지가 제공하는 보완적 데이터를 충분히 반영하지 못한 한계가 존재하며, 데이터 일관성 여부에 따른 예측 모델의 성능 차이를 체계적으로 분석한 연구는 매우 부족한 상황이다. 특히, 데이터의 일관성 여부는 리뷰 유용성 예측의 정확도와 신뢰성에 중요한 영향을 미칠 수 있음에도 불구하고, 이를 다룬 실증적 연구는 거의 이루어지지 않았다.&amp;#xD; 본 연구에서는 리뷰 텍스트와 평점의 일관성을 학습하고, 이를 이미지 정보와 결합하여 리뷰 유용성을 예측할 수 있는 새로운 모델인 MRHP-CCR(Multimodal Review Helpfulness Prediction Considering the Consistency of Review)을 제안한다. 본 모델은 사전학습된 RoBERTa와 VGG-16을 활용하여 텍스트와 이미지에서 각각의 특징을 추출하며, Co-attention 메커니즘을 통해 텍스트와 평점 간의 상호작용을 효과적으로 학습하여 데이터의 일관성을 반영한다. 이를 통해 리뷰 텍스트와 평점 간의 상호작용뿐만 아니라 시각적 특징이 유용성 예측 성능을 향상시키는 데 어떻게 기여하는지를 검증한다. 제안된 모델은 다양한 데이터 일관성 조건에서도 높은 예측 성능을 보여, 전자상거래 환경에서 신뢰성 있는 리뷰 유용성 평가를 가능하게 한다.&amp;#xD; 본 연구는 리뷰 텍스트, 평점, 이미지 간의 통합적 상호작용이 유용성 예측에서 중요한 역할을 한다는 점을 강조하며, 데이터 일관성이 모델 성능에 미치는 영향을 체계적으로 검토하였다. 이를 통해 전자상거래 플랫폼에서 소비자들의 구매 결정을 효과적으로 지원할 수 있는 유용한 정보를 제공하며, 데이터 일관성과 멀티모달 정보가 결합된 환경에서의 예측 성능 향상 가능성을 입증하였다."
        },
        {
          "rank": 39,
          "score": 0.6283655166625977,
          "doc_id": "NART77437325",
          "title": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns",
          "abstract": "Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART77437325&target=NART&cn=NART77437325",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing in a time of empowered stakeholders: Lessons from crowdsourcing campaigns Crowdsourcing can test a company's willingness to relinquish control to key stakeholders. Using past examples of four failed crowdsourcing initiatives, we explore the negative and unintended consequences of crowdsourcing in an age when stakeholders are empowered to speak their minds, make a mockery of organizational initiatives, and direct initiatives as it suits their own agenda. The concepts of crowdthink and crowd hijacking are introduced, and advice is given on how managers can avoid or anticipate some of the potential issues that arise during crowdsourcing endeavors. With these considerations, managers can harness the power of crowds effectively to achieve organizational goals with limited negative consequences."
        },
        {
          "rank": 40,
          "score": 0.6267938017845154,
          "doc_id": "NART51683398",
          "title": "Sampling Based Approximate Algorithm for POMDP",
          "abstract": "Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART51683398&target=NART&cn=NART51683398",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Sampling Based Approximate Algorithm for POMDP Partially observable Markov decision procedure is a kind of problem model which describes the continuous decision making for robot within dynamic uncertain environment. This paper introduces a fast approximate algorithm for special POMDP models which have sparse state transmit matrix. First, this algorithm makes use of the policy from QMDP approximate algorithm for sampling. Then it can use these samples with point based iteration algorithm to create the value function for POMDP. Finally, the optimal policy for action choosing will be generated from the value function. In the same experiment model, the policy generated by this algorithm will make the reward as much as other algorithms. But this algofitm can run faster than others , and can generate a smaller vector set to represent the policy. So, it is more suitable for solving large POMDPs with sparse state transmit matrix than other approximate algorithms."
        },
        {
          "rank": 41,
          "score": 0.625003457069397,
          "doc_id": "JAKO202106153173640",
          "title": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구",
          "abstract": "컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153173640&target=NART&cn=JAKO202106153173640",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고 교육 게임 데이터를 사용한 게임 점수 예측 모델 성능 비교 연구 컴퓨팅 사고는 21세기에 필요한 중요한 소양 중 하나로 여겨지면서 여러 국가에서 컴퓨팅 사고 교육 과정을 도입하여 시행하고 있다. 컴퓨팅 사고 교육 방법 중 교육용 게임 기반 방법은 학생들의 참여와 동기를 증대시키고 컴퓨팅 사고에 대한 접근성을 높여준다. Autothinking은 학습자들에게 컴퓨팅 사고 교육을 제공하기 위한 목적으로 개발한 교육용 게임으로 학습자들에게 동적으로 피드백을 제공하고, 학습자의 컴퓨팅 사고 능력에 따라서 난이도를 자동으로 조절하는 적응적 시스템이다. 하지만 규칙기반으로 게임을 디자인하여 지능적으로 학습자들의 컴퓨팅 사고를 고려하거나 피드백을 주지 못한다. 본 연구에서는 Autothikning을 통해 수집한 게임 데이터를 소개하고, 이를 활용하여 해당 게임의 적응성을 높이기 위해 컴퓨팅 사고를 반영하는 게임 점수의 예측을 수행한다. 이 문제를 해결하기 위해 회귀 문제에 가장 많이 사용되는 선형 회귀, 결정 트리, 렌덤 포레스트, 서포트 벡터 머신 알고리즘에 대한 비교연구를 수행하였다. 연구 수행결과 선형회귀 방법이 게임 점수 예측에 가장 좋은 성능을 보여주었다."
        },
        {
          "rank": 42,
          "score": 0.6240853071212769,
          "doc_id": "JAKO202129857949083",
          "title": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법",
          "abstract": "본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202129857949083&target=NART&cn=JAKO202129857949083",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 스프레드시트를 활용한 지도학습 인공신경망 매개변수 최적화와 활성화함수 기초교육방법 본 논문에서는 비전공자들을 위한 교양과정으로, 기초 인공신경망 과목 커리큘럼을 설계하기 위해, 지도학습 인공신경망 매개변수 최적화 방법과 활성화함수에 대한 기초 교육 방법을 제안하였다. 이를 위해, 프로그래밍 없이, 매개 변수 최적화 해를 스프레드시트로 찾는 방법을 적용하였다. 본 교육 방법을 통해, 인공신경망 동작 및 구현의 기초 원리 교육에 집중할 수 있다. 그리고, 스프레드시트의 시각화된 데이터를 통해 비전공자들의 관심과 교육 효과를 높일 수 있다. 제안한 내용은 인공뉴런과 Sigmoid, ReLU 활성화 함수, 지도학습데이터의 생성, 지도학습 인공신경망 구성과 매개변수 최적화, 스프레드시트를 이용한 지도학습 인공신경망 구현 및 성능 분석 그리고 교육 만족도 분석으로 구성되었다. 본 논문에서는 Sigmoid 뉴런 인공신경망과 ReLU 뉴런 인공신경망에 대해 음수허용 매개변수 최적화를 고려하여, 인공신경망 매개변수 최적화에 대한 네가지 성능분석결과를 교육하는 방법을 제안하고 교육 만족도 분석을 실시하였다."
        },
        {
          "rank": 43,
          "score": 0.623788058757782,
          "doc_id": "ART003219768",
          "title": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning",
          "abstract": "The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART003219768&target=NART&cn=ART003219768",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning Design & Analysis of a Resource Unified Description Scheme Based on Deep Reinforcement Learning The management of physical resources is one of the current research priorities in the field of cloud manufacturing. Managing these physical resources is critical to the product lifecycle. Resource uniform description models can describe various forms of physical resources as data in a uniform format, which facilitates the management and retrieval of resource data. However, resource data is characterized by its large scale and complexity, while the issue of whether the existing resource unified description model can still accurately describe new resource data and whether the resource data can be fully matched with the model is an urgent one at present. In this paper, an optimization strategy based on deep reinforcement learning (DRL) for a resource uniform description model is proposed, which is to ensure that this model can autonomously propose a solution to the current situation when it cannot describe the resource data in a suitable way. A Markov decision process and deep Q network algorithm are introduced to train an agent that can independently optimize the model when the resource data does not match the model. Simulation experimental results validate the effectiveness of the DRL-based optimization strategy when the resource uniform description model does not match the resource data."
        },
        {
          "rank": 44,
          "score": 0.6233385801315308,
          "doc_id": "DIKO0015063257",
          "title": "Visual object tracking using deep reinforcement learning",
          "abstract": "Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015063257&target=NART&cn=DIKO0015063257",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking using deep reinforcement learning Visual object tracking task plays an important role in computer vision research area, which is widely applied on public surveillance, robot navigation and driverless car and so on.&amp;#xD; In this dissertation, two deep reinforcement learning (DRL) based approaches are presented for visual tracking tasks: single object tracking (SOT) and multiple object tracking (MOT). SOT task is essentially to connect two neighboring targets which are co-located in two adjacent video frames and then make all these pairs into one complete trajectory. MOT task is to find the correct relationship of each target in between two adjacent frames, whereby combining object detection and target association becomes necessary. A good MOT algorithm should be able to produce complete trajectory of each target accurately at every frame of video sequence.&amp;#xD; This dissertation proposes an effective SOT approach by means of generating a sequence of actions to transfer previous bounding box towards updating it to current target location. The action sequence is produced by two intelligent agents which are trained via the dueling deep Q-learning (Dueling DQN) algorithm which is composed of movement agent and scaling agent. Movement agent generates horizontal or vertical movement actions while scaling agent performs the actions which can change size of the bounding box. Furthermore, the proposed method enlarges field-of-view with a Siamese network structure which makes judicial adjustment on fast moving targets. Moreover, in order to tackle the low training efficiency and unstable problem of traditional Dueling DQN structure, the action tasks are distributed into movement actions and scaling actions. The proposed distributed action achieves dimensionality reduction which speeds up and stabilizes the training process. The proposed method is tested on two popular standard datasets and compared with state-of-art trackers. The experiment results show that the proposed approach achieves outstanding results in accuracy, speed and robustness.&amp;#xD; For MOT task, rather than introducing yet another MOT tracker, this dissertation proposes to focus on increasing the tracking accuracy with DRL techniques. Due to the unreliable object detection results and complex tracking scenes, recent MOT trackers suffer from low tracking accuracy and poor success rate which can be represented in three types of errors: oversized, partial and false bounding box. The proposed method focuses mainly on oversized and partial errors. In order to correct these errors and improve the tracking accuracy, an intelligent agent is used to generate a sequence of action to transition the incorrect bounding box to its intended right location. The transition model is accomplished by training it with deep Q-learning (DQN) algorithm. After comparing with several state-of-the-art correctors for MOT task, the results indicate that the proposed method achieves better performance in tracking accuracy on existing MOT trackers than other correctors.&amp;#xD; Both of the proposed methods have been proved for addressing and solving the SOT task and the imprecise bounding box problem of MOT task with DRL algorithms. For SOT task, the proposed tracker achieves 0.901 precision and 0.676 success rate on OTB50 benchmark, 0.903 precision and 0.673 success rate on OTB100 benchmark, which makes it completive among many different state-of-the-art trackers. In the case of MOT task, the proposed method is shown to improve tracking accuracy for state-of-the-art MOT trackers from 2% to 7.3%, while having no negative influence on target ID. This helps MOT trackers avoid being influenced by bad object detection results and complex background.&amp;#xD;"
        },
        {
          "rank": 45,
          "score": 0.6227694749832153,
          "doc_id": "NART132126662",
          "title": "Examining chronic kidney disease screening frequency among diabetics: a POMDP approach",
          "abstract": "<P>Forty percent of diabetics will develop chronic kidney disease (CKD) in their lifetimes. However, as many as 50% of these CKD cases may go undiagnosed. We developed screening recommendations stratified by age and previous test history for individuals with diagnosed diabetes and unknown proteinuria status by race and gender groups. To do this, we used a Partially Observed Markov Decision Process (POMDP) to identify whether a patient should be screened at every three-month interval from ages 30-85. Model inputs were drawn from nationally-representative datasets, the medical literature, and a microsimulation that integrates this information into group-specific disease progression rates. We implement the POMDP solution policy in the microsimulation to understand how this policy may impact health outcomes and generate an easily-implementable, non-belief-based approximate policy for easier clinical interpretability. We found that the status quo policy, which is to screen annually for all ages and races, is suboptimal for maximizing expected discounted future net monetary benefits (NMB). The POMDP policy suggests more frequent screening after age 40 in all race and gender groups, with screenings 2-4 times a year for ages 61-70. Black individuals are recommended for screening more frequently than their White counterparts. This policy would increase NMB from the status quo policy between $1,000&nbsp;to&nbsp; $8,000 per diabetic patient at a willingness-to-pay of $150,000 per quality-adjusted life year (QALY).</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART132126662&target=NART&cn=NART132126662",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Examining chronic kidney disease screening frequency among diabetics: a POMDP approach Examining chronic kidney disease screening frequency among diabetics: a POMDP approach Examining chronic kidney disease screening frequency among diabetics: a POMDP approach <P>Forty percent of diabetics will develop chronic kidney disease (CKD) in their lifetimes. However, as many as 50% of these CKD cases may go undiagnosed. We developed screening recommendations stratified by age and previous test history for individuals with diagnosed diabetes and unknown proteinuria status by race and gender groups. To do this, we used a Partially Observed Markov Decision Process (POMDP) to identify whether a patient should be screened at every three-month interval from ages 30-85. Model inputs were drawn from nationally-representative datasets, the medical literature, and a microsimulation that integrates this information into group-specific disease progression rates. We implement the POMDP solution policy in the microsimulation to understand how this policy may impact health outcomes and generate an easily-implementable, non-belief-based approximate policy for easier clinical interpretability. We found that the status quo policy, which is to screen annually for all ages and races, is suboptimal for maximizing expected discounted future net monetary benefits (NMB). The POMDP policy suggests more frequent screening after age 40 in all race and gender groups, with screenings 2-4 times a year for ages 61-70. Black individuals are recommended for screening more frequently than their White counterparts. This policy would increase NMB from the status quo policy between $1,000&nbsp;to&nbsp; $8,000 per diabetic patient at a willingness-to-pay of $150,000 per quality-adjusted life year (QALY).</P>"
        },
        {
          "rank": 46,
          "score": 0.6226062178611755,
          "doc_id": "DIKO0014861002",
          "title": "딥 러닝기반 고객평점 예측모델",
          "abstract": "인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014861002&target=NART&cn=DIKO0014861002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 딥 러닝기반 고객평점 예측모델 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다."
        },
        {
          "rank": 47,
          "score": 0.6222622990608215,
          "doc_id": "JAKO201911263062209",
          "title": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론",
          "abstract": "Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911263062209&target=NART&cn=JAKO201911263062209",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 감정 딥러닝 필터를 활용한 토픽 모델링 방법론 Purpose The purpose of this study is to propose a methodology to derive positive keywords and negative keywords through deep learning to classify reviews into positive reviews and negative ones, and then refine the results of topic modeling using these keywords. Design/methodology/approach In this study, we extracted topic keywords by performing LDA-based topic modeling. At the same time, we performed attention-based deep learning to identify positive and negative keywords. Finally, we refined the topic keywords using these keywords as filters. Findings We collected and analyzed about 6,000 English reviews of Gyeongbokgung, a representative tourist attraction in Korea, from Tripadvisor, a representative travel site. Experimental results show that the proposed methodology properly identifies positive and negative keywords describing major topics."
        },
        {
          "rank": 48,
          "score": 0.6195054054260254,
          "doc_id": "DIKO0017054067",
          "title": "교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구",
          "abstract": "빅데이터와 인공지능 기술의 비약적인 발전으로 시대가 데이터를 바라보는 관점이 달라졌다. 이제 데이터는 모두의 합리적인 의사결정 과정에 활용될 수 있는 귀중한 자원이다. 이는 교육에서도 마찬가지며 특히 교사는 데이터를 잘 수집, 분석, 해석하는 절차를 통해 교수적 의사결정 능력을 향상할 수 있다. 이러한 추세에 따라 정부에서도 AI 디지털교과서 같은 교육 데이터 기반의 맞춤형 수업 지원 방안을 위한 인프라를 조성하고 있고, 민간 기업 차원에서도 학습 관리 시스템(Learning Management System) 같은 플랫폼에 개별 학습자 데이터 보관 및 활용을 강화하여 이를 기반으로 개별화 교수전략을 지원하는 등의 움직임을 보인다. 이를 바탕으로 학계에서는 교사의 데이터 리터러시를 어떻게 향상할 지에 대한 논 의 또한 끊임없이 진행되고 있다. 교사를 위한 데이터 리터러시 역량에는 단순히 데이터를 잘 활용하는 것만을 의미하지는 않는다. 궁극적으로 목표하는 행동인 데이터 기반 의사결정을 촉진하기 위해 문제 확인 및 목표 설정, 데이터 수집, 데이터 분석, 데이터 해석 그리고 교수적 의사결정의 요소를 고려한다. 이러한 역량을 기반으로 교사들의 맞춤형 수업 진행도, 개별화 교수전략 지원도 효과적으로 이뤄질 수 있는 것이다. 반면, 교사들은 데이터 분석 학습에는 높은 비용과 에너지가 요구된다. 대다수 교사는 데이터 분석에 대한 비전공자일 뿐만 아니라 현업을 병행하는 학습자로서 데이터 리터러시 향상을 위한 교육 프로그램을 장기간 체계적으로 이수하기 어려운 상황에 있다. 더불어, 선행연구를 고찰하였을 때, 교육 프로그램을 수강할지라 도 데이터 분석 과정 중에서 통계, 머신러닝 등의 지식 위주로만 학습되고 있었으며, 현장에서의 데이터 분석 활용에 대한 역량 계발 지원이 미흡한 실정이다. 따라서 본 연구는 교사의 데이터 리터러시 향상을 위해 데이터 기반 의사결정의 단 계에 따라 생성형 AI 챗봇을 개발하고 이를 활용하는 방식을 제안하고자 한다. 이를 위해 우선, 프롬프트 엔지니어링 전략을 통해 생성형 AI를 훈련하여 교사의 데이터 기반 의사결정을 위한 챗봇을 개발하고자 하였다. 프롬프트 엔지니어링은 생성형 AI와 같은 대규모 언어모델이 사용자의 명령을 피드백 삼아서 높은 확률과 명확한 예측값을 생성할 수 있도록 훈련하는 것이다. 이러한 방식은 생성형 AI 챗봇을 교육적으로 활용하는 데에 문제가 될 만한 환각(hallucination) 요소를 줄이는 데 효과적이다. 다음으로, 교사가 1:1로 생성형 AI 챗봇을 주체적으로 활용하도록 촉진하기 위해 의사결정 기반 학습을 지원하고자 한다. 데이터 분석에 관한 초보자인 대다수 교사에게 데이터 기반 의사결정 절차에 따라 생성형 AI를 활용하여 데이터 분석을 하도록 함으로써 데이터 기반 의사결정의 효능감을 촉진할 수 있도록 한다. 따라서, 본 연구의 목적은 교사를 대상으로 데이터 리터러시 향상을 위한 생성형 AI 챗봇을 개발하고, 데이터 리터러시 및 데이터 기반 의사결정의 효과성을 양적으로 검증한 후 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정의 요소, 절차 등에 관해 학습한 학습자의 반응을 질적으로 분석하고자 한다. 이를 위해 본 연구에서 설정한 연구 문제는 다음과 같다. 1. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇은 어떻게 구현할 것인가? 2. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇의 효과는 어떠한가? 2.1. 생성형 AI 챗봇을 활용함으로써 데이터 리터러시가 향상되는가? 2.2. 생성형 AI 챗봇을 활용함으로써 데이터 기반 의사결정 효능감이 향상되는가? 3. 데이터 기반 의사결정을 위한 생성형 AI 챗봇에 대한 학습자 반응은 어떠한가? 위 연구 문제에 따른 결과를 검증하기 위해 본 연구는 Richey와 Klein의 설계· 개발 연구방법에 따라 진행하였다. 설계·개발 연구방법 중에서도 유형I의 산출물 및 도구 개발을 택하여 분석, 설계, 개발 및 평가의 4단계를 따랐다. 분석 단계에서는 프롬프트, 데이터 리터러시, 의사결정 학습 절차에 관한 선행연구를 고찰하여 생성형 AI 챗봇 개발을 위한 데이터 기반 의사결정 학습 절차를 구조화했다. 그리고 현장 교사 31명을 대상으로 요구 분석을 진행하여 교사 대상의 생성형 AI 챗봇 활용 데이터 분석에 적합한 교육 데이터 분석 사례를 탐색하고자 했다. 설계 단계에서는 앞서 진행한 문헌 분석과 요구 분석에 따라 생성형 AI 활용 데이터 기반 의사결정 학습 절차를 확고히 했고, 이에 따라 프롬프트 패턴 및 전략 을 참고하여 생성형 AI를 훈련할 프롬프트를 설계했다. 그리고 개발 및 평가 단계 에서는 다량의 프롬프트 입력을 통해 훈련된 생성형 AI 챗봇을 개발하였다. 이후 5인의 전문가 검토와 4인의 파일럿 테스트를 거쳐서 최종적으로 챗봇을 보완한 뒤 단일집단을 대상으로 효과성 검증을 위한 실험을 진행하였다. 총 25명의 교사를 대상으로 1차, 2차 실험을 대략 2주 동안 ZOOM 실험 환경에서 진행하였다. 이후 데이터 리터러시와 데이터 기반 의사결정 효능감에 관한 사전-사후 효과성 검증을 대응표본 t 검정을 통해 진행하였다. 그리고 학습자 반응 분석을 위해 실험에 참여한 교사들이 응답한 성찰일지를 분석하였다. 이를 바탕으로 도출한 본 연구의 주된 결과와 논의 사항은 다음과 같다. 첫째, 9단계의 데이터 기반 의사결정 학습 절차에 따른 교사의 데이터 기반 의 사결정을 위한 생성형 AI 챗봇을 개발하였다. 이를 위해 우선 D0. 사전 안내, D1. 문제 정의 및 가설 설정, D2. 데이터 수집, D3. 데이터 품질 확인을 위한 전처리, D4. 예측 모델을 통한 데이터 분석, D5. 데이터 해석 및 결론 도출, D6. 데이터 평가, D7. 데이터 시각화, D8. 교수적 처치 계획의 총 9단계 데이터 기반 의사결정 학습 절차를 구성하였다. 그 뒤 각 절차에 따른 생성형 AI 챗봇을 구현하기 위해 대화 기반의 프롬프트를 설계하고 이를 훈련했다. 이때 학습 맥락 조정, 학습 키워드 강조, 오류 점검을 위주로 퓨샷(few-shot), 형식지정(format), 핵심어(seed-word), 제로샷(zero-shot), 마크다운(markdown), 사고의 연쇄 기법(CoT), 다시 생각하기(Let’s think about this), 다시 생성하기(ReAct)의 프롬프트 엔지니어링 전략을 활용하였다. 그렇게 GPTs 환경에서 생성형 AI 챗봇이 개발되었다. 둘째, 교사를 대상으로 데이터 기반 의사결정을 위한 생성형 AI 챗봇을 사용하였을 때, 데이터 리터러시와 데이터 기반 의사결정 효능감의 효과성을 검증하였다. 데이터 리터러시는 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 데이터 리터러시의 하위 요소인 문제 확인 및 정의, 데이터 수집 및 관리, 데이터 분석 및 표현, 교수적 의사결정, 평가 및 성찰 요소 모두 통계적으로 유의미하게 향상되었다. 더불어 위 결과에 관하여 생성형 AI 챗봇을 통해 주체적으로 데이터 분석을 진행하고, 데이터 분석에 관한 지식을 유연하고 효율적으로 학습할 수 있었다는 학습자 응답 결과가 뒷받침될 수 있었다. 데이터 기반 의사결정 효능 감 또한 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 그리고 이러한 결과는 생성형 AI 챗봇을 활용하여 데이터 리터러시가 향상된다면, 데이터 기반 의사결정 효능감 또한 향상된 점을 시사한다. 더불어 위의 결과는 생성형 AI 챗봇을 통해 데이터 기반 교수적 의사결정과 처방의 가능성을 탐색했다는 학습자 응답 결과에서도 뒷받침될 수 있었다. 셋째, 생성형 AI 챗봇을 활용한 교사를 대상으로 학습자 반응을 분석하여 학습자가 인식한 단점, 개선할 점을 통해 챗봇의 보완 방향을 도출하였다. 보완 방향에는 총 4가지가 언급되었으며, 주요 내용은 다음과 같다. 인지 부하 조절을 위한 여러 스캐폴딩 요소 지원, 생성형 AI 챗봇이 더욱 직관적이고 편리한 UX와 UI 지원, 한글 사용에 불편함이 없는 생성형 AI 챗봇 지원, 생성형 AI의 활용범위를 확장하여 사용자에게 맞춤화된 경험 지원에 관해 논할 수 있었다. 이를 바탕으로 본 연구의 이론적, 실천적, 방법적인 시사점은 다음과 같다. 첫째, 이론적 시사점으로써 교사를 대상으로 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정 학습 절차에 따라 진행하였을 때 데이터 리터러시 및 데이터 기반 의사결정 효능감이 향상되었다는 것을 밝혀낸 실증 연구로서 기여한 점이다. 둘째, 실천적 시사점으로써 학교 현장 속 교사들의 데이터 기반 의사결정 과정을 지 원해줄 수 있는 생성형 AI 챗봇을 개발한 것이다. 셋째, 방법적 시사점으로써 프롬프트 엔지니어링을 통해 생성형 AI를 훈련하여 챗봇 형태로 구현하고 이를 교사를 위한 데이터 기반 의사결정 학습 차원에서 적용한 것이다. 마지막으로 본 연구의 제한점과 후속 연구를 위한 제언은 다음과 같다. 첫째, 개발된 생성형 AI 챗봇 사용을 위한 접근성 측면에서 ChatGPT 멤버십에 관한 제약이 있었다. 그렇지만, 최근 GPT-4o 버전이 출시되면서 무료화되었다. 따라서 앞으로 교사들이 더욱 접근성 있게 생성형 AI 챗봇을 활용할 수 있도록 여러 기회 와 자원이 지원되어야 할 것이다. 둘째, 연구 참여자의 다양성 측면에서 교사에 관한 전체 모집단을 고려하기엔 본 연구의 표본은 부족했다. 이에 따라 향후 연구에서는 교사들의 연령대, 교직 경력, 학교급, 담당 과목 등을 균등하게 고려하여 더욱 많은 교사를 모집하는 것이 필요하다. 셋째, 교육현장의 훨씬 다양한 맥락에서 데이터 기반 의사결정을 고려하지 못하였다. 이에 따라 앞으로는 학습자 군집에 따른 맞춤형 교수전략 외에 현장에서 접할 수 있는 다양한 맥락을 고려하여 생성형 AI 챗봇을 통한 데이터 기반 의사결정 과정을 지원할 필요가 있다.Big data and artificial intelligence have revolutionized our approach to data, establishing it as a valuable resource for informed decision-making across various fields, including education. Specifically, teachers can improve their ability to make instructional decisions by learning to collect, analyze, and interpret data effectively. For these reasons, the Korean government is developing an infrastructure to support personalized instruction based on educational data, such as AI digital textbooks. At the same time, companies are integrating individual learner data into platforms like learning management systems to support personalized teaching strategies. In addition, there is ongoing research and discussion on how to improve teachers' data literacy, aiming to equip teachers with the necessary skills to effectively interpret and utilize data in their teaching practices. Teachers' data literacy skills encompass more than mere proficiency with data. They are about facilitating data-driven decision-making, which is the ultimate goal. Subcomponents include problem identification and goal setting, data collection, data analysis, data interpretation, and instructional decision-making. With these competencies, teachers can effectively tailor their instruction to meet individual needs and implement personalized teaching strategies. On the other hand, equipping teachers with data analytics skills to enhance their data literacy has proven to be costly and energy-intensive. Most teachers, being novices in data analytics and learning while on the job, find it challenging to systematically complete data literacy training programs over an extended period. In addition, a review of previous studies shows that data analytics courses tend to focus on imparting knowledge in areas like statistics and machine learning, but they fail to provide adequate support for developing competencies in the use of data analytics in practice. Therefore, this study proposes a method to develop and use a generative AI for data-driven decision-making to effectively and efficiently enhance teachers' data literacy. To do so, this study first aimed to develop a chatbot to improve teachers' data literacy by employing a prompt engineering strategy to train generative AI. Prompt engineering involves training large-scale language models, such as generative AI, to generate high probability and more accurate predictions by using user command prompts as feedback. This approach helps reduce issues such as hallucination, which pose significant challenges in the educational application of generative AI chatbots. Next, this study aims to support teachers in using generative AI chatbots in one-on-one settings, following a decision-learning process, to effectively enhance data literacy. By guiding teachers, many of whom are novices in data analysis, through the steps of a data-driven decision-making process using generative AI, teachers’ competency in data-driven decision-making can be promoted. Therefore, the purpose of this study is to develop a generative AI chatbot to improve teachers' data literacy, quantitatively verify the effectiveness of data literacy and data-driven decision-making, and qualitatively analyze teachers' responses to the generative AI chatbot. For this purpose, the following research questions were derived. RQ1. How can a generative AI chatbot be developed for teachers’ data-driven decision-making? RQ2. Is a generative AI chatbot effective for teachers' data-driven decision-making? RQ2.1. Does utilizing generative AI chatbots improve data literacy? RQ2.2. Does utilizing generative AI chatbots improve data-driven decision-making efficacy? RQ3. How do teachers respond to generative AI chatbots for data-driven decision-making? To address the research questions above, this study adopted Richey and Klein's design and development research method. Specifically, following their Type I method for developing products and tools, the study was conducted across four phases: analysis, design, development, and evaluation. In the analysis phase, previous studies on prompts, data literacy, and decision-learning procedures were reviewed to structure a data-driven decision-learning procedure for developing generative AI chatbots. Then, a needs analysis was conducted with 31 teachers in the field to explore educational data analysis cases suitable for data analysis utilizing generative AI chatbots for teachers. In the design phase, the data-driven decision-learning procedure for generative AI was solidified based on the literature review and needs analysis. Prompts were designed to train generative AI by referring to prompt patterns and strategies. In the development and evaluation phase, a generative AI chatbot trained with a large amount of prompt input was developed. The chatbot was then reviewed by five experts and pilot-tested by four participants. Finally, after refining the chatbot, an experiment was conducted to verify its effectiveness. A one-group pre-post paired sample t-test was conducted with a total of 25 teachers on ZOOM for about two weeks. Afterward, the effectiveness of data literacy and data-driven decision-making efficacy were evaluated using paired-sample t-tests. To further analyze teachers’ responses, reflection journals from the teachers who participated in the experiment were examined using open-coding techniques. The main findings and discussions of this study are as follows. First, a generative AI chatbot was developed based on nine data-driven decision-making learning procedures to enhance and support data-driven decision-making among teachers. To do so, To this end, a nine-step data-driven decision-learning process was first constructed, consisting of nine steps: D0. Preliminary guidance, D1. Problem definition and hypothesis generation, D2. Data collection, D3. Preprocessing to check data quality, D4. Data analysis using predictive models, D5. Data interpretation and inference, D6. Data Evaluation, D7. Data Visualization, and D8. Instructional Action Plan. Then, dialog-based prompts were designed and trained according to the data-driven decision-making learning process derived earlier. Various prompting strategies were employed, including few-shot, format, seed-word, zero-shot, markdown, chain-of-thinking (CoT), let's think about this, and re-generate (ReAct). These strategies were used to adjust the learning context, emphasize learning keywords, and check the errors. Subsequently, the generative AI chatbot was developed within the GPTs environment. Second, the effectiveness of using a generative AI chatbot for enhancing teachers' data literacy and data-driven decision-making was verified. Data literacy significantly improved, as indicated by descriptive statistics and paired sample t-tests. The sub-components of data literacy—problem identification and definition, data collection and management, data analysis and representation, instructional decision-making, and evaluation and reflection elements—were all statistically significantly improved. These findings were further supported by teachers' reflective responses, which highlighted their recognition of the generative AI chatbots as a valuable tool. According to their responses, teachers reported taking greater ownership of data analysis and developing flexibility and efficiency in applying their data analysis skills. The results from descriptive statistics and paired-sample t-tests indicated significant improvements in teachers' data-driven decision-making efficacy. These findings suggest that enhancing data literacy through the use of generative AI chatbots also boosts decision-making efficacy. Furthermore, these results are also supported by the teachers' reflective responses in that they explored the possibility of data-driven instructional decision-making and intervention through generative AI chatbots. Third, teachers' responses to teachers using the generative AI chatbot were analyzed to identify areas for improvement. Discussions emphasized the need to provide scaffolding to manage their cognitive load, enhance the UX and UI of generative AI chatbots to make them more intuitive and convenient, ensure the chatbots function seamlessly in Korean, and expand the capabilities of generative AI to deliver customized experiences. Based on these findings, the implications of this study are threefold. First, for a theoretical implication, this study empirically verified that teachers' data literacy and data-driven decision-making efficacy improved when they followed a data-driven decision-making learning process using a generative AI chatbot. Second, for a practical implication, this study developed a generative AI chatbot that can support teachers' data-driven decision-making process in schools. Third, as a methodological implication, the study attempted to demonstrate the application of prompt engineering to train generative AI, which was then implemented as a chatbot and applied in facilitating data-driven decision-making. The limitations of this study and suggestions for further research are as follows. First, accessing the developed generative AI chatbot required a ChatGPT membership, which posed a barrier for teachers. Therefore, future efforts should concentrate on enhancing the accessibility of generative AI chatbots to teachers.Second, the diversity of the participants in the study was insufficient to reflect the overall population. Therefore, future research should consider recruiting a larger and more diverse group of teachers, ensuring equal representation across age, teaching experience, school levels, and subjects. Third, this study's exploration of data-driven decision-making was constrained to a limited range of contexts. Future studies should broaden their scope to include various contexts encountered in the educational field and provide enhanced support for data-driven decision-making processes using generative AI chatbots.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017054067&target=NART&cn=DIKO0017054067",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇 개발연구 빅데이터와 인공지능 기술의 비약적인 발전으로 시대가 데이터를 바라보는 관점이 달라졌다. 이제 데이터는 모두의 합리적인 의사결정 과정에 활용될 수 있는 귀중한 자원이다. 이는 교육에서도 마찬가지며 특히 교사는 데이터를 잘 수집, 분석, 해석하는 절차를 통해 교수적 의사결정 능력을 향상할 수 있다. 이러한 추세에 따라 정부에서도 AI 디지털교과서 같은 교육 데이터 기반의 맞춤형 수업 지원 방안을 위한 인프라를 조성하고 있고, 민간 기업 차원에서도 학습 관리 시스템(Learning Management System) 같은 플랫폼에 개별 학습자 데이터 보관 및 활용을 강화하여 이를 기반으로 개별화 교수전략을 지원하는 등의 움직임을 보인다. 이를 바탕으로 학계에서는 교사의 데이터 리터러시를 어떻게 향상할 지에 대한 논 의 또한 끊임없이 진행되고 있다. 교사를 위한 데이터 리터러시 역량에는 단순히 데이터를 잘 활용하는 것만을 의미하지는 않는다. 궁극적으로 목표하는 행동인 데이터 기반 의사결정을 촉진하기 위해 문제 확인 및 목표 설정, 데이터 수집, 데이터 분석, 데이터 해석 그리고 교수적 의사결정의 요소를 고려한다. 이러한 역량을 기반으로 교사들의 맞춤형 수업 진행도, 개별화 교수전략 지원도 효과적으로 이뤄질 수 있는 것이다. 반면, 교사들은 데이터 분석 학습에는 높은 비용과 에너지가 요구된다. 대다수 교사는 데이터 분석에 대한 비전공자일 뿐만 아니라 현업을 병행하는 학습자로서 데이터 리터러시 향상을 위한 교육 프로그램을 장기간 체계적으로 이수하기 어려운 상황에 있다. 더불어, 선행연구를 고찰하였을 때, 교육 프로그램을 수강할지라 도 데이터 분석 과정 중에서 통계, 머신러닝 등의 지식 위주로만 학습되고 있었으며, 현장에서의 데이터 분석 활용에 대한 역량 계발 지원이 미흡한 실정이다. 따라서 본 연구는 교사의 데이터 리터러시 향상을 위해 데이터 기반 의사결정의 단 계에 따라 생성형 AI 챗봇을 개발하고 이를 활용하는 방식을 제안하고자 한다. 이를 위해 우선, 프롬프트 엔지니어링 전략을 통해 생성형 AI를 훈련하여 교사의 데이터 기반 의사결정을 위한 챗봇을 개발하고자 하였다. 프롬프트 엔지니어링은 생성형 AI와 같은 대규모 언어모델이 사용자의 명령을 피드백 삼아서 높은 확률과 명확한 예측값을 생성할 수 있도록 훈련하는 것이다. 이러한 방식은 생성형 AI 챗봇을 교육적으로 활용하는 데에 문제가 될 만한 환각(hallucination) 요소를 줄이는 데 효과적이다. 다음으로, 교사가 1:1로 생성형 AI 챗봇을 주체적으로 활용하도록 촉진하기 위해 의사결정 기반 학습을 지원하고자 한다. 데이터 분석에 관한 초보자인 대다수 교사에게 데이터 기반 의사결정 절차에 따라 생성형 AI를 활용하여 데이터 분석을 하도록 함으로써 데이터 기반 의사결정의 효능감을 촉진할 수 있도록 한다. 따라서, 본 연구의 목적은 교사를 대상으로 데이터 리터러시 향상을 위한 생성형 AI 챗봇을 개발하고, 데이터 리터러시 및 데이터 기반 의사결정의 효과성을 양적으로 검증한 후 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정의 요소, 절차 등에 관해 학습한 학습자의 반응을 질적으로 분석하고자 한다. 이를 위해 본 연구에서 설정한 연구 문제는 다음과 같다. 1. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇은 어떻게 구현할 것인가? 2. 교사의 데이터 기반 의사결정을 위한 생성형 AI 챗봇의 효과는 어떠한가? 2.1. 생성형 AI 챗봇을 활용함으로써 데이터 리터러시가 향상되는가? 2.2. 생성형 AI 챗봇을 활용함으로써 데이터 기반 의사결정 효능감이 향상되는가? 3. 데이터 기반 의사결정을 위한 생성형 AI 챗봇에 대한 학습자 반응은 어떠한가? 위 연구 문제에 따른 결과를 검증하기 위해 본 연구는 Richey와 Klein의 설계· 개발 연구방법에 따라 진행하였다. 설계·개발 연구방법 중에서도 유형I의 산출물 및 도구 개발을 택하여 분석, 설계, 개발 및 평가의 4단계를 따랐다. 분석 단계에서는 프롬프트, 데이터 리터러시, 의사결정 학습 절차에 관한 선행연구를 고찰하여 생성형 AI 챗봇 개발을 위한 데이터 기반 의사결정 학습 절차를 구조화했다. 그리고 현장 교사 31명을 대상으로 요구 분석을 진행하여 교사 대상의 생성형 AI 챗봇 활용 데이터 분석에 적합한 교육 데이터 분석 사례를 탐색하고자 했다. 설계 단계에서는 앞서 진행한 문헌 분석과 요구 분석에 따라 생성형 AI 활용 데이터 기반 의사결정 학습 절차를 확고히 했고, 이에 따라 프롬프트 패턴 및 전략 을 참고하여 생성형 AI를 훈련할 프롬프트를 설계했다. 그리고 개발 및 평가 단계 에서는 다량의 프롬프트 입력을 통해 훈련된 생성형 AI 챗봇을 개발하였다. 이후 5인의 전문가 검토와 4인의 파일럿 테스트를 거쳐서 최종적으로 챗봇을 보완한 뒤 단일집단을 대상으로 효과성 검증을 위한 실험을 진행하였다. 총 25명의 교사를 대상으로 1차, 2차 실험을 대략 2주 동안 ZOOM 실험 환경에서 진행하였다. 이후 데이터 리터러시와 데이터 기반 의사결정 효능감에 관한 사전-사후 효과성 검증을 대응표본 t 검정을 통해 진행하였다. 그리고 학습자 반응 분석을 위해 실험에 참여한 교사들이 응답한 성찰일지를 분석하였다. 이를 바탕으로 도출한 본 연구의 주된 결과와 논의 사항은 다음과 같다. 첫째, 9단계의 데이터 기반 의사결정 학습 절차에 따른 교사의 데이터 기반 의 사결정을 위한 생성형 AI 챗봇을 개발하였다. 이를 위해 우선 D0. 사전 안내, D1. 문제 정의 및 가설 설정, D2. 데이터 수집, D3. 데이터 품질 확인을 위한 전처리, D4. 예측 모델을 통한 데이터 분석, D5. 데이터 해석 및 결론 도출, D6. 데이터 평가, D7. 데이터 시각화, D8. 교수적 처치 계획의 총 9단계 데이터 기반 의사결정 학습 절차를 구성하였다. 그 뒤 각 절차에 따른 생성형 AI 챗봇을 구현하기 위해 대화 기반의 프롬프트를 설계하고 이를 훈련했다. 이때 학습 맥락 조정, 학습 키워드 강조, 오류 점검을 위주로 퓨샷(few-shot), 형식지정(format), 핵심어(seed-word), 제로샷(zero-shot), 마크다운(markdown), 사고의 연쇄 기법(CoT), 다시 생각하기(Let’s think about this), 다시 생성하기(ReAct)의 프롬프트 엔지니어링 전략을 활용하였다. 그렇게 GPTs 환경에서 생성형 AI 챗봇이 개발되었다. 둘째, 교사를 대상으로 데이터 기반 의사결정을 위한 생성형 AI 챗봇을 사용하였을 때, 데이터 리터러시와 데이터 기반 의사결정 효능감의 효과성을 검증하였다. 데이터 리터러시는 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 데이터 리터러시의 하위 요소인 문제 확인 및 정의, 데이터 수집 및 관리, 데이터 분석 및 표현, 교수적 의사결정, 평가 및 성찰 요소 모두 통계적으로 유의미하게 향상되었다. 더불어 위 결과에 관하여 생성형 AI 챗봇을 통해 주체적으로 데이터 분석을 진행하고, 데이터 분석에 관한 지식을 유연하고 효율적으로 학습할 수 있었다는 학습자 응답 결과가 뒷받침될 수 있었다. 데이터 기반 의사결정 효능 감 또한 기술통계 결과와 대응표본 t-test 결과, 유의미하게 향상되었다. 그리고 이러한 결과는 생성형 AI 챗봇을 활용하여 데이터 리터러시가 향상된다면, 데이터 기반 의사결정 효능감 또한 향상된 점을 시사한다. 더불어 위의 결과는 생성형 AI 챗봇을 통해 데이터 기반 교수적 의사결정과 처방의 가능성을 탐색했다는 학습자 응답 결과에서도 뒷받침될 수 있었다. 셋째, 생성형 AI 챗봇을 활용한 교사를 대상으로 학습자 반응을 분석하여 학습자가 인식한 단점, 개선할 점을 통해 챗봇의 보완 방향을 도출하였다. 보완 방향에는 총 4가지가 언급되었으며, 주요 내용은 다음과 같다. 인지 부하 조절을 위한 여러 스캐폴딩 요소 지원, 생성형 AI 챗봇이 더욱 직관적이고 편리한 UX와 UI 지원, 한글 사용에 불편함이 없는 생성형 AI 챗봇 지원, 생성형 AI의 활용범위를 확장하여 사용자에게 맞춤화된 경험 지원에 관해 논할 수 있었다. 이를 바탕으로 본 연구의 이론적, 실천적, 방법적인 시사점은 다음과 같다. 첫째, 이론적 시사점으로써 교사를 대상으로 생성형 AI 챗봇을 활용하여 데이터 기반 의사결정 학습 절차에 따라 진행하였을 때 데이터 리터러시 및 데이터 기반 의사결정 효능감이 향상되었다는 것을 밝혀낸 실증 연구로서 기여한 점이다. 둘째, 실천적 시사점으로써 학교 현장 속 교사들의 데이터 기반 의사결정 과정을 지 원해줄 수 있는 생성형 AI 챗봇을 개발한 것이다. 셋째, 방법적 시사점으로써 프롬프트 엔지니어링을 통해 생성형 AI를 훈련하여 챗봇 형태로 구현하고 이를 교사를 위한 데이터 기반 의사결정 학습 차원에서 적용한 것이다. 마지막으로 본 연구의 제한점과 후속 연구를 위한 제언은 다음과 같다. 첫째, 개발된 생성형 AI 챗봇 사용을 위한 접근성 측면에서 ChatGPT 멤버십에 관한 제약이 있었다. 그렇지만, 최근 GPT-4o 버전이 출시되면서 무료화되었다. 따라서 앞으로 교사들이 더욱 접근성 있게 생성형 AI 챗봇을 활용할 수 있도록 여러 기회 와 자원이 지원되어야 할 것이다. 둘째, 연구 참여자의 다양성 측면에서 교사에 관한 전체 모집단을 고려하기엔 본 연구의 표본은 부족했다. 이에 따라 향후 연구에서는 교사들의 연령대, 교직 경력, 학교급, 담당 과목 등을 균등하게 고려하여 더욱 많은 교사를 모집하는 것이 필요하다. 셋째, 교육현장의 훨씬 다양한 맥락에서 데이터 기반 의사결정을 고려하지 못하였다. 이에 따라 앞으로는 학습자 군집에 따른 맞춤형 교수전략 외에 현장에서 접할 수 있는 다양한 맥락을 고려하여 생성형 AI 챗봇을 통한 데이터 기반 의사결정 과정을 지원할 필요가 있다.Big data and artificial intelligence have revolutionized our approach to data, establishing it as a valuable resource for informed decision-making across various fields, including education. Specifically, teachers can improve their ability to make instructional decisions by learning to collect, analyze, and interpret data effectively. For these reasons, the Korean government is developing an infrastructure to support personalized instruction based on educational data, such as AI digital textbooks. At the same time, companies are integrating individual learner data into platforms like learning management systems to support personalized teaching strategies. In addition, there is ongoing research and discussion on how to improve teachers' data literacy, aiming to equip teachers with the necessary skills to effectively interpret and utilize data in their teaching practices. Teachers' data literacy skills encompass more than mere proficiency with data. They are about facilitating data-driven decision-making, which is the ultimate goal. Subcomponents include problem identification and goal setting, data collection, data analysis, data interpretation, and instructional decision-making. With these competencies, teachers can effectively tailor their instruction to meet individual needs and implement personalized teaching strategies. On the other hand, equipping teachers with data analytics skills to enhance their data literacy has proven to be costly and energy-intensive. Most teachers, being novices in data analytics and learning while on the job, find it challenging to systematically complete data literacy training programs over an extended period. In addition, a review of previous studies shows that data analytics courses tend to focus on imparting knowledge in areas like statistics and machine learning, but they fail to provide adequate support for developing competencies in the use of data analytics in practice. Therefore, this study proposes a method to develop and use a generative AI for data-driven decision-making to effectively and efficiently enhance teachers' data literacy. To do so, this study first aimed to develop a chatbot to improve teachers' data literacy by employing a prompt engineering strategy to train generative AI. Prompt engineering involves training large-scale language models, such as generative AI, to generate high probability and more accurate predictions by using user command prompts as feedback. This approach helps reduce issues such as hallucination, which pose significant challenges in the educational application of generative AI chatbots. Next, this study aims to support teachers in using generative AI chatbots in one-on-one settings, following a decision-learning process, to effectively enhance data literacy. By guiding teachers, many of whom are novices in data analysis, through the steps of a data-driven decision-making process using generative AI, teachers’ competency in data-driven decision-making can be promoted. Therefore, the purpose of this study is to develop a generative AI chatbot to improve teachers' data literacy, quantitatively verify the effectiveness of data literacy and data-driven decision-making, and qualitatively analyze teachers' responses to the generative AI chatbot. For this purpose, the following research questions were derived. RQ1. How can a generative AI chatbot be developed for teachers’ data-driven decision-making? RQ2. Is a generative AI chatbot effective for teachers' data-driven decision-making? RQ2.1. Does utilizing generative AI chatbots improve data literacy? RQ2.2. Does utilizing generative AI chatbots improve data-driven decision-making efficacy? RQ3. How do teachers respond to generative AI chatbots for data-driven decision-making? To address the research questions above, this study adopted Richey and Klein's design and development research method. Specifically, following their Type I method for developing products and tools, the study was conducted across four phases: analysis, design, development, and evaluation. In the analysis phase, previous studies on prompts, data literacy, and decision-learning procedures were reviewed to structure a data-driven decision-learning procedure for developing generative AI chatbots. Then, a needs analysis was conducted with 31 teachers in the field to explore educational data analysis cases suitable for data analysis utilizing generative AI chatbots for teachers. In the design phase, the data-driven decision-learning procedure for generative AI was solidified based on the literature review and needs analysis. Prompts were designed to train generative AI by referring to prompt patterns and strategies. In the development and evaluation phase, a generative AI chatbot trained with a large amount of prompt input was developed. The chatbot was then reviewed by five experts and pilot-tested by four participants. Finally, after refining the chatbot, an experiment was conducted to verify its effectiveness. A one-group pre-post paired sample t-test was conducted with a total of 25 teachers on ZOOM for about two weeks. Afterward, the effectiveness of data literacy and data-driven decision-making efficacy were evaluated using paired-sample t-tests. To further analyze teachers’ responses, reflection journals from the teachers who participated in the experiment were examined using open-coding techniques. The main findings and discussions of this study are as follows. First, a generative AI chatbot was developed based on nine data-driven decision-making learning procedures to enhance and support data-driven decision-making among teachers. To do so, To this end, a nine-step data-driven decision-learning process was first constructed, consisting of nine steps: D0. Preliminary guidance, D1. Problem definition and hypothesis generation, D2. Data collection, D3. Preprocessing to check data quality, D4. Data analysis using predictive models, D5. Data interpretation and inference, D6. Data Evaluation, D7. Data Visualization, and D8. Instructional Action Plan. Then, dialog-based prompts were designed and trained according to the data-driven decision-making learning process derived earlier. Various prompting strategies were employed, including few-shot, format, seed-word, zero-shot, markdown, chain-of-thinking (CoT), let's think about this, and re-generate (ReAct). These strategies were used to adjust the learning context, emphasize learning keywords, and check the errors. Subsequently, the generative AI chatbot was developed within the GPTs environment. Second, the effectiveness of using a generative AI chatbot for enhancing teachers' data literacy and data-driven decision-making was verified. Data literacy significantly improved, as indicated by descriptive statistics and paired sample t-tests. The sub-components of data literacy—problem identification and definition, data collection and management, data analysis and representation, instructional decision-making, and evaluation and reflection elements—were all statistically significantly improved. These findings were further supported by teachers' reflective responses, which highlighted their recognition of the generative AI chatbots as a valuable tool. According to their responses, teachers reported taking greater ownership of data analysis and developing flexibility and efficiency in applying their data analysis skills. The results from descriptive statistics and paired-sample t-tests indicated significant improvements in teachers' data-driven decision-making efficacy. These findings suggest that enhancing data literacy through the use of generative AI chatbots also boosts decision-making efficacy. Furthermore, these results are also supported by the teachers' reflective responses in that they explored the possibility of data-driven instructional decision-making and intervention through generative AI chatbots. Third, teachers' responses to teachers using the generative AI chatbot were analyzed to identify areas for improvement. Discussions emphasized the need to provide scaffolding to manage their cognitive load, enhance the UX and UI of generative AI chatbots to make them more intuitive and convenient, ensure the chatbots function seamlessly in Korean, and expand the capabilities of generative AI to deliver customized experiences. Based on these findings, the implications of this study are threefold. First, for a theoretical implication, this study empirically verified that teachers' data literacy and data-driven decision-making efficacy improved when they followed a data-driven decision-making learning process using a generative AI chatbot. Second, for a practical implication, this study developed a generative AI chatbot that can support teachers' data-driven decision-making process in schools. Third, as a methodological implication, the study attempted to demonstrate the application of prompt engineering to train generative AI, which was then implemented as a chatbot and applied in facilitating data-driven decision-making. The limitations of this study and suggestions for further research are as follows. First, accessing the developed generative AI chatbot required a ChatGPT membership, which posed a barrier for teachers. Therefore, future efforts should concentrate on enhancing the accessibility of generative AI chatbots to teachers.Second, the diversity of the participants in the study was insufficient to reflect the overall population. Therefore, future research should consider recruiting a larger and more diverse group of teachers, ensuring equal representation across age, teaching experience, school levels, and subjects. Third, this study's exploration of data-driven decision-making was constrained to a limited range of contexts. Future studies should broaden their scope to include various contexts encountered in the educational field and provide enhanced support for data-driven decision-making processes using generative AI chatbots."
        },
        {
          "rank": 49,
          "score": 0.618576169013977,
          "doc_id": "DIKO0013710110",
          "title": "딥 러닝을 이용한 DC 모터 제어",
          "abstract": "딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013710110&target=NART&cn=DIKO0013710110",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝을 이용한 DC 모터 제어 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다."
        },
        {
          "rank": 50,
          "score": 0.6176958084106445,
          "doc_id": "JAKO201909358629233",
          "title": "CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트",
          "abstract": "본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201909358629233&target=NART&cn=JAKO201909358629233",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 CNN 기반 기보학습 및 강화학습을 이용한 인공지능 게임 에이전트 본 논문에서는 인공지능 오델로 게임 에이전트를 구현하기 위해 실제 프로기사들의 기보를 CNN으로 학습시키고 이를 상태의 형세 판단을 위한 근거로 삼아 최소최대탐색을 이용해 현 상태에서 최적의 수를 찾는 의사결정구조를 사용하고 이를 발전시키고자 강화학습 이론을 이용한 자가대국 학습방법을 제안하여 적용하였다. 본 논문에서 제안하는 구현 방법은 기보학습의 성능 평가 차원에서 가치평가를 위한 네트워크로서 기존의 ANN을 사용한 방법과 대국을 통한 방법으로 비교하였으며, 대국 결과 흑일 때 69.7%, 백일 때 72.1%의 승률을 나타내었다. 또한 본 논문에서 제안하는 강화학습 적용 결과 네크워크의 성능을 강화학습을 적용하지 않은 ANN 및 CNN 가치평가 네트워크 기반 에이전트와 비교한 결과 각각 100%, 78% 승률을 나타내어 성능이 개선됨을 확인할 수 있었다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}