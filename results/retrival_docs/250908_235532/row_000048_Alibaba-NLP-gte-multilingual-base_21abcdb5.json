{
  "id": "row_000048",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:38.965617+09:00",
  "trial_id": "21abcdb5",
  "queries": [
    {
      "query": "잡음 환경에서 시청각 음성인식의 인식률을 높이기 위해 은닉 마르코프 모델과 신경망 통합 전략이 어떻게 구성되었는지 간략히 설명해 주실 수 있나요?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.902129054069519,
          "doc_id": "DIKO0011019580",
          "title": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",
          "abstract": "음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다."
        },
        {
          "rank": 2,
          "score": 0.7887457609176636,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 3,
          "score": 0.782332181930542,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.7722302675247192,
          "doc_id": "JAKO201630932328344",
          "title": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법",
          "abstract": "실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201630932328344&target=NART&cn=JAKO201630932328344",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다."
        },
        {
          "rank": 5,
          "score": 0.7470437288284302,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 6,
          "score": 0.7426466941833496,
          "doc_id": "NART56157711",
          "title": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식",
          "abstract": "<P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157711&target=NART&cn=NART56157711",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 <P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>"
        },
        {
          "rank": 7,
          "score": 0.7425546646118164,
          "doc_id": "JAKO200921640756800",
          "title": "은닉 마르코프 모델 기반 동작 인식 방법",
          "abstract": "본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200921640756800&target=NART&cn=JAKO200921640756800",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다."
        },
        {
          "rank": 8,
          "score": 0.7375169396400452,
          "doc_id": "NART56157676",
          "title": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합",
          "abstract": "<P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157676&target=NART&cn=NART56157676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 <P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>"
        },
        {
          "rank": 9,
          "score": 0.731142520904541,
          "doc_id": "JAKO200612842592571",
          "title": "제스처 인식을 위한 은닉 마르코프 모델",
          "abstract": "본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200612842592571&target=NART&cn=JAKO200612842592571",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다."
        },
        {
          "rank": 10,
          "score": 0.7227447032928467,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 11,
          "score": 0.7224593162536621,
          "doc_id": "JAKO201403359905324",
          "title": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원",
          "abstract": "This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201403359905324&target=NART&cn=JAKO201403359905324",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method."
        },
        {
          "rank": 12,
          "score": 0.7219953536987305,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 13,
          "score": 0.7219057083129883,
          "doc_id": "JAKO199911921383665",
          "title": "회귀신경망을 이용한 음성인식에 관한 연구",
          "abstract": "본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921383665&target=NART&cn=JAKO199911921383665",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다."
        },
        {
          "rank": 14,
          "score": 0.7166743278503418,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 15,
          "score": 0.7147630453109741,
          "doc_id": "JAKO202029462558904",
          "title": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식",
          "abstract": "특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029462558904&target=NART&cn=JAKO202029462558904",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다."
        },
        {
          "rank": 16,
          "score": 0.7096235752105713,
          "doc_id": "DIKO0007842188",
          "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
          "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
        },
        {
          "rank": 17,
          "score": 0.7090992331504822,
          "doc_id": "JAKO202510064801583",
          "title": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석",
          "abstract": "항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510064801583&target=NART&cn=JAKO202510064801583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다."
        },
        {
          "rank": 18,
          "score": 0.7086626291275024,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 19,
          "score": 0.7058604955673218,
          "doc_id": "JAKO202011263332681",
          "title": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용",
          "abstract": "가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202011263332681&target=NART&cn=JAKO202011263332681",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다."
        },
        {
          "rank": 20,
          "score": 0.7053238153457642,
          "doc_id": "DIKO0011930560",
          "title": "시청각 음성인식을 위한 새로운 통합방법",
          "abstract": "The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011930560&target=NART&cn=DIKO0011930560",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications."
        },
        {
          "rank": 21,
          "score": 0.7039185166358948,
          "doc_id": "JAKO201935164467523",
          "title": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구",
          "abstract": "본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201935164467523&target=NART&cn=JAKO201935164467523",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다."
        },
        {
          "rank": 22,
          "score": 0.7016621828079224,
          "doc_id": "JAKO199911921528980",
          "title": "다층회귀예측신경망의 음성인식성능에 관한 연구",
          "abstract": "4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921528980&target=NART&cn=JAKO199911921528980",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다."
        },
        {
          "rank": 23,
          "score": 0.7004193067550659,
          "doc_id": "DIKO0015893049",
          "title": "도메인 적대적 신경망을 이용한 종단 간 억양음성인식",
          "abstract": "최근 딥러닝(Deep learning) 기술의 발전은 음성인식 성능 향상에 크게 기여하였다. 이러한 발전에도 불구하고 소음, 감정, 억양 등이 섞인 특정 발화에 대해서는 좋은 성능을 보이지 못하고 있다. 이 가운데 억양이 섞인 발화는 표준 발화와 비교했을 때 언어학적인 차이가 존재하는데, 이러한 차이가 억양이 섞인 발화를 인식하기 어렵게 만든다. 따라서 본 연구에서는 억양이 섞인 발화와 표준 발화 사이에 존재하는 특성의 차이를 줄이고자 도메인 적대적 신경망(Domain Adversarial Neural Network) 기법을 사용하였다. 또한, 종단 간(End-to-end) 기법을 사용하여 음성인식의 과정을 간소화하였다.&amp;#xD; 오래전부터 억양음성인식의 성능을 높이기 위한 연구는 활발히 진행되어 왔다. 2010년대 초반까지는 가우시안 혼합 모델(Gaussian Mixture Model) 기반의 최대 사후 확률(Maximum A Posteriori), 최대 우도 선형 회귀(Maximum Likelihood Linear Regression) 적응 기법이 주로 사용되었다. 하지만 딥러닝 기술이 발전하고 신경망 기반의 모델들이 주목 받기 시작하면서 가우시안 혼합 모델보다는 신경망 모델에 적합한 기법들이 사용되었다. 최근 몇 년간은 음성인식 모델에 억양에 대한 정보를 직접 삽입하는 accent embedding 기법이 많이 사용되었다. Accent embedding 기법은 억양음성인식의 성능을 향상시켰지만 몇 가지 문제점을 가지고 있다. 첫째, 억양을 분류하여 accent embedding 특징들을 만들어내는 모델을 독립적으로 만들어 훈련시켜야 하며, 해당 모델의 억양 분류 정확도가 음성인식 모델의 성능에 큰 영향을 미치기 때문에 모델을 정교하게 만들어야 하는 부담감이 있다. &amp;#xD; 둘째, 억양 분류 모델의 결과를 음성인식 모델의 추가적인 입력 특징(Input feature)으로 사용하기 때문에 음성인식 모델의 매개변수를 증가시키며 계산량 또한 증가한다는 문제가 있다. 따라서 본 연구에서는 추가적인 입력 특징이 필요하지 않고 음성인식에서 기본적으로 사용되는 특징인 주파수 정보(스펙트로그램)만을 이용하여 학습이 가능한 도메인 적대적 신경망을 기법을 제안하였다. &amp;#xD; 도메인 적대적 신경망은 소스 도메인(Source domain) 데이터와 타겟 도메인(Target domain) 데이터가 적대적으로 학습이 되면서 두 도메인 간의 분포 차이를 줄이는 것을 목적으로 한다. 본 연구의 목표인 억양음성인식에서는 표준 발화를 소스 도메인으로, 억양이 섞인 발화를 타겟 도메인으로 정하였다. 도메인 적대적 신경망은 특징 추출기(Feature extractor), 도메인 분류기(Domain classifier), 레이블 예측기(Label predictor) 총 3개의 부분망(sub-network)으로 구성된다. 각각의 부분망은 서로 다른 역할을 수행하기 때문에 신경망의 특성을 고려하여 만들어야 한다. 따라서 본 연구에서는 신경망의 특성을 고려하여 특징 추출기에는 합성곱 신경망(Convolutional Neural Network)을, 도메인 분류기에는 심층 신경망(Deep Neural Network)을, 그리고 레이블 예측기에는 양방향 게이트 순환 유닛(Bidirectional Gated Recurrent Unit)을 이용하여 도메인 적대적 신경망을 구성하였다. 또한, 레이블을 예측할 때 종단 간 기법을 활용하여 입력 데이터를 사전 분할하지 않고, 레이블 예측 이후의 후처리 작업을 없애면서 음성인식 과정을 간소화하였다.&amp;#xD; 본 연구에서 제안한 도메인 적대적 학습 기반의 억양음성인식 기법의 효과를 입증하기 위하여 Baseline 모델과 DANN 모델을 만들어 실험을 진행하였다. 실험 데이터로는 Mozilla의 Common Voice 코퍼스를 사용하였는데, Common Voice 코퍼스는 여러 언어에 대해 막대한 양의 검증된 음성파일을 오픈소스로 제공하기 때문에 음성인식 연구에서 많이 사용된다. 또한, Common Voice 코퍼스는 음성 녹음 파일과 함께 억양 정보도 같이 제공을 하기 때문에 억양음성인식 연구에 효율적으로 사용될 수 있다. &amp;#xD; Common Voice 코퍼스의 영어 데이터셋은 여러 억양의 음성파일들을 가지고 있는데, 본 연구에서는 미국 억양, 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양의 데이터를 실험에 사용하였으며, 미국 억양을 소스 도메인으로 나머지 네 개의 억양을 타겟 도메인으로 정하였다.&amp;#xD; 실험 결과 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양 모두에서 DANN 모델의 성능이 Baseline 모델보다 높은 성능을 보였다. 하지만 억양에 따라 성능 개선의 차이가 있었으며, 캐나다 억양에 비해 잉글랜드 억양과 인도 억양에서 성능이 눈에 띄게 향상되었다. 이 같은 결과는 잉글랜드 억양과 인도 억양이 소스 도메인으로 사용된 미국 억양 데이터와 언어학적으로 큰 차이가 존재하여 baseline 모델에서는 성능이 낮았으나, 도메인 적대적 학습을 통해 생성된 DANN 모델이 타겟 억양의 특성을 반영함으로써 성능이 크게 개선된 것으로 분석된다. 따라서 도메인 적대적 신경망은 소스 도메인과 타겟 도메인 사이의 분포의 차이를 줄임으로서 억양음성인식의 성능을 향상시킬 수 있음이 확인되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015893049&target=NART&cn=DIKO0015893049",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "도메인 적대적 신경망을 이용한 종단 간 억양음성인식 도메인 적대적 신경망을 이용한 종단 간 억양음성인식 도메인 적대적 신경망을 이용한 종단 간 억양음성인식 최근 딥러닝(Deep learning) 기술의 발전은 음성인식 성능 향상에 크게 기여하였다. 이러한 발전에도 불구하고 소음, 감정, 억양 등이 섞인 특정 발화에 대해서는 좋은 성능을 보이지 못하고 있다. 이 가운데 억양이 섞인 발화는 표준 발화와 비교했을 때 언어학적인 차이가 존재하는데, 이러한 차이가 억양이 섞인 발화를 인식하기 어렵게 만든다. 따라서 본 연구에서는 억양이 섞인 발화와 표준 발화 사이에 존재하는 특성의 차이를 줄이고자 도메인 적대적 신경망(Domain Adversarial Neural Network) 기법을 사용하였다. 또한, 종단 간(End-to-end) 기법을 사용하여 음성인식의 과정을 간소화하였다.&amp;#xD; 오래전부터 억양음성인식의 성능을 높이기 위한 연구는 활발히 진행되어 왔다. 2010년대 초반까지는 가우시안 혼합 모델(Gaussian Mixture Model) 기반의 최대 사후 확률(Maximum A Posteriori), 최대 우도 선형 회귀(Maximum Likelihood Linear Regression) 적응 기법이 주로 사용되었다. 하지만 딥러닝 기술이 발전하고 신경망 기반의 모델들이 주목 받기 시작하면서 가우시안 혼합 모델보다는 신경망 모델에 적합한 기법들이 사용되었다. 최근 몇 년간은 음성인식 모델에 억양에 대한 정보를 직접 삽입하는 accent embedding 기법이 많이 사용되었다. Accent embedding 기법은 억양음성인식의 성능을 향상시켰지만 몇 가지 문제점을 가지고 있다. 첫째, 억양을 분류하여 accent embedding 특징들을 만들어내는 모델을 독립적으로 만들어 훈련시켜야 하며, 해당 모델의 억양 분류 정확도가 음성인식 모델의 성능에 큰 영향을 미치기 때문에 모델을 정교하게 만들어야 하는 부담감이 있다. &amp;#xD; 둘째, 억양 분류 모델의 결과를 음성인식 모델의 추가적인 입력 특징(Input feature)으로 사용하기 때문에 음성인식 모델의 매개변수를 증가시키며 계산량 또한 증가한다는 문제가 있다. 따라서 본 연구에서는 추가적인 입력 특징이 필요하지 않고 음성인식에서 기본적으로 사용되는 특징인 주파수 정보(스펙트로그램)만을 이용하여 학습이 가능한 도메인 적대적 신경망을 기법을 제안하였다. &amp;#xD; 도메인 적대적 신경망은 소스 도메인(Source domain) 데이터와 타겟 도메인(Target domain) 데이터가 적대적으로 학습이 되면서 두 도메인 간의 분포 차이를 줄이는 것을 목적으로 한다. 본 연구의 목표인 억양음성인식에서는 표준 발화를 소스 도메인으로, 억양이 섞인 발화를 타겟 도메인으로 정하였다. 도메인 적대적 신경망은 특징 추출기(Feature extractor), 도메인 분류기(Domain classifier), 레이블 예측기(Label predictor) 총 3개의 부분망(sub-network)으로 구성된다. 각각의 부분망은 서로 다른 역할을 수행하기 때문에 신경망의 특성을 고려하여 만들어야 한다. 따라서 본 연구에서는 신경망의 특성을 고려하여 특징 추출기에는 합성곱 신경망(Convolutional Neural Network)을, 도메인 분류기에는 심층 신경망(Deep Neural Network)을, 그리고 레이블 예측기에는 양방향 게이트 순환 유닛(Bidirectional Gated Recurrent Unit)을 이용하여 도메인 적대적 신경망을 구성하였다. 또한, 레이블을 예측할 때 종단 간 기법을 활용하여 입력 데이터를 사전 분할하지 않고, 레이블 예측 이후의 후처리 작업을 없애면서 음성인식 과정을 간소화하였다.&amp;#xD; 본 연구에서 제안한 도메인 적대적 학습 기반의 억양음성인식 기법의 효과를 입증하기 위하여 Baseline 모델과 DANN 모델을 만들어 실험을 진행하였다. 실험 데이터로는 Mozilla의 Common Voice 코퍼스를 사용하였는데, Common Voice 코퍼스는 여러 언어에 대해 막대한 양의 검증된 음성파일을 오픈소스로 제공하기 때문에 음성인식 연구에서 많이 사용된다. 또한, Common Voice 코퍼스는 음성 녹음 파일과 함께 억양 정보도 같이 제공을 하기 때문에 억양음성인식 연구에 효율적으로 사용될 수 있다. &amp;#xD; Common Voice 코퍼스의 영어 데이터셋은 여러 억양의 음성파일들을 가지고 있는데, 본 연구에서는 미국 억양, 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양의 데이터를 실험에 사용하였으며, 미국 억양을 소스 도메인으로 나머지 네 개의 억양을 타겟 도메인으로 정하였다.&amp;#xD; 실험 결과 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양 모두에서 DANN 모델의 성능이 Baseline 모델보다 높은 성능을 보였다. 하지만 억양에 따라 성능 개선의 차이가 있었으며, 캐나다 억양에 비해 잉글랜드 억양과 인도 억양에서 성능이 눈에 띄게 향상되었다. 이 같은 결과는 잉글랜드 억양과 인도 억양이 소스 도메인으로 사용된 미국 억양 데이터와 언어학적으로 큰 차이가 존재하여 baseline 모델에서는 성능이 낮았으나, 도메인 적대적 학습을 통해 생성된 DANN 모델이 타겟 억양의 특성을 반영함으로써 성능이 크게 개선된 것으로 분석된다. 따라서 도메인 적대적 신경망은 소스 도메인과 타겟 도메인 사이의 분포의 차이를 줄임으로서 억양음성인식의 성능을 향상시킬 수 있음이 확인되었다."
        },
        {
          "rank": 24,
          "score": 0.7002394199371338,
          "doc_id": "JAKO201115537947340",
          "title": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식",
          "abstract": "음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201115537947340&target=NART&cn=JAKO201115537947340",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다."
        },
        {
          "rank": 25,
          "score": 0.6985523700714111,
          "doc_id": "JAKO201911338887557",
          "title": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법",
          "abstract": "본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911338887557&target=NART&cn=JAKO201911338887557",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다."
        },
        {
          "rank": 26,
          "score": 0.6977411508560181,
          "doc_id": "JAKO200111920771822",
          "title": "인과 2D 은닉 마르코프 모델",
          "abstract": "2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111920771822&target=NART&cn=JAKO200111920771822",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다."
        },
        {
          "rank": 27,
          "score": 0.6948948502540588,
          "doc_id": "NART20682074",
          "title": "Robust combination of neural networks and hidden Markov models for speech recognition",
          "abstract": "Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20682074&target=NART&cn=NART20682074",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs."
        },
        {
          "rank": 28,
          "score": 0.6934860348701477,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        },
        {
          "rank": 29,
          "score": 0.6923493146896362,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 30,
          "score": 0.6917682886123657,
          "doc_id": "JAKO201707851605473",
          "title": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표",
          "abstract": "본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201707851605473&target=NART&cn=JAKO201707851605473",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다."
        },
        {
          "rank": 31,
          "score": 0.6909885406494141,
          "doc_id": "NART06155061",
          "title": "Speech enhancement based on neural predictive hidden Markov model",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06155061&target=NART&cn=NART06155061",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model <P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>"
        },
        {
          "rank": 32,
          "score": 0.6904353499412537,
          "doc_id": "NART56158825",
          "title": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법",
          "abstract": "<P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158825&target=NART&cn=NART56158825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 <P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>"
        },
        {
          "rank": 33,
          "score": 0.6893845200538635,
          "doc_id": "NART56159050",
          "title": "은닉 마르코프 모델 기반 손 제스처 적출을 위한 임계치 모델",
          "abstract": "<P> 본 논문에서는 실시간 제스처 인식 시스템을 위하여 연속적인 손동작으로부터 제스처 부분을 적출(spotting)하는 새로운 방법을 제안한다. 제안된 방법은 제스처의 구분문제(segmentation problem)를 해결할 수 있고 시공간적인 변이를 흡수할 수 있는 은닉 마르코프 모델에 기초를 두고 있다. 특히, 입력패턴으로부터 제스처가 아닌 패턴의 제거를 위하여, 임계치 모델(threshold model)이라는 새로운 모델을 도입하여 입력패턴의 임계 유사도를 계산하고 이를 이용하여 입력패턴이 제스처 패턴과 얼마나 유사한 지를 판정해 주도록 한다. 제안된 방법을 이용하면 연속적인 손동작으로부터 93.38%의 신뢰도로 의미있는 제스처를 추출할 수 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56159050&target=NART&cn=NART56159050",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 기반 손 제스처 적출을 위한 임계치 모델 은닉 마르코프 모델 기반 손 제스처 적출을 위한 임계치 모델 은닉 마르코프 모델 기반 손 제스처 적출을 위한 임계치 모델 <P> 본 논문에서는 실시간 제스처 인식 시스템을 위하여 연속적인 손동작으로부터 제스처 부분을 적출(spotting)하는 새로운 방법을 제안한다. 제안된 방법은 제스처의 구분문제(segmentation problem)를 해결할 수 있고 시공간적인 변이를 흡수할 수 있는 은닉 마르코프 모델에 기초를 두고 있다. 특히, 입력패턴으로부터 제스처가 아닌 패턴의 제거를 위하여, 임계치 모델(threshold model)이라는 새로운 모델을 도입하여 입력패턴의 임계 유사도를 계산하고 이를 이용하여 입력패턴이 제스처 패턴과 얼마나 유사한 지를 판정해 주도록 한다. 제안된 방법을 이용하면 연속적인 손동작으로부터 93.38%의 신뢰도로 의미있는 제스처를 추출할 수 있다.</P>"
        },
        {
          "rank": 34,
          "score": 0.6887392997741699,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 35,
          "score": 0.6872061491012573,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 36,
          "score": 0.6865779757499695,
          "doc_id": "JAKO201734964189755",
          "title": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식",
          "abstract": "본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734964189755&target=NART&cn=JAKO201734964189755",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다."
        },
        {
          "rank": 37,
          "score": 0.6852990984916687,
          "doc_id": "JAKO201120661417407",
          "title": "계층적 은닉 마르코프 모델을 이용한 이동 센서 기반 행동 인식",
          "abstract": "최근 구글의 안드로이드폰과 애플의 아이폰 등 다양한 센서를 갖추고 있는 스마트 폰이 증가하면서 스마트폰에 내장된 센서를 이용하는 서비스나 연구가 활발히 진행되고 있다. 그 중에서도 가속도 센서를 이용하여 사용자의 동작 상태나 행동을 안식하기 위한 연구는 스마트폰이 등장하기 이전에도 사용자 맞춤형 서비스를 제공하기 위해 많이 진행되어 왔다. 본 논문에서는 안드로이드 폰을 기반으로 내장된 가속도 센서로부터 수집되는 3축 가속도 정보에 계층적 은닉 마르코프 모델을 적용하여 사랑의 행동을 인식하는 연구를 진행하였다. 은닉마르코프모델은 시계열 패턴 인식에 좋은 성능을 보이지만, 모바일 기기에서는 메모리외 CPU 사용에 제약이 있으므로 복잡한 확률모델을 그대로 저수준 데이터에 사용하기에는 무리가 있다. 본 논문에서는 동작 계층과 행동 계층을 나누어 은닉마르코프 모델을 설계하고, 동작 계층에서 처리된 정보를 이용하여 행동 인식 모델이 모바일 기기에서 잘 동작하는 것을 보였다. 또한 제안하는 방법의 가능성을 보이기 위하여 실제 수집된 가속도 데이터에 대해서 정확도를 비교/분석하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201120661417407&target=NART&cn=JAKO201120661417407",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "계층적 은닉 마르코프 모델을 이용한 이동 센서 기반 행동 인식 계층적 은닉 마르코프 모델을 이용한 이동 센서 기반 행동 인식 계층적 은닉 마르코프 모델을 이용한 이동 센서 기반 행동 인식 최근 구글의 안드로이드폰과 애플의 아이폰 등 다양한 센서를 갖추고 있는 스마트 폰이 증가하면서 스마트폰에 내장된 센서를 이용하는 서비스나 연구가 활발히 진행되고 있다. 그 중에서도 가속도 센서를 이용하여 사용자의 동작 상태나 행동을 안식하기 위한 연구는 스마트폰이 등장하기 이전에도 사용자 맞춤형 서비스를 제공하기 위해 많이 진행되어 왔다. 본 논문에서는 안드로이드 폰을 기반으로 내장된 가속도 센서로부터 수집되는 3축 가속도 정보에 계층적 은닉 마르코프 모델을 적용하여 사랑의 행동을 인식하는 연구를 진행하였다. 은닉마르코프모델은 시계열 패턴 인식에 좋은 성능을 보이지만, 모바일 기기에서는 메모리외 CPU 사용에 제약이 있으므로 복잡한 확률모델을 그대로 저수준 데이터에 사용하기에는 무리가 있다. 본 논문에서는 동작 계층과 행동 계층을 나누어 은닉마르코프 모델을 설계하고, 동작 계층에서 처리된 정보를 이용하여 행동 인식 모델이 모바일 기기에서 잘 동작하는 것을 보였다. 또한 제안하는 방법의 가능성을 보이기 위하여 실제 수집된 가속도 데이터에 대해서 정확도를 비교/분석하였다."
        },
        {
          "rank": 38,
          "score": 0.6837457418441772,
          "doc_id": "JAKO200624718627058",
          "title": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식",
          "abstract": "본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200624718627058&target=NART&cn=JAKO200624718627058",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다."
        },
        {
          "rank": 39,
          "score": 0.6827706694602966,
          "doc_id": "JAKO201809242561431",
          "title": "합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델",
          "abstract": "도시 유동인구가 증가함에 따라 도시 환경 소음에 관한 연구의 중요성이 증가하고 있다. 본 연구에서는 교통상황에서 발생하는 이상 소음을 최근 환경 소음 분류 연구에서 높은 성능을 보이는 딥러닝 알고리즘을 이용하여 분류한다. 구체적으로는 타이어 제동 마찰음, 자동차 충돌음, 자동차 경적음, 정상 소음 네 개의 클래스에 대하여 합성곱 신경망을 이용하여 분류한다. 또한, 실제 교통 상황에서의 환경잡음에 강인한 분류 성능을 갖기 위해 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음을 설정하였고 이를 활용하여 분류 모델을 설계하였으며 3 dB SNR(Signal to Noise Ratio) 조건에서 88 % 이상의 분류 성능을 가진다. 제시한 교통 소음에 대하여 기존 선행연구 대비 높은 분류 성능을 보이고, 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음에 강인한 교통 소음 분류 모델을 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809242561431&target=NART&cn=JAKO201809242561431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 도시 유동인구가 증가함에 따라 도시 환경 소음에 관한 연구의 중요성이 증가하고 있다. 본 연구에서는 교통상황에서 발생하는 이상 소음을 최근 환경 소음 분류 연구에서 높은 성능을 보이는 딥러닝 알고리즘을 이용하여 분류한다. 구체적으로는 타이어 제동 마찰음, 자동차 충돌음, 자동차 경적음, 정상 소음 네 개의 클래스에 대하여 합성곱 신경망을 이용하여 분류한다. 또한, 실제 교통 상황에서의 환경잡음에 강인한 분류 성능을 갖기 위해 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음을 설정하였고 이를 활용하여 분류 모델을 설계하였으며 3 dB SNR(Signal to Noise Ratio) 조건에서 88 % 이상의 분류 성능을 가진다. 제시한 교통 소음에 대하여 기존 선행연구 대비 높은 분류 성능을 보이고, 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음에 강인한 교통 소음 분류 모델을 제안한다."
        },
        {
          "rank": 40,
          "score": 0.6815801858901978,
          "doc_id": "NART17510385",
          "title": "Hidden-articulator Markov models for speech recognition",
          "abstract": "<P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART17510385&target=NART&cn=NART17510385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition <P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>"
        },
        {
          "rank": 41,
          "score": 0.6807585954666138,
          "doc_id": "NART18014750",
          "title": "Neural nets and hidden Markov models: Review and generalizations",
          "abstract": "Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18014750&target=NART&cn=NART18014750",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs)."
        },
        {
          "rank": 42,
          "score": 0.6800708174705505,
          "doc_id": "NART56158002",
          "title": "은닉 마르코프 모델을 이용한 효율적인 한국어 품사의 태깅",
          "abstract": "<P> 품사 태깅은 자연언어 처리 분야에서 품사의 모호성 해소는 물론 음성인식 및 문자인식의 후처리기로서 많이 사용되고 있다. 본 논문은 은닉 마르코프 모델을 이용한 한국어 품사 태깅에 관해서 논한다. 한국어는 영어와는 달리 품사 태깅을 할때에 어절이 분리 되어야 한다. 어절이 분리될 때에 한국어의 경우에 여러 종류로 분리되어 이를 은닉 마르코프 모델에 적용할 경우에 다입력열(다입력 단어열) 문제가 발생된다. 본 논문에서는 은닉 마르코프 모델을 이용하여 한국어 품사 태깅 문제를 풀 때에 이와 같은 문제의 해결 방법을 제시하고, 이들에 대한 효율적인 방법을 제시한다. 한국어 품사 태깅을 위한 은닉 마르코프 모델의 학습은 올바른 형태소를 분리한 학습 말뭉치를 만듦으로써 해결하고, 품사열(상태열) 찾기는 공유 단어열의 개념을 이용하여 해결하고 가상 단어 개념을 이용하여 좀더 효율적인 방법을 제시한다. 또 한국어 문장에 대한 품사 태깅을 실제 적용 실행하여 제시한 방법의 유용성을 보였다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158002&target=NART&cn=NART56158002",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 효율적인 한국어 품사의 태깅 은닉 마르코프 모델을 이용한 효율적인 한국어 품사의 태깅 은닉 마르코프 모델을 이용한 효율적인 한국어 품사의 태깅 <P> 품사 태깅은 자연언어 처리 분야에서 품사의 모호성 해소는 물론 음성인식 및 문자인식의 후처리기로서 많이 사용되고 있다. 본 논문은 은닉 마르코프 모델을 이용한 한국어 품사 태깅에 관해서 논한다. 한국어는 영어와는 달리 품사 태깅을 할때에 어절이 분리 되어야 한다. 어절이 분리될 때에 한국어의 경우에 여러 종류로 분리되어 이를 은닉 마르코프 모델에 적용할 경우에 다입력열(다입력 단어열) 문제가 발생된다. 본 논문에서는 은닉 마르코프 모델을 이용하여 한국어 품사 태깅 문제를 풀 때에 이와 같은 문제의 해결 방법을 제시하고, 이들에 대한 효율적인 방법을 제시한다. 한국어 품사 태깅을 위한 은닉 마르코프 모델의 학습은 올바른 형태소를 분리한 학습 말뭉치를 만듦으로써 해결하고, 품사열(상태열) 찾기는 공유 단어열의 개념을 이용하여 해결하고 가상 단어 개념을 이용하여 좀더 효율적인 방법을 제시한다. 또 한국어 문장에 대한 품사 태깅을 실제 적용 실행하여 제시한 방법의 유용성을 보였다.</P>"
        },
        {
          "rank": 43,
          "score": 0.6796681880950928,
          "doc_id": "JAKO199215875841266",
          "title": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교",
          "abstract": "음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199215875841266&target=NART&cn=JAKO199215875841266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다."
        },
        {
          "rank": 44,
          "score": 0.6788015365600586,
          "doc_id": "NPAP07942137",
          "title": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP07942137&target=NART&cn=NPAP07942137",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 45,
          "score": 0.6777280569076538,
          "doc_id": "NART56158762",
          "title": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델",
          "abstract": "<P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158762&target=NART&cn=NART56158762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 <P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>"
        },
        {
          "rank": 46,
          "score": 0.6765409111976624,
          "doc_id": "NART37979687",
          "title": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network",
          "abstract": "<P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART37979687&target=NART&cn=NART37979687",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network <P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>"
        },
        {
          "rank": 47,
          "score": 0.6758784055709839,
          "doc_id": "JAKO201120661418238",
          "title": "음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거",
          "abstract": "본 논문에서는 먼저 신경회로망의 학습에 오차역전파 학습 알고리즘을 사용하여 각 프레임에서의 음성 및 잡음 구간의 검출에 의한 음성인식 알고리즘을 제안한다. 그리고 신경회로망에 의하여 음성 및 잡음 구간의 검출에 따라서 각 프레임에서 잡음을 제거하는 스펙트럼 차감법을 제안한다. 본 실험에서는 제안한 음성인식알고리즘의 성능을 원음성에 백색잡음 및 자동차 잡음을 부가하여 인식율을 평가한다. 또한 인식시스템에 의하여 검출된 음성 및 잡음 구간을 이용하여 각 프레임에서의 스펙트럼 차감법에 의한 잡음제거의 실험결과를 나타낸다. 잡음에 의하여 오염된 음성에 대하여 신호대잡음비를 사용하여 본 알고리즘이 유효하다는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201120661418238&target=NART&cn=JAKO201120661418238",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 본 논문에서는 먼저 신경회로망의 학습에 오차역전파 학습 알고리즘을 사용하여 각 프레임에서의 음성 및 잡음 구간의 검출에 의한 음성인식 알고리즘을 제안한다. 그리고 신경회로망에 의하여 음성 및 잡음 구간의 검출에 따라서 각 프레임에서 잡음을 제거하는 스펙트럼 차감법을 제안한다. 본 실험에서는 제안한 음성인식알고리즘의 성능을 원음성에 백색잡음 및 자동차 잡음을 부가하여 인식율을 평가한다. 또한 인식시스템에 의하여 검출된 음성 및 잡음 구간을 이용하여 각 프레임에서의 스펙트럼 차감법에 의한 잡음제거의 실험결과를 나타낸다. 잡음에 의하여 오염된 음성에 대하여 신호대잡음비를 사용하여 본 알고리즘이 유효하다는 것을 확인한다."
        },
        {
          "rank": 48,
          "score": 0.6742585897445679,
          "doc_id": "JAKO201719951669089",
          "title": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링",
          "abstract": "This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201719951669089&target=NART&cn=JAKO201719951669089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method."
        },
        {
          "rank": 49,
          "score": 0.6731933355331421,
          "doc_id": "JAKO201016450104831",
          "title": "잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법",
          "abstract": "음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널잡음에 의한 왜곡이다. 일반적으로 배경잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 받게 한다. DSR (Distributed Speech Recognition) 기반의 음성인식 역시 이와 같은 문제로 성능 향상에 어려움을 겪고 있다. 이러한 문제를 해결하기 위해 다양한 잡음제거 알고리듬이 사용되고 있으나 낮은 SNR환경에서 부정확한 잡음추정으로 발생하는 스펙트럼 손상과 잔존 잡음은 음성인식기의 인식환경과 학습 환경의 불일치를 만들게 되어 인식률을 저하시키는 원인이 된다. 본 논문에서는 이와 같은 문제를 해결하기 위해 잡음제거 알고리듬으로 MMSE-STSA 방법을 사용하였고 손상된 스펙트럼을 보상하기 위해 Ideal Binary Mask를 이용하였다. 잡음환경 (SNR 15 ~ 0 dB)에 따른 실험결과 제안된 방법을 사용했을 때 향상된 스펙트럼을 얻을 수 있었고 향상된 인식성능을 확인했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201016450104831&target=NART&cn=JAKO201016450104831",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널잡음에 의한 왜곡이다. 일반적으로 배경잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 받게 한다. DSR (Distributed Speech Recognition) 기반의 음성인식 역시 이와 같은 문제로 성능 향상에 어려움을 겪고 있다. 이러한 문제를 해결하기 위해 다양한 잡음제거 알고리듬이 사용되고 있으나 낮은 SNR환경에서 부정확한 잡음추정으로 발생하는 스펙트럼 손상과 잔존 잡음은 음성인식기의 인식환경과 학습 환경의 불일치를 만들게 되어 인식률을 저하시키는 원인이 된다. 본 논문에서는 이와 같은 문제를 해결하기 위해 잡음제거 알고리듬으로 MMSE-STSA 방법을 사용하였고 손상된 스펙트럼을 보상하기 위해 Ideal Binary Mask를 이용하였다. 잡음환경 (SNR 15 ~ 0 dB)에 따른 실험결과 제안된 방법을 사용했을 때 향상된 스펙트럼을 얻을 수 있었고 향상된 인식성능을 확인했다."
        },
        {
          "rank": 50,
          "score": 0.6715066432952881,
          "doc_id": "JAKO200416642157049",
          "title": "Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식",
          "abstract": "In this paper, a new noise compensation method based on the eigenvoice framework in feature space is proposed to reduce the mismatch between training and testing environments. The difference between clean and noisy environments is represented by the linear combination of K eigenvectors that represent the variation among environments. In the proposed method, the performance improvement of speech recognition systems is largely affected by how to construct the noisy models and the bias vector set. In this paper, two methods, the one based on MAP adaptation method and the other using stereo DB, are proposed to construct the noisy models. In experiments using Aurora 2 DB, we obtained 44.86% relative improvement with eigen-environment method in comparison with baseline system. Especially, in clean condition training mode, our proposed method yielded 66.74% relative improvement, which is better performance than several methods previously proposed in Aurora project.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200416642157049&target=NART&cn=JAKO200416642157049",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 In this paper, a new noise compensation method based on the eigenvoice framework in feature space is proposed to reduce the mismatch between training and testing environments. The difference between clean and noisy environments is represented by the linear combination of K eigenvectors that represent the variation among environments. In the proposed method, the performance improvement of speech recognition systems is largely affected by how to construct the noisy models and the bias vector set. In this paper, two methods, the one based on MAP adaptation method and the other using stereo DB, are proposed to construct the noisy models. In experiments using Aurora 2 DB, we obtained 44.86% relative improvement with eigen-environment method in comparison with baseline system. Especially, in clean condition training mode, our proposed method yielded 66.74% relative improvement, which is better performance than several methods previously proposed in Aurora project."
        }
      ]
    },
    {
      "query": "잡음 환경에서 시청각 음성인식의 인식률을 높이기 위한 통합 전략에서 은닉 마르코프 모델(HMM)은 어떤 역할을 수행하나요?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8548996448516846,
          "doc_id": "DIKO0011019580",
          "title": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",
          "abstract": "음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다."
        },
        {
          "rank": 2,
          "score": 0.8211723566055298,
          "doc_id": "DIKO0007842188",
          "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
          "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
        },
        {
          "rank": 3,
          "score": 0.8031054735183716,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.7963769435882568,
          "doc_id": "JAKO200612842592571",
          "title": "제스처 인식을 위한 은닉 마르코프 모델",
          "abstract": "본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200612842592571&target=NART&cn=JAKO200612842592571",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다."
        },
        {
          "rank": 5,
          "score": 0.7949606776237488,
          "doc_id": "NPAP07942137",
          "title": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP07942137&target=NART&cn=NPAP07942137",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 6,
          "score": 0.7901841402053833,
          "doc_id": "NART56157676",
          "title": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합",
          "abstract": "<P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157676&target=NART&cn=NART56157676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 <P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>"
        },
        {
          "rank": 7,
          "score": 0.7893585562705994,
          "doc_id": "JAKO200111921140843",
          "title": "회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM (Hidden Markov Model)의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경 망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용 데이터에 대하여 Elman망 예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 98.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111921140843&target=NART&cn=JAKO200111921140843",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM (Hidden Markov Model)의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경 망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용 데이터에 대하여 Elman망 예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 98.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 8,
          "score": 0.7849828004837036,
          "doc_id": "JAKO200111920771822",
          "title": "인과 2D 은닉 마르코프 모델",
          "abstract": "2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111920771822&target=NART&cn=JAKO200111920771822",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다."
        },
        {
          "rank": 9,
          "score": 0.7840015888214111,
          "doc_id": "NART18015173",
          "title": "Speech recognition using hidden Markov models: A CMU perspective",
          "abstract": "Hidden Markov Models (HMMs) have become the predominant approach for speech recognition systems. One example of an HMM-based system is SPHINX, a large-vocabulary, speaker-independent, continuous-speech recognition system developed at CMU. In this paper, we introduce Hidden Markov Modelling techniques, analyze the reason for their success, and describe some improvements to the standard HMM used in SPHINX.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18015173&target=NART&cn=NART18015173",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech recognition using hidden Markov models: A CMU perspective Speech recognition using hidden Markov models: A CMU perspective Speech recognition using hidden Markov models: A CMU perspective Hidden Markov Models (HMMs) have become the predominant approach for speech recognition systems. One example of an HMM-based system is SPHINX, a large-vocabulary, speaker-independent, continuous-speech recognition system developed at CMU. In this paper, we introduce Hidden Markov Modelling techniques, analyze the reason for their success, and describe some improvements to the standard HMM used in SPHINX."
        },
        {
          "rank": 10,
          "score": 0.7776838541030884,
          "doc_id": "NART17510385",
          "title": "Hidden-articulator Markov models for speech recognition",
          "abstract": "<P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART17510385&target=NART&cn=NART17510385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition <P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>"
        },
        {
          "rank": 11,
          "score": 0.7774991989135742,
          "doc_id": "JAKO202123157167812",
          "title": "은닉 마르코프 모델을 이용한 국가별 주가지수 예측",
          "abstract": "은닉 마르코프 모델(hidden Markov model, HMM)은 은닉된 상태와 관찰 가능한 결과의 두 가지 요소로 이루어진 통계적 모형으로 확률론적 접근이 가능하고, 다양한 수학적인 구조를 가지고 있어 여러 분야에서 활발하게 사용되고 있다. 특히 금융 분야의 시계열 데이터에 응용되어 다양한 연구가 진행되고 있다. 본 연구는 HMM 이론을 국내 KOSPI200 주가지수와 더불어 NIKKEI225, HSI, S&P500, FTSE100과 같은 해외 주가지수 예측에 적용해 보고자 한다. 또한, 최근 인공지능 분야의 발전으로 인해 주식 가격 예측에 빈번하게 사용되는 서포트 벡터 회귀(support vector regression, SVR) 결과와 어떤 차이가 있는지 비교하여 살펴보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202123157167812&target=NART&cn=JAKO202123157167812",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델(hidden Markov model, HMM)은 은닉된 상태와 관찰 가능한 결과의 두 가지 요소로 이루어진 통계적 모형으로 확률론적 접근이 가능하고, 다양한 수학적인 구조를 가지고 있어 여러 분야에서 활발하게 사용되고 있다. 특히 금융 분야의 시계열 데이터에 응용되어 다양한 연구가 진행되고 있다. 본 연구는 HMM 이론을 국내 KOSPI200 주가지수와 더불어 NIKKEI225, HSI, S&P500, FTSE100과 같은 해외 주가지수 예측에 적용해 보고자 한다. 또한, 최근 인공지능 분야의 발전으로 인해 주식 가격 예측에 빈번하게 사용되는 서포트 벡터 회귀(support vector regression, SVR) 결과와 어떤 차이가 있는지 비교하여 살펴보고자 한다."
        },
        {
          "rank": 12,
          "score": 0.7764846086502075,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        },
        {
          "rank": 13,
          "score": 0.7737518548965454,
          "doc_id": "JAKO201403359905324",
          "title": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원",
          "abstract": "This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201403359905324&target=NART&cn=JAKO201403359905324",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method."
        },
        {
          "rank": 14,
          "score": 0.772139310836792,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 15,
          "score": 0.7710771560668945,
          "doc_id": "NART56158825",
          "title": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법",
          "abstract": "<P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158825&target=NART&cn=NART56158825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 <P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>"
        },
        {
          "rank": 16,
          "score": 0.76918625831604,
          "doc_id": "NART56158762",
          "title": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델",
          "abstract": "<P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158762&target=NART&cn=NART56158762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 <P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>"
        },
        {
          "rank": 17,
          "score": 0.7670490741729736,
          "doc_id": "JAKO202510064801583",
          "title": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석",
          "abstract": "항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510064801583&target=NART&cn=JAKO202510064801583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다."
        },
        {
          "rank": 18,
          "score": 0.7668654322624207,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 19,
          "score": 0.7653234601020813,
          "doc_id": "JAKO201630932328344",
          "title": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법",
          "abstract": "실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201630932328344&target=NART&cn=JAKO201630932328344",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다."
        },
        {
          "rank": 20,
          "score": 0.7573953866958618,
          "doc_id": "NART70632792",
          "title": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis",
          "abstract": "<P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70632792&target=NART&cn=NART70632792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis <P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>"
        },
        {
          "rank": 21,
          "score": 0.748615562915802,
          "doc_id": "NART13081886",
          "title": "Speech recognition under noisy environments using segmental unit input HMM",
          "abstract": "<P>In this paper, we apply a segmental unit input HMM to noisy speech recognition. In this modeling, several successive frames are combined and treated as an input vector. We expect that the segmental unit input HMM will be effective for noisy speech recognition because segmental statistics considering correlation between frames reduce noise effects when the correlation of noise between frames is assumed to be small. In recognition experiments, we compared the segmental unit input HMM with a conventional frame-based HMM and found the segmental unit input HMM to be superior. We also compared the segmental unit input HMM with dynamic cepstral coefficients, which have both static and dynamic features, and found that the segmental unit input HMM is more effective than the dynamic cepstrum. We also combined the segmental unit input HMM with a spectral subtraction method and confirmed the effectiveness of the method. Additionally, in experiments using acoustic models trained with noisy speech, the segmental unit input HMM outperformed the conventional HMM. From these results, we propose PMC for the segmental unit input HMM. Experimental results showed the PMC for segmental unit input HMM offered better recognition performance than the original PMC. &copy; 2002 Wiley Periodicals, Inc. Syst Comp Jpn, 33(8): 111&ndash;120, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.1151</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13081886&target=NART&cn=NART13081886",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech recognition under noisy environments using segmental unit input HMM Speech recognition under noisy environments using segmental unit input HMM Speech recognition under noisy environments using segmental unit input HMM <P>In this paper, we apply a segmental unit input HMM to noisy speech recognition. In this modeling, several successive frames are combined and treated as an input vector. We expect that the segmental unit input HMM will be effective for noisy speech recognition because segmental statistics considering correlation between frames reduce noise effects when the correlation of noise between frames is assumed to be small. In recognition experiments, we compared the segmental unit input HMM with a conventional frame-based HMM and found the segmental unit input HMM to be superior. We also compared the segmental unit input HMM with dynamic cepstral coefficients, which have both static and dynamic features, and found that the segmental unit input HMM is more effective than the dynamic cepstrum. We also combined the segmental unit input HMM with a spectral subtraction method and confirmed the effectiveness of the method. Additionally, in experiments using acoustic models trained with noisy speech, the segmental unit input HMM outperformed the conventional HMM. From these results, we propose PMC for the segmental unit input HMM. Experimental results showed the PMC for segmental unit input HMM offered better recognition performance than the original PMC. &copy; 2002 Wiley Periodicals, Inc. Syst Comp Jpn, 33(8): 111&ndash;120, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.1151</P>"
        },
        {
          "rank": 22,
          "score": 0.7479051351547241,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 23,
          "score": 0.7478466033935547,
          "doc_id": "JAKO201326952134359",
          "title": "은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬",
          "abstract": "동영상에서 추출한 변수값을 은닉 마르코프 모델(Hidden Markov Model; HMM)에 적용한 새로운 낙상 인식 알고리듬을 제안한다. 개인간 낙상 양식의 차이나 유사 낙상을 실제 낙상과 구분하기 위한 기계 학습 방법으로 HMM알고리듬을 사용하였다. 비디오의 낙상 특징 변수를 얻기 위해 동영상의 광류를 구한 후 이를 주성분 분석 방식에 적용하여 움직임을 정량화하였다. 주성분 분석으로 얻어진 전체 움직임 벡터의 각도, 장단축의 비, 속도등의 조합으로 새로운 여러 종류의 낙상 특징 변수를 정의한 후 이를 HMM에 적용하여 결과를 비교, 분석하였다. 이들 변수들 중에 각도에 의해 얻어진 변수가 가장 좋은 결과를 보여 본 실험에서 91.5%의 민감도(성공 감지율)와 88.01% 의 특이도(실패 감지율)를 나타내었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201326952134359&target=NART&cn=JAKO201326952134359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 동영상에서 추출한 변수값을 은닉 마르코프 모델(Hidden Markov Model; HMM)에 적용한 새로운 낙상 인식 알고리듬을 제안한다. 개인간 낙상 양식의 차이나 유사 낙상을 실제 낙상과 구분하기 위한 기계 학습 방법으로 HMM알고리듬을 사용하였다. 비디오의 낙상 특징 변수를 얻기 위해 동영상의 광류를 구한 후 이를 주성분 분석 방식에 적용하여 움직임을 정량화하였다. 주성분 분석으로 얻어진 전체 움직임 벡터의 각도, 장단축의 비, 속도등의 조합으로 새로운 여러 종류의 낙상 특징 변수를 정의한 후 이를 HMM에 적용하여 결과를 비교, 분석하였다. 이들 변수들 중에 각도에 의해 얻어진 변수가 가장 좋은 결과를 보여 본 실험에서 91.5%의 민감도(성공 감지율)와 88.01% 의 특이도(실패 감지율)를 나타내었다."
        },
        {
          "rank": 24,
          "score": 0.7475348711013794,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 25,
          "score": 0.7429857850074768,
          "doc_id": "NART56157711",
          "title": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식",
          "abstract": "<P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157711&target=NART&cn=NART56157711",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 <P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>"
        },
        {
          "rank": 26,
          "score": 0.74223792552948,
          "doc_id": "NART37979687",
          "title": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network",
          "abstract": "<P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART37979687&target=NART&cn=NART37979687",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network <P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>"
        },
        {
          "rank": 27,
          "score": 0.7409557104110718,
          "doc_id": "JAKO200606140790765",
          "title": "Discrimination of Pathological Speech Using Hidden Markov Models",
          "abstract": "Diagnosis of pathological voice is one of the important issues in biomedical applications of speech technology. This study focuses on the discrimination of voice disorder using HMM (Hidden Markov Model) for automatic detection between normal voice and vocal fold disorder voice. This is a non-intrusive, non-expensive and fully automated method using only a speech sample of the subject. Speech data from normal people and patients were collected. Mel-frequency filter cepstral coefficients (MFCCs) were modeled by HMM classifier. Different states (3 states, 5 states and 7 states), 3 mixtures and left to right HMMs were formed. This method gives an accuracy of 93.8% for train data and 91.7% for test data in the discrimination of normal and vocal fold disorder voice for sustained /a/.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200606140790765&target=NART&cn=JAKO200606140790765",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Discrimination of Pathological Speech Using Hidden Markov Models Discrimination of Pathological Speech Using Hidden Markov Models Discrimination of Pathological Speech Using Hidden Markov Models Diagnosis of pathological voice is one of the important issues in biomedical applications of speech technology. This study focuses on the discrimination of voice disorder using HMM (Hidden Markov Model) for automatic detection between normal voice and vocal fold disorder voice. This is a non-intrusive, non-expensive and fully automated method using only a speech sample of the subject. Speech data from normal people and patients were collected. Mel-frequency filter cepstral coefficients (MFCCs) were modeled by HMM classifier. Different states (3 states, 5 states and 7 states), 3 mixtures and left to right HMMs were formed. This method gives an accuracy of 93.8% for train data and 91.7% for test data in the discrimination of normal and vocal fold disorder voice for sustained /a/."
        },
        {
          "rank": 28,
          "score": 0.7408703565597534,
          "doc_id": "NART06155061",
          "title": "Speech enhancement based on neural predictive hidden Markov model",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06155061&target=NART&cn=NART06155061",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model <P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>"
        },
        {
          "rank": 29,
          "score": 0.7395178079605103,
          "doc_id": "NART20682074",
          "title": "Robust combination of neural networks and hidden Markov models for speech recognition",
          "abstract": "Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20682074&target=NART&cn=NART20682074",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs."
        },
        {
          "rank": 30,
          "score": 0.7389408349990845,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 31,
          "score": 0.7384272813796997,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 32,
          "score": 0.735316276550293,
          "doc_id": "JAKO199615875841474",
          "title": "천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식",
          "abstract": "본 논문에서는 상태간의 천이가 특정한 시간 구간에서만 발생하도록 하는 천이 제한(transition constrained) HMM를 제안하고 잡음 환경에서의 성능을 평가하였다. 천이 제한 HMM는 상태 지속을 제한하고 음성 신호의 시간적 변화를 단순하고 효과적으로 표현할 수 있다. 제안된 천이 제한 HMM은 기존 HMM 보다 성능이 우수할 뿐만아니라 계산량도 매우 감소한다.  제안된 방법의 성능을 평가하기 위하여 반연속(semi-continuous) HMM을 이용하여 잡음이 SNR 20, 10, 0 dB로 첨가된 음성에 화자독립 단독음 인식실험을 수행하였다. 실험 결과에서 제안된 방법은 잡음에 강인한 특성을 나타내었다. 두 가지 종류의 잡음을 SNR 10dB로 첨가하여 사용한 경우, 천이제한 HMM의 인식률은 기존 HMM의 단어 인식률 81.08%와 75.36%에 비하여 각각 7.31%와 10.35% 향상되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199615875841474&target=NART&cn=JAKO199615875841474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 본 논문에서는 상태간의 천이가 특정한 시간 구간에서만 발생하도록 하는 천이 제한(transition constrained) HMM를 제안하고 잡음 환경에서의 성능을 평가하였다. 천이 제한 HMM는 상태 지속을 제한하고 음성 신호의 시간적 변화를 단순하고 효과적으로 표현할 수 있다. 제안된 천이 제한 HMM은 기존 HMM 보다 성능이 우수할 뿐만아니라 계산량도 매우 감소한다.  제안된 방법의 성능을 평가하기 위하여 반연속(semi-continuous) HMM을 이용하여 잡음이 SNR 20, 10, 0 dB로 첨가된 음성에 화자독립 단독음 인식실험을 수행하였다. 실험 결과에서 제안된 방법은 잡음에 강인한 특성을 나타내었다. 두 가지 종류의 잡음을 SNR 10dB로 첨가하여 사용한 경우, 천이제한 HMM의 인식률은 기존 HMM의 단어 인식률 81.08%와 75.36%에 비하여 각각 7.31%와 10.35% 향상되었다."
        },
        {
          "rank": 33,
          "score": 0.7346793413162231,
          "doc_id": "JAKO200624718627058",
          "title": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식",
          "abstract": "본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200624718627058&target=NART&cn=JAKO200624718627058",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다."
        },
        {
          "rank": 34,
          "score": 0.7345998883247375,
          "doc_id": "NART00705015",
          "title": "Speaker recognition using HMM composition in noisy environments",
          "abstract": "<P><B>Abstract</B></P><P>This paper investigates a speaker recognition method that is robust against background noise. In noisy environments, one important issue is how to create a model for each speaker so as to compensate for noise. The method described here is based on hidden Markov model (HMM) composition, which combines a speaker HMM and a noise-source HMM into a noise-added speaker HMM with a particular signal-to-noise ratio (SNR). Since it is difficult to measure the SNR of input speech with non-stationary noise exactly, this method creates several noise-added speaker HMMs with various SNRs. The HMM that has the highest likelihood value for the input speech is selected, and a speaker decision is made using this likelihood value. Experimental application of this method to text-independent speaker identification and verification in various kinds of noisy environments demonstrated considerable improvement in speaker recognition for speech utterances of male speakers.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART00705015&target=NART&cn=NART00705015",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speaker recognition using HMM composition in noisy environments Speaker recognition using HMM composition in noisy environments Speaker recognition using HMM composition in noisy environments <P><B>Abstract</B></P><P>This paper investigates a speaker recognition method that is robust against background noise. In noisy environments, one important issue is how to create a model for each speaker so as to compensate for noise. The method described here is based on hidden Markov model (HMM) composition, which combines a speaker HMM and a noise-source HMM into a noise-added speaker HMM with a particular signal-to-noise ratio (SNR). Since it is difficult to measure the SNR of input speech with non-stationary noise exactly, this method creates several noise-added speaker HMMs with various SNRs. The HMM that has the highest likelihood value for the input speech is selected, and a speaker decision is made using this likelihood value. Experimental application of this method to text-independent speaker identification and verification in various kinds of noisy environments demonstrated considerable improvement in speaker recognition for speech utterances of male speakers.</P>"
        },
        {
          "rank": 35,
          "score": 0.7342296838760376,
          "doc_id": "JAKO200921640756800",
          "title": "은닉 마르코프 모델 기반 동작 인식 방법",
          "abstract": "본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200921640756800&target=NART&cn=JAKO200921640756800",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다."
        },
        {
          "rank": 36,
          "score": 0.7312391400337219,
          "doc_id": "NART56157876",
          "title": "한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합",
          "abstract": "<P> 본 논문에서는 일반적인 한국어 텍스트 문장에서 단어범주를 예측하기 위하여 HMM(Hidden Markov Model)과 신경망을 결합한 모델을 제안하였다.  한국어의 단어범주를 품사와 조사의 격 및 형에 따라 33개로 분류하였으며, 분류된 단어범주를 이용하여 국민학교 교과서를 대상으로 텍스트 데이타베이스를 구성하였다. 기존의 단어범주예측을 위해 제안된 NETgram은 동적, 정적 특징을 모두 신경망으로 표현하지만 본 논문에서는 시간에 따른 동적 변화를 잘 표현해주는 HMM을 신경망과 결합하는 방법을 제안하였다. 임의의 한국어 텍스트 문장으로 실험한 결과 4-gram 예측에서 종료상태가 고정되지 않고 6개의 관찰확률을 가지며 입력관찰열을 2번 순환반복으로 훈련시킨 HMM 모델과 신경망을 결합한 모델이 가장 우수하여 단어범주예측률이 20.22%를 차지하였다. 이것은 기존의 NETgram을 이용한 방식에 비하여 2.14% 향상된 것이다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157876&target=NART&cn=NART56157876",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 <P> 본 논문에서는 일반적인 한국어 텍스트 문장에서 단어범주를 예측하기 위하여 HMM(Hidden Markov Model)과 신경망을 결합한 모델을 제안하였다.  한국어의 단어범주를 품사와 조사의 격 및 형에 따라 33개로 분류하였으며, 분류된 단어범주를 이용하여 국민학교 교과서를 대상으로 텍스트 데이타베이스를 구성하였다. 기존의 단어범주예측을 위해 제안된 NETgram은 동적, 정적 특징을 모두 신경망으로 표현하지만 본 논문에서는 시간에 따른 동적 변화를 잘 표현해주는 HMM을 신경망과 결합하는 방법을 제안하였다. 임의의 한국어 텍스트 문장으로 실험한 결과 4-gram 예측에서 종료상태가 고정되지 않고 6개의 관찰확률을 가지며 입력관찰열을 2번 순환반복으로 훈련시킨 HMM 모델과 신경망을 결합한 모델이 가장 우수하여 단어범주예측률이 20.22%를 차지하였다. 이것은 기존의 NETgram을 이용한 방식에 비하여 2.14% 향상된 것이다.</P>"
        },
        {
          "rank": 37,
          "score": 0.7280498147010803,
          "doc_id": "NART18014750",
          "title": "Neural nets and hidden Markov models: Review and generalizations",
          "abstract": "Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18014750&target=NART&cn=NART18014750",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs)."
        },
        {
          "rank": 38,
          "score": 0.7248288989067078,
          "doc_id": "JAKO201935164467523",
          "title": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구",
          "abstract": "본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201935164467523&target=NART&cn=JAKO201935164467523",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다."
        },
        {
          "rank": 39,
          "score": 0.7218688130378723,
          "doc_id": "JAKO202029462558904",
          "title": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식",
          "abstract": "특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029462558904&target=NART&cn=JAKO202029462558904",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다."
        },
        {
          "rank": 40,
          "score": 0.7173705101013184,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 41,
          "score": 0.7132303714752197,
          "doc_id": "NART133898062",
          "title": "Hidden Markov Neural Networks",
          "abstract": "<P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133898062&target=NART&cn=NART133898062",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Neural Networks Hidden Markov Neural Networks Hidden Markov Neural Networks <P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>"
        },
        {
          "rank": 42,
          "score": 0.7115476131439209,
          "doc_id": "DIKO0011930560",
          "title": "시청각 음성인식을 위한 새로운 통합방법",
          "abstract": "The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011930560&target=NART&cn=DIKO0011930560",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications."
        },
        {
          "rank": 43,
          "score": 0.7093616724014282,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 44,
          "score": 0.7093607187271118,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 45,
          "score": 0.7087228298187256,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 46,
          "score": 0.7071497440338135,
          "doc_id": "NART13642943",
          "title": "Speech recognition based on HMM decomposition and composition method with a microphone array in noisy reverberant environments",
          "abstract": "<P>Handling background noise or echo (reverberation) etc. is very important for having an automated robot etc. recognize remote speech in a real environment. As effective schemes for handling this problem, noise reducing schemes such as model adaptation schemes including HMM decomposition and composition or microphone array (beamformer) signal processing, spectral subtraction, etc. have been proposed. In particular, a model adaptation scheme is very effective for speech recognition in a noisy environment and its recognition performance increases in proportion to the signal-to-noise ratio (SNR). In this paper, improving the recognition performance in a low-SNR environment by receiving speech at a high SNR using a microphone array before HMM decomposition and composition is attempted. The results of speech recognition experiments conducted in a noisy environment in an acoustic laboratory show an improvement in the recognition rate of about 25% by the proposed method for the case in which the SNR in a single microphone is 0 dB, as compared with the cases of using microphone array signal processing, HMM decomposition and composition alone. In addition, the proposed method shows recognition performance comparable to the case of using cepstrum mean normalization and spectral subtraction performed with an optimal coefficient given to the speech after microphone array processing. &copy; 2002 Wiley Periodicals, Inc. Electron Comm Jpn Pt 2, 85(9): 13&ndash;22, 2002; Published online in Wiley InterScience (www.interscience. wiley.com). DOI 10.1002/ecjb.10068</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13642943&target=NART&cn=NART13642943",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech recognition based on HMM decomposition and composition method with a microphone array in noisy reverberant environments Speech recognition based on HMM decomposition and composition method with a microphone array in noisy reverberant environments Speech recognition based on HMM decomposition and composition method with a microphone array in noisy reverberant environments <P>Handling background noise or echo (reverberation) etc. is very important for having an automated robot etc. recognize remote speech in a real environment. As effective schemes for handling this problem, noise reducing schemes such as model adaptation schemes including HMM decomposition and composition or microphone array (beamformer) signal processing, spectral subtraction, etc. have been proposed. In particular, a model adaptation scheme is very effective for speech recognition in a noisy environment and its recognition performance increases in proportion to the signal-to-noise ratio (SNR). In this paper, improving the recognition performance in a low-SNR environment by receiving speech at a high SNR using a microphone array before HMM decomposition and composition is attempted. The results of speech recognition experiments conducted in a noisy environment in an acoustic laboratory show an improvement in the recognition rate of about 25% by the proposed method for the case in which the SNR in a single microphone is 0 dB, as compared with the cases of using microphone array signal processing, HMM decomposition and composition alone. In addition, the proposed method shows recognition performance comparable to the case of using cepstrum mean normalization and spectral subtraction performed with an optimal coefficient given to the speech after microphone array processing. &copy; 2002 Wiley Periodicals, Inc. Electron Comm Jpn Pt 2, 85(9): 13&ndash;22, 2002; Published online in Wiley InterScience (www.interscience. wiley.com). DOI 10.1002/ecjb.10068</P>"
        },
        {
          "rank": 47,
          "score": 0.7069128751754761,
          "doc_id": "JAKO202011263332681",
          "title": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용",
          "abstract": "가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202011263332681&target=NART&cn=JAKO202011263332681",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다."
        },
        {
          "rank": 48,
          "score": 0.7065266370773315,
          "doc_id": "NART48832461",
          "title": "Incorporating the voicing information into HMM-based automatic speech recognition in noisy environments",
          "abstract": "In this paper, we propose a model for the incorporation of voicing information into a speech recognition system in noisy environments. The employed voicing information is estimated by a novel method that can provide this information for each filter-bank channel and does not require information about the fundamental frequency. The voicing information is modelled by employing the Bernoulli distribution. The voicing model is obtained for each HMM state and mixture by a Viterbi-style training procedure. The proposed voicing incorporation is evaluated both within a standard model and two other models that had compensated for the noise effect, the missing-feature and the multi-conditional training model. Experiments are first performed on noisy speech data from the Aurora 2 database. Significant performance improvements are achieved when the voicing information is incorporated within the standard model as well as the noise-compensated models. The employment of voicing information is also demonstrated on a phoneme recognition task on the noise-corrupted TIMIT database and considerable improvements are observed.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART48832461&target=NART&cn=NART48832461",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Incorporating the voicing information into HMM-based automatic speech recognition in noisy environments Incorporating the voicing information into HMM-based automatic speech recognition in noisy environments Incorporating the voicing information into HMM-based automatic speech recognition in noisy environments In this paper, we propose a model for the incorporation of voicing information into a speech recognition system in noisy environments. The employed voicing information is estimated by a novel method that can provide this information for each filter-bank channel and does not require information about the fundamental frequency. The voicing information is modelled by employing the Bernoulli distribution. The voicing model is obtained for each HMM state and mixture by a Viterbi-style training procedure. The proposed voicing incorporation is evaluated both within a standard model and two other models that had compensated for the noise effect, the missing-feature and the multi-conditional training model. Experiments are first performed on noisy speech data from the Aurora 2 database. Significant performance improvements are achieved when the voicing information is incorporated within the standard model as well as the noise-compensated models. The employment of voicing information is also demonstrated on a phoneme recognition task on the noise-corrupted TIMIT database and considerable improvements are observed."
        },
        {
          "rank": 49,
          "score": 0.7037016153335571,
          "doc_id": "NART95825020",
          "title": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition",
          "abstract": "<P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95825020&target=NART&cn=NART95825020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition <P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>"
        },
        {
          "rank": 50,
          "score": 0.6993131637573242,
          "doc_id": "JAKO201115537947340",
          "title": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식",
          "abstract": "음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201115537947340&target=NART&cn=JAKO201115537947340",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다."
        }
      ]
    },
    {
      "query": "잡음 환경에서 시청각 음성인식의 인식률을 높이기 위한 통합 전략에서 신경망(NN)은 어떤 역할을 수행하나요?",
      "query_meta": {
        "type": "single_hop",
        "index": 1
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8400788307189941,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 2,
          "score": 0.7968089580535889,
          "doc_id": "DIKO0011019580",
          "title": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",
          "abstract": "음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다."
        },
        {
          "rank": 3,
          "score": 0.7508105039596558,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 4,
          "score": 0.721164882183075,
          "doc_id": "DIKO0015893049",
          "title": "도메인 적대적 신경망을 이용한 종단 간 억양음성인식",
          "abstract": "최근 딥러닝(Deep learning) 기술의 발전은 음성인식 성능 향상에 크게 기여하였다. 이러한 발전에도 불구하고 소음, 감정, 억양 등이 섞인 특정 발화에 대해서는 좋은 성능을 보이지 못하고 있다. 이 가운데 억양이 섞인 발화는 표준 발화와 비교했을 때 언어학적인 차이가 존재하는데, 이러한 차이가 억양이 섞인 발화를 인식하기 어렵게 만든다. 따라서 본 연구에서는 억양이 섞인 발화와 표준 발화 사이에 존재하는 특성의 차이를 줄이고자 도메인 적대적 신경망(Domain Adversarial Neural Network) 기법을 사용하였다. 또한, 종단 간(End-to-end) 기법을 사용하여 음성인식의 과정을 간소화하였다.&amp;#xD; 오래전부터 억양음성인식의 성능을 높이기 위한 연구는 활발히 진행되어 왔다. 2010년대 초반까지는 가우시안 혼합 모델(Gaussian Mixture Model) 기반의 최대 사후 확률(Maximum A Posteriori), 최대 우도 선형 회귀(Maximum Likelihood Linear Regression) 적응 기법이 주로 사용되었다. 하지만 딥러닝 기술이 발전하고 신경망 기반의 모델들이 주목 받기 시작하면서 가우시안 혼합 모델보다는 신경망 모델에 적합한 기법들이 사용되었다. 최근 몇 년간은 음성인식 모델에 억양에 대한 정보를 직접 삽입하는 accent embedding 기법이 많이 사용되었다. Accent embedding 기법은 억양음성인식의 성능을 향상시켰지만 몇 가지 문제점을 가지고 있다. 첫째, 억양을 분류하여 accent embedding 특징들을 만들어내는 모델을 독립적으로 만들어 훈련시켜야 하며, 해당 모델의 억양 분류 정확도가 음성인식 모델의 성능에 큰 영향을 미치기 때문에 모델을 정교하게 만들어야 하는 부담감이 있다. &amp;#xD; 둘째, 억양 분류 모델의 결과를 음성인식 모델의 추가적인 입력 특징(Input feature)으로 사용하기 때문에 음성인식 모델의 매개변수를 증가시키며 계산량 또한 증가한다는 문제가 있다. 따라서 본 연구에서는 추가적인 입력 특징이 필요하지 않고 음성인식에서 기본적으로 사용되는 특징인 주파수 정보(스펙트로그램)만을 이용하여 학습이 가능한 도메인 적대적 신경망을 기법을 제안하였다. &amp;#xD; 도메인 적대적 신경망은 소스 도메인(Source domain) 데이터와 타겟 도메인(Target domain) 데이터가 적대적으로 학습이 되면서 두 도메인 간의 분포 차이를 줄이는 것을 목적으로 한다. 본 연구의 목표인 억양음성인식에서는 표준 발화를 소스 도메인으로, 억양이 섞인 발화를 타겟 도메인으로 정하였다. 도메인 적대적 신경망은 특징 추출기(Feature extractor), 도메인 분류기(Domain classifier), 레이블 예측기(Label predictor) 총 3개의 부분망(sub-network)으로 구성된다. 각각의 부분망은 서로 다른 역할을 수행하기 때문에 신경망의 특성을 고려하여 만들어야 한다. 따라서 본 연구에서는 신경망의 특성을 고려하여 특징 추출기에는 합성곱 신경망(Convolutional Neural Network)을, 도메인 분류기에는 심층 신경망(Deep Neural Network)을, 그리고 레이블 예측기에는 양방향 게이트 순환 유닛(Bidirectional Gated Recurrent Unit)을 이용하여 도메인 적대적 신경망을 구성하였다. 또한, 레이블을 예측할 때 종단 간 기법을 활용하여 입력 데이터를 사전 분할하지 않고, 레이블 예측 이후의 후처리 작업을 없애면서 음성인식 과정을 간소화하였다.&amp;#xD; 본 연구에서 제안한 도메인 적대적 학습 기반의 억양음성인식 기법의 효과를 입증하기 위하여 Baseline 모델과 DANN 모델을 만들어 실험을 진행하였다. 실험 데이터로는 Mozilla의 Common Voice 코퍼스를 사용하였는데, Common Voice 코퍼스는 여러 언어에 대해 막대한 양의 검증된 음성파일을 오픈소스로 제공하기 때문에 음성인식 연구에서 많이 사용된다. 또한, Common Voice 코퍼스는 음성 녹음 파일과 함께 억양 정보도 같이 제공을 하기 때문에 억양음성인식 연구에 효율적으로 사용될 수 있다. &amp;#xD; Common Voice 코퍼스의 영어 데이터셋은 여러 억양의 음성파일들을 가지고 있는데, 본 연구에서는 미국 억양, 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양의 데이터를 실험에 사용하였으며, 미국 억양을 소스 도메인으로 나머지 네 개의 억양을 타겟 도메인으로 정하였다.&amp;#xD; 실험 결과 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양 모두에서 DANN 모델의 성능이 Baseline 모델보다 높은 성능을 보였다. 하지만 억양에 따라 성능 개선의 차이가 있었으며, 캐나다 억양에 비해 잉글랜드 억양과 인도 억양에서 성능이 눈에 띄게 향상되었다. 이 같은 결과는 잉글랜드 억양과 인도 억양이 소스 도메인으로 사용된 미국 억양 데이터와 언어학적으로 큰 차이가 존재하여 baseline 모델에서는 성능이 낮았으나, 도메인 적대적 학습을 통해 생성된 DANN 모델이 타겟 억양의 특성을 반영함으로써 성능이 크게 개선된 것으로 분석된다. 따라서 도메인 적대적 신경망은 소스 도메인과 타겟 도메인 사이의 분포의 차이를 줄임으로서 억양음성인식의 성능을 향상시킬 수 있음이 확인되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015893049&target=NART&cn=DIKO0015893049",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "도메인 적대적 신경망을 이용한 종단 간 억양음성인식 도메인 적대적 신경망을 이용한 종단 간 억양음성인식 도메인 적대적 신경망을 이용한 종단 간 억양음성인식 최근 딥러닝(Deep learning) 기술의 발전은 음성인식 성능 향상에 크게 기여하였다. 이러한 발전에도 불구하고 소음, 감정, 억양 등이 섞인 특정 발화에 대해서는 좋은 성능을 보이지 못하고 있다. 이 가운데 억양이 섞인 발화는 표준 발화와 비교했을 때 언어학적인 차이가 존재하는데, 이러한 차이가 억양이 섞인 발화를 인식하기 어렵게 만든다. 따라서 본 연구에서는 억양이 섞인 발화와 표준 발화 사이에 존재하는 특성의 차이를 줄이고자 도메인 적대적 신경망(Domain Adversarial Neural Network) 기법을 사용하였다. 또한, 종단 간(End-to-end) 기법을 사용하여 음성인식의 과정을 간소화하였다.&amp;#xD; 오래전부터 억양음성인식의 성능을 높이기 위한 연구는 활발히 진행되어 왔다. 2010년대 초반까지는 가우시안 혼합 모델(Gaussian Mixture Model) 기반의 최대 사후 확률(Maximum A Posteriori), 최대 우도 선형 회귀(Maximum Likelihood Linear Regression) 적응 기법이 주로 사용되었다. 하지만 딥러닝 기술이 발전하고 신경망 기반의 모델들이 주목 받기 시작하면서 가우시안 혼합 모델보다는 신경망 모델에 적합한 기법들이 사용되었다. 최근 몇 년간은 음성인식 모델에 억양에 대한 정보를 직접 삽입하는 accent embedding 기법이 많이 사용되었다. Accent embedding 기법은 억양음성인식의 성능을 향상시켰지만 몇 가지 문제점을 가지고 있다. 첫째, 억양을 분류하여 accent embedding 특징들을 만들어내는 모델을 독립적으로 만들어 훈련시켜야 하며, 해당 모델의 억양 분류 정확도가 음성인식 모델의 성능에 큰 영향을 미치기 때문에 모델을 정교하게 만들어야 하는 부담감이 있다. &amp;#xD; 둘째, 억양 분류 모델의 결과를 음성인식 모델의 추가적인 입력 특징(Input feature)으로 사용하기 때문에 음성인식 모델의 매개변수를 증가시키며 계산량 또한 증가한다는 문제가 있다. 따라서 본 연구에서는 추가적인 입력 특징이 필요하지 않고 음성인식에서 기본적으로 사용되는 특징인 주파수 정보(스펙트로그램)만을 이용하여 학습이 가능한 도메인 적대적 신경망을 기법을 제안하였다. &amp;#xD; 도메인 적대적 신경망은 소스 도메인(Source domain) 데이터와 타겟 도메인(Target domain) 데이터가 적대적으로 학습이 되면서 두 도메인 간의 분포 차이를 줄이는 것을 목적으로 한다. 본 연구의 목표인 억양음성인식에서는 표준 발화를 소스 도메인으로, 억양이 섞인 발화를 타겟 도메인으로 정하였다. 도메인 적대적 신경망은 특징 추출기(Feature extractor), 도메인 분류기(Domain classifier), 레이블 예측기(Label predictor) 총 3개의 부분망(sub-network)으로 구성된다. 각각의 부분망은 서로 다른 역할을 수행하기 때문에 신경망의 특성을 고려하여 만들어야 한다. 따라서 본 연구에서는 신경망의 특성을 고려하여 특징 추출기에는 합성곱 신경망(Convolutional Neural Network)을, 도메인 분류기에는 심층 신경망(Deep Neural Network)을, 그리고 레이블 예측기에는 양방향 게이트 순환 유닛(Bidirectional Gated Recurrent Unit)을 이용하여 도메인 적대적 신경망을 구성하였다. 또한, 레이블을 예측할 때 종단 간 기법을 활용하여 입력 데이터를 사전 분할하지 않고, 레이블 예측 이후의 후처리 작업을 없애면서 음성인식 과정을 간소화하였다.&amp;#xD; 본 연구에서 제안한 도메인 적대적 학습 기반의 억양음성인식 기법의 효과를 입증하기 위하여 Baseline 모델과 DANN 모델을 만들어 실험을 진행하였다. 실험 데이터로는 Mozilla의 Common Voice 코퍼스를 사용하였는데, Common Voice 코퍼스는 여러 언어에 대해 막대한 양의 검증된 음성파일을 오픈소스로 제공하기 때문에 음성인식 연구에서 많이 사용된다. 또한, Common Voice 코퍼스는 음성 녹음 파일과 함께 억양 정보도 같이 제공을 하기 때문에 억양음성인식 연구에 효율적으로 사용될 수 있다. &amp;#xD; Common Voice 코퍼스의 영어 데이터셋은 여러 억양의 음성파일들을 가지고 있는데, 본 연구에서는 미국 억양, 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양의 데이터를 실험에 사용하였으며, 미국 억양을 소스 도메인으로 나머지 네 개의 억양을 타겟 도메인으로 정하였다.&amp;#xD; 실험 결과 호주 억양, 캐나다 억양, 잉글랜드 억양, 인도 억양 모두에서 DANN 모델의 성능이 Baseline 모델보다 높은 성능을 보였다. 하지만 억양에 따라 성능 개선의 차이가 있었으며, 캐나다 억양에 비해 잉글랜드 억양과 인도 억양에서 성능이 눈에 띄게 향상되었다. 이 같은 결과는 잉글랜드 억양과 인도 억양이 소스 도메인으로 사용된 미국 억양 데이터와 언어학적으로 큰 차이가 존재하여 baseline 모델에서는 성능이 낮았으나, 도메인 적대적 학습을 통해 생성된 DANN 모델이 타겟 억양의 특성을 반영함으로써 성능이 크게 개선된 것으로 분석된다. 따라서 도메인 적대적 신경망은 소스 도메인과 타겟 도메인 사이의 분포의 차이를 줄임으로서 억양음성인식의 성능을 향상시킬 수 있음이 확인되었다."
        },
        {
          "rank": 5,
          "score": 0.7208656668663025,
          "doc_id": "JAKO202029462558904",
          "title": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식",
          "abstract": "특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029462558904&target=NART&cn=JAKO202029462558904",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다."
        },
        {
          "rank": 6,
          "score": 0.719289243221283,
          "doc_id": "JAKO201809242561431",
          "title": "합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델",
          "abstract": "도시 유동인구가 증가함에 따라 도시 환경 소음에 관한 연구의 중요성이 증가하고 있다. 본 연구에서는 교통상황에서 발생하는 이상 소음을 최근 환경 소음 분류 연구에서 높은 성능을 보이는 딥러닝 알고리즘을 이용하여 분류한다. 구체적으로는 타이어 제동 마찰음, 자동차 충돌음, 자동차 경적음, 정상 소음 네 개의 클래스에 대하여 합성곱 신경망을 이용하여 분류한다. 또한, 실제 교통 상황에서의 환경잡음에 강인한 분류 성능을 갖기 위해 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음을 설정하였고 이를 활용하여 분류 모델을 설계하였으며 3 dB SNR(Signal to Noise Ratio) 조건에서 88 % 이상의 분류 성능을 가진다. 제시한 교통 소음에 대하여 기존 선행연구 대비 높은 분류 성능을 보이고, 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음에 강인한 교통 소음 분류 모델을 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201809242561431&target=NART&cn=JAKO201809242561431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 합성곱 신경망 기반 환경잡음에 강인한 교통 소음 분류 모델 도시 유동인구가 증가함에 따라 도시 환경 소음에 관한 연구의 중요성이 증가하고 있다. 본 연구에서는 교통상황에서 발생하는 이상 소음을 최근 환경 소음 분류 연구에서 높은 성능을 보이는 딥러닝 알고리즘을 이용하여 분류한다. 구체적으로는 타이어 제동 마찰음, 자동차 충돌음, 자동차 경적음, 정상 소음 네 개의 클래스에 대하여 합성곱 신경망을 이용하여 분류한다. 또한, 실제 교통 상황에서의 환경잡음에 강인한 분류 성능을 갖기 위해 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음을 설정하였고 이를 활용하여 분류 모델을 설계하였으며 3 dB SNR(Signal to Noise Ratio) 조건에서 88 % 이상의 분류 성능을 가진다. 제시한 교통 소음에 대하여 기존 선행연구 대비 높은 분류 성능을 보이고, 빗소리, 바람 소리, 군중 소리의 세 가지 환경잡음에 강인한 교통 소음 분류 모델을 제안한다."
        },
        {
          "rank": 7,
          "score": 0.7175414562225342,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 8,
          "score": 0.7172502279281616,
          "doc_id": "JAKO201734964189755",
          "title": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식",
          "abstract": "본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201734964189755&target=NART&cn=JAKO201734964189755",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 주목 메커니즘 기반의 심층신경망을 이용한 음성 감정인식 본 논문에서는 주목 메커니즘 기반의 심층 신경망을 사용한 음성 감정인식 방법을 제안한다. 제안하는 방식은 CNN(Convolution Neural Networks), GRU(Gated Recurrent Unit), DNN(Deep Neural Networks)의 결합으로 이루어진 심층 신경망 구조와 주목 메커니즘으로 구성된다. 음성의 스펙트로그램에는 감정에 따른 특징적인 패턴이 포함되어 있으므로 제안하는 방식에서는 일반적인 CNN에서 컨벌루션 필터를 tuned Gabor 필터로 사용하는 GCNN(Gabor CNN)을 사용하여 패턴을 효과적으로 모델링한다. 또한 CNN과 FC(Fully-Connected)레이어 기반의 주목 메커니즘을 적용하여 추출된 특징의 맥락 정보를 고려한 주목 가중치를 구해 감정인식에 사용한다. 본 논문에서 제안하는 방식의 검증을 위해 6가지 감정에 대해 인식 실험을 진행하였다. 실험 결과, 제안한 방식이 음성 감정인식에서 기존의 방식보다 더 높은 성능을 보였다."
        },
        {
          "rank": 9,
          "score": 0.7163320183753967,
          "doc_id": "JAKO201911338887557",
          "title": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법",
          "abstract": "본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911338887557&target=NART&cn=JAKO201911338887557",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다."
        },
        {
          "rank": 10,
          "score": 0.7162022590637207,
          "doc_id": "JAKO199911921528980",
          "title": "다층회귀예측신경망의 음성인식성능에 관한 연구",
          "abstract": "4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921528980&target=NART&cn=JAKO199911921528980",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 다층회귀예측신경망의 음성인식성능에 관한 연구 4층구조의 다층퍼셉트론을 변형하여 3 종류의 다층회귀예측신경망을 구성하고, 예측차수, 두 은닉층의 뉴런개수, 연결세기의 초기치 및 전달함수 변화에 따른 각 망의 음성인식성능을 실험을 통해 각각 비교 분석한다. 실험결과에 의하면, 다층회귀신경망이 다층퍼셉트론에 비해 음성인식성능이 우수하다. 그리고 구조적으로는 상위은닉층의 출력을 하위은닉층으로 회귀할 때 인식성능이 가장 우수하며, 각 망 공히 상, 하위은닉층의 뉴런 10 혹은 15개, 예측차수 3 혹은 4차일 때 인식률이 양호하다. 학습시 연결세기의 초기치를 -0.5에서 0.5사이로 설정하고, 하위은닉층에서 단극성 시그모이드 전달함수를 사용할 때 인식성능이 더욱 향상된다."
        },
        {
          "rank": 11,
          "score": 0.7110310792922974,
          "doc_id": "JAKO201707851605473",
          "title": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표",
          "abstract": "본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201707851605473&target=NART&cn=JAKO201707851605473",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 효과적인 음성 인식 평가를 위한 심층 신경망 기반의 음성 인식 성능 지표 본 논문에서는 음성 데이터베이스를 평가하기 위해 여러 가지의 음성 특성 지표 추출 알고리즘을 설명하고 심층 신경망 기반의 새로운 음성 성능 지표 생성 방법을 제안한다. 선행 연구에서는 효과적인 음성 인식 성능 지표를 생성하기 위해 대표적인 음성 인식 성능 지표인 단어 오인식률(Word Error Rate, WER)과 상관도가 높은 여러 가지 음성 특성 지표들을 조합하여 새로운 성능 지표를 생성하였다. 생성된 음성 성능 지표는 다양한 잡음 환경에서 각 음성 특성 지표를 단독으로 사용할 때보다 단어 오인식률과 높은 상관도를 나타내어 음성 인식 성능을 예측하는데 효과적임을 입증 하였다. 본 논문에서는 심층 신경망을 기반으로 한 음성 특성 지표 추출 방법에 대해 설명하며 선행 연구에서 조합에 사용한 GMM(Gaussian Mixture Model) 음향 모델 확률 값을 심층 신경망 학습을 통해 추출한 확률 값으로 대체해 조합함으로써 단어 오인식률과 보다 높은 상관도를 갖는 것을 확인한다."
        },
        {
          "rank": 12,
          "score": 0.7103432416915894,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 13,
          "score": 0.7075982093811035,
          "doc_id": "JAKO199911921383665",
          "title": "회귀신경망을 이용한 음성인식에 관한 연구",
          "abstract": "본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921383665&target=NART&cn=JAKO199911921383665",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다."
        },
        {
          "rank": 14,
          "score": 0.706853449344635,
          "doc_id": "NPAP12270893",
          "title": "Speech Recognition in Noisy Environments with Convolutional Neural Networks",
          "abstract": "<P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12270893&target=NART&cn=NPAP12270893",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks <P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>"
        },
        {
          "rank": 15,
          "score": 0.7065582275390625,
          "doc_id": "JAKO202011263332681",
          "title": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용",
          "abstract": "가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202011263332681&target=NART&cn=JAKO202011263332681",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다."
        },
        {
          "rank": 16,
          "score": 0.7048206329345703,
          "doc_id": "JAKO200727500210663",
          "title": "신경망을 이용한 영역 행위 예측",
          "abstract": "목적 지향 대화에서 사용자의 의도는 화행과 개념열의 쌍으로 구성된 영역행위로 표현될 수 있다. 사용자 발화에 대한 영역행위 예측은 음성 인식 오류를 보정하는데 유용하며, 시스템 발화에 대한 영역행위 예측은 유연한 응답 생성에 유용하다. 본 논문에서는 신경망을 이용하여 영역행위를 예측하는 모델을 제안한다. 제안 모델은 대화 이력 벡터와 현재 영역행위를 신경망의 입력으로 사용하여 다음 영역행위를 예측한다. 실험 결과, 제안 모델은 화행 예측과 개념열 예측에서 각각 80.02%, 82.09%의 정확률을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200727500210663&target=NART&cn=JAKO200727500210663",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망을 이용한 영역 행위 예측 신경망을 이용한 영역 행위 예측 신경망을 이용한 영역 행위 예측 목적 지향 대화에서 사용자의 의도는 화행과 개념열의 쌍으로 구성된 영역행위로 표현될 수 있다. 사용자 발화에 대한 영역행위 예측은 음성 인식 오류를 보정하는데 유용하며, 시스템 발화에 대한 영역행위 예측은 유연한 응답 생성에 유용하다. 본 논문에서는 신경망을 이용하여 영역행위를 예측하는 모델을 제안한다. 제안 모델은 대화 이력 벡터와 현재 영역행위를 신경망의 입력으로 사용하여 다음 영역행위를 예측한다. 실험 결과, 제안 모델은 화행 예측과 개념열 예측에서 각각 80.02%, 82.09%의 정확률을 보였다."
        },
        {
          "rank": 17,
          "score": 0.7045219540596008,
          "doc_id": "JAKO202007650437226",
          "title": "CNN 잡음 감쇠기에서 커널 사이즈의 최적화",
          "abstract": "본 논문은 음향잡음감쇠기에서 CNN(: Convolutional Neural Network) 계층의 커널 사이즈가 성능에 미치는 영향을 위한 연구하였다 이 시스템은 기존의 적응필터를 이용하는 대신 신경망 적응예측필터를 이용한 심층학습 알고리즘으로 잡음감쇠 성능을 개선한다. 100-neuron, 16-filter CNN 필터와 오차 역전파(back propagation) 알고리즘을 이용하여 잡음이 포함된 단일입력 음성신호로부터 음성을 추정한다. 이는 음성신호가 갖는 유성음 구간에서의 준주기적 성질을 이용하는 것이다. 본 연구에서 커널 사이즈에 대한 잡음감쇠기의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 모의실험 결과, 커널 사이즈가 16 정도일 때 평균자승오차(MSE: Mean Square Error) 및 평균절대값오차(MAE: Mean Absolute Error) 값이 가장 작은 것으로 나타났으며 사이즈가 이보다 더 작거나 커지면 MSE 및 MAE 값이 증가하는 것을 볼 수 있다. 이는 음성신호의 경우 커널 사이즈가 16 정도일 때 특성을 가장 잘 포집할 수 있음을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007650437226&target=NART&cn=JAKO202007650437226",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "CNN 잡음 감쇠기에서 커널 사이즈의 최적화 CNN 잡음 감쇠기에서 커널 사이즈의 최적화 CNN 잡음 감쇠기에서 커널 사이즈의 최적화 본 논문은 음향잡음감쇠기에서 CNN(: Convolutional Neural Network) 계층의 커널 사이즈가 성능에 미치는 영향을 위한 연구하였다 이 시스템은 기존의 적응필터를 이용하는 대신 신경망 적응예측필터를 이용한 심층학습 알고리즘으로 잡음감쇠 성능을 개선한다. 100-neuron, 16-filter CNN 필터와 오차 역전파(back propagation) 알고리즘을 이용하여 잡음이 포함된 단일입력 음성신호로부터 음성을 추정한다. 이는 음성신호가 갖는 유성음 구간에서의 준주기적 성질을 이용하는 것이다. 본 연구에서 커널 사이즈에 대한 잡음감쇠기의 성능을 검증하기 위하여 Tensorflow와 Keras 라이브러리를 사용한 시뮬레이션 프로그램을 작성하고 모의실험을 수행하였다. 모의실험 결과, 커널 사이즈가 16 정도일 때 평균자승오차(MSE: Mean Square Error) 및 평균절대값오차(MAE: Mean Absolute Error) 값이 가장 작은 것으로 나타났으며 사이즈가 이보다 더 작거나 커지면 MSE 및 MAE 값이 증가하는 것을 볼 수 있다. 이는 음성신호의 경우 커널 사이즈가 16 정도일 때 특성을 가장 잘 포집할 수 있음을 알 수 있다."
        },
        {
          "rank": 18,
          "score": 0.7043007612228394,
          "doc_id": "DIKO0011930560",
          "title": "시청각 음성인식을 위한 새로운 통합방법",
          "abstract": "The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011930560&target=NART&cn=DIKO0011930560",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 시청각 음성인식을 위한 새로운 통합방법 The automatic speech recognition (ASR) is one of the most interesting problems applied to human computer interaction applications; for example, spoken digit recognition for mobile environments. One of the challenges of this problem is that the accuracy of speech recognition will be decrease much if the speaker talks under noisy place such as: restaurant, subway, street… The invention of lip-reading opens a potential chance to improve the performance of recognition. Indeed, human perception considers both auditory and visual nature of speech. The speech recognition system will be more intelligible if the lip motion of speaker is available together with acoustic signal. The combined audio visual speech recognition has been proved to be able enhance the overall performance of recognition, especially under noisy environment. In general, if the two streams are available for speech recognition, they can be integrated by two ways: early integration and late integration. The early integration approach combines the features of two streams into one concatenated feature vector, and uses single classifier for recognition. The late integration approach combines the results of two separate classifiers for recognition in which the reliability of modalities is applied to summation based fusion. The late integration method shows the better performance actually through many experiments. There are several factors are considered to measure reliability including word confusability, SNR level of acoustic signal, the noise type, and illumination change in visual stream rather than the only SNR level based confidence of conventional audio visual speech recognition. In this study, we propose an effective fusion scheme for audio visual speech recognition (AVSR) in which the appropriate combination weights are measured by using an integrated reliability. The significant idea of integrated reliability is the combination of not only acoustic noise but also model confusability for audio visual reliability measurement The experimental results using Samsung AVSR database shows the improved performance of our approach compared to conventional ones. This demonstrates the effectiveness and feasibility of this invention for real speech recognition applications."
        },
        {
          "rank": 19,
          "score": 0.7041224241256714,
          "doc_id": "JAKO201120661418238",
          "title": "음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거",
          "abstract": "본 논문에서는 먼저 신경회로망의 학습에 오차역전파 학습 알고리즘을 사용하여 각 프레임에서의 음성 및 잡음 구간의 검출에 의한 음성인식 알고리즘을 제안한다. 그리고 신경회로망에 의하여 음성 및 잡음 구간의 검출에 따라서 각 프레임에서 잡음을 제거하는 스펙트럼 차감법을 제안한다. 본 실험에서는 제안한 음성인식알고리즘의 성능을 원음성에 백색잡음 및 자동차 잡음을 부가하여 인식율을 평가한다. 또한 인식시스템에 의하여 검출된 음성 및 잡음 구간을 이용하여 각 프레임에서의 스펙트럼 차감법에 의한 잡음제거의 실험결과를 나타낸다. 잡음에 의하여 오염된 음성에 대하여 신호대잡음비를 사용하여 본 알고리즘이 유효하다는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201120661418238&target=NART&cn=JAKO201120661418238",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 음성 및 잡음 인식 알고리즘을 이용한 환경 배경잡음의 제거 본 논문에서는 먼저 신경회로망의 학습에 오차역전파 학습 알고리즘을 사용하여 각 프레임에서의 음성 및 잡음 구간의 검출에 의한 음성인식 알고리즘을 제안한다. 그리고 신경회로망에 의하여 음성 및 잡음 구간의 검출에 따라서 각 프레임에서 잡음을 제거하는 스펙트럼 차감법을 제안한다. 본 실험에서는 제안한 음성인식알고리즘의 성능을 원음성에 백색잡음 및 자동차 잡음을 부가하여 인식율을 평가한다. 또한 인식시스템에 의하여 검출된 음성 및 잡음 구간을 이용하여 각 프레임에서의 스펙트럼 차감법에 의한 잡음제거의 실험결과를 나타낸다. 잡음에 의하여 오염된 음성에 대하여 신호대잡음비를 사용하여 본 알고리즘이 유효하다는 것을 확인한다."
        },
        {
          "rank": 20,
          "score": 0.7016726732254028,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 21,
          "score": 0.6992620229721069,
          "doc_id": "JAKO201125736640517",
          "title": "잡음환경에서의 Noise Cancel DTW를 이용한 음성인식에 관한 연구",
          "abstract": "본 논문에서는 잡음 환경에서의 음성인식 개선에 관한 내용으로 기존의 DTW에서 일종의 특징보상기법을 적용한 방식으로 예측잡음이 아닌 실생활에서의 음성잡음 데이터를 적용하여 인식모델을 잡음상황에 맞도록 적응시키는 방법으로 제안하는 Noise Cancel DTW를 사용하였다. 음성인식 시 주변노이즈를 고려한 참조패턴을 생성하여 특징 보상으로 인식률을 향상 시키는 방법으로 잡음 환경에서 음성 인식률을 향상 시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201125736640517&target=NART&cn=JAKO201125736640517",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음환경에서의 Noise Cancel DTW를 이용한 음성인식에 관한 연구 잡음환경에서의 Noise Cancel DTW를 이용한 음성인식에 관한 연구 잡음환경에서의 Noise Cancel DTW를 이용한 음성인식에 관한 연구 본 논문에서는 잡음 환경에서의 음성인식 개선에 관한 내용으로 기존의 DTW에서 일종의 특징보상기법을 적용한 방식으로 예측잡음이 아닌 실생활에서의 음성잡음 데이터를 적용하여 인식모델을 잡음상황에 맞도록 적응시키는 방법으로 제안하는 Noise Cancel DTW를 사용하였다. 음성인식 시 주변노이즈를 고려한 참조패턴을 생성하여 특징 보상으로 인식률을 향상 시키는 방법으로 잡음 환경에서 음성 인식률을 향상 시켰다."
        },
        {
          "rank": 22,
          "score": 0.6990220546722412,
          "doc_id": "ATN0026985104",
          "title": "영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구",
          "abstract": "In this paper, it is realized an image filter for a noise elimination using a recurrent neural networks with fuzzy. The proposed fuzzy neural networks structure is to converge weights and the number of iteration for a certain value by using basically recurrent neural networks structure and is simplified computation and complexity of mathematics by applying the hybrid fuzzy membership function operator.In this paper, the proposed method, the recurrent neural networks applying fuzzy which is collected a certain value, has been proved improving average 0.38dB than the conventional method, the generalied recurrent neural networks, by using PSNR. Also, a result image of the proposed method was similar to the original image than a result image of the conventional method by comparing to visual images.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0026985104&target=NART&cn=ATN0026985104",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 영상 잡음 제거 필터를 위한 퍼지 순환 신경망 연구 In this paper, it is realized an image filter for a noise elimination using a recurrent neural networks with fuzzy. The proposed fuzzy neural networks structure is to converge weights and the number of iteration for a certain value by using basically recurrent neural networks structure and is simplified computation and complexity of mathematics by applying the hybrid fuzzy membership function operator.In this paper, the proposed method, the recurrent neural networks applying fuzzy which is collected a certain value, has been proved improving average 0.38dB than the conventional method, the generalied recurrent neural networks, by using PSNR. Also, a result image of the proposed method was similar to the original image than a result image of the conventional method by comparing to visual images."
        },
        {
          "rank": 23,
          "score": 0.6971805095672607,
          "doc_id": "JAKO201115537947340",
          "title": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식",
          "abstract": "음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201115537947340&target=NART&cn=JAKO201115537947340",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 멀티밴드 스펙트럼 차감법과 엔트로피 하모닉을 이용한 잡음환경에 강인한 분산음성인식 음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널에 의한 왜곡이다. 일반적으로 잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 많이 받고 있다. DSR(Distributed Speech Recognition) 기반의 음성인식 역시 이 같은 문제로 성능 향상에 어려움을 겪고 있다. 이 논문은 잡음환경에서 DSR기반의 음성인식률 향상을 위해 정확한 음성구간을 검출하고, 잡음을 제거하여 잡음에 강인한 특징추출을 하도록 설계하였다. 제안된 방법은 엔트로피와 음성의 하모닉을 이용해 음성구간을 검출하며 멀티밴드 스펙트럼 차감법을 이용하여 잡음을 제거한다. 음성의 스펙트럼 에너지에 대한 엔트로피를 사용하여 음성검출을 하게 되면 비교적 높은 SNR 환경 (SNR 15dB) 에서는 성능이 우수하나 잡음환경의 변화에 따라 음성과 비음성의 문턱 값이 변화하여 낮은 SNR환경(SNR 0dB)에시는 정확한 음성 검출이 어렵다. 이 논문은 낮은 SNR 환경(0dB)에서도 정확한 음성을 검출할 수 있도록 음성의 스펙트럴 엔트로피와 하모닉 성분을 이용하였으며 정확한 음성 구간 검출에 따라 잡음을 제거하여 잡음에 강인한 특정을 추출하도록 하였다. 실험결과 잡음환경에 따른 인식조건에서 개선된 인식성능을 보였다."
        },
        {
          "rank": 24,
          "score": 0.6966446042060852,
          "doc_id": "DIKO0007842188",
          "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
          "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
        },
        {
          "rank": 25,
          "score": 0.6919717788696289,
          "doc_id": "JAKO201016450104831",
          "title": "잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법",
          "abstract": "음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널잡음에 의한 왜곡이다. 일반적으로 배경잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 받게 한다. DSR (Distributed Speech Recognition) 기반의 음성인식 역시 이와 같은 문제로 성능 향상에 어려움을 겪고 있다. 이러한 문제를 해결하기 위해 다양한 잡음제거 알고리듬이 사용되고 있으나 낮은 SNR환경에서 부정확한 잡음추정으로 발생하는 스펙트럼 손상과 잔존 잡음은 음성인식기의 인식환경과 학습 환경의 불일치를 만들게 되어 인식률을 저하시키는 원인이 된다. 본 논문에서는 이와 같은 문제를 해결하기 위해 잡음제거 알고리듬으로 MMSE-STSA 방법을 사용하였고 손상된 스펙트럼을 보상하기 위해 Ideal Binary Mask를 이용하였다. 잡음환경 (SNR 15 ~ 0 dB)에 따른 실험결과 제안된 방법을 사용했을 때 향상된 스펙트럼을 얻을 수 있었고 향상된 인식성능을 확인했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201016450104831&target=NART&cn=JAKO201016450104831",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 잡음환경에서 음성인식 성능향상을 위한 바이너리 마스크를 이용한 스펙트럼 향상 방법 음성인식의 실용화에 가장 저해되는 요소는 배경잡음과 채널잡음에 의한 왜곡이다. 일반적으로 배경잡음은 음성인식 시스템의 성능을 저하시키고 이로 인해 사용 장소의 제약을 받게 한다. DSR (Distributed Speech Recognition) 기반의 음성인식 역시 이와 같은 문제로 성능 향상에 어려움을 겪고 있다. 이러한 문제를 해결하기 위해 다양한 잡음제거 알고리듬이 사용되고 있으나 낮은 SNR환경에서 부정확한 잡음추정으로 발생하는 스펙트럼 손상과 잔존 잡음은 음성인식기의 인식환경과 학습 환경의 불일치를 만들게 되어 인식률을 저하시키는 원인이 된다. 본 논문에서는 이와 같은 문제를 해결하기 위해 잡음제거 알고리듬으로 MMSE-STSA 방법을 사용하였고 손상된 스펙트럼을 보상하기 위해 Ideal Binary Mask를 이용하였다. 잡음환경 (SNR 15 ~ 0 dB)에 따른 실험결과 제안된 방법을 사용했을 때 향상된 스펙트럼을 얻을 수 있었고 향상된 인식성능을 확인했다."
        },
        {
          "rank": 26,
          "score": 0.6918733716011047,
          "doc_id": "JAKO201935164467523",
          "title": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구",
          "abstract": "본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201935164467523&target=NART&cn=JAKO201935164467523",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다."
        },
        {
          "rank": 27,
          "score": 0.6874986886978149,
          "doc_id": "JAKO200011920771446",
          "title": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축",
          "abstract": "본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920771446&target=NART&cn=JAKO200011920771446",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 건설적 선택학습 신경망을 이용한 앙상블 머신의 구축 본 논문에서는 효과적인 앙상블 머신의 구축을 위한 새로운 방안을 제시한다. 효과적인 앙상블의 구축을 위해서는 앙상블 멤버들간의 상관관계가 아주 낮아야 하며 또한 각 앙상블 멤버들은 전체 문제를 어느 정도는 정확하게 학습하면서도 서로들간의 불일치 하는 부분이 존재해야 한다는 것이 여러 논문들에 발표되었다. 본 논문에서는 주어진 문제의 다양한 면을 학습한 다수의 앙상블 후보 네트웍을 생성하기 위하여 건설적 학습 알고리즘과 능동 학습 알고리즘을 결합한 형태의 신경망 학습 알고리즘을 이용한다. 이 신경망의 학습은 최소 은닉 노드에서 최대 은닉노드까지 점진적으로 은닉노드를 늘려나감과 동시에 후보 데이타 집합에서 학습에 사용할 훈련 데이타를 점진적으로 선택해 나가면서 이루어진다. 은닉 노드의 증가시점에서 앙상블의 후부 네트웍이 생성된다. 이러한 한 차례의 학습 진행을 한 chain이라 정의한다. 다수의 chain을 통하여 다양한 형태의 네트웍 크기와 다양한 형태의 데이타 분포를 학습한 후보 내트웍들이 생성된다. 이렇게 생성된 후보 네트웍들은 확률적 비례 선택법에 의해 선택된 후 generalized ensemble method (GEM)에 의해 결합되어 최종적인 앙상블 성능을 보여준다. 제안된 알고리즘은 한개의 인공 데이타와 한 개의 실세계 데이타에 적용되었다. 실험을 통하여 제안된 알고리즘에 의해 구성된 앙상블의 최대 일반화 성능은 다른 알고리즘에 의한 그것보다 우수함을 알 수 있다."
        },
        {
          "rank": 28,
          "score": 0.6868298053741455,
          "doc_id": "NART80772700",
          "title": "Noisy training for deep neural networks in speech recognition",
          "abstract": "<P><B>Abstract</B><P>Deep neural networks (DNNs) have gained remarkable success in speech recognition, partially attributed to the flexibility of DNN models in learning complex patterns of speech signals. This flexibility, however, may lead to serious over-fitting and hence miserable performance degradation in adverse acoustic conditions such as those with high ambient noises. We propose a noisy training approach to tackle this problem: by injecting moderate noises into the training data intentionally and randomly, more generalizable DNN models can be learned. This &lsquo;noise injection&rsquo; technique, although known to the neural computation community already, has not been studied with DNNs which involve a highly complex objective function. The experiments presented in this paper confirm that the noisy training approach works well for the DNN model and can provide substantial performance improvement for DNN-based speech recognition.</P></P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART80772700&target=NART&cn=NART80772700",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy training for deep neural networks in speech recognition Noisy training for deep neural networks in speech recognition Noisy training for deep neural networks in speech recognition <P><B>Abstract</B><P>Deep neural networks (DNNs) have gained remarkable success in speech recognition, partially attributed to the flexibility of DNN models in learning complex patterns of speech signals. This flexibility, however, may lead to serious over-fitting and hence miserable performance degradation in adverse acoustic conditions such as those with high ambient noises. We propose a noisy training approach to tackle this problem: by injecting moderate noises into the training data intentionally and randomly, more generalizable DNN models can be learned. This &lsquo;noise injection&rsquo; technique, although known to the neural computation community already, has not been studied with DNNs which involve a highly complex objective function. The experiments presented in this paper confirm that the noisy training approach works well for the DNN model and can provide substantial performance improvement for DNN-based speech recognition.</P></P>"
        },
        {
          "rank": 29,
          "score": 0.6866621375083923,
          "doc_id": "JAKO199215875841266",
          "title": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교",
          "abstract": "음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199215875841266&target=NART&cn=JAKO199215875841266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식 신경망을 위한 음성 파라키터들의 성능 비교 음성 인식에 신경망 모델을 적용하는 많은 연구들이 있었지만, 주된 관심은 음성인식에 적합한 구조와 학습 방법이었다.  그러나 음성인식에 신경망 모델을 적용한 시스템의 효율 향상은 모델 자체의 구조뿐 아니라, 신경망 모델의 입력으로 어떤 음성 파라미터를 사용하는가에 따라서도 큰 영향을 받는다.  본 논문은 기존 음성인식에 신경망 모델을 적용한 많은 연구들에서 사용한 음성 파라미터를 살펴보고, 대표적인 음성 파라미터 6개를 선정하여, 같은 데이타와 같은 신경망 모델 하에서 어떻게 성능이 달라지는지를 분석한다.  인식 실험에 있어서는 한국어 파열음 9개에 대한 8개 데이터 집합과 모음 8개에 대한 18개 데이터 집합을 음성 파라미터로 하고 신경망 모델은 순환 신경망 모델을 사용하여 노드의 수를 일정하게 한뒤 다양한 입력 파라미터의 성능을 비교하였다.  그 결과 선형 예측 계수로부터 얻어진 delta cepstrum의 음성 파라미터가 가장 좋은 성능을 보였으며 이때 인식률은 같은 학습 데이터에 대해 파열음 100.0%, 모음 95.1%이었다."
        },
        {
          "rank": 30,
          "score": 0.6859487295150757,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 31,
          "score": 0.6848316192626953,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 32,
          "score": 0.682497501373291,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 33,
          "score": 0.6752161979675293,
          "doc_id": "JAKO201719951669089",
          "title": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링",
          "abstract": "This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201719951669089&target=NART&cn=JAKO201719951669089",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 원어민 및 외국인 화자의 음성인식을 위한 심층 신경망 기반 음향모델링 This paper proposes a new method to train Deep Neural Network (DNN)-based acoustic models for speech recognition of native and foreign speakers. The proposed method consists of determining multi-set state clusters with various acoustic properties, training a DNN-based acoustic model, and recognizing speech based on the model. In the proposed method, hidden nodes of DNN are shared, but output nodes are separated to accommodate different acoustic properties for native and foreign speech. In an English speech recognition task for speakers of Korean and English respectively, the proposed method is shown to slightly improve recognition accuracy compared to the conventional multi-condition training method."
        },
        {
          "rank": 34,
          "score": 0.6749303936958313,
          "doc_id": "JAKO202007163147892",
          "title": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발",
          "abstract": "전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202007163147892&target=NART&cn=JAKO202007163147892",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 심층강화학습을 이용한 Convolutional Network 기반 전산화단층영상 잡음 저감 기술 개발 전산화단층영상 품질 개선을 위해 사용되는 지도학습 기반의 딥러닝 기술은 사전 학습을 위해 많은 양의 데이터를 필요로 하는 단점이 있다. 또한 지도학습 기반의 딥러닝 기술은 학습에 사용된 영상의 특징과 학습된 모델에 입력된 영상의 특징이 다른 경우 영상 내부 구조적 왜곡이 유발되는 한계점이 있다. 본 연구에서는 기존 지도학습 기반 딥러닝 기술의 단점을 보완하고 전산화단층영상의 잡음을 감소시킬 수 있는 심층강화학습 기반 영상화 모델을 개발하였다. 심층강화학습 기반 영상화 모델은 shared, value 및 policy 네트워크로 구성하였으며, 영상 잡음 특징 추출 및 모델의 성능 향상을 위해 합성곱, rectified linear unit(ReLU) 활성화 함수, dilation factor 및 게이트순환유닛을 사용하였다. 또한 기존 지도학습 기반 딥러닝 기술을 통해 획득한 영상의 영상품질 비교를 통해 본 연구에서 개발한 영상화 모델의 성능을 평가하였다. 연구결과 기존 기술에 비해 본 연구에서 개발한 영상화 모델 적용 시 전산화단층영상의 정량적 정확도는 큰 폭으로 향상, 잡음은 큰 폭으로 감소함을 확인하였다. 또한 영상화 모델 학습 시 사용한 영상과 구조적 특징이 다른 영상에 대해서도 잡음 감소 효과를 확인하였다. 따라서 본 연구에서 개발한 심층강화학습 기반 영상화 모델을 통해 전산화단층영상의 구조적 특징을 보전함과 동시에 잡음을 감소시킬 수 있다."
        },
        {
          "rank": 35,
          "score": 0.673776388168335,
          "doc_id": "JAKO201630932328344",
          "title": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법",
          "abstract": "실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201630932328344&target=NART&cn=JAKO201630932328344",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다."
        },
        {
          "rank": 36,
          "score": 0.6727384328842163,
          "doc_id": "JAKO199900842577131",
          "title": "다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화",
          "abstract": "이 논문에서는 오차 역전파 학습 알고리듬의 학습 속도를 향상시키기 위한 새로운 학습 방법을 제안한다. 제안하고자 하는 방법은 시그모이드 형태를 갖는 신경회로망의 활성화 함수(activation function) 자체에 고차항(higher order)을 적절히 이용하여 초기 학습 단계에서 발생할 수 있는 조기 포화(premature saturation) 현상을 계산량의 큰 증가 없이 효과적으로 대처할 수 있다. 고차항을 이용함으로써 은닉층 활성화 함수의 도합수가 작은 값으로 감소함에 따라 신경망의 연결 강도를 학습시키는 학습율은 적응적으로 큰 값을 갖게 된다. 또한, 은닉층에 고차항을 이용하는 제안한 방법에 모멘텀(momentum) 학습 알고리듬을 결합하는 새로운 hybrid 학습 방법을 제안한다. 컴퓨터 모의 실험을 통해 제안하고자 하는 학습 방법과 기존의 방법들과의 학습 속도 성능을 비교한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199900842577131&target=NART&cn=JAKO199900842577131",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 다층 구조 신경회로망의 학습 속도 향상을 위한 활성화 함수의 변화 이 논문에서는 오차 역전파 학습 알고리듬의 학습 속도를 향상시키기 위한 새로운 학습 방법을 제안한다. 제안하고자 하는 방법은 시그모이드 형태를 갖는 신경회로망의 활성화 함수(activation function) 자체에 고차항(higher order)을 적절히 이용하여 초기 학습 단계에서 발생할 수 있는 조기 포화(premature saturation) 현상을 계산량의 큰 증가 없이 효과적으로 대처할 수 있다. 고차항을 이용함으로써 은닉층 활성화 함수의 도합수가 작은 값으로 감소함에 따라 신경망의 연결 강도를 학습시키는 학습율은 적응적으로 큰 값을 갖게 된다. 또한, 은닉층에 고차항을 이용하는 제안한 방법에 모멘텀(momentum) 학습 알고리듬을 결합하는 새로운 hybrid 학습 방법을 제안한다. 컴퓨터 모의 실험을 통해 제안하고자 하는 학습 방법과 기존의 방법들과의 학습 속도 성능을 비교한다."
        },
        {
          "rank": 37,
          "score": 0.671798825263977,
          "doc_id": "JAKO201721558887385",
          "title": "벌크 지표의 신경망 학습에 기반한 한국어 모음 'ㅡ'의 음성 인식",
          "abstract": "음성 인식은 HCI 분야에서 널리 사용되는 기술 중 하나이다. 가정 자동화, 자동 통역, 차량 내비게이션 등 음성 인식 기술이 적용될 수 있는 많은 응용들이 현재 개발되고 있다. 또한, 모바일 환경에서 작동 가능한 음성 인식 시스템에 대한 수요도 급속히 증대되고 있다. 본 논문은 한국어 음성 인식 시스템의 일부로서, 한국어 모음 'ㅡ'를 빠르게 인식할 수 있는 방안을 제시한다. 제안하는 방식은 주파수 영역 대신, 시간 영역에서 계산되는 지표인 벌크 지표를 사용하므로, 인식을 위한 계산 비용을 절감할 수 있다. 모음 'ㅡ'의 전형적인 시퀀스 패턴들을 표현하는 벌크 지표들에 대한 신경망 학습을 수행하며, 최종적인 인식을 위해 학습된 신경망을 사용한다. 실험 결과를 통해, 제안하는 방식이 모음 'ㅡ'를 88.7%의 정확도로 인식할 수 있음을 확인하였고, 인식 속도는 어절 당 0.74msec이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721558887385&target=NART&cn=JAKO201721558887385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "벌크 지표의 신경망 학습에 기반한 한국어 모음 'ㅡ'의 음성 인식 벌크 지표의 신경망 학습에 기반한 한국어 모음 'ㅡ'의 음성 인식 벌크 지표의 신경망 학습에 기반한 한국어 모음 'ㅡ'의 음성 인식 음성 인식은 HCI 분야에서 널리 사용되는 기술 중 하나이다. 가정 자동화, 자동 통역, 차량 내비게이션 등 음성 인식 기술이 적용될 수 있는 많은 응용들이 현재 개발되고 있다. 또한, 모바일 환경에서 작동 가능한 음성 인식 시스템에 대한 수요도 급속히 증대되고 있다. 본 논문은 한국어 음성 인식 시스템의 일부로서, 한국어 모음 'ㅡ'를 빠르게 인식할 수 있는 방안을 제시한다. 제안하는 방식은 주파수 영역 대신, 시간 영역에서 계산되는 지표인 벌크 지표를 사용하므로, 인식을 위한 계산 비용을 절감할 수 있다. 모음 'ㅡ'의 전형적인 시퀀스 패턴들을 표현하는 벌크 지표들에 대한 신경망 학습을 수행하며, 최종적인 인식을 위해 학습된 신경망을 사용한다. 실험 결과를 통해, 제안하는 방식이 모음 'ㅡ'를 88.7%의 정확도로 인식할 수 있음을 확인하였고, 인식 속도는 어절 당 0.74msec이다."
        },
        {
          "rank": 38,
          "score": 0.6717950105667114,
          "doc_id": "JAKO202211540138171",
          "title": "기계학습에 의한 후두 장애음성 식별기의 성능 비교",
          "abstract": "본 논문은 후두 장애음성 데이터의 식별률을 CNN과 기계학습 앙상블 학습 방법에 의해 개선하는 방법에 대한 연구이다. 일반적으로 후두 장애음성 데이터는 그 수가 적으므로 통계적 방법에 의해 식별기가 구성되더라도, 훈련 방식에 따라 과적합으로 인해 일어나는 현상으로 인해 외부 데이터에 노출될 시 식별률의 저하가 발생할 수 있다. 본 연구에서는 다양한 정확도를 갖도록 훈련된 CNN 모델과 기계학습 모델로부터 도출된 결과를 다중 투표 방식으로 결합하여 원래의 훈련된 모델에 비해 향상된 분류 효율을 갖도록 하는 방법과 함께, 기존의 기계학습 중 앙상블 방법을 적용해 보고 그 결과를 확인하였다. 알고리즘을 훈련하고 검증하기 위해 PNUH(Pusan National University Hospital) 데이터셋을 이용하였다. 데이터셋에는 정상음성과 양성종양 및 악성 종양의 음성 데이터가 포함되어 있다. 실험에서는 정상 및 양성 종양과 악성종양을 구분하는 시도를 하였다. 실험결과 random forest 방법이 가장 우수한 앙상블 방법으로 나타났으며 85%의 식별률을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202211540138171&target=NART&cn=JAKO202211540138171",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기계학습에 의한 후두 장애음성 식별기의 성능 비교 기계학습에 의한 후두 장애음성 식별기의 성능 비교 기계학습에 의한 후두 장애음성 식별기의 성능 비교 본 논문은 후두 장애음성 데이터의 식별률을 CNN과 기계학습 앙상블 학습 방법에 의해 개선하는 방법에 대한 연구이다. 일반적으로 후두 장애음성 데이터는 그 수가 적으므로 통계적 방법에 의해 식별기가 구성되더라도, 훈련 방식에 따라 과적합으로 인해 일어나는 현상으로 인해 외부 데이터에 노출될 시 식별률의 저하가 발생할 수 있다. 본 연구에서는 다양한 정확도를 갖도록 훈련된 CNN 모델과 기계학습 모델로부터 도출된 결과를 다중 투표 방식으로 결합하여 원래의 훈련된 모델에 비해 향상된 분류 효율을 갖도록 하는 방법과 함께, 기존의 기계학습 중 앙상블 방법을 적용해 보고 그 결과를 확인하였다. 알고리즘을 훈련하고 검증하기 위해 PNUH(Pusan National University Hospital) 데이터셋을 이용하였다. 데이터셋에는 정상음성과 양성종양 및 악성 종양의 음성 데이터가 포함되어 있다. 실험에서는 정상 및 양성 종양과 악성종양을 구분하는 시도를 하였다. 실험결과 random forest 방법이 가장 우수한 앙상블 방법으로 나타났으며 85%의 식별률을 보였다."
        },
        {
          "rank": 39,
          "score": 0.6717081069946289,
          "doc_id": "JAKO202311540154298",
          "title": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색",
          "abstract": "본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202311540154298&target=NART&cn=JAKO202311540154298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 그래프 합성곱-신경망 구조 탐색 : 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 본 논문은 그래프 합성곱 신경망을 이용한 신경망 구조 탐색 모델 설계를 제안한다. 딥 러닝은 블랙박스로 학습이 진행되는 특성으로 인해 설계한 모델이 최적화된 성능을 가지는 구조인지 검증하지 못하는 문제점이 존재한다. 신경망 구조 탐색 모델은 모델을 생성하는 순환 신경망과 생성된 네트워크인 합성곱 신경망으로 구성되어있다. 통상의 신경망 구조 탐색 모델은 순환신경망 계열을 사용하지만 우리는 본 논문에서 순환신경망 대신 그래프 합성곱 신경망을 사용하여 합성곱 신경망 모델을 생성하는 GC-NAS를 제안한다. 제안하는 GC-NAS는 Layer Extraction Block을 이용하여 Depth를 탐색하며 Hyper Parameter Prediction Block을 이용하여 Depth 정보를 기반으로 한 spatial, temporal 정보(hyper parameter)를 병렬적으로 탐색합니다. 따라서 Depth 정보를 반영하기 때문에 탐색 영역이 더 넓으며 Depth 정보와 병렬적 탐색을 진행함으로 모델의 탐색 영역의 목적성이 분명하기 때문에 GC-NAS대비 이론적 구조에 있어서 우위에 있다고 판단된다. GC-NAS는 그래프 합성곱 신경망 블록 및 그래프 생성 알고리즘을 통하여 기존 신경망 구조 탐색 모델에서 순환 신경망이 가지는 고차원 시간 축의 문제와 공간적 탐색의 범위 문제를 해결할 것으로 기대한다. 또한 우리는 본 논문이 제안하는 GC-NAS를 통하여 신경망 구조 탐색에 그래프 합성곱 신경망을 적용하는 연구가 활발히 이루어질 수 있는 계기가 될 수 있기를 기대한다."
        },
        {
          "rank": 40,
          "score": 0.6705964803695679,
          "doc_id": "NART133898062",
          "title": "Hidden Markov Neural Networks",
          "abstract": "<P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133898062&target=NART&cn=NART133898062",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Neural Networks Hidden Markov Neural Networks Hidden Markov Neural Networks <P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>"
        },
        {
          "rank": 41,
          "score": 0.6669025421142578,
          "doc_id": "JAKO202106153179641",
          "title": "뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출",
          "abstract": "뇌파(electroencephalogram, EEG)를 이용한 진단이 확대되면서 EEG 신호를 자동으로 분류하기 위한 다양한 연구가 활발히 이루어지고 있다. 본 논문은 일반인과 뇌전증 환자에게서 추출한 EEG 신호를 효과적으로 식별할 수 있는 CNN 모델을 제안한다. CNN의 학습에 필요한 데이터를 확장하기 위하여 EEG 신호를 낮은 차원의 신호로 분할하고, 이것을 다시 여러 개의 세그먼트로 중첩 분할하여 CNN 학습에 이용한다. 이와 더불어 CNN의 성능을 개선하기 위하여 CNN 앙상블 전략을 제안한다. 공개된 Bonn 데이터세트로 실험을 수행한 결과 뇌전증 발작을 99.0% 이상의 정확도로 검출하였고, 앙상블 방식에 의해 3-클래스와 5-클래스의 EEG 분류에서 정확도가 향상되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202106153179641&target=NART&cn=JAKO202106153179641",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출 뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출 뇌파의 중첩 분할에 기반한 CNN 앙상블 모델을 이용한 뇌전증 발작 검출 뇌파(electroencephalogram, EEG)를 이용한 진단이 확대되면서 EEG 신호를 자동으로 분류하기 위한 다양한 연구가 활발히 이루어지고 있다. 본 논문은 일반인과 뇌전증 환자에게서 추출한 EEG 신호를 효과적으로 식별할 수 있는 CNN 모델을 제안한다. CNN의 학습에 필요한 데이터를 확장하기 위하여 EEG 신호를 낮은 차원의 신호로 분할하고, 이것을 다시 여러 개의 세그먼트로 중첩 분할하여 CNN 학습에 이용한다. 이와 더불어 CNN의 성능을 개선하기 위하여 CNN 앙상블 전략을 제안한다. 공개된 Bonn 데이터세트로 실험을 수행한 결과 뇌전증 발작을 99.0% 이상의 정확도로 검출하였고, 앙상블 방식에 의해 3-클래스와 5-클래스의 EEG 분류에서 정확도가 향상되었다."
        },
        {
          "rank": 42,
          "score": 0.6648138165473938,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 43,
          "score": 0.6625422239303589,
          "doc_id": "DIKO0017114224",
          "title": "딥러닝을 활용한 초음파 영상 개선",
          "abstract": "의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017114224&target=NART&cn=DIKO0017114224",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 딥러닝을 활용한 초음파 영상 개선 의료용 초음파 이미지(Clinical Ultrasonic Image) 기법은 인체 내부의 대한 영상을 비침습적, 안전적, 실시간적 있는 도구로, 의료 분야에서 사용되는 대표적인 진단 의료 영상 중 하나이다. 초고속 초음파(Ultra-fast Ultrasound)는 다수의 초음파 송수신을 통하여 상대적으로 고품질의 초음파 이미지를 얻을 수 있다. 그러나, 초음파 빔의 다양성, 복원 이미지의 해상도, 관심 영역(Region of Interest)의 크기 등은 실시간성과 절충 관계(Trade-off)에 있기에 초당 프레임 수(FPS)를 방어하기에 하드웨어적으로 어려움이 있다. 본 연구에서는 딥러닝(Deep Learning) 모델을 활용하여 단일 평면파(Single Plane-wave)의 저품질의 초음파 이미지를 고품질 다중 평면파(Multi-angle Plane-wave)의 고품질 초음파 이미지로 강화하는 것을 목표로 한다. U-Net 구조로 이루어진 딥러닝 모델은 다양한 크기의 합성곱 필터를 이용하여 복잡한 이미지의 세부 정보의 특징을 효과적으로 추출할 수 있다. 제안된 딥러닝 모델은 피크 대 잡음 비율(PSNR), 신호 대 잡음 비율(SNR), 스페클 신호 대 잡음 비율(SSNR) 등의 성능 지표를 통해 효과적인 잡음 감소 및 신호 보존을 보였으며, 상관계수(Correlation)를 통하여 강화된 이미지와 실제 이미지 간의 높은 유사성 및 정확성을 보였다. 향후 연구로는 본 작업에 영향을 줄 수 있는 세부 요인들을 조사하고, 모델 구조를 세밀하게 조정 및 최적화하여 강화되는 이미지의 품질을 더욱 향상시키고, 보다 다양한 부위에 대한 실험을 통해 일반화 성능을 확장할 수 있다."
        },
        {
          "rank": 44,
          "score": 0.6624674797058105,
          "doc_id": "NART37979687",
          "title": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network",
          "abstract": "<P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART37979687&target=NART&cn=NART37979687",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network <P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>"
        },
        {
          "rank": 45,
          "score": 0.6611639261245728,
          "doc_id": "NART75359998",
          "title": "Artificial Neural Networks Applied to Image Steganography",
          "abstract": "<P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART75359998&target=NART&cn=NART75359998",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography Artificial Neural Networks Applied to Image Steganography <P>This paper presents a technique for transmitting information efficiently and securely, hiding confidential messages on seemingly innocent messages using steganography. The insertion technique in the least significant bit is used to insert images into digital pictures or other secret watermark. Artificial Neural Networks are used in the process of withdrawal of encrypted information acting as keys that determine the existence of hidden information.</P>"
        },
        {
          "rank": 46,
          "score": 0.6606994867324829,
          "doc_id": "JAKO200614222983757",
          "title": "Missing-Feature 복구를 위한 대역 독립 방식의 베이시안 분류기 기반 마스크 예측 기법",
          "abstract": "본 논문에서는 알려지지 않은 잡음 환경에서 강인한 음성 인식 성능을 위하여 missing-feature복구 기법을 다루며, 베이시안 분류기를 기반으로 하는 마스크 예측 기법의 성능을 향상시킬 수 있는 방법을 제안한다. 기존의 마스크 예측 기법에서는 배경 잡음 종류에 독립적인 성능을 위해 전 주파수 대역을 분할하여 발생시킨 유색 잡음을 마스크 예측기의 훈련에 이용하였으나, 제한된 양의 훈련 데이터베이스 조건에서는 성능의 한계가 불가피하다. 보다 다양한 잡음 스펙트럼을 반영하면서 마스크 예측의 성능을 향상시키기 위해, 서로 다른 주파수 대역에 독립적인 구조를 가지는 베이시안 분류기를 제안하며, 훈련에 사용하는 유색 잡음의 생성 방식을 이에 맞게 수정한다. 각각의 주파수 대역을 분할하여 유색 잡음을 생성함으로써 다양한 잡음 환경을 반영하는 동시에 훈련 데이터베이스 부족 문제를 줄일 수 있다. 제안하는 마스크 예측 기법을 클러스터 기반의 missing-feature 복구 기법과 결합하여 음성 인식기에 적용함으로써 성능을 평가한다. 실험 결과는 제안한 기법이 백색 잡음, 자동차잡음, 배경 음악환경에서 기존의 방법에 비해 향상된 성능을 가짐을 입증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200614222983757&target=NART&cn=JAKO200614222983757",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Missing-Feature 복구를 위한 대역 독립 방식의 베이시안 분류기 기반 마스크 예측 기법 Missing-Feature 복구를 위한 대역 독립 방식의 베이시안 분류기 기반 마스크 예측 기법 Missing-Feature 복구를 위한 대역 독립 방식의 베이시안 분류기 기반 마스크 예측 기법 본 논문에서는 알려지지 않은 잡음 환경에서 강인한 음성 인식 성능을 위하여 missing-feature복구 기법을 다루며, 베이시안 분류기를 기반으로 하는 마스크 예측 기법의 성능을 향상시킬 수 있는 방법을 제안한다. 기존의 마스크 예측 기법에서는 배경 잡음 종류에 독립적인 성능을 위해 전 주파수 대역을 분할하여 발생시킨 유색 잡음을 마스크 예측기의 훈련에 이용하였으나, 제한된 양의 훈련 데이터베이스 조건에서는 성능의 한계가 불가피하다. 보다 다양한 잡음 스펙트럼을 반영하면서 마스크 예측의 성능을 향상시키기 위해, 서로 다른 주파수 대역에 독립적인 구조를 가지는 베이시안 분류기를 제안하며, 훈련에 사용하는 유색 잡음의 생성 방식을 이에 맞게 수정한다. 각각의 주파수 대역을 분할하여 유색 잡음을 생성함으로써 다양한 잡음 환경을 반영하는 동시에 훈련 데이터베이스 부족 문제를 줄일 수 있다. 제안하는 마스크 예측 기법을 클러스터 기반의 missing-feature 복구 기법과 결합하여 음성 인식기에 적용함으로써 성능을 평가한다. 실험 결과는 제안한 기법이 백색 잡음, 자동차잡음, 배경 음악환경에서 기존의 방법에 비해 향상된 성능을 가짐을 입증한다."
        },
        {
          "rank": 47,
          "score": 0.6605777144432068,
          "doc_id": "JAKO200416642157049",
          "title": "Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식",
          "abstract": "In this paper, a new noise compensation method based on the eigenvoice framework in feature space is proposed to reduce the mismatch between training and testing environments. The difference between clean and noisy environments is represented by the linear combination of K eigenvectors that represent the variation among environments. In the proposed method, the performance improvement of speech recognition systems is largely affected by how to construct the noisy models and the bias vector set. In this paper, two methods, the one based on MAP adaptation method and the other using stereo DB, are proposed to construct the noisy models. In experiments using Aurora 2 DB, we obtained 44.86% relative improvement with eigen-environment method in comparison with baseline system. Especially, in clean condition training mode, our proposed method yielded 66.74% relative improvement, which is better performance than several methods previously proposed in Aurora project.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200416642157049&target=NART&cn=JAKO200416642157049",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 Eigen - Environment 잡음 보상 방법을 이용한 강인한 음성인식 In this paper, a new noise compensation method based on the eigenvoice framework in feature space is proposed to reduce the mismatch between training and testing environments. The difference between clean and noisy environments is represented by the linear combination of K eigenvectors that represent the variation among environments. In the proposed method, the performance improvement of speech recognition systems is largely affected by how to construct the noisy models and the bias vector set. In this paper, two methods, the one based on MAP adaptation method and the other using stereo DB, are proposed to construct the noisy models. In experiments using Aurora 2 DB, we obtained 44.86% relative improvement with eigen-environment method in comparison with baseline system. Especially, in clean condition training mode, our proposed method yielded 66.74% relative improvement, which is better performance than several methods previously proposed in Aurora project."
        },
        {
          "rank": 48,
          "score": 0.6600598096847534,
          "doc_id": "DIKO0014014312",
          "title": "나이브 베이즈 분류기를 이용한 분류기 통합 모델",
          "abstract": "본 연구에서는 새로운 확률적 특성을 가진 분류기 통합 모델을 제안한다. 제안하는 CIM-NB(Classifier Integration Model with Naive Bayes)은 기존의 분류기 보다 학습속도를 최소화 하면서 높은 분류정확도를 얻기 위하여 나이브 베이즈 (Naive Bayes Classifier)와 기존의 분류기 통합 모델 (Classifier Integration Model : CIM)을 결합한 모델이다. 나이브 베이즈를 지역분류기로 채택한 CIM-NB은 베이즈 이론을 기반으로 데이터의 각 특징 및 지역 분류기가 독립이라고 가정하기 때문에 특징 벡터가 클래스에 포함될 확률을 신속히 계산할 수 있고 지역 분류기의 분류 결과를 이용해 주어진 데이터의 더 정확한 클래스를 예측한다. CIM-NB의 성능을 평가하기 위해서 Iris 데이터와 Caltech 영상 이미지 데이터를 사용하는 포괄적인 실험을 진행한 결과, 본 연구에서 제안된 CIM-NB는 기존의 Conventional 이나 CIM 분류기보다 학습 속도 및 분류 정확도 측면에서 향상된 성능을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014014312&target=NART&cn=DIKO0014014312",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "나이브 베이즈 분류기를 이용한 분류기 통합 모델 나이브 베이즈 분류기를 이용한 분류기 통합 모델 나이브 베이즈 분류기를 이용한 분류기 통합 모델 본 연구에서는 새로운 확률적 특성을 가진 분류기 통합 모델을 제안한다. 제안하는 CIM-NB(Classifier Integration Model with Naive Bayes)은 기존의 분류기 보다 학습속도를 최소화 하면서 높은 분류정확도를 얻기 위하여 나이브 베이즈 (Naive Bayes Classifier)와 기존의 분류기 통합 모델 (Classifier Integration Model : CIM)을 결합한 모델이다. 나이브 베이즈를 지역분류기로 채택한 CIM-NB은 베이즈 이론을 기반으로 데이터의 각 특징 및 지역 분류기가 독립이라고 가정하기 때문에 특징 벡터가 클래스에 포함될 확률을 신속히 계산할 수 있고 지역 분류기의 분류 결과를 이용해 주어진 데이터의 더 정확한 클래스를 예측한다. CIM-NB의 성능을 평가하기 위해서 Iris 데이터와 Caltech 영상 이미지 데이터를 사용하는 포괄적인 실험을 진행한 결과, 본 연구에서 제안된 CIM-NB는 기존의 Conventional 이나 CIM 분류기보다 학습 속도 및 분류 정확도 측면에서 향상된 성능을 보여주었다."
        },
        {
          "rank": 49,
          "score": 0.6597700715065002,
          "doc_id": "NART110592194",
          "title": "뇌-컴퓨터 인터페이스 예술에서 고찰한 혼합현실 콘텐츠의 발전 방안",
          "abstract": "본 연구는 비침습형 뇌-컴퓨터 인터페이스 예술을 참조하여 뇌-컴퓨터 인터페이스 분야의 한계를 보완하고 혼합현실에서 활용될 방안을 모색하고자 한다. 즉 뇌-컴퓨터 인터페이스 음악과 미술은 심리적 거부감을 줄이는데 활용될 수 있으며, 혼합현실 기술은 비침습형 방식에서 생체신호 정보의 누락과 잡음을 개선하는데 적극 이용될 수 있다. 그 결과 뇌-인터페이스 기술은 크게 세 가지 분야의 혼합현실에서 널리 채택될 수 있을 것이다. 첫째는 의료나 헬스 케어 분야로써, 뉴로 피드백에 혼합현실을 활용하여 빠른 시각화 정보로 신속한 대응에 도움을 주고, 증강휴먼기술과 뇌-컴퓨터 인터페이스 기술을 융합하여 장애인의 신체적 제약을 극복하며, 비장애인 기존의 신체 능력을 향상시킬 수 있을 것이다. 둘째, 교육과 훈련 관련 분야에서 뇌-컴퓨터 인터페이스는 뇌파를 통한 직관적 정보 전달, 혼합현실의 시각화를 활용한 시뮬레이션, 그리고 실시간으로 상호 작용이 가능한 교육 훈련에 활용될 수 있을 것이다. 셋째, 게임을 비롯한 여가활동과 창조활동 부문에서는, 뇌-컴퓨터 인터페이스 기술에 다양한 기기착용 방식을 사용하는 혼합현실 콘텐츠를 활용하고, 뇌-컴퓨터 인터페이스기술의 오감과 바이오 매트릭스를 활용할 수 있을 것이다. 뇌- 컴퓨터 인터페이스는 사람의 신체나 정서 상태에 따라 사람들 또는 기계들과 서로 교감하도록 상호 작용을 통한 자연스러운 친근감을 주는 혼합 현실 기술과 함께 발전할 것으로 예상된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART110592194&target=NART&cn=NART110592194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "뇌-컴퓨터 인터페이스 예술에서 고찰한 혼합현실 콘텐츠의 발전 방안 뇌-컴퓨터 인터페이스 예술에서 고찰한 혼합현실 콘텐츠의 발전 방안 뇌-컴퓨터 인터페이스 예술에서 고찰한 혼합현실 콘텐츠의 발전 방안 본 연구는 비침습형 뇌-컴퓨터 인터페이스 예술을 참조하여 뇌-컴퓨터 인터페이스 분야의 한계를 보완하고 혼합현실에서 활용될 방안을 모색하고자 한다. 즉 뇌-컴퓨터 인터페이스 음악과 미술은 심리적 거부감을 줄이는데 활용될 수 있으며, 혼합현실 기술은 비침습형 방식에서 생체신호 정보의 누락과 잡음을 개선하는데 적극 이용될 수 있다. 그 결과 뇌-인터페이스 기술은 크게 세 가지 분야의 혼합현실에서 널리 채택될 수 있을 것이다. 첫째는 의료나 헬스 케어 분야로써, 뉴로 피드백에 혼합현실을 활용하여 빠른 시각화 정보로 신속한 대응에 도움을 주고, 증강휴먼기술과 뇌-컴퓨터 인터페이스 기술을 융합하여 장애인의 신체적 제약을 극복하며, 비장애인 기존의 신체 능력을 향상시킬 수 있을 것이다. 둘째, 교육과 훈련 관련 분야에서 뇌-컴퓨터 인터페이스는 뇌파를 통한 직관적 정보 전달, 혼합현실의 시각화를 활용한 시뮬레이션, 그리고 실시간으로 상호 작용이 가능한 교육 훈련에 활용될 수 있을 것이다. 셋째, 게임을 비롯한 여가활동과 창조활동 부문에서는, 뇌-컴퓨터 인터페이스 기술에 다양한 기기착용 방식을 사용하는 혼합현실 콘텐츠를 활용하고, 뇌-컴퓨터 인터페이스기술의 오감과 바이오 매트릭스를 활용할 수 있을 것이다. 뇌- 컴퓨터 인터페이스는 사람의 신체나 정서 상태에 따라 사람들 또는 기계들과 서로 교감하도록 상호 작용을 통한 자연스러운 친근감을 주는 혼합 현실 기술과 함께 발전할 것으로 예상된다."
        },
        {
          "rank": 50,
          "score": 0.6585400104522705,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        }
      ]
    },
    {
      "query": "은닉 마르코프 모델(HMM)과 신경망(NN)은 잡음 환경 시청각 음성인식의 인식률 향상을 위한 통합 전략에서 구체적으로 어떻게 결합되거나 통합되나요?",
      "query_meta": {
        "type": "single_hop",
        "index": 2
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8439188003540039,
          "doc_id": "DIKO0007842188",
          "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
          "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
        },
        {
          "rank": 2,
          "score": 0.835145115852356,
          "doc_id": "DIKO0011019580",
          "title": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",
          "abstract": "음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다."
        },
        {
          "rank": 3,
          "score": 0.8106510639190674,
          "doc_id": "NART56157676",
          "title": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합",
          "abstract": "<P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157676&target=NART&cn=NART56157676",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 온라인 필기문자의 인식을 위한 은닉 마르코프 모델과 신경망 분류기의 결합 <P> 최근에 음성인식 분야에서 널리 사용되고 있는 은닉 마르코프 모델(HMM)을 이용하여 필기문자를 인식하고자 하는 연구가 활발히 진행되고 있다. 하지만, HMM은 시간에 따라서 변하는 입력특성을 잘 처리하는 장점이 있는 반면에, 각 모델을 독립적으로 학습시키는 경우에 각 패턴 사이의 분별력이 다소 떨어지는 문제가 있다. 본 논문에서는 HMM을 통해서 얻어진 각 모델의 내부 출력값을 이용하여 신경망 분류기로 추가적인 분류작업을 수행하는 방법을 제시한다. 또, 온라인 필기 데이타로 숫자와 영문자 대소문자를 인식하는 실험을 통해서 제시된 방법의 유용성을 입증한다.</P>"
        },
        {
          "rank": 4,
          "score": 0.8026080131530762,
          "doc_id": "NART20042187",
          "title": "Neural networks with hidden Markov process",
          "abstract": "Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20042187&target=NART&cn=NART20042187",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural networks with hidden Markov process Neural networks with hidden Markov process Neural networks with hidden Markov process Observed data contain global structural information and local statistical fluctuation.  To catch both global and local information, neural network models with hidden Markov process are presented. Hidden Markov model(HMM) is a rather general framework which can effectively deal with sequential structure based on stochastic process theory.  Neural networks have strong learning ability which makes it easier to free statistical fluctuation.  By introducing the dependence of weights of neural networks on the states of the systems, neural networks combined with HMM are realized.  The process underlying the transitions of the states is a Markov process. Dependent observations are generated by the neural networks corresponding to the states.  A modified maximum likelihood procedure are employed to estimate both transition probability of Markov process and weights of neural networks.  Applications of neural networks with HMM to econometrics, pattern matching, speech recognition and image process are discussed.(Author abstract)"
        },
        {
          "rank": 5,
          "score": 0.7935324907302856,
          "doc_id": "NPAP07942137",
          "title": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP07942137&target=NART&cn=NPAP07942137",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 음성 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용. 데이터에 대하여 Elman망예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 99.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 6,
          "score": 0.7833142876625061,
          "doc_id": "NART16453920",
          "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
          "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
        },
        {
          "rank": 7,
          "score": 0.782922625541687,
          "doc_id": "JAKO200428635215914",
          "title": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구",
          "abstract": "본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200428635215914&target=NART&cn=JAKO200428635215914",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 다층회귀신경예측 모델 및 HMM 를 이용한 임베디드 음성인식 시스템 개발에 관한 연구 본 논문은 주인식기로 흔히 사용되는 HMM 인식 알고리즘을 보완하기 위한 방법으로 회귀신경회로망(Recurrent neural networks : RNN)을 적용하였다. 이 회귀신경회로망 중에서 실 시간적으로 동작이 가능하게 한 방법인 다층회귀신경예측 모델 (Multi-layer Recurrent Neural Prediction Model : MRNPM)을 사용하여 학습 및 인식기로 구현하였으며, HMM과 MRNPM 을 이용하여 Hybrid형태의 주 인식기로 설계하였다. 설계된 음성 인식 알고리즘을 잘 구별되지 않는 한국어 숫자음(13개 단어)에 대해 화자 독립형으로 인식률 테스트 한 결과 기존의 HMM인식기 보다 5%정도의 인식률 향상이 나타났다. 이 결과를 이용하여 실제 DSP(TMS320C6711) 환경 내에서 최적(인식) 코드만을 추출하여 임베디드 음성 인식 시스템을 구현하였다. 마찬가지로 임베디드 시스템의 구현 결과도 기존 단독 HMM 인식시스템보다 향상된 인식시스템을 구현할 수 있게 되었다."
        },
        {
          "rank": 8,
          "score": 0.7815042734146118,
          "doc_id": "JAKO200011920774657",
          "title": "은닉 마코프 모델 기반 병렬음성인식 시스템",
          "abstract": "본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200011920774657&target=NART&cn=JAKO200011920774657",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 은닉 마코프 모델 기반 병렬음성인식 시스템 본 논문의 병렬음성인식 모델은 연속 은닉 마코프 모델(HMM; hidden Markov model)에 기반한 병렬 음소인식모듈과 계층구조의 지식베이스에 기반한 병렬 문장인식모듈로 구성된다. 병렬 음소인식 모듈은 수천개의 HMM을 병렬 프로세서에 분산시킨 수, 할당된 HMM에 대한 출력확률 계산과 Viterbi 알고리즘을 담당한다. 지식베이스 기반 병렬 문장인식모듈은 음소모듈에서 공급되는 음소열과 지안하는 병렬 음성인식 알고리즘은 분산메모리 MIMD 구조의 다중 트랜스퓨터와 Parsytec CC 상에 구현되었다. 실험결과, 병렬 음소인식모듈을 통한 실행시간 향상과 병렬 문장인식모듈을 통한 인식률 향상을 얻을 수 있었으며 병렬 음성인식 시스템의 실시간 구현 가능성을 확인하였다."
        },
        {
          "rank": 9,
          "score": 0.7733418941497803,
          "doc_id": "JAKO200111921140843",
          "title": "회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구",
          "abstract": "본문에서는 예측형 회귀신경망과 HMM (Hidden Markov Model)의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경 망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용 데이터에 대하여 Elman망 예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 98.5%로 우수한 결과를 얻었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111921140843&target=NART&cn=JAKO200111921140843",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 회귀신경망 예측 HMM을 이용한 숫자음 인식에 관한 연구 본문에서는 예측형 회귀신경망과 HMM (Hidden Markov Model)의 하이브리드 네트워크인 회귀신경망 예측 HMM을 구성하였다. 회귀신경망 예측 HMM은 예측형 회귀신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경 망에 의한 예측치를 이용하므로 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가진다. 따라서 음성과 같은 시계열 패턴의 인식에 유리하다. 회귀신경망 예측 HMM은 예측형 회귀신경망의 구조에 따라 Elman망 예측 HMM과 Jordan망 예측 HMM으로 구분하였다. 실험에서는 회귀신경망 예측 HMM의 상태수를 4, 5, 6으로 증가시켜 각 상태 수별로 예측차수 및 중간층 유니트 수의 변화에 따른 인식성능을 조사하였다. 실험결과 평가용 데이터에 대하여 Elman망 예측 HMM은 상태수가 6이고, 예측차수가 3차, 중간층 유니트의 수가 15차원일 때, Jordan망 예측 HMM의 경우 상태수가 5이고, 예측차수가 3차, 중간층 유니트의 수가 10차원일 때 각각 98.5%로 우수한 결과를 얻었다."
        },
        {
          "rank": 10,
          "score": 0.7727301120758057,
          "doc_id": "JAKO200411922338894",
          "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
          "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
        },
        {
          "rank": 11,
          "score": 0.7665711045265198,
          "doc_id": "JAKO200311922043899",
          "title": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구",
          "abstract": "본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200311922043899&target=NART&cn=JAKO200311922043899",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 Hidden Markov Network 음성인식 시스템의 성능평가에 관한 연구 본 논문에서는 한국어 음성 데이터를 대상으로 HM-Net(Hidden Markov Network) 음성인식 시스템의 성능평가를 수행하였다. 음향모델 작성은 음성인식에서 널리 사용되고 있는 통계적인 모델링 방법인 HMM(Hidden Markov Model)을 개량한 HM-Net을 도입하였다. HM-Net은 기존의 SSS(Successive State Splitting) 알고리즘을 개량한 PDT(Phonetic Decision Tree)-SSS 알고리즘에 의해 문맥방향과 시간방향의 상태분할을 수행하여 생성되는데, 특히 문맥방향 상태분할의 경우 학습 음성데이터에 출현하지 않는 문맥정보를 효과적으로 표현하기 위해 음소결정트리를 채용하고 있으며, 시간방향 상태분할의 경우 학습 음성데이터에서 각 음소별 지속시간 정보를 효과적으로 표현하기 위한 상태분할을 수행하며, 마지막으로 파라미터의 공유를 통해 triphone 형태의 최적인 모델 네트워크를 작성하게 된다. 인식에 사용된 알고리즘은 음소 및 단어인식의 경우에는 One-Pass Viterbi 빔 탐색을 사용하며 트리 구조 형태의 사전과 phone/word-pair 문법을 채용하고 있다. 연속음성인식의 경우에는 단어 bigram과 단어 trigram 언어모델과 목구조 형태의 사전을 채용한 Multi-Pass 빔 탐색을 사용하고 있다. 전체적으로 본 논문에서는 다양한 조건에서 HM-Net 음성인식 시스템의 성능평가를 수행하였으며, 지금까지 소개된 음성인식 시스템과 비교하여 매우 우수한 인식성능을 보임을 실험을 통해 확인할 수 있었다."
        },
        {
          "rank": 12,
          "score": 0.7606053352355957,
          "doc_id": "NART37979687",
          "title": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network",
          "abstract": "<P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART37979687&target=NART&cn=NART37979687",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network Noisy Speech Recognition Based on Hybrid Model of Hidden Markov Models and Wavelet Neural Network <P>A new method for noisy speech recognition based on a hybrid model of hidden Markov models (HMM) and wavelet neural network (WNN) is presented. The HMM was employed to compute the Viterbi output score. Then the score was used as the input of WNN to acquire the classification information. The result of recognition was made by these two kinds of recognition information. Recognition experiment shows that this hybrid model has higher performance than hidden Markov model in noisy speech recognition.</P>"
        },
        {
          "rank": 13,
          "score": 0.7597678899765015,
          "doc_id": "NART20682074",
          "title": "Robust combination of neural networks and hidden Markov models for speech recognition",
          "abstract": "Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART20682074&target=NART&cn=NART20682074",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Robust combination of neural networks and hidden Markov models for speech recognition Acoustic modeling in state-of-the-art speech recognition systems usually relies on hidden Markov models (HMMs) with Gaussian emission densities. HMMs suffer from intrinsic limitations, mainly due to their arbitrary parametric assumption. Artificial neural networks (ANNs) appear to be a promising alternative in this respect, but they historically failed as a general solution to the acoustic modeling problem. This paper introduces algorithms based on a gradient-ascent technique for global training of a hybrid ANN/HMM system, in which the ANN is trained for estimating the emission probabilities of the states of the HMM. The approach is related to the major hybrid systems proposed by Bourlard and Morgan and by Bengio, with the aim of combining their benefits within a unified framework and to overcome their limitations. Several viable solutions to the 'divergence problem'-that may arise when training is accomplished over the maximum-likelihood (ML) criterion-are proposed. Experimental results in speaker-independent, continuous speech recognition over Italian digit-strings validate the novel hybrid framework, allowing for improved recognition performance over HMMs with mixtures of Gaussian components, as well as over Bourlard and Morgan's paradigm. In particular, it is shown that the maximum a posteriori (MAP) version of the algorithm yields a 46.34% relative word error rate reduction with respect to standard HMMs."
        },
        {
          "rank": 14,
          "score": 0.7582241892814636,
          "doc_id": "JAKO200612842592571",
          "title": "제스처 인식을 위한 은닉 마르코프 모델",
          "abstract": "본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200612842592571&target=NART&cn=JAKO200612842592571",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 제스처 인식을 위한 은닉 마르코프 모델 본 논문에서는 은닉 마르코프 모델 (HMM: hidden Markov model)을 이용한 제스처 인식 방법을 제안하고, 이를 게임 시스템의 인터페이스로 적용한 사례를 소개한다. 제안된 방법은 다음의 두 가지 특징을 가진다. 첫 번째는 사전에 분할된 데이터 열을 입력으로 사용하는 기존의 방법과는 달리, 제안된 방법은 카메라로부터 입력되는 비디오 스트림을 HMM의 입력으로 사용한다는 것이다. 두 번째는 제안된 HMM은 제스처의 분할과 인식을 동시에 수행한다는 것이다. 제안된 방법에서 사용자의 제스처는 13개의 제스처들을 인식하는 13개의 specific-HMM들을 결합하는 하나의 통합된 HMM을 통해 인식된다. 제안된 HMM은 사용자의 머리와 양손의 2D-위치 좌표로 구성된 포즈 심볼들의 열을 입력받는다. 그리고 새로운 포즈가 입력될 때마다, HMM의 상태 확률 값을 갱신한다. 그때, 만약 특정 상태의 확률 값이 미리 정해둔 임계치보다 큰 경우, 그 특정 상태를 포함하고 있는 제스처로 인식한다 제안된 방법의 정당성을 입증하기 위하여, 제안된 방법은 Quake II라는 컴퓨터 게임에 적용되었다. 실험결과는 제안된 방법이 높은 인식 정확률과, 계산 시간을 확연하게 감소시킬 수 있었음을 보여주었다."
        },
        {
          "rank": 15,
          "score": 0.7544835209846497,
          "doc_id": "JAKO200111920771822",
          "title": "인과 2D 은닉 마르코프 모델",
          "abstract": "2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200111920771822&target=NART&cn=JAKO200111920771822",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 인과 2D 은닉 마르코프 모델 2D로 확장한 HMM은 다수 제안되었지만 엄밀한 의미에 있어서 2D HMM이라고 하기에 부족한 점이 많다. 본 논문에서는 기존의 랜덤 필드 모형이 아닌 새로운 2D HMM을 제안한다. 상하 및 좌우 방향의 causal chain 관계를 가정하고 완전한 격자 형성 조건을 두어 2D HMM의 평가, 매개 변수를 추정하는 알고리즘을 제시하였다. 각각의 알고리즘은 동적 프로그래밍과 최우 추정법에 근거한 것이다. 변수 추정 알고리즘은 반복적으로 이루어지며 국소 최적치에 수렴함을 보였다."
        },
        {
          "rank": 16,
          "score": 0.7515090703964233,
          "doc_id": "NART18014750",
          "title": "Neural nets and hidden Markov models: Review and generalizations",
          "abstract": "Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18014750&target=NART&cn=NART18014750",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Neural nets and hidden Markov models: Review and generalizations Previous work has shown the ability of Srtificial Neural Networks (ANNs), and Multilayer Perceptrons (MLPs) in particular, to estimate a posteriori probabilities that can be used, after division by the a priori probabilities of the classes, as emission probabilities for Hidden Markov Models (HMMs). The advantages of aspeech recognition system incorporating both MLPs and HMMs are the best discrimination and the ability to incorporate multiple sources of evidence (features, temporal context) without restrictive assumptions of distributions or statistical independence. While this approach has been shown useful for speech recognition, it is still important to understand the underlying problems and limitations and to consider its consequences on other algorithms. For example, while state of the art HMM-based speech recognizers now model context-dependent phonetic units such as triphones instead of phonemes to improve their performance, most of the MLP-based approaches are restricted to phoneme models. After a short review, it is shown here how such neural network approaches can be generalized to context-dependent phoneme models. Also, it is discussed how previous theoretical results can affect the development of other algorithms like nonlinear Autoregressive (AR) Models and Radial Basis Functions (RBFs)."
        },
        {
          "rank": 17,
          "score": 0.7489428520202637,
          "doc_id": "NART133898062",
          "title": "Hidden Markov Neural Networks",
          "abstract": "<P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART133898062&target=NART&cn=NART133898062",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden Markov Neural Networks Hidden Markov Neural Networks Hidden Markov Neural Networks <P>We define an evolving in-time Bayesian neural network called a Hidden Markov Neural Network, which addresses the crucial challenge in time-series forecasting and continual learning: striking a balance between adapting to new data and appropriately forgetting outdated information. This is achieved by modelling the weights of a neural network as the hidden states of a Hidden Markov model, with the observed process defined by the available data. A filtering algorithm is employed to learn a variational approximation of the evolving-in-time posterior distribution over the weights. By leveraging a sequential variant of Bayes by Backprop, enriched with a stronger regularization technique called variational DropConnect, Hidden Markov Neural Networks achieve robust regularization and scalable inference. Experiments on MNIST, dynamic classification tasks, and next-frame forecasting in videos demonstrate that Hidden Markov Neural Networks provide strong predictive performance while enabling effective uncertainty quantification.</P>"
        },
        {
          "rank": 18,
          "score": 0.7448585629463196,
          "doc_id": "JAKO201415642601987",
          "title": "SNR 매핑을 이용한 환경적응 기반 음성인식",
          "abstract": "다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201415642601987&target=NART&cn=JAKO201415642601987",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 SNR 매핑을 이용한 환경적응 기반 음성인식 다 모델 기반의 음성인식기는 음성인식에서 매우 성공적임이 알려져 있다. 그것은 다양한 신호-대-잡음비(SNR)와 잡음종류에 해당하는 다수의 HMM을 사용함으로서 선택된 음향모델이 인식잡음음성에 매우 근접한 일치성을 가질 수 있기 때문이다. 그러나 실제 사용시에 HMM의 개수가 제한됨에 따라서 음향모델의 불일치는 여전히 문제로 남아 있다. 본 논문에서는 인식잡음음성과 HMM 간의 SNR 불일치를 줄이고자 이들 간의 최적의 SNR 매핑 (mapping)을 실험적으로 결정하였다. 인식잡음음성으로 부터 추정된 SNR 값을 사용하는 대신 제안된 SNR 매핑을 사용함으로서 향상된 인식결과를 얻을 수 있었다. 다 모델 기반인식기에 제안된 방법을 적용하여 Aurora 2 데이터베이스에 대해서 인식 실험한 결과 기존의 MTR 이나 다 모델 기반 음성인식기에 비해서 6.3%와 9.4%의 상대적 단어 오인식율 감소를 이룰 수 있었다."
        },
        {
          "rank": 19,
          "score": 0.742103636264801,
          "doc_id": "NART56157876",
          "title": "한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합",
          "abstract": "<P> 본 논문에서는 일반적인 한국어 텍스트 문장에서 단어범주를 예측하기 위하여 HMM(Hidden Markov Model)과 신경망을 결합한 모델을 제안하였다.  한국어의 단어범주를 품사와 조사의 격 및 형에 따라 33개로 분류하였으며, 분류된 단어범주를 이용하여 국민학교 교과서를 대상으로 텍스트 데이타베이스를 구성하였다. 기존의 단어범주예측을 위해 제안된 NETgram은 동적, 정적 특징을 모두 신경망으로 표현하지만 본 논문에서는 시간에 따른 동적 변화를 잘 표현해주는 HMM을 신경망과 결합하는 방법을 제안하였다. 임의의 한국어 텍스트 문장으로 실험한 결과 4-gram 예측에서 종료상태가 고정되지 않고 6개의 관찰확률을 가지며 입력관찰열을 2번 순환반복으로 훈련시킨 HMM 모델과 신경망을 결합한 모델이 가장 우수하여 단어범주예측률이 20.22%를 차지하였다. 이것은 기존의 NETgram을 이용한 방식에 비하여 2.14% 향상된 것이다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157876&target=NART&cn=NART56157876",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 한국어 단어범주예측을 위한 은닉마르코프 모델과 신경망의 결합 <P> 본 논문에서는 일반적인 한국어 텍스트 문장에서 단어범주를 예측하기 위하여 HMM(Hidden Markov Model)과 신경망을 결합한 모델을 제안하였다.  한국어의 단어범주를 품사와 조사의 격 및 형에 따라 33개로 분류하였으며, 분류된 단어범주를 이용하여 국민학교 교과서를 대상으로 텍스트 데이타베이스를 구성하였다. 기존의 단어범주예측을 위해 제안된 NETgram은 동적, 정적 특징을 모두 신경망으로 표현하지만 본 논문에서는 시간에 따른 동적 변화를 잘 표현해주는 HMM을 신경망과 결합하는 방법을 제안하였다. 임의의 한국어 텍스트 문장으로 실험한 결과 4-gram 예측에서 종료상태가 고정되지 않고 6개의 관찰확률을 가지며 입력관찰열을 2번 순환반복으로 훈련시킨 HMM 모델과 신경망을 결합한 모델이 가장 우수하여 단어범주예측률이 20.22%를 차지하였다. 이것은 기존의 NETgram을 이용한 방식에 비하여 2.14% 향상된 것이다.</P>"
        },
        {
          "rank": 20,
          "score": 0.7381014823913574,
          "doc_id": "NART06155061",
          "title": "Speech enhancement based on neural predictive hidden Markov model",
          "abstract": "<P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06155061&target=NART&cn=NART06155061",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model Speech enhancement based on neural predictive hidden Markov model <P><B>Abstract</B></P><P>In this paper, we describe a new approach to speech enhancement by modeling directly the statistical characteristics of the speech waveform. To represent the nonlinear and nonstationary nature of speech, it is assumed that speech is the output of a neural predictive hidden Markov model (NPHMM). The NPHMM is a nonlinear autoregressive process whose time-varying parameters are controlled by a Markov chain. Given some speech data, the parameter of NPHMM is estimated by a learning algorithm based on the combination of Baum&#x2013;Welch algorithm and a neural network learning algorithm using the well known back propagation technique. Given the parameters of NPHMM, a recursive estimation method using multiple Kalman filters, governed by a Markov state chain according to the transition probabilities is developed for enhancing speech signals degraded by statistically independent additive noise characteristics assumed to be white and Gaussian. Under various input signal-to-noise ratios (SNRs), the proposed recursive speech enhancement method achieves an improvement over the method based on hidden filter model (Lee and Shirai, 1996) of about 0.8&#x2013;1.2dB in terms of the measured output SNR.</P>"
        },
        {
          "rank": 21,
          "score": 0.7374410629272461,
          "doc_id": "JAKO199811921284763",
          "title": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식",
          "abstract": "한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199811921284763&target=NART&cn=JAKO199811921284763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 은닉 마르코프 모델과 레벨 빌딩을 이용한 한국어 연속 음성 인식 한국어 연속 음성에서 발생하는 조음결합문제를 해결하기 위하여 단어를 기본 인식 단위로 사용할 경우 각 단어의 효율적인 표현 방법, 연속된 단어로 이루어진 여러 문장의 표현 방법 그리고 입력된 연속음성을 연속된 여러 단어로의 정합 방법에 관한 연구가 선행되어야 한다. 본 논문에서는 은닉 마르코프 모델과 레벨빌딩 알고리즘을 이용한 한국어 연속 음성 인식 시스템을 제안한다. 각 단어는 은닉 마르코프 모델로 표현하고 문장을 표현하기 위하여 단어 모델을 연결한 형태인 인식 네트워크를 구성한다. 인식네트워크의 탐색 알고리즘으로는 레벨 빌딩 알고리즘을 사용한다. 제안한 방법은 항공기 예약 시스템에 적용한 실험에서 인식율과 인식속도면에서 실용적이었으며 또한 비교적 적은 저장공간으로 전체 문장을 표현하고 쉽게 확장할 수 있다는 장점을 가지고 있다."
        },
        {
          "rank": 22,
          "score": 0.7331912517547607,
          "doc_id": "JAKO200211921444549",
          "title": "2층 구조의 입체 시각형 신경망 기반 음소인식",
          "abstract": "본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200211921444549&target=NART&cn=JAKO200211921444549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 2층 구조의 입체 시각형 신경망 기반 음소인식 본 연구는 입체 시각을 위한 신경망에 대한 연구 결과로서 인간의 음성을 인식하는데 적용된다. 입체 시각신경망(SVNN)에 기반한 음성인식에서, 먼저 입력된 음성 신호를 표준 모델과 비교함으로써 유사성이 얻어진다. 이 값들은 다이나믹한 처리 과정으로 주어지고 이웃한 신경소자들 사이에서 경쟁적이고 협력적인 처리를 거치게 된다. 이러한 다이나믹한 처리과정을 통해 단 하나의 가장 우수한 신경세포(winner neuron)만이 최후에 검출된다. 비교연구에서 2층 구조의 SVNN은 HMM 인식기보다 인식정확도 측면에서 7.7% 더 높았다. 평가 결과. SVNN은 기손리 HMM 인식기 성능을 능가하는 것으로 나타났다."
        },
        {
          "rank": 23,
          "score": 0.7325831651687622,
          "doc_id": "JAKO202123157167812",
          "title": "은닉 마르코프 모델을 이용한 국가별 주가지수 예측",
          "abstract": "은닉 마르코프 모델(hidden Markov model, HMM)은 은닉된 상태와 관찰 가능한 결과의 두 가지 요소로 이루어진 통계적 모형으로 확률론적 접근이 가능하고, 다양한 수학적인 구조를 가지고 있어 여러 분야에서 활발하게 사용되고 있다. 특히 금융 분야의 시계열 데이터에 응용되어 다양한 연구가 진행되고 있다. 본 연구는 HMM 이론을 국내 KOSPI200 주가지수와 더불어 NIKKEI225, HSI, S&P500, FTSE100과 같은 해외 주가지수 예측에 적용해 보고자 한다. 또한, 최근 인공지능 분야의 발전으로 인해 주식 가격 예측에 빈번하게 사용되는 서포트 벡터 회귀(support vector regression, SVR) 결과와 어떤 차이가 있는지 비교하여 살펴보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202123157167812&target=NART&cn=JAKO202123157167812",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델을 이용한 국가별 주가지수 예측 은닉 마르코프 모델(hidden Markov model, HMM)은 은닉된 상태와 관찰 가능한 결과의 두 가지 요소로 이루어진 통계적 모형으로 확률론적 접근이 가능하고, 다양한 수학적인 구조를 가지고 있어 여러 분야에서 활발하게 사용되고 있다. 특히 금융 분야의 시계열 데이터에 응용되어 다양한 연구가 진행되고 있다. 본 연구는 HMM 이론을 국내 KOSPI200 주가지수와 더불어 NIKKEI225, HSI, S&P500, FTSE100과 같은 해외 주가지수 예측에 적용해 보고자 한다. 또한, 최근 인공지능 분야의 발전으로 인해 주식 가격 예측에 빈번하게 사용되는 서포트 벡터 회귀(support vector regression, SVR) 결과와 어떤 차이가 있는지 비교하여 살펴보고자 한다."
        },
        {
          "rank": 24,
          "score": 0.7319259643554688,
          "doc_id": "NPAP00072266",
          "title": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models",
          "abstract": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP00072266&target=NART&cn=NPAP00072266",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error."
        },
        {
          "rank": 25,
          "score": 0.7314120531082153,
          "doc_id": "NART18015173",
          "title": "Speech recognition using hidden Markov models: A CMU perspective",
          "abstract": "Hidden Markov Models (HMMs) have become the predominant approach for speech recognition systems. One example of an HMM-based system is SPHINX, a large-vocabulary, speaker-independent, continuous-speech recognition system developed at CMU. In this paper, we introduce Hidden Markov Modelling techniques, analyze the reason for their success, and describe some improvements to the standard HMM used in SPHINX.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART18015173&target=NART&cn=NART18015173",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech recognition using hidden Markov models: A CMU perspective Speech recognition using hidden Markov models: A CMU perspective Speech recognition using hidden Markov models: A CMU perspective Hidden Markov Models (HMMs) have become the predominant approach for speech recognition systems. One example of an HMM-based system is SPHINX, a large-vocabulary, speaker-independent, continuous-speech recognition system developed at CMU. In this paper, we introduce Hidden Markov Modelling techniques, analyze the reason for their success, and describe some improvements to the standard HMM used in SPHINX."
        },
        {
          "rank": 26,
          "score": 0.7308247089385986,
          "doc_id": "NART17510385",
          "title": "Hidden-articulator Markov models for speech recognition",
          "abstract": "<P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART17510385&target=NART&cn=NART17510385",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition Hidden-articulator Markov models for speech recognition <P><B>Abstract</B></P><P>Most existing automatic speech recognition systems today do not explicitly use knowledge about human speech production. We show that the incorporation of articulatory knowledge into these systems is a promising direction for speech recognition, with the potential for lower error rates and more robust performance. To this end, we introduce the Hidden-Articulator Markov model (HAMM), a model which directly integrates articulatory information into speech recognition.</P><P>The HAMM is an extension of the articulatory-feature model introduced by Erler in 1996. We extend the model by using diphone units, developing a new technique for model initialization, and constructing a novel articulatory feature mapping. We also introduce a method to decrease the number of parameters, making the HAMM comparable in size to standard HMMs. We demonstrate that the HAMM can reasonably predict the movement of articulators, which results in a decreased word error rate (WER). The articulatory knowledge also proves useful in noisy acoustic conditions. When combined with a standard model, the HAMM reduces WER 28&#x2013;35% relative to the standard model alone.</P>"
        },
        {
          "rank": 27,
          "score": 0.7308169603347778,
          "doc_id": "JAKO201630932328344",
          "title": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법",
          "abstract": "실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201630932328344&target=NART&cn=JAKO201630932328344",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 가산 잡음 또는 반향 환경에 강인한 음성인식을 위한 은닉 마르코프 모델 기반 특징 향상 방법 실세계 환경의 원거리에서 녹음된 음성은 가산 잡음이나 반향 성분으로 왜곡되기 때문에 음성인식 성능이 현저히 떨어진다. 따라서 음성 전처리 과정은 실세계 환경에서 강인한 음성인식을 위한 필수과정이다. 모델 기반 특징 향상 방법은 전처리 방법 중 하나로 특징 영역 데이터의 적절한 동적 범위(dynamic range)와 차원 수로 인하여 실시간 처리가 가능하고 깨끗한 음성의 선험적 정보를 모델링하기에 용이하다. 또, 인식을 위한 최종 특징 입력에 가까운 단계에서 데이터를 처리하므로 인식에 밀접한 영향을 준다는 장점이 있다. 그러나 대략적인 왜곡 요인 관련 파라미터 추정 때문에 음성인식 성능이 하락되는 단점이 있다. 최근에 기존 모델 기반 특징 향상의 단점을 개선하여 가산 잡음이나 반향 환경에 적합한 방법이 제안되었다. 이글에서는 특징 향상 방법을 소개하고 개선된 방법의 음성인식 강인성을 알아보고자 한다."
        },
        {
          "rank": 28,
          "score": 0.7288203835487366,
          "doc_id": "NART56158825",
          "title": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법",
          "abstract": "<P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158825&target=NART&cn=NART56158825",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 은닉 마르코프 메쉬 랜덤 필드 모델을 위한 모수 추정기법 <P> 최근들어, 1차원 은닉 마르코프 모델(Hidden Markov Model: HMM)을 2차원 모델로 확장 하려는 연구가 시도되고 있다. 그러나, 이러한 연구 노력은 안정된 2차원 모델을 확립하는데 있어서의 어려움과 모델 자체가 갖는 계산 복잡도로 인해 완전 연결된 진정한 2차원 모델이 아닌 축소된 형태의 연결 구조를 갖는 의사 2차원 모델로 확장하는데 그치고 있다. 본 논문에서는 영상이 3차 마르코프 메쉬 랜덤 필드(Markov Mesh Random Field: MMRF)에 의해 표현될 수 있다는 가정하에 영상의 모델링과 인식을 위한 새로운 통계적 모델인 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델을 제안하고, 이를 위한 효과적인 모수 추정 기법을 개발한다.  제안된 모수 추정 기법은 HMMRF 모델에 대한 최대 주변 사후 확률(a maximum, marginal a posteriori probability) 기준에 기반을 둔 &quot;look-ahead&quot; 기법을 확장, 이용함으로써 모수를 추정하는 재귀적 기법이다. HMMRF 모델에 대한 제안된 모수 추정 기법이 실세계 문제에 적용 가능한가를 입중하기 위하여 오프라인 글씨 인식 문제에 실험한 결과, 많은 변형을 갖는 글씨 데이타의 모델링 및 인식에 유용하게 사용될 수 있음을 확인할 수 있었다.</P>"
        },
        {
          "rank": 29,
          "score": 0.7286248207092285,
          "doc_id": "JAKO202510064801583",
          "title": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석",
          "abstract": "항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202510064801583&target=NART&cn=JAKO202510064801583",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 은닉 마르코프 모델을 활용한 조종사 시선추적 데이터 분석 항공기 자동화 시스템의 발전으로 많은 부분이 자동화되었음에도 불구하고, 비행 중 신속하고 정확한 의사 결정을 위해 상황인식은 중요한 역할을 한다. 최근 시각추적기술이 발전하면서 조종사의 시선 움직임을 정량적으로 분석할 수 있는 가능성이 높아졌으며, 이를 활용한 연구가 항공 분야에서도 확대되고 있다. 본 연구에서는 조종사의 시선추적 데이터를 활용하여 은닉 마르코프 모델(HMM)을 적용하고, 비행 단계별 시선 이동 패턴과 주의 집중 변화를 분석하였다. 분석 결과 조종사의 시선 집중 영역은 비행 단계에 따라 차이를 보였으며, 착륙 및 접근 단계에서 높은 인지 부하가 발생하는 경향이 나타났다. 또한 조종사의 시선 이동 패턴을 정량적으로 분석하여 주의 집중 상태의 변화를 평가할 수 있음을 확인하였다. 본 연구의 결과는 조종사 훈련의 효과성을 높이는 데 기여할 것으로 기대된다."
        },
        {
          "rank": 30,
          "score": 0.7264145612716675,
          "doc_id": "JAKO201403359905324",
          "title": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원",
          "abstract": "This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201403359905324&target=NART&cn=JAKO201403359905324",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 가산잡음환경에서 강인음성인식을 위한 은닉 마르코프 모델 기반 손실 특징 복원 This paper describes a robust speech recognition technique by reconstructing spectral components mismatched with a training environment. Although the cluster-based reconstruction method can compensate the unreliable components from reliable components in the same spectral vector by assuming an independent, identically distributed Gaussian-mixture process of training spectral vectors, the presented method exploits the temporal dependency of speech to reconstruct the components by introducing a hidden-Markov-model prior which incorporates an internal state transition plausible for an observed spectral vector sequence. The experimental results indicate that the described method can provide temporally consistent reconstruction and further improve recognition performance on average compared to the conventional method."
        },
        {
          "rank": 31,
          "score": 0.7260528802871704,
          "doc_id": "JAKO202029462558904",
          "title": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식",
          "abstract": "특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202029462558904&target=NART&cn=JAKO202029462558904",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 심층신경망 기반의 음성인식을 위한 절충된 특징 정규화 방식 특징 정규화는 음성 특징 파라미터들의 통계적인 특성의 정규화를 통해 훈련 및 테스트 조건 사이의 환경 불일치의 영향을 감소시키는 방법으로서 기존의 Gaussian mixture model-hidden Markov model(GMM-HMM) 기반의 음성인식 시스템에서 우수한 성능개선을 입증한 바 있다. 하지만 심층신경망(deep neural network, DNN) 기반의 음성인식 시스템에서는 환경 불일치의 영향을 최소화 하는 것이 반드시 최고의 성능 개선으로 연결되지는 않는다. 본 논문에서는 이러한 현상의 원인을 과도한 특징 정규화로 인한 정보손실 때문이라 보고, 음향모델을 훈련 하는데 유용한 정보는 보존하면서 환경 불일치의 영향은 적절히 감소시켜 음성인식 성능을 최대화 하는 특징 정규화 방식이 있는 지 검토해보고자 한다. 이를 위해 평균 정규화(mean normalization, MN)와 평균 및 분산 정규화(mean and variance normalization, MVN)의 절충 방식인 평균 및 지수적 분산 정규화(mean and exponentiated variance normalization, MEVN)를 도입하여, 잡음 및 잔향 환경에서 분산에 대한 정규화의 정도에 따른 DNN 기반의 음성인식 시스템의 성능을 비교한다. 실험 결과, 성능 개선의 폭이 크지는 않으나 분산 정규화의 정도에 따라 MEVN이 MN과 MVN보다 성능이 우수함을 보여준다."
        },
        {
          "rank": 32,
          "score": 0.7252562046051025,
          "doc_id": "NART30128358",
          "title": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer",
          "abstract": "<P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART30128358&target=NART&cn=NART30128358",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer Inversion-based nonlinear adaptation of noisy acoustic parameters for a neural/HMM speech recognizer <P><B>Abstract</B></P><P>Spoken human&ndash;machine interaction in real-world environments requires acoustic models that are robust to changes in acoustic conditions, e.g. presence of noise. Unfortunately, the popular hidden Markov models (HMM) are not noise tolerant. One way to increase recognition performance is to acquire a small adaptation set of noisy utterances, which is used to estimate a normalization mapping between noisy and clean features to be fed into the acoustic model. This paper proposes an unsupervised maximum-likelihood gradient-ascent training algorithm (instead of the usual least squares regression) for a neural feature adaptation module, properly combined with a hybrid connectionist/HMM speech recognizer. The algorithm is inspired by the so-called &ldquo;inversion principle&rdquo;, that prescribes the optimization of the input features instead of the model parameters. Simulation results on a real-world speaker-independent continuous speech corpus of connected Italian digits, corrupted by noise, validate the approach. A small neural net (13 hidden neurons) trained over a single adaptation utterance for one iteration yields a 18.79% relative word error rate (WER) reduction over the bare hybrid, and a 65.10% relative WER reduction over the Gaussian-based HMM.</P>"
        },
        {
          "rank": 33,
          "score": 0.7211377024650574,
          "doc_id": "NART56157711",
          "title": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식",
          "abstract": "<P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157711&target=NART&cn=NART56157711",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 은닉 마르코프 모델을 이용한 필기체 한글의 오프라인 인식 <P> 본 논문에서는 다양한 변화를 내포하고 있는 입력 패턴을 확률적으로 모델링할 수 있는 은닉 마르코프 모델을 이용하여 필기체 한글을 오프라인 인식하는 방법을 제안한다. 제안된 방법은 하나의 입력 문자 패턴에 대해 영역 투영 외곽선 변환을 이용하여 4 종류의 영역 투영 외곽선을 추출한 다음, 이들 외곽선에 대해 방향 성분을 이용하여 4 종류의 은닉 마르코프 모델을 학습 단계에서 각기 구성한다. 학습 단계에서 구성된 4 종류의 은닉 마르코프 모델들은 인식 단계에서 결합되어 입력 문자 패턴에 대한 최종적인 인식 결과를 출력한다. 효율적인 인식 시스템의 구성을 위하여 은닉 마르코프 모델의 매개변수에 몇가지 제약을 가함으로써 불필요한 매개변수의 추정을 피하였으며, 퍼지 트리 분류기를 사용함으로써 전반적인 처리 속도를 향상시켰다.</P>"
        },
        {
          "rank": 34,
          "score": 0.721032440662384,
          "doc_id": "NART56158762",
          "title": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델",
          "abstract": "<P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56158762&target=NART&cn=NART56158762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 오프라인 글씨 인식을 위한 은닉 마르코프 메쉬 랜덤 필드 모델 <P> 2차원 영상을 다루는데 있어 1차원 은닉 마르코프 모델(Hidden Markov Model : HMM)의 한계가 지적됨에 따라 새로이 등장한 은닉 마르코프 메쉬 랜덤 필드(Hidden Markov Mesh Random Field HMMRF) 모델은 영상의 모델링과 인식을 위한 새로운 통계적 모델이다. 이 모델은 영상이 마르코프 메쉬 랜덤 필드(Malkov Mesh Random Field MMRF)에 의해 표현될 수 있다는 가정하에서 제안된 모델로서, 본 논문에서는 2차원 통계적 모델인 HMMRF 모델을 기반으로 하여 오프라인 글씨 인식을 위한 새로운 방법론을 제안한다. 제안된 HMMRF 모델이 글씨 인식의 문제에 적용되기 위해서는 디코팅(혹은 레이블링) 단계와 훈련 단계가 필요하며 본 논문에서는 관측값들에 포함되어 있는 정보를 기반으로 화소의 상태를 결정하는 디코딩 문제를 중점적으로 다루고자 한다. 이 문제에 대한 해결 방안은 HMMRF 모델에 대하여 최대 주변 사후 확률 분포 기준에 기반을 둔 &quot;look-ahead&quot; 기법으로 부터 유도될 수 있다.  오프라인 글씨 인식을 위한 2차원 HMMRF 모델의 유용성을 입증하기 위하여 1차원 모델과의 성능 비교가 이루어졌으며, 실험 결과 HMMRF 모델이 기존의 1차원 모델이 갖는 한계를 극복할 수 있다는 점에서 오프라인 글씨 인식 분야에서 대표적인 통계적 모델로서 확립될 수 있으리라 판단된다.</P>"
        },
        {
          "rank": 35,
          "score": 0.7195833921432495,
          "doc_id": "NART70632792",
          "title": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis",
          "abstract": "<P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70632792&target=NART&cn=NART70632792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis <P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>"
        },
        {
          "rank": 36,
          "score": 0.719254732131958,
          "doc_id": "JAKO201935164467523",
          "title": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구",
          "abstract": "본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201935164467523&target=NART&cn=JAKO201935164467523",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 심층신경망 구조에 따른 구개인두부전증 환자 음성 인식 향상 연구 본 논문에서는 구개인두부전증(VeloPharyngeal Insufficiency, VPI) 환자의 음성을 효과적으로 인식하기 위해 컨볼루션 신경망 (Convolutional Neural Network, CNN), 장단기 모델(Long Short Term Memory, LSTM) 구조 신경망을 은닉 마르코프 모델(Hidden Markov Model, HMM)과 결합한 하이브리드 구조의 음성 인식 시스템을 구축하고 모델 적응 기법을 적용하여, 기존 Gaussian Mixture Model(GMM-HMM), 완전 연결형 Deep Neural Network(DNN-HMM) 기반의 음성 인식 시스템과 성능을 비교한다. 정상인 화자가 PBW452단어를 발화한 데이터를 이용하여 초기 모델을 학습하고 정상인 화자의 VPI 모의 음성을 이용하여 화자 적응의 사전 모델을 생성한 후에 VPI 환자들의 음성으로 추가 적응 학습을 진행한다. VPI환자의 화자 적응 시에 CNN-HMM 기반 모델에서는 일부층만 적응 학습하고, LSTM-HMM 기반 모델의 경우에는 드롭 아웃 규제기법을 적용하여 성능을 관찰한 결과 기존 완전 연결형 DNN-HMM 인식기보다 3.68 % 향상된 음성 인식 성능을 나타낸다. 이러한 결과는 본 논문에서 제안하는 LSTM-HMM 기반의 하이브리드 음성 인식 기법이 많은 데이터를 확보하기 어려운 VPI 환자 음성에 대해 보다 향상된 인식률의 음성 인식 시스템을 구축하는데 효과적임을 입증한다."
        },
        {
          "rank": 37,
          "score": 0.7157713174819946,
          "doc_id": "NART56157981",
          "title": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식",
          "abstract": "<P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART56157981&target=NART&cn=NART56157981",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 은닉 마르코프 모델 네트워크에 의한 온라인 흘림 필기 한글 인식 <P> 본 논문은 흘려쓴 온라인 필기의 다양한 변형을 극복하고 간단히 인식할 수 있는 방법을 제시하고자 한다. 은닉 마르코프 모델을 사용하여 각 자속별로 모형을 하나씩 설계하고 이들을 제자 원리에 따라 연결함으로써 하나의 글자 네트워크 모형을 구성한다. 특히, 흘림과 그에 따르는 변형을 모형화하기 위해 연결획 개념을 확장 정의하고 독립적인 모형을 구성하였다. 이렇게 구성된 네트워크는 한글의 모든 음절 글씨를 위한 모형으로서, 다양한 글씨를 하나의 틀 안에 수용한다.  네트워크 모형에서 글자 인식이란 입력에 대해서 최적 경로를 찾는 탐색 문제로 변환된다. 확률적으로 정의되는 이러한 경로는 비터비 알고리즘을 계층 구조의 네트워크에 확장 적용함으로써 효율적으로 구할 수 있는데, 인식 결과와 자소간의 경계점을 동시에 얻을 수 있다. 한편 연결획을 자소와 같은 개체로 취급함에 따라서 일관성 있는 모델 구성과 간단한 인식 알고리즘 등 방법론 상의 장점을 갖고 있다.</P>"
        },
        {
          "rank": 38,
          "score": 0.7156178951263428,
          "doc_id": "JAKO201326952134359",
          "title": "은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬",
          "abstract": "동영상에서 추출한 변수값을 은닉 마르코프 모델(Hidden Markov Model; HMM)에 적용한 새로운 낙상 인식 알고리듬을 제안한다. 개인간 낙상 양식의 차이나 유사 낙상을 실제 낙상과 구분하기 위한 기계 학습 방법으로 HMM알고리듬을 사용하였다. 비디오의 낙상 특징 변수를 얻기 위해 동영상의 광류를 구한 후 이를 주성분 분석 방식에 적용하여 움직임을 정량화하였다. 주성분 분석으로 얻어진 전체 움직임 벡터의 각도, 장단축의 비, 속도등의 조합으로 새로운 여러 종류의 낙상 특징 변수를 정의한 후 이를 HMM에 적용하여 결과를 비교, 분석하였다. 이들 변수들 중에 각도에 의해 얻어진 변수가 가장 좋은 결과를 보여 본 실험에서 91.5%의 민감도(성공 감지율)와 88.01% 의 특이도(실패 감지율)를 나타내었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201326952134359&target=NART&cn=JAKO201326952134359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 은닉 마르코프 모델을 이용한 동영상 기반 낙상 인식 알고리듬 동영상에서 추출한 변수값을 은닉 마르코프 모델(Hidden Markov Model; HMM)에 적용한 새로운 낙상 인식 알고리듬을 제안한다. 개인간 낙상 양식의 차이나 유사 낙상을 실제 낙상과 구분하기 위한 기계 학습 방법으로 HMM알고리듬을 사용하였다. 비디오의 낙상 특징 변수를 얻기 위해 동영상의 광류를 구한 후 이를 주성분 분석 방식에 적용하여 움직임을 정량화하였다. 주성분 분석으로 얻어진 전체 움직임 벡터의 각도, 장단축의 비, 속도등의 조합으로 새로운 여러 종류의 낙상 특징 변수를 정의한 후 이를 HMM에 적용하여 결과를 비교, 분석하였다. 이들 변수들 중에 각도에 의해 얻어진 변수가 가장 좋은 결과를 보여 본 실험에서 91.5%의 민감도(성공 감지율)와 88.01% 의 특이도(실패 감지율)를 나타내었다."
        },
        {
          "rank": 39,
          "score": 0.7144405245780945,
          "doc_id": "JAKO200624718627058",
          "title": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식",
          "abstract": "본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200624718627058&target=NART&cn=JAKO200624718627058",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 은닉 마르코프 모델과 계층 정보를 이용한 개체명 경계 인식 본 논문은 통계 기반 접근 방식인 HMM(Hidden Markov model)과 생물학의 개체명에 관한 온톨로지 정보를 이용한 생물학 문서에서의 개체명(named entity) 경계 인식 방법을 제안한다. 제안하는 방법은 31개의 자질 정보를 이용한 평탄화 기법을 사용하며 생물학 개체명의 계층 정보를 이용하여 HMM의 자료 부족 문제를 완화시킬 수 있도록 하였다. 개체명 경계 인식의 학습과 실험을 위하여 GENIA 코퍼스 ver 2.1을 사용하였으며 개체명 경계 인식 실험을 수행한 결과 모든 부류를 사용한 경우보다 정확도 및 실행 속도가 개선됨을 확인하였다."
        },
        {
          "rank": 40,
          "score": 0.7133039236068726,
          "doc_id": "NART95825020",
          "title": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition",
          "abstract": "<P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART95825020&target=NART&cn=NART95825020",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition End-to-end acoustic modeling using convolutional neural networks for HMM-based automatic speech recognition <P><B>Abstract</B></P>  <P>In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level ( &asymp; 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn &ldquo;in-parts&rdquo; formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Novel CNN-based end-to-end acoustic modeling approach is proposed. </LI> <LI>  Relevant features are automatically learned from the signal by discriminating phones. </LI> <LI>  Learned features are more discriminative than cepstral-based features. </LI> <LI>  Learned features are somewhat invariant to languages and domains. </LI> <LI>  Proposed approach leads to better ASR systems. </LI> </UL> </P>"
        },
        {
          "rank": 41,
          "score": 0.7109172344207764,
          "doc_id": "JAKO200921640756800",
          "title": "은닉 마르코프 모델 기반 동작 인식 방법",
          "abstract": "본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200921640756800&target=NART&cn=JAKO200921640756800",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 은닉 마르코프 모델 기반 동작 인식 방법 본 논문은 비전 기반 동작 인식 방법으로 모범 동작의 유형을 모형화하고 이를 이용하여 사용자의 동작을 인식하고 모범동작과 사용자의 동작간의 유사도를 측정하는 방법을 제안한다. 동작 인식을 위하여 은닉 마르코프 모델 기반의 유형화 기법을 통하여 모범 동작의 유형 모델을 구성하고 이를 이용하여 사용자의 동작을 인식한다. 유사도 측정을 위하여 편집 거리 알고리즘을 응용하여 모범 동작과 사용자 동작의 유사도를 측정하고 점수 표기가 가능하도록 하였다. 본 논문에서 제안하는 동작 인식 처리 방법은 평균 93% 이상의 높은 인식율을 보였다. 본 연구의 결과는 동작 인식 기반 게임, 자세인식, 동작의 반복 훈련 및 훈련 달성도 측정을 요하는 재활훈련 시스템 등에 활용 가능하다."
        },
        {
          "rank": 42,
          "score": 0.7105050086975098,
          "doc_id": "NART00705015",
          "title": "Speaker recognition using HMM composition in noisy environments",
          "abstract": "<P><B>Abstract</B></P><P>This paper investigates a speaker recognition method that is robust against background noise. In noisy environments, one important issue is how to create a model for each speaker so as to compensate for noise. The method described here is based on hidden Markov model (HMM) composition, which combines a speaker HMM and a noise-source HMM into a noise-added speaker HMM with a particular signal-to-noise ratio (SNR). Since it is difficult to measure the SNR of input speech with non-stationary noise exactly, this method creates several noise-added speaker HMMs with various SNRs. The HMM that has the highest likelihood value for the input speech is selected, and a speaker decision is made using this likelihood value. Experimental application of this method to text-independent speaker identification and verification in various kinds of noisy environments demonstrated considerable improvement in speaker recognition for speech utterances of male speakers.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART00705015&target=NART&cn=NART00705015",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speaker recognition using HMM composition in noisy environments Speaker recognition using HMM composition in noisy environments Speaker recognition using HMM composition in noisy environments <P><B>Abstract</B></P><P>This paper investigates a speaker recognition method that is robust against background noise. In noisy environments, one important issue is how to create a model for each speaker so as to compensate for noise. The method described here is based on hidden Markov model (HMM) composition, which combines a speaker HMM and a noise-source HMM into a noise-added speaker HMM with a particular signal-to-noise ratio (SNR). Since it is difficult to measure the SNR of input speech with non-stationary noise exactly, this method creates several noise-added speaker HMMs with various SNRs. The HMM that has the highest likelihood value for the input speech is selected, and a speaker decision is made using this likelihood value. Experimental application of this method to text-independent speaker identification and verification in various kinds of noisy environments demonstrated considerable improvement in speaker recognition for speech utterances of male speakers.</P>"
        },
        {
          "rank": 43,
          "score": 0.7100399732589722,
          "doc_id": "NPAP12270893",
          "title": "Speech Recognition in Noisy Environments with Convolutional Neural Networks",
          "abstract": "<P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NPAP12270893&target=NART&cn=NPAP12270893",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks Speech Recognition in Noisy Environments with Convolutional Neural Networks <P>One of the biggest challenges in speech recognition today is its use on a daily basis, in which distortion and noise in the environment are present and hinder the recognition task. In the last thirty years, hundreds of methods for noise-robust recognition were proposed, each with its own advantages and disadvantages. In this paper, the use of convolutional neural networks (CNN) as acoustic models in automatic speech recognition systems (ASR) is proposed as an alternative to the classical recognition methods based on HMM without any noise-robust method applied. The experiment showed that the presented method reduces the equal error rate in word recognition tasks with additive noise.</P>"
        },
        {
          "rank": 44,
          "score": 0.7046620845794678,
          "doc_id": "JAKO199911921383665",
          "title": "회귀신경망을 이용한 음성인식에 관한 연구",
          "abstract": "본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199911921383665&target=NART&cn=JAKO199911921383665",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 회귀신경망을 이용한 음성인식에 관한 연구 본 논문은 회귀신경망을 이용한 음성인식에 관한 연구이다. 예측형 신경망으로 음절단위로 모델링한 후 미지의 입력음성에 대하여 예측오차가 최소가 되는 모델을 인식결과로 한다. 이를 위해서 예측형으로 구성된 신경망에 음성의 시변성을 신경망 내부에 흡수시키기 위해서 회귀구조의 동적인 신경망인 회귀예측신경망을 구성하고 Elman과 Jordan이 제안한 회귀구조에 따라 인식성능을 서로 비교하였다. 음성DB는 ETRI의 샘돌이 음성 데이터를 사용하였다. 그리고, 신경망의 최적모델을 구하기 위하여 예측차수와 은닉층 유니트 수의 변화에 따른 인식률의 변화와 문맥층에서 자기회귀계수를 두어 이전의 값들이 문맥층에서 누적되도록 하였을 경우에 대한 인식률의 변화를 비교하였다. 실험결과, 최적의 예측차수, 은닉층 유니트수, 자기회귀계수는 신경망의 구조에 따라 차이가 나타났으며, 전반적으로 Jordan망이 Elman망보다 인식률이 높았으며, 자기회귀계수에 대한 영향은 신경망의 구조와 계수값에 따라 불규칙하게 나타났다."
        },
        {
          "rank": 45,
          "score": 0.7038936614990234,
          "doc_id": "JAKO199615875841474",
          "title": "천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식",
          "abstract": "본 논문에서는 상태간의 천이가 특정한 시간 구간에서만 발생하도록 하는 천이 제한(transition constrained) HMM를 제안하고 잡음 환경에서의 성능을 평가하였다. 천이 제한 HMM는 상태 지속을 제한하고 음성 신호의 시간적 변화를 단순하고 효과적으로 표현할 수 있다. 제안된 천이 제한 HMM은 기존 HMM 보다 성능이 우수할 뿐만아니라 계산량도 매우 감소한다.  제안된 방법의 성능을 평가하기 위하여 반연속(semi-continuous) HMM을 이용하여 잡음이 SNR 20, 10, 0 dB로 첨가된 음성에 화자독립 단독음 인식실험을 수행하였다. 실험 결과에서 제안된 방법은 잡음에 강인한 특성을 나타내었다. 두 가지 종류의 잡음을 SNR 10dB로 첨가하여 사용한 경우, 천이제한 HMM의 인식률은 기존 HMM의 단어 인식률 81.08%와 75.36%에 비하여 각각 7.31%와 10.35% 향상되었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO199615875841474&target=NART&cn=JAKO199615875841474",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 천이 제한 HMM을 이용한 잡음 환경에서의 음성 인식 본 논문에서는 상태간의 천이가 특정한 시간 구간에서만 발생하도록 하는 천이 제한(transition constrained) HMM를 제안하고 잡음 환경에서의 성능을 평가하였다. 천이 제한 HMM는 상태 지속을 제한하고 음성 신호의 시간적 변화를 단순하고 효과적으로 표현할 수 있다. 제안된 천이 제한 HMM은 기존 HMM 보다 성능이 우수할 뿐만아니라 계산량도 매우 감소한다.  제안된 방법의 성능을 평가하기 위하여 반연속(semi-continuous) HMM을 이용하여 잡음이 SNR 20, 10, 0 dB로 첨가된 음성에 화자독립 단독음 인식실험을 수행하였다. 실험 결과에서 제안된 방법은 잡음에 강인한 특성을 나타내었다. 두 가지 종류의 잡음을 SNR 10dB로 첨가하여 사용한 경우, 천이제한 HMM의 인식률은 기존 HMM의 단어 인식률 81.08%와 75.36%에 비하여 각각 7.31%와 10.35% 향상되었다."
        },
        {
          "rank": 46,
          "score": 0.7036198377609253,
          "doc_id": "NART13081886",
          "title": "Speech recognition under noisy environments using segmental unit input HMM",
          "abstract": "<P>In this paper, we apply a segmental unit input HMM to noisy speech recognition. In this modeling, several successive frames are combined and treated as an input vector. We expect that the segmental unit input HMM will be effective for noisy speech recognition because segmental statistics considering correlation between frames reduce noise effects when the correlation of noise between frames is assumed to be small. In recognition experiments, we compared the segmental unit input HMM with a conventional frame-based HMM and found the segmental unit input HMM to be superior. We also compared the segmental unit input HMM with dynamic cepstral coefficients, which have both static and dynamic features, and found that the segmental unit input HMM is more effective than the dynamic cepstrum. We also combined the segmental unit input HMM with a spectral subtraction method and confirmed the effectiveness of the method. Additionally, in experiments using acoustic models trained with noisy speech, the segmental unit input HMM outperformed the conventional HMM. From these results, we propose PMC for the segmental unit input HMM. Experimental results showed the PMC for segmental unit input HMM offered better recognition performance than the original PMC. &copy; 2002 Wiley Periodicals, Inc. Syst Comp Jpn, 33(8): 111&ndash;120, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.1151</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART13081886&target=NART&cn=NART13081886",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Speech recognition under noisy environments using segmental unit input HMM Speech recognition under noisy environments using segmental unit input HMM Speech recognition under noisy environments using segmental unit input HMM <P>In this paper, we apply a segmental unit input HMM to noisy speech recognition. In this modeling, several successive frames are combined and treated as an input vector. We expect that the segmental unit input HMM will be effective for noisy speech recognition because segmental statistics considering correlation between frames reduce noise effects when the correlation of noise between frames is assumed to be small. In recognition experiments, we compared the segmental unit input HMM with a conventional frame-based HMM and found the segmental unit input HMM to be superior. We also compared the segmental unit input HMM with dynamic cepstral coefficients, which have both static and dynamic features, and found that the segmental unit input HMM is more effective than the dynamic cepstrum. We also combined the segmental unit input HMM with a spectral subtraction method and confirmed the effectiveness of the method. Additionally, in experiments using acoustic models trained with noisy speech, the segmental unit input HMM outperformed the conventional HMM. From these results, we propose PMC for the segmental unit input HMM. Experimental results showed the PMC for segmental unit input HMM offered better recognition performance than the original PMC. &copy; 2002 Wiley Periodicals, Inc. Syst Comp Jpn, 33(8): 111&ndash;120, 2002; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.1151</P>"
        },
        {
          "rank": 47,
          "score": 0.7025532722473145,
          "doc_id": "NART06964546",
          "title": "Low resolution, degraded document recognition using neural networks and hidden Markov models",
          "abstract": "<P><B>Abstract</B></P><P>We collected a large, real world database, containing degraded, old and faxed documents and present a comparison between two leading edge commercial software packages and human reading performance which shows quantitatively the huge performance gap between humans and machines, even on random character documents where no context can be used. This indicates room for possible improvements. We implemented an integrated segmentation and recognition algorithm using neural networks and hidden Markov models trained on the database and present results which show the superior performance of the algorithm.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART06964546&target=NART&cn=NART06964546",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Low resolution, degraded document recognition using neural networks and hidden Markov models Low resolution, degraded document recognition using neural networks and hidden Markov models Low resolution, degraded document recognition using neural networks and hidden Markov models <P><B>Abstract</B></P><P>We collected a large, real world database, containing degraded, old and faxed documents and present a comparison between two leading edge commercial software packages and human reading performance which shows quantitatively the huge performance gap between humans and machines, even on random character documents where no context can be used. This indicates room for possible improvements. We implemented an integrated segmentation and recognition algorithm using neural networks and hidden Markov models trained on the database and present results which show the superior performance of the algorithm.</P>"
        },
        {
          "rank": 48,
          "score": 0.6984403133392334,
          "doc_id": "JAKO202011263332681",
          "title": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용",
          "abstract": "가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202011263332681&target=NART&cn=JAKO202011263332681",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 심층신경망을 이용한 짧은 발화 음성인식에서 극점 필터링 기반의 특징 정규화 적용 가우스 혼합 모델-은닉 마코프 모델(Gaussian Mixture Model-Hidden Markov Model, GMM-HMM)을 이용하는 전통적인 음성인식 시스템에서는, 극점 필터링 기반의 켑스트럼 특징 정규화 방식이 잡음 환경에서 짧은 발화의 인식 성능을 향상시키는데 효과적이었다. 본 논문에서는 심층신경망(Deep Neural Network, DNN)을 이용하는 최신의 음성인식 시스템에서도 이 방식의 유용성이 있는지 검토한다. AURORA 2 DB에 대한 실험 결과, 특히 훈련 및 테스트 환경 사이의 불일치가 클 때에, 극점 필터링 기반의 켑스트럼 평균 분산 정규화 방식이 극점 필터링을 사용하지 않는 방식에 비해 매우 짧은 발화의 인식 성능을 개선시킴을 보여 준다."
        },
        {
          "rank": 49,
          "score": 0.6926778554916382,
          "doc_id": "DIKO0017057156",
          "title": "하이브리드 딥러닝 및 머신러닝 모델기반 감시 영상에서의 인간 상호작용 인식",
          "abstract": "본 연구는 실내환경에서 여러대의 CCTV카메라를 사용해 일반적으로 관찰되는 인간 상호작용 5종류(껴안기, 발로 차기, 밀기, 가르키기, 상호작용 없음)를 기준으로 건강한 남녀 13명을 대상으로 직접 녹화하며, 데이터셋을 직접 구축했다. 데이터셋은 4개의 서로 다른 방향에서 촬영된 영상으로 고성하였으며, 전처리를 통해 표준화하였다. 이후 ResNet모델의 2D CNN(Convolutional Neural Network)를 기반으로 경량 아키텍처를 구축하였다.&amp;#xD; 본 연구에서는 딥러닝과 머신러닝 분류기를 결합한 하이브리드(Hybrid Deep Learning)분류 방법을 활용해 인간의 상호작용을 분류하는 모델을 제안했다. 모델 훈련을 위한 데이터셋을 처리하는 과정에서, 비디오 시퀀스로 이루어진 데이터셋에서 신체의 핵심을 추출하는 단계는 딥러닝 모델이 적용되었으며, 추출된 특징을 활용해 분류하는 단계에는 머신러닝이 활용되었다.&amp;#xD; 본 연구에서 제안한 방법은 순천향대학교 차일드어세스룸에서 촬영된 4채널 CCTV 카메라를 통해 수집된 5가지 인간 상호작용 영상을 활용, 학습데이터와 평가데이터를 구성했으며, 연구자가 제안한 인간 상호작용 분류모델의 정확도는 95.45% 달성했다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017057156&target=NART&cn=DIKO0017057156",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "하이브리드 딥러닝 및 머신러닝 모델기반 감시 영상에서의 인간 상호작용 인식 하이브리드 딥러닝 및 머신러닝 모델기반 감시 영상에서의 인간 상호작용 인식 하이브리드 딥러닝 및 머신러닝 모델기반 감시 영상에서의 인간 상호작용 인식 본 연구는 실내환경에서 여러대의 CCTV카메라를 사용해 일반적으로 관찰되는 인간 상호작용 5종류(껴안기, 발로 차기, 밀기, 가르키기, 상호작용 없음)를 기준으로 건강한 남녀 13명을 대상으로 직접 녹화하며, 데이터셋을 직접 구축했다. 데이터셋은 4개의 서로 다른 방향에서 촬영된 영상으로 고성하였으며, 전처리를 통해 표준화하였다. 이후 ResNet모델의 2D CNN(Convolutional Neural Network)를 기반으로 경량 아키텍처를 구축하였다.&amp;#xD; 본 연구에서는 딥러닝과 머신러닝 분류기를 결합한 하이브리드(Hybrid Deep Learning)분류 방법을 활용해 인간의 상호작용을 분류하는 모델을 제안했다. 모델 훈련을 위한 데이터셋을 처리하는 과정에서, 비디오 시퀀스로 이루어진 데이터셋에서 신체의 핵심을 추출하는 단계는 딥러닝 모델이 적용되었으며, 추출된 특징을 활용해 분류하는 단계에는 머신러닝이 활용되었다.&amp;#xD; 본 연구에서 제안한 방법은 순천향대학교 차일드어세스룸에서 촬영된 4채널 CCTV 카메라를 통해 수집된 5가지 인간 상호작용 영상을 활용, 학습데이터와 평가데이터를 구성했으며, 연구자가 제안한 인간 상호작용 분류모델의 정확도는 95.45% 달성했다."
        },
        {
          "rank": 50,
          "score": 0.6905755996704102,
          "doc_id": "JAKO201911338887557",
          "title": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법",
          "abstract": "본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201911338887557&target=NART&cn=JAKO201911338887557",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 잡음 환경 음성 인식을 위한 심층 신경망 기반의 잡음 오염 함수 예측을 통한 음향 모델 적응 기법 본 논문에서는 잡음 환경에서 효과적인 음성 인식을 위하여 DNN(Deep Neural Network) 기반의 잡음 오염 함수 예측을 이용한 음향 모델 적응 기법을 제안한다. 깨끗한 음성과 잡음 정보를 입력으로 하고 오염된 음성에 대한 특징 벡터를 출력으로 하는 DNN을 학습하여 비선형 관계를 갖는 잡음 오염 함수를 예측한다. 예측된 잡음 오염 함수를 음향모델의 평균 벡터에 적용하여 잡음 환경에 적응된 음향 모델을 생성한다. Aurora 2.0 데이터를 이용한 음성 인식 성능 평가에서 본 논문에서 제안한 모델 적응 기법이 기존의 전처리, 모델 적응 기법에 비해 일치, 불일치 잡음 환경에서 모두 평균적으로 우수한 성능을 나타낸다. 특히 불일치 잡음 환경에서 평균 오류율이 15.87 %의 상대 향상률을 나타낸다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}