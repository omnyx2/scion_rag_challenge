{
  "id": "row_000020",
  "model_name": "Alibaba-NLP/gte-multilingual-base",
  "timestamp_kst": "2025-09-08T23:55:34.786437+09:00",
  "trial_id": "793500fb",
  "queries": [
    {
      "query": "제조 품질 개선을 위해 제안된 식스 시그마 기반 Big Data 활용 방법의 주요 절차를 요약해 주시겠습니까?",
      "query_meta": {
        "type": "original"
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8386000394821167,
          "doc_id": "DIKO0015505861",
          "title": "Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구",
          "abstract": "20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015505861&target=NART&cn=DIKO0015505861",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다."
        },
        {
          "rank": 2,
          "score": 0.7996029853820801,
          "doc_id": "JAKO201721961719817",
          "title": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법",
          "abstract": "제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721961719817&target=NART&cn=JAKO201721961719817",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다."
        },
        {
          "rank": 3,
          "score": 0.763455867767334,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.7368650436401367,
          "doc_id": "JAKO201615262489674",
          "title": "제조 공정 분석을 위한 빅데이터 클라우드 서비스",
          "abstract": "정보통신 기술의 발달로 과거에는 다룰 수 없었던 대용량의 데이터 처리가 가능해지면서 빅데이터의 관심이 고조되고 있다. 제조 산업은 축적된 데이터가 풍부하여 빅데이터의 적용 및 활용이 가장 기대되는 분야이다. 제조 기업의 공정은 생산설계, 생산, 판매 등의 프로세스가 복잡하게 얽혀있기 때문에 품질 관리와 생산효율성의 증대를 위해 제조 공정 프로세스의 효율화가 중요하다. 본 연구에서는 빅데이터 기술과 프로세스 마이닝 기법을 제조 공정 분석에 접목시킨 빅데이터 클라우드 서비스를 제안한다. 제조 기업은 클라우드 서비스를 활용하여 공정 프로세스의 개선 및 비용절감 등의 효과를 거둘 수 있다. 빅데이터 클라우드 서비스는 공정 프로세스 분석, 공정 시간 분석 등의 다양한 분석 서비스를 제공하며 구현 완료하였다. 사례 연구를 통해 클라우드 서비스의 유효성을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201615262489674&target=NART&cn=JAKO201615262489674",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 공정 분석을 위한 빅데이터 클라우드 서비스 제조 공정 분석을 위한 빅데이터 클라우드 서비스 제조 공정 분석을 위한 빅데이터 클라우드 서비스 정보통신 기술의 발달로 과거에는 다룰 수 없었던 대용량의 데이터 처리가 가능해지면서 빅데이터의 관심이 고조되고 있다. 제조 산업은 축적된 데이터가 풍부하여 빅데이터의 적용 및 활용이 가장 기대되는 분야이다. 제조 기업의 공정은 생산설계, 생산, 판매 등의 프로세스가 복잡하게 얽혀있기 때문에 품질 관리와 생산효율성의 증대를 위해 제조 공정 프로세스의 효율화가 중요하다. 본 연구에서는 빅데이터 기술과 프로세스 마이닝 기법을 제조 공정 분석에 접목시킨 빅데이터 클라우드 서비스를 제안한다. 제조 기업은 클라우드 서비스를 활용하여 공정 프로세스의 개선 및 비용절감 등의 효과를 거둘 수 있다. 빅데이터 클라우드 서비스는 공정 프로세스 분석, 공정 시간 분석 등의 다양한 분석 서비스를 제공하며 구현 완료하였다. 사례 연구를 통해 클라우드 서비스의 유효성을 검증하였다."
        },
        {
          "rank": 5,
          "score": 0.7295393943786621,
          "doc_id": "JAKO201623562837809",
          "title": "빅데이터 기반 군수품 품질정보 활용방안에 대한 연구",
          "abstract": "국방산업에 관련된 데이터의 양적팽창과 기술성장에 따라, 유의미한 품질정보를 추출하고 이를 통해 정책 제정 및 품질보증 업무에 활용하는 것이 요구되고 있다. 데이터에 기반한 경향 파악 및 의사결정 도출은 다수의 상황에 유연하게 대처할 수 있도록 하여 업무의 생산성을 높이고 새로운 기회를 발견하는 핵심 수단으로 활용될 수 있다. 따라서 국방산업에서는 개발단계부터 양산단계까지 다양한 품질정보들을 수집하고 이를 활용할 수 있도록 빅데이터 기반의 업무체계 구축이 필요하며, 축적된 정보를 활용하기 위한 방안이 필요하다. 본 연구는 정보체계 운용을 통해 신뢰성이 확보된 군수품의 품질정보를 수집하여 정형화된 빅데이터를 구축하는 방안을 제시하였으며, 사용자가 이를 활용할 수 있는 종합표준플랫폼을 제시하였다. 제안된 종합표준플랫폼은 군수품시험성적서 정보시스템(Test Report Information Service for Military Supplies, TRIS 시스템) 구축을 통하여 수행하였으며, TRIS 시스템을 통해 축적되는 정형 데이터의 활용방안을 제안하였다. 더불어 국방산업 비정형 데이터 활용방안에 대해 연구하였다. 본 연구의 결과는 향후 국방산업의 데이터 인프라 형성에 기여할 것으로 기대되며, 종합표준플랫폼을 통해 수집된 정보들은 군수품 품질보증에 관한 무기체계 별 전략 수립 및 동향 파악에 유용하게 활용될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623562837809&target=NART&cn=JAKO201623562837809",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 국방산업에 관련된 데이터의 양적팽창과 기술성장에 따라, 유의미한 품질정보를 추출하고 이를 통해 정책 제정 및 품질보증 업무에 활용하는 것이 요구되고 있다. 데이터에 기반한 경향 파악 및 의사결정 도출은 다수의 상황에 유연하게 대처할 수 있도록 하여 업무의 생산성을 높이고 새로운 기회를 발견하는 핵심 수단으로 활용될 수 있다. 따라서 국방산업에서는 개발단계부터 양산단계까지 다양한 품질정보들을 수집하고 이를 활용할 수 있도록 빅데이터 기반의 업무체계 구축이 필요하며, 축적된 정보를 활용하기 위한 방안이 필요하다. 본 연구는 정보체계 운용을 통해 신뢰성이 확보된 군수품의 품질정보를 수집하여 정형화된 빅데이터를 구축하는 방안을 제시하였으며, 사용자가 이를 활용할 수 있는 종합표준플랫폼을 제시하였다. 제안된 종합표준플랫폼은 군수품시험성적서 정보시스템(Test Report Information Service for Military Supplies, TRIS 시스템) 구축을 통하여 수행하였으며, TRIS 시스템을 통해 축적되는 정형 데이터의 활용방안을 제안하였다. 더불어 국방산업 비정형 데이터 활용방안에 대해 연구하였다. 본 연구의 결과는 향후 국방산업의 데이터 인프라 형성에 기여할 것으로 기대되며, 종합표준플랫폼을 통해 수집된 정보들은 군수품 품질보증에 관한 무기체계 별 전략 수립 및 동향 파악에 유용하게 활용될 것이다."
        },
        {
          "rank": 6,
          "score": 0.7202744483947754,
          "doc_id": "JAKO201310635656321",
          "title": "빅 데이터의 품질 요소 제안",
          "abstract": "빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201310635656321&target=NART&cn=JAKO201310635656321",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다."
        },
        {
          "rank": 7,
          "score": 0.7178694605827332,
          "doc_id": "DIKO0014874448",
          "title": "빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로",
          "abstract": "오늘날 대부분의 장치산업은 많은 복잡한 공정 파라미터와 데이터들로 구성되어 있으며, 이로 인해 원인을 파악하는 데 많은 시간, 비용 및 자원을 요구한다. 이러한 환경을 극복하고 경쟁에서 앞서나가려면 생산 경쟁력이 요구되는데 이제까지는 경쟁력 향상 방안의 하나로써 일부 기업들을 중심으로 6시그마 방법론을 주로 사용하였다. 그러나 위와 같이 Volume, Variety, Velocity특성을 내포하는 빅데이터를 사용해야 하는 과제에서는 분석에 있어 한계에 직면하게 된다. 근래 디스플레이, 반도체 등 장치산업에서는 빅데이터 분석을 활용하여 공정최적화에 상당한 효과를 거두고 있지만, 빅데이터 활용을 통한 이점 뿐 아니라 다른 부작용, 예를 들면 상관관계를 인과관계로 해석하거나 편향된 결과로 오판할 수도 있으며, 전체적 관점의 문제 해결이 아닌 국부적 요소 최적화로 재현성 확보가 어려울 뿐 만 아니라 예측 적확도가 오히려 떨어질 수도 있다. 이를 위해 6시그마 방법론의 전체 관점 문제 해결 프로세스, 빅데이터 분석의 데이터 형태와 관계없이 전수데이터를 중심으로 한 분석 및 최적화, 즉 6시그마 방법론과 빅데이터 분석 방법론의 장점을 접목한 새로운 적용 방안을 연구하고자 하며, 솔라셀 공정을 사례로 하여 효과를 검증하였다. 빅데이터 분석과6시그마의 대표적인 프로세스인 Define – Measure – Analyze – Improve – Control (DMAIC)를 접목한 새로운 문제해결 방법론 적용으로 보다 체계적이고 논리적인 변수선택 방법론을 제시하였고, 솔라셀 공정의 결과 수 천개의 공정 파라미터를 수 십개로 축소한 가운데 예측 적확도는 90%를 달성하였고 중요 특성인 효율 또한 Max 0.23%까지 개선 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014874448&target=NART&cn=DIKO0014874448",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 오늘날 대부분의 장치산업은 많은 복잡한 공정 파라미터와 데이터들로 구성되어 있으며, 이로 인해 원인을 파악하는 데 많은 시간, 비용 및 자원을 요구한다. 이러한 환경을 극복하고 경쟁에서 앞서나가려면 생산 경쟁력이 요구되는데 이제까지는 경쟁력 향상 방안의 하나로써 일부 기업들을 중심으로 6시그마 방법론을 주로 사용하였다. 그러나 위와 같이 Volume, Variety, Velocity특성을 내포하는 빅데이터를 사용해야 하는 과제에서는 분석에 있어 한계에 직면하게 된다. 근래 디스플레이, 반도체 등 장치산업에서는 빅데이터 분석을 활용하여 공정최적화에 상당한 효과를 거두고 있지만, 빅데이터 활용을 통한 이점 뿐 아니라 다른 부작용, 예를 들면 상관관계를 인과관계로 해석하거나 편향된 결과로 오판할 수도 있으며, 전체적 관점의 문제 해결이 아닌 국부적 요소 최적화로 재현성 확보가 어려울 뿐 만 아니라 예측 적확도가 오히려 떨어질 수도 있다. 이를 위해 6시그마 방법론의 전체 관점 문제 해결 프로세스, 빅데이터 분석의 데이터 형태와 관계없이 전수데이터를 중심으로 한 분석 및 최적화, 즉 6시그마 방법론과 빅데이터 분석 방법론의 장점을 접목한 새로운 적용 방안을 연구하고자 하며, 솔라셀 공정을 사례로 하여 효과를 검증하였다. 빅데이터 분석과6시그마의 대표적인 프로세스인 Define – Measure – Analyze – Improve – Control (DMAIC)를 접목한 새로운 문제해결 방법론 적용으로 보다 체계적이고 논리적인 변수선택 방법론을 제시하였고, 솔라셀 공정의 결과 수 천개의 공정 파라미터를 수 십개로 축소한 가운데 예측 적확도는 90%를 달성하였고 중요 특성인 효율 또한 Max 0.23%까지 개선 하였다."
        },
        {
          "rank": 8,
          "score": 0.6986260414123535,
          "doc_id": "ATN0025418069",
          "title": "머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구",
          "abstract": "In this study, I propose a method to automate the method to diagnose the quality of big data. The reason for automating the quality diagnosis of Big Data is that as the Fourth Industrial Revolution becomes a issue, there is a growing demand for more volumes of data to be generated and utilized. Data is growing rapidly. However, if it takes a lot of time to diagnose the quality of the data, it can take a long time to utilize the data or the quality of the data may be lowered.If you make decisions or predictions from these low-quality data, then the results will also give you the wrong direction.To solve this problem, I have developed a model that can automate diagnosis for improving the quality of Big Data using machine learning which can quickly diagnose and improve the data. Machine learning is used to automate domain classification tasks to prevent errors that may occur during domain classification and reduce work time. Based on the results of the research, I can contribute to the improvement of data quality to utilize big data by continuing research on the importance of data conversion, learning methods for unlearned data, and development of classification models for each domain.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025418069&target=NART&cn=ATN0025418069",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 In this study, I propose a method to automate the method to diagnose the quality of big data. The reason for automating the quality diagnosis of Big Data is that as the Fourth Industrial Revolution becomes a issue, there is a growing demand for more volumes of data to be generated and utilized. Data is growing rapidly. However, if it takes a lot of time to diagnose the quality of the data, it can take a long time to utilize the data or the quality of the data may be lowered.If you make decisions or predictions from these low-quality data, then the results will also give you the wrong direction.To solve this problem, I have developed a model that can automate diagnosis for improving the quality of Big Data using machine learning which can quickly diagnose and improve the data. Machine learning is used to automate domain classification tasks to prevent errors that may occur during domain classification and reduce work time. Based on the results of the research, I can contribute to the improvement of data quality to utilize big data by continuing research on the importance of data conversion, learning methods for unlearned data, and development of classification models for each domain."
        },
        {
          "rank": 9,
          "score": 0.695304274559021,
          "doc_id": "ATN0042342282",
          "title": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구",
          "abstract": "자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0042342282&target=NART&cn=ATN0042342282",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다."
        },
        {
          "rank": 10,
          "score": 0.6948313117027283,
          "doc_id": "JAKO202407845708604",
          "title": "빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로",
          "abstract": "지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비 절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와,오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한 신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407845708604&target=NART&cn=JAKO202407845708604",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비 절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와,오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한 신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다."
        },
        {
          "rank": 11,
          "score": 0.6934694647789001,
          "doc_id": "ATN0030121814",
          "title": "Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법",
          "abstract": "Recent focus on Big Data highlights the importance of organization’s data analytics capabilities. To meet the demand of such trend, research in Six Sigma quality innovation, a data driven solution, is becoming increasingly aware of Machine Learning and Big Data analytics. Traditionally, Six Sigma emphasizes the study of interpretable statistical models generated by designed data obtained through specified objects and processes. In contrast, the field of Machine Learning emphasizes predictability of a model generated with raw data and algorithmic techniques. For manufacturing industry, Six Sigma methodologies provide advantages over Machine Learning techniques because manufacturing industry requires clearly defined processes and high interpretability for applications on the field. Moreover, established processes in manufacturing industry facilitate collection of processed data from development, operation, and management stages. However, increase in sensing/log data from automated processes and elevated focus on association between quality/reliability and customer/market related raw data can impose limitations on DMAIC, one of Six Sigma breakthrough used for a project implementation. This paper introduces DPELR, a new Six Sigma breakthrough for project using Big Data, and presents details for proposed stages.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030121814&target=NART&cn=ATN0030121814",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Recent focus on Big Data highlights the importance of organization’s data analytics capabilities. To meet the demand of such trend, research in Six Sigma quality innovation, a data driven solution, is becoming increasingly aware of Machine Learning and Big Data analytics. Traditionally, Six Sigma emphasizes the study of interpretable statistical models generated by designed data obtained through specified objects and processes. In contrast, the field of Machine Learning emphasizes predictability of a model generated with raw data and algorithmic techniques. For manufacturing industry, Six Sigma methodologies provide advantages over Machine Learning techniques because manufacturing industry requires clearly defined processes and high interpretability for applications on the field. Moreover, established processes in manufacturing industry facilitate collection of processed data from development, operation, and management stages. However, increase in sensing/log data from automated processes and elevated focus on association between quality/reliability and customer/market related raw data can impose limitations on DMAIC, one of Six Sigma breakthrough used for a project implementation. This paper introduces DPELR, a new Six Sigma breakthrough for project using Big Data, and presents details for proposed stages."
        },
        {
          "rank": 12,
          "score": 0.689720094203949,
          "doc_id": "DIKO0016979118",
          "title": "빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로",
          "abstract": "지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와, 오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시&amp;#xD; 그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016979118&target=NART&cn=DIKO0016979118",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와, 오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시&amp;#xD; 그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다."
        },
        {
          "rank": 13,
          "score": 0.6890172958374023,
          "doc_id": "ATN0037480329",
          "title": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안",
          "abstract": "정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037480329&target=NART&cn=ATN0037480329",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다."
        },
        {
          "rank": 14,
          "score": 0.683397650718689,
          "doc_id": "ATN0025427128",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025427128&target=NART&cn=ATN0025427128",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice."
        },
        {
          "rank": 15,
          "score": 0.6805275678634644,
          "doc_id": "NART97302075",
          "title": "Big data processing framework for manufacturing",
          "abstract": "<P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97302075&target=NART&cn=NART97302075",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data processing framework for manufacturing Big data processing framework for manufacturing Big data processing framework for manufacturing <P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>"
        },
        {
          "rank": 16,
          "score": 0.6723029613494873,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 17,
          "score": 0.6719233989715576,
          "doc_id": "JAKO201507639684549",
          "title": "공간빅데이터를 위한 정보 시각화 방법",
          "abstract": "본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201507639684549&target=NART&cn=JAKO201507639684549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다."
        },
        {
          "rank": 18,
          "score": 0.6648510694503784,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 19,
          "score": 0.6640945672988892,
          "doc_id": "JAKO201710748277717",
          "title": "제조 공정 빅데이터 분석을 위한 플랫폼 연구",
          "abstract": "IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201710748277717&target=NART&cn=JAKO201710748277717",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다."
        },
        {
          "rank": 20,
          "score": 0.6637665629386902,
          "doc_id": "JAKO201430756851021",
          "title": "빅데이터 분산처리시스템의 품질평가모델",
          "abstract": "IT기술이 발전함에 따라, 우리가 접하는 데이터의 양은 기하급수적으로 늘어나고 있다. 이처럼 방대한 데이터들을 분석하고 관리하기 위한 기술로 등장한 것이 빅데이터 분산처리시스템이다. 기존 분산처리시스템에 대한 품질평가는 정형 데이터 중심의 환경을 바탕으로 이루어져 왔다. 그러므로, 이를 비정형 데이터 분석이 핵심인 빅데이터 분산처리시스템에 그대로 적용시킬 경우, 정확한 품질평가가 이루어질 수 없다. 따라서, 빅데이터 분석 환경을 고려한 분산처리시스템의 품질평가모델에 대한 연구가 필요하다. 본 논문에서는 소프트웨어 품질에 관한 국제 표준인 ISO/IEC9126에 근거하여 빅데이터 분산처리 시스템에서 요구되는 품질평가 요소를 도출하고, 이를 측정하기 위한 메트릭을 정의함으로써 새로이 품질평가모델을 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201430756851021&target=NART&cn=JAKO201430756851021",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분산처리시스템의 품질평가모델 빅데이터 분산처리시스템의 품질평가모델 빅데이터 분산처리시스템의 품질평가모델 IT기술이 발전함에 따라, 우리가 접하는 데이터의 양은 기하급수적으로 늘어나고 있다. 이처럼 방대한 데이터들을 분석하고 관리하기 위한 기술로 등장한 것이 빅데이터 분산처리시스템이다. 기존 분산처리시스템에 대한 품질평가는 정형 데이터 중심의 환경을 바탕으로 이루어져 왔다. 그러므로, 이를 비정형 데이터 분석이 핵심인 빅데이터 분산처리시스템에 그대로 적용시킬 경우, 정확한 품질평가가 이루어질 수 없다. 따라서, 빅데이터 분석 환경을 고려한 분산처리시스템의 품질평가모델에 대한 연구가 필요하다. 본 논문에서는 소프트웨어 품질에 관한 국제 표준인 ISO/IEC9126에 근거하여 빅데이터 분산처리 시스템에서 요구되는 품질평가 요소를 도출하고, 이를 측정하기 위한 메트릭을 정의함으로써 새로이 품질평가모델을 제안한다."
        },
        {
          "rank": 21,
          "score": 0.6607059836387634,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 22,
          "score": 0.6573786735534668,
          "doc_id": "ATN0030169335",
          "title": "중소기업을 위한 제조 빅데이터 분석 플랫폼 구축",
          "abstract": "To cope with Industry 4.0 and digital innovation, small and medium-sized manufacturers must use big data. It is difficult for small and medium-sized manufacturing companies that lack basic infrastructure such as budget, technology, and manpower to establish and operate their own big data analysis environment. The purpose of this study is to consider how to build a big data analysis platform from a supplier's perspective in order to promote the use of big data by SMEs.We proposed an integrated platform environment, in which domain experts who are the core of the three elements of manufacturing big data analytics platform, such as resources, technology, and human resources, collaborate with computer experts to perform various analysis. In order to verify the effectiveness of the established big data analysis system, we provided services to 7 SMEs and verified its usefulness. Data analysts conveniently performed various analysis in an integrated environment using this big data platform. The analyzed results were traced and managed through real time monitoring.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030169335&target=NART&cn=ATN0030169335",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 To cope with Industry 4.0 and digital innovation, small and medium-sized manufacturers must use big data. It is difficult for small and medium-sized manufacturing companies that lack basic infrastructure such as budget, technology, and manpower to establish and operate their own big data analysis environment. The purpose of this study is to consider how to build a big data analysis platform from a supplier's perspective in order to promote the use of big data by SMEs.We proposed an integrated platform environment, in which domain experts who are the core of the three elements of manufacturing big data analytics platform, such as resources, technology, and human resources, collaborate with computer experts to perform various analysis. In order to verify the effectiveness of the established big data analysis system, we provided services to 7 SMEs and verified its usefulness. Data analysts conveniently performed various analysis in an integrated environment using this big data platform. The analyzed results were traced and managed through real time monitoring."
        },
        {
          "rank": 23,
          "score": 0.6554337739944458,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 24,
          "score": 0.6531357765197754,
          "doc_id": "JAKO201831960581451",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "4차 산업혁명이 일어나면서 각 산업에서 새로운 개념이 탄생되었다. 각 산업의 새로운 개념은 빅데이터를 핵심 인프라로 가정하여 발전하고 있다. 따라서 빅데이터에 대한 품질관리가 점점 중요해 지고 있다. 본 논문에서는 빅데이터 품질 사례 연구를 통하여 빅데이터 품질관리 체계를 제시하고자 한다. 사례 연구를 위하여 새로운 정보기술을 활용한 법률서비스인 리걸테크 분야를 대상으로 하였다. 최근에 구현하고 있는 법무부 생활법률지식서비스를 위한 빅데이터 품질체계를 도출하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201831960581451&target=NART&cn=JAKO201831960581451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 4차 산업혁명이 일어나면서 각 산업에서 새로운 개념이 탄생되었다. 각 산업의 새로운 개념은 빅데이터를 핵심 인프라로 가정하여 발전하고 있다. 따라서 빅데이터에 대한 품질관리가 점점 중요해 지고 있다. 본 논문에서는 빅데이터 품질 사례 연구를 통하여 빅데이터 품질관리 체계를 제시하고자 한다. 사례 연구를 위하여 새로운 정보기술을 활용한 법률서비스인 리걸테크 분야를 대상으로 하였다. 최근에 구현하고 있는 법무부 생활법률지식서비스를 위한 빅데이터 품질체계를 도출하였다."
        },
        {
          "rank": 25,
          "score": 0.6530581712722778,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 26,
          "score": 0.6501783132553101,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 27,
          "score": 0.6479159593582153,
          "doc_id": "JAKO202032362242352",
          "title": "빅데이터 분석을 위한 파티션 기반 시각화 알고리즘",
          "abstract": "오늘날 빅데이터로부터 유의미한 결과를 도출하는 연구가 활발히 진행되고 있다. 본 논문에선 빅데이터의 데이터의 영역들을 파티션(partition)으로 설정하고 각 파티션들의 대표 값을 계산하여 변수들 사이의 상관관계를 분석 할 수 있는 파티션 기반 빅데이터 분석 알고리즘을 제안한다. 본 논문에선 파티션의 크기조절이 가능한 파티션 기반 빅데이터 분석 알고리즘의 파티션 크기 변화에 따른 시각화 결과를 비교분석하였다. 제안한 파티션 기반 빅데이터 분석 알고리즘을 검증하기 위해 의류 회사 'A'의 빅데이터를 분석하여 온도와 판매 가격 변화에 따른 상품의 판매량 변화를 분석하고 시각화하여 유의미한 결과를 얻을 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242352&target=NART&cn=JAKO202032362242352",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 오늘날 빅데이터로부터 유의미한 결과를 도출하는 연구가 활발히 진행되고 있다. 본 논문에선 빅데이터의 데이터의 영역들을 파티션(partition)으로 설정하고 각 파티션들의 대표 값을 계산하여 변수들 사이의 상관관계를 분석 할 수 있는 파티션 기반 빅데이터 분석 알고리즘을 제안한다. 본 논문에선 파티션의 크기조절이 가능한 파티션 기반 빅데이터 분석 알고리즘의 파티션 크기 변화에 따른 시각화 결과를 비교분석하였다. 제안한 파티션 기반 빅데이터 분석 알고리즘을 검증하기 위해 의류 회사 'A'의 빅데이터를 분석하여 온도와 판매 가격 변화에 따른 상품의 판매량 변화를 분석하고 시각화하여 유의미한 결과를 얻을 수 있었다."
        },
        {
          "rank": 28,
          "score": 0.6446369886398315,
          "doc_id": "JAKO201033359738092",
          "title": "공급망 품질향상을 위한 6시그마 적용방법",
          "abstract": "For the success of total six sigma innovation, it is necessary to improve the suppliers' quality in the supply chain. This paper presents the deployment and support system of six sigma innovation for supply chain quality improvement, with the application to an aerospace production company. The process of project selection, project implementation, financial effect verification, benefit sharing is presented. This paper will benefit the companies which are going to enhance all the companies in the supply chain via six sigma activities.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201033359738092&target=NART&cn=JAKO201033359738092",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공급망 품질향상을 위한 6시그마 적용방법 공급망 품질향상을 위한 6시그마 적용방법 공급망 품질향상을 위한 6시그마 적용방법 For the success of total six sigma innovation, it is necessary to improve the suppliers' quality in the supply chain. This paper presents the deployment and support system of six sigma innovation for supply chain quality improvement, with the application to an aerospace production company. The process of project selection, project implementation, financial effect verification, benefit sharing is presented. This paper will benefit the companies which are going to enhance all the companies in the supply chain via six sigma activities."
        },
        {
          "rank": 29,
          "score": 0.6435511112213135,
          "doc_id": "JAKO202130053207367",
          "title": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출",
          "abstract": "'빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202130053207367&target=NART&cn=JAKO202130053207367",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 '빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다."
        },
        {
          "rank": 30,
          "score": 0.642531156539917,
          "doc_id": "JAKO202408557619302",
          "title": "빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현",
          "abstract": "본 논문은 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현을 제안한다. 제안하는 시스템은 빅데이터로 구성된 미세먼지 및 기상 정보를 통해 미세먼지 대기환경지수를 분류하는 시스템이다. 이 시스템은 머신러닝 기반의 대기환경지수 분류 카테고리별 이상치에 따른 이상치 탐지 알고리즘 설계를 통해 미세먼지를 분류한다. 카메라에서 수집된 영상의 심도 데이터는 미세먼지 농도에 따른 영상을 수집한 후 미세먼지 가시마스크를 생성합니다. 그리고 모노 심도 추정 알고리즘을 통한 학습 기반 핑거프린팅 기법으로 모노스코프 카메라에서 수집된 미세먼지의 가시거리를 추론하여 미세먼지 농도를 도출합니다. 본 방법의 실험 및 분석을 위해 미세먼지 농도 데이터와 지역별, 시간별 CCTV 영상 데이터를 매칭하여 학습 데이터를 생성한 후 모델을 생성하여 실제 환경에서 테스트한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202408557619302&target=NART&cn=JAKO202408557619302",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 본 논문은 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현을 제안한다. 제안하는 시스템은 빅데이터로 구성된 미세먼지 및 기상 정보를 통해 미세먼지 대기환경지수를 분류하는 시스템이다. 이 시스템은 머신러닝 기반의 대기환경지수 분류 카테고리별 이상치에 따른 이상치 탐지 알고리즘 설계를 통해 미세먼지를 분류한다. 카메라에서 수집된 영상의 심도 데이터는 미세먼지 농도에 따른 영상을 수집한 후 미세먼지 가시마스크를 생성합니다. 그리고 모노 심도 추정 알고리즘을 통한 학습 기반 핑거프린팅 기법으로 모노스코프 카메라에서 수집된 미세먼지의 가시거리를 추론하여 미세먼지 농도를 도출합니다. 본 방법의 실험 및 분석을 위해 미세먼지 농도 데이터와 지역별, 시간별 CCTV 영상 데이터를 매칭하여 학습 데이터를 생성한 후 모델을 생성하여 실제 환경에서 테스트한다."
        },
        {
          "rank": 31,
          "score": 0.6416454315185547,
          "doc_id": "ATN0030123503",
          "title": "자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용",
          "abstract": "Success strategy in emerging automobile IT industry must start from the clear understanding of authentication system for automobile parts, established by international cooperation organizations. Major automobile producing countries established authentication systems for individual parts in 1980s. Moreover, they were operating internationally integrated part authentication systems by late 1990s. Consequently, domestic producers, who are late entrants in the international automobile market, need innovative methods to properly and urgently react to already well-established authentication systems. The following paper will identify and outline Six Sigma improvement process that can be applied within the industry. In order to do so, the paper will compare and contrast structures and characteristics of ISO/TS 16949 and ISO 26262, established authentication standards in the international automobile industry. Such approach will enhance domestic producer’s competitive advantages in surging areas of electric and/or self-driving automobiles. Domestic corporations who entered the field of automobile IT industry will be able to further advance their competitiveness by combining quality innovation from home appliance industry and newly acquired improvement process.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123503&target=NART&cn=ATN0030123503",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 Success strategy in emerging automobile IT industry must start from the clear understanding of authentication system for automobile parts, established by international cooperation organizations. Major automobile producing countries established authentication systems for individual parts in 1980s. Moreover, they were operating internationally integrated part authentication systems by late 1990s. Consequently, domestic producers, who are late entrants in the international automobile market, need innovative methods to properly and urgently react to already well-established authentication systems. The following paper will identify and outline Six Sigma improvement process that can be applied within the industry. In order to do so, the paper will compare and contrast structures and characteristics of ISO/TS 16949 and ISO 26262, established authentication standards in the international automobile industry. Such approach will enhance domestic producer’s competitive advantages in surging areas of electric and/or self-driving automobiles. Domestic corporations who entered the field of automobile IT industry will be able to further advance their competitiveness by combining quality innovation from home appliance industry and newly acquired improvement process."
        },
        {
          "rank": 32,
          "score": 0.6407805681228638,
          "doc_id": "DIKO0017154536",
          "title": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템",
          "abstract": "IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017154536&target=NART&cn=DIKO0017154536",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다."
        },
        {
          "rank": 33,
          "score": 0.6403403878211975,
          "doc_id": "JAKO201617338764393",
          "title": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구",
          "abstract": "본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201617338764393&target=NART&cn=JAKO201617338764393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다."
        },
        {
          "rank": 34,
          "score": 0.640143871307373,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 35,
          "score": 0.6388123035430908,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        },
        {
          "rank": 36,
          "score": 0.6365983486175537,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        },
        {
          "rank": 37,
          "score": 0.6364502906799316,
          "doc_id": "ART002127072",
          "title": "Development of a Big Data Capability Assessment Model",
          "abstract": "Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002127072&target=NART&cn=ART002127072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback."
        },
        {
          "rank": 38,
          "score": 0.6357386112213135,
          "doc_id": "ATN0048509631",
          "title": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안",
          "abstract": "빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0048509631&target=NART&cn=ATN0048509631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다."
        },
        {
          "rank": 39,
          "score": 0.6357104778289795,
          "doc_id": "JAKO201723954939431",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723954939431&target=NART&cn=JAKO201723954939431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다."
        },
        {
          "rank": 40,
          "score": 0.6351886987686157,
          "doc_id": "JAKO202125761334616",
          "title": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구",
          "abstract": "4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125761334616&target=NART&cn=JAKO202125761334616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다."
        },
        {
          "rank": 41,
          "score": 0.6347922682762146,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 42,
          "score": 0.634226381778717,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 43,
          "score": 0.6338154077529907,
          "doc_id": "JAKO201835146902109",
          "title": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법",
          "abstract": "인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201835146902109&target=NART&cn=JAKO201835146902109",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다."
        },
        {
          "rank": 44,
          "score": 0.6325014233589172,
          "doc_id": "JAKO201012259057254",
          "title": "데이터 품질관리 프레임워크와 비즈니스 시나리오",
          "abstract": "e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201012259057254&target=NART&cn=JAKO201012259057254",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 데이터 품질관리 프레임워크와 비즈니스 시나리오 e-비즈니스의 활성화로 기업과 조직에서 이해당사자 간의 데이터 교환이 활발해 짐에 따라, 신뢰성 있는 데이터의 확보 및 관리가 시급한 과제로 떠오르고 있다. 이러한 문제를 해결하기 위해, 본 논문은 데이터의 품질을 체계적으로 관리할 수 있는 프레임워크를 시나리오와 함께 제시한다. 데이터 품질 관리 프레임워크는 데이터 품질 모니터링, 데이터 품질 개선, 데이터 활용의 3단계로 구분되어 있으며 각 단계마다 3개씩, 총 9개의 프로세스로 구성되어 있다. 각 프로세스에는 필요성, 기능, 역할, 프로세스간의 관계가 명시되어 있다. 또한, 본 프레임워크를 현장에 직접 적용할 수 있도록, e-비즈니스에서 많이 사용되는 상품식별 및 분류 코드체계의 사례를 이용하여 업무 시나리오를 제시하였다."
        },
        {
          "rank": 45,
          "score": 0.6320399045944214,
          "doc_id": "JAKO202317861205261",
          "title": "준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안",
          "abstract": "국립해양조사원(KHOA, Korea Hydrographic and Oceanographic Agency)은 국가해양관측망의 안정적인 운영과 해양관측자료의 품질 향상을 위하여 관측시설물 유지관리와 해양관측자료의 품질처리(실시간 및 비실시간)를 수행하고 있다. 실시간 품질처리는 다양한 물리적 알고리즘 및 기준을 이용하여 자동 품질처리를 수행하는 것으로, 실시간 품질처리가 완료된 관측자료는 '국립해양조사원 홈페이지 누리집'을 통해 제공 중이다. 비실시간 품질처리는 매월 초순에 전월의 관측자료를 대상으로 품질관리 담당자가 수동 품질처리를 수행하는 것이며, 비실시간 품질처리가 완료된 자료는 가공 및 분석을 통해 통계 자료, 1시간 조위 등을 산출하여 해당 정보들을 간행물에서 제공하고 있다. 본 연구는 국내 해양관측자료의 품질처리 방법 개선을 위하여 기존 실시간, 비실시간 품질처리 기법 외 적용이 가능한 준실시간 품질처리 기법을 조사하고, 해당 기법을 해수위 관측자료에 적용 및 실험하여 활용 가능성을 검토하였다. 해양관측자료 준실시간 품질처리 기법의 조사 결과, 다양한 해양과 관련된 국제적인 유관기관(IOC, GLOSS 등)에서는 해수위(조위) 관측자료의 품질개선을 위해 SELENE(SEa LEvel NEar-real time quality control processing) 알고리즘의 적용을 적극 권장하고 있다. 이에 국립해양조사원의 조위관측소에서 수집한 조위 자료에 대해 품질처리 최적화 실험을 통해 적합한 매개변수를 산출하였으며, 해당 기법을 적용하여 품질처리 정확도를 분석하였다. 분석 결과, 특이상황을 제외한 조위 관측자료의 준실시간 품질처리 정확도는 평균 90% 이상으로 매우 양호하게 나타났다. 따라서 실시간 및 비실시간 품질검사 외 해당 준실시간 품질처리 기법을 품질검사 현업에 도입&#x00B7;적용한다면, 조위 관측자료의 품질개선과 더불어 신속한 품질처리 자료 생산으로 해양정보 서비스 활용도 향상에 큰 도움이 될 것으로 생각된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202317861205261&target=NART&cn=JAKO202317861205261",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 국립해양조사원(KHOA, Korea Hydrographic and Oceanographic Agency)은 국가해양관측망의 안정적인 운영과 해양관측자료의 품질 향상을 위하여 관측시설물 유지관리와 해양관측자료의 품질처리(실시간 및 비실시간)를 수행하고 있다. 실시간 품질처리는 다양한 물리적 알고리즘 및 기준을 이용하여 자동 품질처리를 수행하는 것으로, 실시간 품질처리가 완료된 관측자료는 '국립해양조사원 홈페이지 누리집'을 통해 제공 중이다. 비실시간 품질처리는 매월 초순에 전월의 관측자료를 대상으로 품질관리 담당자가 수동 품질처리를 수행하는 것이며, 비실시간 품질처리가 완료된 자료는 가공 및 분석을 통해 통계 자료, 1시간 조위 등을 산출하여 해당 정보들을 간행물에서 제공하고 있다. 본 연구는 국내 해양관측자료의 품질처리 방법 개선을 위하여 기존 실시간, 비실시간 품질처리 기법 외 적용이 가능한 준실시간 품질처리 기법을 조사하고, 해당 기법을 해수위 관측자료에 적용 및 실험하여 활용 가능성을 검토하였다. 해양관측자료 준실시간 품질처리 기법의 조사 결과, 다양한 해양과 관련된 국제적인 유관기관(IOC, GLOSS 등)에서는 해수위(조위) 관측자료의 품질개선을 위해 SELENE(SEa LEvel NEar-real time quality control processing) 알고리즘의 적용을 적극 권장하고 있다. 이에 국립해양조사원의 조위관측소에서 수집한 조위 자료에 대해 품질처리 최적화 실험을 통해 적합한 매개변수를 산출하였으며, 해당 기법을 적용하여 품질처리 정확도를 분석하였다. 분석 결과, 특이상황을 제외한 조위 관측자료의 준실시간 품질처리 정확도는 평균 90% 이상으로 매우 양호하게 나타났다. 따라서 실시간 및 비실시간 품질검사 외 해당 준실시간 품질처리 기법을 품질검사 현업에 도입&#x00B7;적용한다면, 조위 관측자료의 품질개선과 더불어 신속한 품질처리 자료 생산으로 해양정보 서비스 활용도 향상에 큰 도움이 될 것으로 생각된다."
        },
        {
          "rank": 46,
          "score": 0.6319866180419922,
          "doc_id": "NART98480176",
          "title": "Factors influencing effective use of big data: A research framework",
          "abstract": "<P><B>Abstract</B></P>  <P>Information systems (IS) research has explored &ldquo;effective use&rdquo; in a variety of contexts. However, it is yet to specifically consider it in the context of the unique characteristics of big data. Yet, organizations have a high appetite for big data, and there is growing evidence that investments in big data solutions do not always lead to the derivation of intended value. Accordingly, there is a need for rigorous academic guidance on what factors enable effective use of big data. With this paper, we aim to guide IS researchers such that the expansion of the body of knowledge on the effective use of big data can proceed in a structured and systematic manner and can subsequently lead to empirically driven guidance for organizations. Namely, with this paper, we cast a wide net to understand and consolidate from literature the potential factors that can influence the effective use of big data, so they may be further studied. To do so, we first conduct a systematic literature review. Our review identifies 41 factors, which we categorize into 7 themes, namely data quality; data privacy and security and governance; perceived organizational benefit; process management; people aspects; systems, tools, and technologies; and organizational aspects. To explore the existence of these themes in practice, we then analyze 45 published case studies that document insights into how specific companies use big data successfully. Finally, we propose a framework for the study of effective use of big data as a basis for future research. Our contributions aim to guide researchers in establishing the relevance and relationships within the identified themes and factors and are a step toward developing a deeper understanding of effective use of big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Comprehensive review of the literature relating to the effective use of big data. </LI> <LI>  Identification of 7 themes, from the current body of literature. </LI> <LI>  We propose a framework and highlight research areas that require attention. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98480176&target=NART&cn=NART98480176",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Factors influencing effective use of big data: A research framework Factors influencing effective use of big data: A research framework Factors influencing effective use of big data: A research framework <P><B>Abstract</B></P>  <P>Information systems (IS) research has explored &ldquo;effective use&rdquo; in a variety of contexts. However, it is yet to specifically consider it in the context of the unique characteristics of big data. Yet, organizations have a high appetite for big data, and there is growing evidence that investments in big data solutions do not always lead to the derivation of intended value. Accordingly, there is a need for rigorous academic guidance on what factors enable effective use of big data. With this paper, we aim to guide IS researchers such that the expansion of the body of knowledge on the effective use of big data can proceed in a structured and systematic manner and can subsequently lead to empirically driven guidance for organizations. Namely, with this paper, we cast a wide net to understand and consolidate from literature the potential factors that can influence the effective use of big data, so they may be further studied. To do so, we first conduct a systematic literature review. Our review identifies 41 factors, which we categorize into 7 themes, namely data quality; data privacy and security and governance; perceived organizational benefit; process management; people aspects; systems, tools, and technologies; and organizational aspects. To explore the existence of these themes in practice, we then analyze 45 published case studies that document insights into how specific companies use big data successfully. Finally, we propose a framework for the study of effective use of big data as a basis for future research. Our contributions aim to guide researchers in establishing the relevance and relationships within the identified themes and factors and are a step toward developing a deeper understanding of effective use of big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  Comprehensive review of the literature relating to the effective use of big data. </LI> <LI>  Identification of 7 themes, from the current body of literature. </LI> <LI>  We propose a framework and highlight research areas that require attention. </LI> </UL> </P>"
        },
        {
          "rank": 47,
          "score": 0.6307086944580078,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 48,
          "score": 0.6299519538879395,
          "doc_id": "JAKO202413350409295",
          "title": "빅데이터 기반의 화물운송 효율성 분석 방법론 개발",
          "abstract": "본 연구는 화물차 적재 여부를 추정하는 인공지능 모델을 개발을 통해 화물차 적재율을 분석하고 물류 운송 효율성을 측정할 수 있는 지표를 개발하는 것을 목표로 한다. 이를 위해, 데이터 파이프라인 개념을 도입하여 다양한 데이터를 융합하고, 화물차의 출&#x00B7;도착지, 운행경로, 방문 시설 등을 추출하였다. 이를 기반으로 XGBoost를 활용하여 화물차의 적재 여부 추정 모델을 개발하였으며, 최종적으로 화물 운송의 효율성을 측정할 수 있는 주요 지표들을 도출하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202413350409295&target=NART&cn=JAKO202413350409295",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반의 화물운송 효율성 분석 방법론 개발 빅데이터 기반의 화물운송 효율성 분석 방법론 개발 빅데이터 기반의 화물운송 효율성 분석 방법론 개발 본 연구는 화물차 적재 여부를 추정하는 인공지능 모델을 개발을 통해 화물차 적재율을 분석하고 물류 운송 효율성을 측정할 수 있는 지표를 개발하는 것을 목표로 한다. 이를 위해, 데이터 파이프라인 개념을 도입하여 다양한 데이터를 융합하고, 화물차의 출&#x00B7;도착지, 운행경로, 방문 시설 등을 추출하였다. 이를 기반으로 XGBoost를 활용하여 화물차의 적재 여부 추정 모델을 개발하였으며, 최종적으로 화물 운송의 효율성을 측정할 수 있는 주요 지표들을 도출하였다."
        },
        {
          "rank": 49,
          "score": 0.6288004517555237,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 50,
          "score": 0.6285861730575562,
          "doc_id": "ATN0038877162",
          "title": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구",
          "abstract": "Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038877162&target=NART&cn=ATN0038877162",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented."
        }
      ]
    },
    {
      "query": "제조 품질 개선을 위해 제안된 식스 시그마 기반 Big Data 활용 방법의 주요 절차는 무엇입니까?",
      "query_meta": {
        "type": "single_hop",
        "index": 0
      },
      "top_k": 50,
      "hits": [
        {
          "rank": 1,
          "score": 0.8608673810958862,
          "doc_id": "DIKO0015505861",
          "title": "Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구",
          "abstract": "20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015505861&target=NART&cn=DIKO0015505861",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다."
        },
        {
          "rank": 2,
          "score": 0.810658872127533,
          "doc_id": "JAKO201721961719817",
          "title": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법",
          "abstract": "제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201721961719817&target=NART&cn=JAKO201721961719817",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템을 위한 효과적인 시각화 기법 제조 빅데이터 시스템은 제조 전 공정에서 관련된 4M 데이터의 수집, 저장, 관리, 예측적 분석을 통해 선제적 제조 활동 개선이 가능한 의사결정을 지원하고 있다. 이러한 시스템에서 데이터의 효율적인 관리와 운영을 위해 데이터를 효과적으로 시각화하는 것이 무엇보다도 중요하다. 본 논문에서는 제조 빅데이터 시스템에서 데이터 수집, 분석 및 예측 결과를 효과적으로 보여 주기 위해 사용가능한 시각화 기법을 제시한다. 본 논문에서 제시된 시각화 기법을 통해 제조 현장에서 발생하는 문제를 보다 손쉽게 파악할 수 있었을 뿐만 아니라 이들 문제를 효과적으로 대응할 수 있어 매우 유용하게 사용될 수 있음을 확인하였다."
        },
        {
          "rank": 3,
          "score": 0.7806967496871948,
          "doc_id": "JAKO201810852361492",
          "title": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법",
          "abstract": "품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201810852361492&target=NART&cn=JAKO201810852361492",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 유제품 산업의 품질검사를 위한 빅데이터 플랫폼 개발: 머신러닝 접근법 품질검사는 중간상품이나 최종상품을 품질관리 표준을 만족하는 양품과 불량품으로 분리하는 일을 수행한다. 대량생산체계에서 품질을 수작업으로 검사하는 것은 일관성과 효율성을 저하시키므로 대량으로 생산되는 상품의 품질을 검사하는 것은 다수의 공정에서 기계에 의한 자동 확인과 분류를 포함하게 된다. 생산공정에서 발생하는 데이터를 활용하여 공정을 개선하고 최적화하려는 선행 연구들이 많았음에도 불구하고, 실시간에 많은 데이터를 처리하는데 있어서의 기술적인 한계로 인해 실제 구현에서의 제약이 많이 있었다. 최근 빅데이터에 관한 연구에서는 데이터 처리기술을 개선하였고, 실시간에 데이터를 수집, 처리, 분석하는 과정을 가능하게 하게 하고 있다. 본 논문에서는 품질검사를 위한 빅데이터 적용의 단계와 세부사항을 제안하고, 유제품 산업에 적용 사례를 제시하려고 한다. 먼저 선행 연구들을 조사하고, 제조 부문에 적용할 수 있는 빅데이터 분석절차를 제안하며 제안된 방법의 실현가능성을 평가하기 위해서, 유제품 산업 분야의 품질검사과정 중 하나에 회선신경망(Convolutional Neural Network) 기술 및 랜덤포레스트(Random Forest) 기술을 적용하였다. 품질검사를 위해 제품의 뚜껑 및 빨대의 사진을 수집, 처리, 분석하여, 결함 여부를 판단하고, 과거 품질 검사결과와 비교하였다. 제안된 방법은 과거에 수행되었던 품질검사에 비해 분류 정확성 측면에서 의미 있는 개선을 확인할 수 있었다. 본 연구를 통해, 유제품 산업의 빅데이터 활용을 통한 품질검사 정확도 개선 가능성을 확인하였다."
        },
        {
          "rank": 4,
          "score": 0.7558906674385071,
          "doc_id": "JAKO201615262489674",
          "title": "제조 공정 분석을 위한 빅데이터 클라우드 서비스",
          "abstract": "정보통신 기술의 발달로 과거에는 다룰 수 없었던 대용량의 데이터 처리가 가능해지면서 빅데이터의 관심이 고조되고 있다. 제조 산업은 축적된 데이터가 풍부하여 빅데이터의 적용 및 활용이 가장 기대되는 분야이다. 제조 기업의 공정은 생산설계, 생산, 판매 등의 프로세스가 복잡하게 얽혀있기 때문에 품질 관리와 생산효율성의 증대를 위해 제조 공정 프로세스의 효율화가 중요하다. 본 연구에서는 빅데이터 기술과 프로세스 마이닝 기법을 제조 공정 분석에 접목시킨 빅데이터 클라우드 서비스를 제안한다. 제조 기업은 클라우드 서비스를 활용하여 공정 프로세스의 개선 및 비용절감 등의 효과를 거둘 수 있다. 빅데이터 클라우드 서비스는 공정 프로세스 분석, 공정 시간 분석 등의 다양한 분석 서비스를 제공하며 구현 완료하였다. 사례 연구를 통해 클라우드 서비스의 유효성을 검증하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201615262489674&target=NART&cn=JAKO201615262489674",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 공정 분석을 위한 빅데이터 클라우드 서비스 제조 공정 분석을 위한 빅데이터 클라우드 서비스 제조 공정 분석을 위한 빅데이터 클라우드 서비스 정보통신 기술의 발달로 과거에는 다룰 수 없었던 대용량의 데이터 처리가 가능해지면서 빅데이터의 관심이 고조되고 있다. 제조 산업은 축적된 데이터가 풍부하여 빅데이터의 적용 및 활용이 가장 기대되는 분야이다. 제조 기업의 공정은 생산설계, 생산, 판매 등의 프로세스가 복잡하게 얽혀있기 때문에 품질 관리와 생산효율성의 증대를 위해 제조 공정 프로세스의 효율화가 중요하다. 본 연구에서는 빅데이터 기술과 프로세스 마이닝 기법을 제조 공정 분석에 접목시킨 빅데이터 클라우드 서비스를 제안한다. 제조 기업은 클라우드 서비스를 활용하여 공정 프로세스의 개선 및 비용절감 등의 효과를 거둘 수 있다. 빅데이터 클라우드 서비스는 공정 프로세스 분석, 공정 시간 분석 등의 다양한 분석 서비스를 제공하며 구현 완료하였다. 사례 연구를 통해 클라우드 서비스의 유효성을 검증하였다."
        },
        {
          "rank": 5,
          "score": 0.7529938817024231,
          "doc_id": "JAKO201623562837809",
          "title": "빅데이터 기반 군수품 품질정보 활용방안에 대한 연구",
          "abstract": "국방산업에 관련된 데이터의 양적팽창과 기술성장에 따라, 유의미한 품질정보를 추출하고 이를 통해 정책 제정 및 품질보증 업무에 활용하는 것이 요구되고 있다. 데이터에 기반한 경향 파악 및 의사결정 도출은 다수의 상황에 유연하게 대처할 수 있도록 하여 업무의 생산성을 높이고 새로운 기회를 발견하는 핵심 수단으로 활용될 수 있다. 따라서 국방산업에서는 개발단계부터 양산단계까지 다양한 품질정보들을 수집하고 이를 활용할 수 있도록 빅데이터 기반의 업무체계 구축이 필요하며, 축적된 정보를 활용하기 위한 방안이 필요하다. 본 연구는 정보체계 운용을 통해 신뢰성이 확보된 군수품의 품질정보를 수집하여 정형화된 빅데이터를 구축하는 방안을 제시하였으며, 사용자가 이를 활용할 수 있는 종합표준플랫폼을 제시하였다. 제안된 종합표준플랫폼은 군수품시험성적서 정보시스템(Test Report Information Service for Military Supplies, TRIS 시스템) 구축을 통하여 수행하였으며, TRIS 시스템을 통해 축적되는 정형 데이터의 활용방안을 제안하였다. 더불어 국방산업 비정형 데이터 활용방안에 대해 연구하였다. 본 연구의 결과는 향후 국방산업의 데이터 인프라 형성에 기여할 것으로 기대되며, 종합표준플랫폼을 통해 수집된 정보들은 군수품 품질보증에 관한 무기체계 별 전략 수립 및 동향 파악에 유용하게 활용될 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201623562837809&target=NART&cn=JAKO201623562837809",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 빅데이터 기반 군수품 품질정보 활용방안에 대한 연구 국방산업에 관련된 데이터의 양적팽창과 기술성장에 따라, 유의미한 품질정보를 추출하고 이를 통해 정책 제정 및 품질보증 업무에 활용하는 것이 요구되고 있다. 데이터에 기반한 경향 파악 및 의사결정 도출은 다수의 상황에 유연하게 대처할 수 있도록 하여 업무의 생산성을 높이고 새로운 기회를 발견하는 핵심 수단으로 활용될 수 있다. 따라서 국방산업에서는 개발단계부터 양산단계까지 다양한 품질정보들을 수집하고 이를 활용할 수 있도록 빅데이터 기반의 업무체계 구축이 필요하며, 축적된 정보를 활용하기 위한 방안이 필요하다. 본 연구는 정보체계 운용을 통해 신뢰성이 확보된 군수품의 품질정보를 수집하여 정형화된 빅데이터를 구축하는 방안을 제시하였으며, 사용자가 이를 활용할 수 있는 종합표준플랫폼을 제시하였다. 제안된 종합표준플랫폼은 군수품시험성적서 정보시스템(Test Report Information Service for Military Supplies, TRIS 시스템) 구축을 통하여 수행하였으며, TRIS 시스템을 통해 축적되는 정형 데이터의 활용방안을 제안하였다. 더불어 국방산업 비정형 데이터 활용방안에 대해 연구하였다. 본 연구의 결과는 향후 국방산업의 데이터 인프라 형성에 기여할 것으로 기대되며, 종합표준플랫폼을 통해 수집된 정보들은 군수품 품질보증에 관한 무기체계 별 전략 수립 및 동향 파악에 유용하게 활용될 것이다."
        },
        {
          "rank": 6,
          "score": 0.7393107414245605,
          "doc_id": "DIKO0014874448",
          "title": "빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로",
          "abstract": "오늘날 대부분의 장치산업은 많은 복잡한 공정 파라미터와 데이터들로 구성되어 있으며, 이로 인해 원인을 파악하는 데 많은 시간, 비용 및 자원을 요구한다. 이러한 환경을 극복하고 경쟁에서 앞서나가려면 생산 경쟁력이 요구되는데 이제까지는 경쟁력 향상 방안의 하나로써 일부 기업들을 중심으로 6시그마 방법론을 주로 사용하였다. 그러나 위와 같이 Volume, Variety, Velocity특성을 내포하는 빅데이터를 사용해야 하는 과제에서는 분석에 있어 한계에 직면하게 된다. 근래 디스플레이, 반도체 등 장치산업에서는 빅데이터 분석을 활용하여 공정최적화에 상당한 효과를 거두고 있지만, 빅데이터 활용을 통한 이점 뿐 아니라 다른 부작용, 예를 들면 상관관계를 인과관계로 해석하거나 편향된 결과로 오판할 수도 있으며, 전체적 관점의 문제 해결이 아닌 국부적 요소 최적화로 재현성 확보가 어려울 뿐 만 아니라 예측 적확도가 오히려 떨어질 수도 있다. 이를 위해 6시그마 방법론의 전체 관점 문제 해결 프로세스, 빅데이터 분석의 데이터 형태와 관계없이 전수데이터를 중심으로 한 분석 및 최적화, 즉 6시그마 방법론과 빅데이터 분석 방법론의 장점을 접목한 새로운 적용 방안을 연구하고자 하며, 솔라셀 공정을 사례로 하여 효과를 검증하였다. 빅데이터 분석과6시그마의 대표적인 프로세스인 Define – Measure – Analyze – Improve – Control (DMAIC)를 접목한 새로운 문제해결 방법론 적용으로 보다 체계적이고 논리적인 변수선택 방법론을 제시하였고, 솔라셀 공정의 결과 수 천개의 공정 파라미터를 수 십개로 축소한 가운데 예측 적확도는 90%를 달성하였고 중요 특성인 효율 또한 Max 0.23%까지 개선 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0014874448&target=NART&cn=DIKO0014874448",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 빅데이터 기반의 6시그마 적용 방안에 관한 연구 : 솔라셀 공정 최적화 사례 중심으로 오늘날 대부분의 장치산업은 많은 복잡한 공정 파라미터와 데이터들로 구성되어 있으며, 이로 인해 원인을 파악하는 데 많은 시간, 비용 및 자원을 요구한다. 이러한 환경을 극복하고 경쟁에서 앞서나가려면 생산 경쟁력이 요구되는데 이제까지는 경쟁력 향상 방안의 하나로써 일부 기업들을 중심으로 6시그마 방법론을 주로 사용하였다. 그러나 위와 같이 Volume, Variety, Velocity특성을 내포하는 빅데이터를 사용해야 하는 과제에서는 분석에 있어 한계에 직면하게 된다. 근래 디스플레이, 반도체 등 장치산업에서는 빅데이터 분석을 활용하여 공정최적화에 상당한 효과를 거두고 있지만, 빅데이터 활용을 통한 이점 뿐 아니라 다른 부작용, 예를 들면 상관관계를 인과관계로 해석하거나 편향된 결과로 오판할 수도 있으며, 전체적 관점의 문제 해결이 아닌 국부적 요소 최적화로 재현성 확보가 어려울 뿐 만 아니라 예측 적확도가 오히려 떨어질 수도 있다. 이를 위해 6시그마 방법론의 전체 관점 문제 해결 프로세스, 빅데이터 분석의 데이터 형태와 관계없이 전수데이터를 중심으로 한 분석 및 최적화, 즉 6시그마 방법론과 빅데이터 분석 방법론의 장점을 접목한 새로운 적용 방안을 연구하고자 하며, 솔라셀 공정을 사례로 하여 효과를 검증하였다. 빅데이터 분석과6시그마의 대표적인 프로세스인 Define – Measure – Analyze – Improve – Control (DMAIC)를 접목한 새로운 문제해결 방법론 적용으로 보다 체계적이고 논리적인 변수선택 방법론을 제시하였고, 솔라셀 공정의 결과 수 천개의 공정 파라미터를 수 십개로 축소한 가운데 예측 적확도는 90%를 달성하였고 중요 특성인 효율 또한 Max 0.23%까지 개선 하였다."
        },
        {
          "rank": 7,
          "score": 0.7376468777656555,
          "doc_id": "JAKO201310635656321",
          "title": "빅 데이터의 품질 요소 제안",
          "abstract": "빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201310635656321&target=NART&cn=JAKO201310635656321",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터의 품질 요소 제안 빅 데이터가 새로운 가치 창출과 문제 해결의 핵심 엔진이 되는 데이터 중심 시대가 본격적으로 시작되고 있다. 본 논문은 빅 데이터를 활용하기 위하여 빅 데이터의 품질 확보를 위한 품질 요소 정의와 품질 요소별 품질확보 전략에 대하여 논한다. 이를 위해 빅 데이터의 구축 사례, 빅 데이터의 자원 확보 방안 및 빅 데이터의 요소기술, 분석기술과 처리기술 등에 대해 살펴 보았다. 이를 통하여 빅 데이터의 품질 요소를 정의하고 품질 요소별 품질 확보 전략을 제안한다. 빅 데이터의 품질이 확보되면 기업은 대용량의 데이터에서 데이터의 재해석을 통하여 빅 데이터를 추출하고 기업의 경쟁력 제고를 위한 각종 전략을 수립할 것이다."
        },
        {
          "rank": 8,
          "score": 0.7215090990066528,
          "doc_id": "ATN0030121814",
          "title": "Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법",
          "abstract": "Recent focus on Big Data highlights the importance of organization’s data analytics capabilities. To meet the demand of such trend, research in Six Sigma quality innovation, a data driven solution, is becoming increasingly aware of Machine Learning and Big Data analytics. Traditionally, Six Sigma emphasizes the study of interpretable statistical models generated by designed data obtained through specified objects and processes. In contrast, the field of Machine Learning emphasizes predictability of a model generated with raw data and algorithmic techniques. For manufacturing industry, Six Sigma methodologies provide advantages over Machine Learning techniques because manufacturing industry requires clearly defined processes and high interpretability for applications on the field. Moreover, established processes in manufacturing industry facilitate collection of processed data from development, operation, and management stages. However, increase in sensing/log data from automated processes and elevated focus on association between quality/reliability and customer/market related raw data can impose limitations on DMAIC, one of Six Sigma breakthrough used for a project implementation. This paper introduces DPELR, a new Six Sigma breakthrough for project using Big Data, and presents details for proposed stages.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030121814&target=NART&cn=ATN0030121814",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Big Data의 활용을 위한 새로운 Six Sigma 프로젝트 실행 방법 Recent focus on Big Data highlights the importance of organization’s data analytics capabilities. To meet the demand of such trend, research in Six Sigma quality innovation, a data driven solution, is becoming increasingly aware of Machine Learning and Big Data analytics. Traditionally, Six Sigma emphasizes the study of interpretable statistical models generated by designed data obtained through specified objects and processes. In contrast, the field of Machine Learning emphasizes predictability of a model generated with raw data and algorithmic techniques. For manufacturing industry, Six Sigma methodologies provide advantages over Machine Learning techniques because manufacturing industry requires clearly defined processes and high interpretability for applications on the field. Moreover, established processes in manufacturing industry facilitate collection of processed data from development, operation, and management stages. However, increase in sensing/log data from automated processes and elevated focus on association between quality/reliability and customer/market related raw data can impose limitations on DMAIC, one of Six Sigma breakthrough used for a project implementation. This paper introduces DPELR, a new Six Sigma breakthrough for project using Big Data, and presents details for proposed stages."
        },
        {
          "rank": 9,
          "score": 0.7209175825119019,
          "doc_id": "JAKO202407845708604",
          "title": "빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로",
          "abstract": "지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비 절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와,오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한 신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202407845708604&target=NART&cn=JAKO202407845708604",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석: DX SS를 중심으로 지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비 절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와,오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한 신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다."
        },
        {
          "rank": 10,
          "score": 0.7168766260147095,
          "doc_id": "DIKO0016979118",
          "title": "빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로",
          "abstract": "지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와, 오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시&amp;#xD; 그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016979118&target=NART&cn=DIKO0016979118",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 빅데이터 기반 6시그마 방법론의 유효성 분석 : DX SS를 중심으로 지난 수년간 6시그마는 제조업의 주요 혁신 방법론으로, 품질개선과 경비절감을 위해 사용되었다. 그러나 스마트공장 확산으로 인한 초 단위 데이터 생성 등, 방대한 양의 데이터를 분석하기 어려운 문제와, 오랫동안 정착된 형식적 사용으로 인해, 6시그마의 한계가 지적되었다. 6시그마의 한계를 극복하기 위해, 최근에 빅데이터 기반 6시그마 기법이 연구되고 있다. 빅데이터 기반 6시&amp;#xD; 그마는, 6시그마의 강점인 통계적 검증, 수학적 최적화, 높은 해석력과, 빅데이터 분석의 강점인 기계학습을 모두 활용할 수 있다. 그러나, 최근 연구된 빅데이터 기반 6시그마 기법이 제조공정 및 경영 성과에 미치는 영향에 대한 검증은 미비하다. 이러한 이유로 실무에서는, 빅데이터 기반 6시그마 기법에 대한신뢰성이 높지 않아 제대로 활용하지 못하고 있다. 본 연구에서는, 빅데이터 기반 6시그마인 DX SS의 유효성 분석을 통해 제조공정의 효율성에 미치는 영향을 알아본다. 또한 기업에서 이 기법을 성공적으로 도입 및 정착시키기 위한 핵심 성공 정책을 도출한다. 추가적으로, 성공 정책에 대한 연구 없이 전 임직원의 참여가 수반되지 못한 잘못된 정책으로 방법론이 중단된 사례는, 핵심 성공 정책 연구에 대한 중요성을 보여준다. 제조기업들이 본 연구에서 제시하는 방법론을 적극 도입하고 사용하여 성공적인 성과를 거둘 수 있도록 본 연구가 도움이 되기를 기대한다."
        },
        {
          "rank": 11,
          "score": 0.7147189378738403,
          "doc_id": "ATN0037480329",
          "title": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안",
          "abstract": "정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0037480329&target=NART&cn=ATN0037480329",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 빅데이터(Big data) 기술 적용 시스템 감리 점검방안 정보시스템감리의 제도화는 정보화사업의 품질향상에 큰 도움이 된 것으로 파악된다. 그러나, 한편으로는 감리활동이 통제측면에서 의견을 제시하는 경향이 있고 이는 사업에 부담으로만 작용하고 품질 확보에는 오히려 도움이 되지 못한다는 주장도 제기되고 있다. 또한 감리 결과가 주관적인 측면이 많아 감리원의 역량에 따라서 의견이 다른 경우가 발생하고, 이는 감리 의견에 대한 신뢰성을 저하시키는 요인이 된다는 것이며, 정보시스템감리 결과에 대한 성과 평가체계 미비, 최신 IT 기술에 대한 감리원 수행능력(전문성) 부족 등의 문제점은 감리가 일정부분 정보화사업의 성공에 공헌한 바가 있으나, 질적 개선이 필요한 것으로 볼 수 있다. 정보시스템 감리의 품질 향상을 위해서는 1차적으로 감리를 수행하는 주체의 노력이 중요하지만, 이의 기반이 되는 적절한 점검체계나 가이드 등에 대한 정비 노력이 선행되어야 할 것으로 판단된다. 이에 본 연구에서는 빅데이터와 같은 최신 기술을 적용한 정보화 사업의 특징과 발주기관 요구사항을 감안하여 빅데이터 기반의 공공 서비스를 구축하는 사업의 감리 수행 시 참조할 수 있는 점검 포인트를 구축 단계별로 제시하였다. 빅데이터와 같은 최신 기술 적용 사업의 감리를 효과적으로 수행하며 사업의 목적에 부합한 가이드를 제시할 수 있도록 구체적인 감리수행 방안을 마련하는 것이 본 연구의 목적이다."
        },
        {
          "rank": 12,
          "score": 0.7140234112739563,
          "doc_id": "ATN0042342282",
          "title": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구",
          "abstract": "자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0042342282&target=NART&cn=ATN0042342282",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 빅데이터 기반 태깅 시스템의 데이터 식별 프로세스 개선을 위한 실증적 연구 자동식별 및 데이터 획득(Automatic Identification & Data Capture) 시스템 AIDC는 개별 항목의 정보를 식별, 확인, 기록, 통신 및 저장하는 기술이다. 자동식별 및 데이터 획득은 4차 산업혁명을 기반으로 하는 진보된 다양한 분야에서 사용이 가능하며, 산업분야에서 프로세스 자동화의 핵심 기술로 사용되고 있다. 기존의 데이터를 수집하고 식별 하는 방법은 바코드, 스캔 기능 단말기, 라벨 기능 코드, RF 주파수 스펙트럼을 사용 한다. 일반적으로 사용되는 자동식별 및 데이터 획득 기술의 수동 태그는 리더의 전자기장에서 파생 된 전력을 사용하여 데이터를 리더로 다시 전송하게 된다. 리더는 식별 범위 안에 들어오는 많은 수의 태그들은 동시에 식별을 하기 위하여 태그 충돌 현상을 만들어서 식별 성능의 문제를 가져올 수 있다. 리더의 식별 범위 안에 들어오는 많은 수의 태그들이 동시에 식별을 시도 할 때, 태그 충돌 현상이 발생 되고 결과적으로 정확한 식별을 하지 못하게 된다. 태그 식별 기술에서 시스템의 효율을 향상 시키는 많은 방법들이 존재하며 식별 프로세스가 복잡하면 다수의 비용적인 부분이 발생하게 된다. 4차산업 혁명 기반 기술에 적용을 위하여, 기존 방법의 식별 알고리즘을 빅데이터 분석 기법을 사용하여, 태그수와 프레임 수를 증가하며 시뮬레이션을 수행 하였다. 결과적으로 추측 가능한 태그의 수를 알아낼 수 있는 기존의 예측 방법을 빅데이터 분석을 통하여 추정 하였다."
        },
        {
          "rank": 13,
          "score": 0.712491512298584,
          "doc_id": "ATN0025418069",
          "title": "머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구",
          "abstract": "In this study, I propose a method to automate the method to diagnose the quality of big data. The reason for automating the quality diagnosis of Big Data is that as the Fourth Industrial Revolution becomes a issue, there is a growing demand for more volumes of data to be generated and utilized. Data is growing rapidly. However, if it takes a lot of time to diagnose the quality of the data, it can take a long time to utilize the data or the quality of the data may be lowered.If you make decisions or predictions from these low-quality data, then the results will also give you the wrong direction.To solve this problem, I have developed a model that can automate diagnosis for improving the quality of Big Data using machine learning which can quickly diagnose and improve the data. Machine learning is used to automate domain classification tasks to prevent errors that may occur during domain classification and reduce work time. Based on the results of the research, I can contribute to the improvement of data quality to utilize big data by continuing research on the importance of data conversion, learning methods for unlearned data, and development of classification models for each domain.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025418069&target=NART&cn=ATN0025418069",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 In this study, I propose a method to automate the method to diagnose the quality of big data. The reason for automating the quality diagnosis of Big Data is that as the Fourth Industrial Revolution becomes a issue, there is a growing demand for more volumes of data to be generated and utilized. Data is growing rapidly. However, if it takes a lot of time to diagnose the quality of the data, it can take a long time to utilize the data or the quality of the data may be lowered.If you make decisions or predictions from these low-quality data, then the results will also give you the wrong direction.To solve this problem, I have developed a model that can automate diagnosis for improving the quality of Big Data using machine learning which can quickly diagnose and improve the data. Machine learning is used to automate domain classification tasks to prevent errors that may occur during domain classification and reduce work time. Based on the results of the research, I can contribute to the improvement of data quality to utilize big data by continuing research on the importance of data conversion, learning methods for unlearned data, and development of classification models for each domain."
        },
        {
          "rank": 14,
          "score": 0.7109463214874268,
          "doc_id": "ATN0025427128",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025427128&target=NART&cn=ATN0025427128",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 With the advent of the fourth industrial revolution, each industry has been innovated with new concepts. New concept of each industry takes advantage of new information technologies based on big data infra. Thus quality control of big data is becoming more important. In this paper, we try to develop a framework of big data service quality through a case study. A ‘Legal Tech’ service was selected for the case study. Especially a big data quality framework was developed for a living law service in the Ministry of Justice."
        },
        {
          "rank": 15,
          "score": 0.7031412124633789,
          "doc_id": "NART97302075",
          "title": "Big data processing framework for manufacturing",
          "abstract": "<P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART97302075&target=NART&cn=NART97302075",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data processing framework for manufacturing Big data processing framework for manufacturing Big data processing framework for manufacturing <P><B>Abstract</B></P>  <P>Data analysis of manufacturing plays a vital part in the intelligent manufacturing service of Product-Service Systems (PSS). In order to solve the problem that, manufacturing companies can&rsquo;t obtain valuable information from enterprise&rsquo;s big data through traditional data analysis methods, this paper put forward a data processing architecture framework and introduce the predictive algorithm (Random Forest). Finally, a real-time prediction of quality under this framework which uses the random forest algorithm is given to verify the usefulness of the architecture framework.</P>"
        },
        {
          "rank": 16,
          "score": 0.7000528573989868,
          "doc_id": "ATN0025420763",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420763&target=NART&cn=ATN0025420763",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 The research on data quality has been performed for a long time. However, the research focused on structured data.With the recent digital revolution or the fourth industrial revolution, quality control of big data is becoming more important.In this paper, we analyze and classify big data quality types through previous research. The types of big data quality can be classified into value, data structure, process, value chain, and maturity model. Based on these comparative studies, this paper proposes a new standard, service quality of big data."
        },
        {
          "rank": 17,
          "score": 0.6924809217453003,
          "doc_id": "JAKO201430756851021",
          "title": "빅데이터 분산처리시스템의 품질평가모델",
          "abstract": "IT기술이 발전함에 따라, 우리가 접하는 데이터의 양은 기하급수적으로 늘어나고 있다. 이처럼 방대한 데이터들을 분석하고 관리하기 위한 기술로 등장한 것이 빅데이터 분산처리시스템이다. 기존 분산처리시스템에 대한 품질평가는 정형 데이터 중심의 환경을 바탕으로 이루어져 왔다. 그러므로, 이를 비정형 데이터 분석이 핵심인 빅데이터 분산처리시스템에 그대로 적용시킬 경우, 정확한 품질평가가 이루어질 수 없다. 따라서, 빅데이터 분석 환경을 고려한 분산처리시스템의 품질평가모델에 대한 연구가 필요하다. 본 논문에서는 소프트웨어 품질에 관한 국제 표준인 ISO/IEC9126에 근거하여 빅데이터 분산처리 시스템에서 요구되는 품질평가 요소를 도출하고, 이를 측정하기 위한 메트릭을 정의함으로써 새로이 품질평가모델을 제안한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201430756851021&target=NART&cn=JAKO201430756851021",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분산처리시스템의 품질평가모델 빅데이터 분산처리시스템의 품질평가모델 빅데이터 분산처리시스템의 품질평가모델 IT기술이 발전함에 따라, 우리가 접하는 데이터의 양은 기하급수적으로 늘어나고 있다. 이처럼 방대한 데이터들을 분석하고 관리하기 위한 기술로 등장한 것이 빅데이터 분산처리시스템이다. 기존 분산처리시스템에 대한 품질평가는 정형 데이터 중심의 환경을 바탕으로 이루어져 왔다. 그러므로, 이를 비정형 데이터 분석이 핵심인 빅데이터 분산처리시스템에 그대로 적용시킬 경우, 정확한 품질평가가 이루어질 수 없다. 따라서, 빅데이터 분석 환경을 고려한 분산처리시스템의 품질평가모델에 대한 연구가 필요하다. 본 논문에서는 소프트웨어 품질에 관한 국제 표준인 ISO/IEC9126에 근거하여 빅데이터 분산처리 시스템에서 요구되는 품질평가 요소를 도출하고, 이를 측정하기 위한 메트릭을 정의함으로써 새로이 품질평가모델을 제안한다."
        },
        {
          "rank": 18,
          "score": 0.6855661273002625,
          "doc_id": "JAKO201710748277717",
          "title": "제조 공정 빅데이터 분석을 위한 플랫폼 연구",
          "abstract": "IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201710748277717&target=NART&cn=JAKO201710748277717",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 제조 공정 빅데이터 분석을 위한 플랫폼 연구 IoT, 클라우드 컴퓨팅, 빅데이터와 같은 주요 ICT 기술이 제조 분야에 적용되기 시작하면서 스마트 공장 구축이 본격화 되고 있다. 스마트 공장 구현의 핵심은 공장 내외부의 데이터 확보 및 분석력에 있다. 따라서 빅데이터 분석 플랫폼에 대한 필요성이 증가하고 있다. 본 연구의 목적은 제조 공정 빅데이터 분석을 위한 플랫폼을 구성하고, 분석을 위한 통합 메소드를 제안하는데 있다. 제안하는 플랫폼은 대량의 데이터 셋을 분산 처리하기 위해 분석도구 R과 하둡을 통합한 RHadoop 기반 구조로서 자동화 시스템의 단위 공정 및 공장 내에서 수집되는 빅데이터를 하둡 HBase에 직접 저장 및 분석이 가능하다. 또한 기존 RDB 기반 분석의 한계점을 보완하였다. 이러한 플랫폼은 스마트 공장을 위한 단위 공정 적합성을 고려하여 개발되어야 하며, 제조 공정에 스마트 공장을 도입하고자 하는 중소기업에 IoT 플랫폼 구축의 가이드가 될 수 있을 것으로 전망된다."
        },
        {
          "rank": 19,
          "score": 0.6798116564750671,
          "doc_id": "JAKO201507639684549",
          "title": "공간빅데이터를 위한 정보 시각화 방법",
          "abstract": "본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201507639684549&target=NART&cn=JAKO201507639684549",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 공간빅데이터를 위한 정보 시각화 방법 본 연구에서는 공간빅데이터의 개념과 특징을 정의하고 데이터에 대한 통찰력을 높일 수 있는 정보 시각화 방법론을 조사하였다. 또한 시각화 과정에서 발생할 수 있는 문제점 및 해결방법을 제시하였다. 공간빅데이터를 공간정보의 정량적인 확장의 결과와 빅데이터의 정성적인 확장의 결과로 정의하였다. 공간빅데이터는 6V(Volume, Variety, Velocity, Value, Veracity, Visualization)의 특징을 갖고 있으며, 최근 활용 서비스 측면이 이슈화 되면서 공간빅데이터에 대한 통찰력을 제공하여 데이터의 활용 가치를 높이기 위해 공간빅데이터의 시각화가 주목받고 있다. 정보 시각화의 방법은 Matthias, Ben, 정보디자인교과서 등을 통하여 다양한 방법으로 정의 되어 있으나 공간빅데이터의 시각화는 방대한 양의 원시 데이터를 대상으로 하기 때문에 데이터의 조직화 과정을 거쳐야 하며 이를 통해 사용자에게 전달하려는 정보를 추출해야 하는 차이점이 있다. 추출된 정보는 특성에 따른 적합한 시각적 표현 방법을 사용해야 하며, 많은 양의 데이터를 시각적으로 표현하는 것은 사용자에게 정확한 정보를 제공 할 수 없으므로 필터링, 샘플링, 데이터 비닝, 클러스터링 등을 이용하여 데이터를 축소하여 표현하는 방법이 필요하다."
        },
        {
          "rank": 20,
          "score": 0.6793869733810425,
          "doc_id": "JAKO201409150679222",
          "title": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례-",
          "abstract": "지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201409150679222&target=NART&cn=JAKO201409150679222",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 기업의 빅데이터 적용방안 연구 -A사, Y사 빅데이터 시스템 적용 사례- 지난 수년간 스마트 폰 같은 스마트 기기의 빠른 확산과 함께 인터넷과 SNS 등 소셜 미디어가 급성장함에 따라 개인 정보와 소비패턴, 위치 정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, M2M (Machine to Machine)과 IoT (Internet of Things) 등이 활성화되면서 IT 및 생산인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 및 비정형 데이터의 적용사례를 고찰함으로써 데이터 유형에 따른적용 영역별 파급효과를 알아본다. 또한 일반적으로 알려져 있는 비정형 빅데이터는 물론 정형빅데이터를 활용하여 실제로 기업에 보다 나은 가치를 창출할 수 있는 방안을 알아보는 것을 목적으로 한다. 이에 대한연구 결과로 빅데이터의 기업내 활동이 나아갈 수 있는 지향점으로써 내 외부에서 발생하는 정형데이터와 비정형 데이터를 적절히 결합함으로써 분석의 효과를 극대화 할 수 있음을 보여 주었다."
        },
        {
          "rank": 21,
          "score": 0.6749540567398071,
          "doc_id": "ATN0030169335",
          "title": "중소기업을 위한 제조 빅데이터 분석 플랫폼 구축",
          "abstract": "To cope with Industry 4.0 and digital innovation, small and medium-sized manufacturers must use big data. It is difficult for small and medium-sized manufacturing companies that lack basic infrastructure such as budget, technology, and manpower to establish and operate their own big data analysis environment. The purpose of this study is to consider how to build a big data analysis platform from a supplier's perspective in order to promote the use of big data by SMEs.We proposed an integrated platform environment, in which domain experts who are the core of the three elements of manufacturing big data analytics platform, such as resources, technology, and human resources, collaborate with computer experts to perform various analysis. In order to verify the effectiveness of the established big data analysis system, we provided services to 7 SMEs and verified its usefulness. Data analysts conveniently performed various analysis in an integrated environment using this big data platform. The analyzed results were traced and managed through real time monitoring.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030169335&target=NART&cn=ATN0030169335",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 중소기업을 위한 제조 빅데이터 분석 플랫폼 구축 To cope with Industry 4.0 and digital innovation, small and medium-sized manufacturers must use big data. It is difficult for small and medium-sized manufacturing companies that lack basic infrastructure such as budget, technology, and manpower to establish and operate their own big data analysis environment. The purpose of this study is to consider how to build a big data analysis platform from a supplier's perspective in order to promote the use of big data by SMEs.We proposed an integrated platform environment, in which domain experts who are the core of the three elements of manufacturing big data analytics platform, such as resources, technology, and human resources, collaborate with computer experts to perform various analysis. In order to verify the effectiveness of the established big data analysis system, we provided services to 7 SMEs and verified its usefulness. Data analysts conveniently performed various analysis in an integrated environment using this big data platform. The analyzed results were traced and managed through real time monitoring."
        },
        {
          "rank": 22,
          "score": 0.6749364733695984,
          "doc_id": "JAKO201506849872281",
          "title": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰",
          "abstract": "빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201506849872281&target=NART&cn=JAKO201506849872281",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 효과적인 빅데이터분석 기획 접근법에 대한 융합적 고찰 빅데이터분석은 조직의 문제해결을 위한 융합적 수단이다. 효과적인 문제해결을 위해서는 문제의 형태, 데이터의 유형 및 존재여부, 데이터 분석역량, 분석을 위한 기반정보기술의 수준 등 다양한 요인을 융합적으로 고려하여 문제해결의 접근법이 결정되어야 한다. 본 연구에서는 기획 접근법으로 논리적인 하향식 접근법, 데이터기반의 상향식 접근법, 그리고 문제해결 환경의 불확실성을 극복하기 위한 프로토타이핑 접근법 등 세 가지 유형을 제안한다. 특히, 이 유형 중에서 창의적 문제해결과 상향식 접근법이 어떤 연관성을 갖는지 살펴본다. 또한 데이터 거버넌스와 데이터 분석역량을 융합적으로 고려하여 조직의 빅데이터분석의 소싱과 관련한 주요 전략적 이슈를 도출한다."
        },
        {
          "rank": 23,
          "score": 0.6736873388290405,
          "doc_id": "ATN0030123503",
          "title": "자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용",
          "abstract": "Success strategy in emerging automobile IT industry must start from the clear understanding of authentication system for automobile parts, established by international cooperation organizations. Major automobile producing countries established authentication systems for individual parts in 1980s. Moreover, they were operating internationally integrated part authentication systems by late 1990s. Consequently, domestic producers, who are late entrants in the international automobile market, need innovative methods to properly and urgently react to already well-established authentication systems. The following paper will identify and outline Six Sigma improvement process that can be applied within the industry. In order to do so, the paper will compare and contrast structures and characteristics of ISO/TS 16949 and ISO 26262, established authentication standards in the international automobile industry. Such approach will enhance domestic producer’s competitive advantages in surging areas of electric and/or self-driving automobiles. Domestic corporations who entered the field of automobile IT industry will be able to further advance their competitiveness by combining quality innovation from home appliance industry and newly acquired improvement process.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0030123503&target=NART&cn=ATN0030123503",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 자동차 IT 전장 분야 품질 혁신을 위한 식스 시그마 개선 방법의 적용 Success strategy in emerging automobile IT industry must start from the clear understanding of authentication system for automobile parts, established by international cooperation organizations. Major automobile producing countries established authentication systems for individual parts in 1980s. Moreover, they were operating internationally integrated part authentication systems by late 1990s. Consequently, domestic producers, who are late entrants in the international automobile market, need innovative methods to properly and urgently react to already well-established authentication systems. The following paper will identify and outline Six Sigma improvement process that can be applied within the industry. In order to do so, the paper will compare and contrast structures and characteristics of ISO/TS 16949 and ISO 26262, established authentication standards in the international automobile industry. Such approach will enhance domestic producer’s competitive advantages in surging areas of electric and/or self-driving automobiles. Domestic corporations who entered the field of automobile IT industry will be able to further advance their competitiveness by combining quality innovation from home appliance industry and newly acquired improvement process."
        },
        {
          "rank": 24,
          "score": 0.6723984479904175,
          "doc_id": "JAKO201831960581451",
          "title": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계",
          "abstract": "4차 산업혁명이 일어나면서 각 산업에서 새로운 개념이 탄생되었다. 각 산업의 새로운 개념은 빅데이터를 핵심 인프라로 가정하여 발전하고 있다. 따라서 빅데이터에 대한 품질관리가 점점 중요해 지고 있다. 본 논문에서는 빅데이터 품질 사례 연구를 통하여 빅데이터 품질관리 체계를 제시하고자 한다. 사례 연구를 위하여 새로운 정보기술을 활용한 법률서비스인 리걸테크 분야를 대상으로 하였다. 최근에 구현하고 있는 법무부 생활법률지식서비스를 위한 빅데이터 품질체계를 도출하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201831960581451&target=NART&cn=JAKO201831960581451",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 빅데이터 품질 사례연구 : 법률 서비스 품질 체계 4차 산업혁명이 일어나면서 각 산업에서 새로운 개념이 탄생되었다. 각 산업의 새로운 개념은 빅데이터를 핵심 인프라로 가정하여 발전하고 있다. 따라서 빅데이터에 대한 품질관리가 점점 중요해 지고 있다. 본 논문에서는 빅데이터 품질 사례 연구를 통하여 빅데이터 품질관리 체계를 제시하고자 한다. 사례 연구를 위하여 새로운 정보기술을 활용한 법률서비스인 리걸테크 분야를 대상으로 하였다. 최근에 구현하고 있는 법무부 생활법률지식서비스를 위한 빅데이터 품질체계를 도출하였다."
        },
        {
          "rank": 25,
          "score": 0.6713277101516724,
          "doc_id": "JAKO202130053207367",
          "title": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출",
          "abstract": "'빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202130053207367&target=NART&cn=JAKO202130053207367",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 스마트시티 IoT 품질 지표 개발 및 우선순위 도출 '빅데이터'는 '21세기 원유'로 비유될 만큼 그 중요성이 증대되고 있다. 스마트시티에서 생성 및 수집되는 IoT 데이터의 경우 데이터의 품질이 공공서비스의 품질과 연관되므로 품질관리에 주의를 기울여야 한다. 그러나 ISO/IEC 기관 및 국내/외 여러 기관을 통해 제시된 데이터 품질 지표는 '사용자' 중심에 한정되어 있다는 한계점을 지닌다. 본 연구는 이러한 한계점을 보완하기 위해 공급자 중심의 지표와 그 우선순위를 도출하였다. 공급자 중심의 스마트시티 IoT 데이터 품질 평가지표 3개의 카테고리와 13개의 지표를 도출한 후 AHP 분석을 통하여 지표 카테고리와 데이터 품질 지표의 우선순위를 도출하였고 각 지표의 타당성을 조사하였다. 해당 연구를 통해 센서 데이터를 수집하고 취합하여 전달하는 직무를 수행하는 개인 혹은 기업에게 데이터가 지녀야 하는 기본적인 요건을 제시함으로써 센서 데이터 품질 향상에 기여할 수 있다. 또한 지표 우선순위를 기반으로 데이터 품질관리를 수행하여 품질관리 업무 효율의 향상을 제공할 수 있다."
        },
        {
          "rank": 26,
          "score": 0.6700133681297302,
          "doc_id": "DIKO0015551607",
          "title": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법",
          "abstract": "오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0015551607&target=NART&cn=DIKO0015551607",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 데이터 증강을 통한 딥 러닝 네트워크 정확도 향상 방법 오늘날 딥 러닝(Deep Learning)이란 머신러닝의 세부적인 방법과 개념&amp;#xD; 및 기법들을 통칭한다. 딥 러닝은 크게는 컴퓨터 비전(Computer vision)으&amp;#xD; 로부터 시작하여 패턴 인식(Pattern recognition), 색상 및 픽셀 복원, 추청&amp;#xD; 과 진단 등 다양한 곳에 사용이 되고 있다. 그 중 대게 객체 및 사람을 인&amp;#xD; 식하는 단계 및 추적을 더불어 대상의 안면 인식을 할 수 있는 단계까지&amp;#xD; 발달했다. 기본적인 네트워크인 컨볼루션 뉴럴 네트워크(CNN :&amp;#xD; convolutional neural network)를 시작으로 순환신경망(RNN : Recurrent&amp;#xD; Neural Network), 볼츠만 머신(RBM : Restricted Boltzmann Machine), 생&amp;#xD; 성 대립 신경망(GAN : Generative Adversarial Network) 그리고 Google의&amp;#xD; 딥 마인드에서 개발한 관계형 네트워크(RL : Relation Networks)등이 존재&amp;#xD; 한다. 이와 같은 네트워크 모델들은 다양한 강점들을 가지고 있는데 그 중&amp;#xD; 데이터를 이용한 요인 추출(feature extraction)이나 학습을 통한 결과 추론&amp;#xD; 이라고 볼 수 있다. 위와 같은 요인들을 성공적으로 학습시키기 위해서는&amp;#xD; 적합한 환경에 맞는 데이터 세트인지 판단하고, 모델에 관한 특징들을 파악&amp;#xD; 하여 가장 적합한 형태의 모델을 구현하여 효과적으로 학습 할 수 있도록&amp;#xD; 진행한다. 하지만 위 과정 중에서 데이터 세트들은 손쉽게 만들어지지 않는&amp;#xD; 다. 그 이유는 여러 다양한 방법으로 디자인되고 환경에 맞게 제작이 되어&amp;#xD; 야하기 때문이다.&amp;#xD; 본 논문에서는 기존 데이터 세트들을 이용하여 여러 다양한 방법을 이&amp;#xD; 용하여 데이터를 증강(data augmentation)시키는 연구를 진행한다. 객체 인&amp;#xD; 식 및 판단을 목적으로 딥 러닝을 학습 시킬 경우에는 이미지의 데이터 정&amp;#xD; 보들을 통해 학습을 진행한다. 학습하는 데이터 정보는 관심이 있는 영역이&amp;#xD; 나 혹은 주요 지정된 객체의 정보를 학습하는 것을 목표로 한다. 이것을 달&amp;#xD; 성하기 위해 데이터 세트를 이용하여 유용한 정보를 추출하고 학습 후 객&amp;#xD; 체에 관한 인식을 할 수 있게 진행했다. 여기에서 데이터 세트들은 대부분&amp;#xD; ILSVRC (Image Large Scale Visual Recognition Challenges) 및 PASCAL&amp;#xD; VOC (Visual Object Classes) 같은 것으로 이루어져 있다. 하지만 이와 같&amp;#xD; 은 데이터 세트는 특수한 상황이나 제한된 상황에서 사용하기가 매우 어렵&amp;#xD; 다. 상황에 맞게 데이터 세트들을 제작을 해야 하는 경우 이는 매우 많은&amp;#xD; 시간이 걸린다. 또한 만들어진 데이터 세트들을 테스트해야 하는 시간 또한&amp;#xD; 오래 걸린다. 본 논문에서는 제안된 방법을 사용하여 이를 해결한다. 기본&amp;#xD; 적인 영상처리부터 시작하여 알고리즘 및 3D 환경에서까지의 방법을 설명&amp;#xD; 한다. 이 방법들을 통해 생성된 데이터들은 성능 검증을 위해 실시간 모델&amp;#xD; 인 YOLO ver2(You Only Look Once)를 사용한다. 그리고 이미지 생성 후&amp;#xD; 분류에 사용할 CNN과 VGGNet(Very Deep Convolutional Networks for&amp;#xD; Large-Scale Image Recognition)을 이용한다. 최종적으로 제시한 방법을&amp;#xD; 통해 데이터 세트의 수를 수백 배 이상 생성했으며, 객체 간의 정확도는 5&amp;#xD; ∼ 10% 이상 증가시켰다."
        },
        {
          "rank": 27,
          "score": 0.6686441898345947,
          "doc_id": "DIKO0013413499",
          "title": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구",
          "abstract": "글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0013413499&target=NART&cn=DIKO0013413499",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 글로벌 환경에서 생존하기 위해서는 기업 당면한 다양한 문제를 효과적으로 해결하는 것이 필요하다. 빅 데이터는 기존 IT 시스템에서는 해결할 수 없는 다양한 문제해결능력 및 예측 능력으로 기업의 문제를 효과적으로 해결하고, 경쟁력을 향상시켜줄 수 있는 도구로 인식되고 있다.&amp;#xD; 빅 데이터는 21세기 원유라 불리고 있으며, 기업이 보유한 빅 데이터를 통해 전략적 가치를 도출하고 이를 비즈니스에 제대로 적용하는 기업과 조직이 향후 경쟁우위를 확보할 수 있을 것으로 예상하고 있다. 빅 데이터가 각광 받는 이유는 기존 IT 기술이 가능성 수준에서 많이 도태되었다면, 빅 데이터는 기술적 가능성을 뛰어넘어 빅 데이터 분석을 통해 비즈니스 최적화, 신규 비즈니스창출 등 새로운 가치를 창출하기 위해 활용될 수 있다는 장점이 있기 때문이다.&amp;#xD; 빅 데이터가 가지고 있는 높은 전략적 가치를 인식하고, 글로벌 선도 기업을 중심으로 빅 데이터를 전략적으로 활용하기 위해 적극적으로 도입을 추진하였다. 하지만, 빅 데이터를 통한 전략적 가치 도출 및 성과를 염두하지 않은 성급한 도입으로 인해 빅 데이터를 통한 전략적 가치 도출 및 데이터 활용 측면에서 어려움을 겪고 있다.&amp;#xD; 전 세계 18개국 1,800여명의 IT 전문가를 대상으로 조사한 결과 빅 데이터를 잘 활용하고 있는 기업의 비율은 28%에 불과하였으며, 빅 데이터를 통한 전략적 가치 도출 및 운영에 많은 어려움이 있다고 응답하였다. 빅 데이터를 도입하기 위해서는 기업이 목표로 하는 전략적 가치를 도출하고, 기업 내부, 외부 , 관련 법규 및 제도 등 환경적 측면을 고려해야하는데 이를 반영하지 못한 것이다. IT트렌드 및 주변 환경에 의해 빅 데이터를 도입하였으나 도입여건이 마련되지 않은 상황에서 성급하게 도입을 추진한 것이 실패의 원인인 것으로 나타났다.&amp;#xD; 성공적인 빅 데이터 도입을 위해서는 빅 데이터를 통해 얻을 수 있는 전략적 가치를 명확하게 파악하고, 적용 가능성에 대한 체계적인 환경 분석이 매우 중요하지만 기업들은 빅 데이터를 통하여 얻을 수 있는 부분적인 성과와 기술적인 측면만을 고려하고 있어 성공적인 도입이 이루어지지 못하고 있다.&amp;#xD; 빅 데이터 도입을 고려하고 있는 기업에게는 전략적 가치 및 도입 여건에 대한 부분을 고려한 연구가 필요하나 현재의 빅 데이터 관련 연구를 살펴보면 빅 데이터의 개념 및 전략적 가치에 관한 연구, 기술에 관한 연구, 도입 및 활성화에 관한 개념적 연구만 이루어져 기업의 빅 데이터 도입을 위한 가이드라인을 제시해 줄 수 있는 연구가 매우 부족한 실정이다.&amp;#xD; 이에 본 연구에서는 빅 데이터 도입에 미치는 영향요인들을 파악하고, 이를 실증적으로 분석함으로써 이론적으로 타당하고 실무적으로 유용한 빅 데이터 도입 가이드라인을 제시하고자 하였다.&amp;#xD; 이를 위해 기업의 빅 데이터 도입 영향요인을 파악하기 위하여 정보시스템 성공요인, 전략적 가치인식 요인, 정보시스템 도입 환경 고려요인 및 빅 데이터 관련 문헌을 검토하여 빅 데이터 도입의도에 영향을 미칠 수 있는 요인을 도출하였고, 구조화된 설문지를 개발하였다. 이후 기업 내 빅 데이터 관련 담당자를 대상으로 설문조사와 통계분석을 수행하였다.&amp;#xD; 통계분석 결과 전략적 가치 인식 요인과 산업내부환경요인이 빅 데이터 도입의도에 긍정적인 영향을 미치는 것으로 나타났으며, 연구결과를 통해 도출된 이론적, 실무적, 정책적 시사점은 다음과 같다.&amp;#xD; 이론적 시사점으로는 첫째, 전략적 가치 인식과 환경요인, 빅 데이터 관련 선행연구를 검토하여 빅 데이터 도입의도에 미치는 영향요인을 이론적으로 제시하고 실증 분석하여 검증된 변수와 측정항목을 제시하였다는 점이다. 독립변수와 종속변수와의 관계를 구조방정식 모형을 통하여 검증함으로써 각 변수가 도입의도에 미치는 영향력을 측정하였다는 측면에서 이론적 의미를 가지고 있다고 할 수 있다. 둘째, 빅 데이터 도입의도에 대한 독립변수(전략적 가치 인식, 환경), 종속변수(도입의도), 조절변수(업종, 기업규모)를 정의하였으며, 신뢰성 및 타당성이 확보된 측정항목을 개발함으로써 향후 빅 데이터 관련분야를 실증적으로 연구하는데 있어 이론적인 토대를 마련하였다. 셋째, 기존 선행연구에서 제시한 전략적 가치 인식 요인과 환경요인에 대한 유의성을 검증함으로써 향후 빅 데이터 도입 영향요인에 대한 실증연구에 도움을 줄 수 있을 것이다.&amp;#xD; 실무적 시사점으로는 첫째, 전략적 가치 인식 요인과 환경요인이 도입의도에 미치는 영향력에 대한 인과관계를 규명하고, 정의 및 신뢰성, 타당성이 확보된 측정항목을 제시함으로써 빅 데이터 분야에 대한 실증적 연구 기반을 조성하였다. 둘째, 전략적 가치 인식 요인의 경우 빅 데이터 도입의도에 긍정적인 영향을 미치는 연구결과를 제시하였는데, 전략적 가치 인식의 중요성을 제시하였다는 측면이다. 셋째, 빅 데이터 도입 기업은 산업내부환경에 대한 정확한 분석을 통하여 빅 데이터 도입을 고려하여야 한다는 것을 제시하였다. 넷째, 기업의 규모와 업종에 따른 빅 데이터 도입 영향요인의 차이를 제시함으로써 빅 데이터를 도입할 때에는 해당 기업의 규모와 업종을 고려해야한다는 점을 제시하였다.&amp;#xD; 정책적 시사점으로는 첫째, 빅 데이터 활용 다양성이 필요하다는 것이다. 빅 데이터가 가지는 전략적 가치는 제품 및 서비스측면, 생산성측면, 의사결정측면에서 다양한 접근이 가능하고 이를 토대로 기업의 전 비즈니스 분야에 활용이 가능한데, 국내 주요 기업이 도입을 고려하고 있는 부분은 제품 및 서비스측면의 일부분에 국한되어 있다. 따라서, 빅 데이터를 도입할 경우 활용에 대한 측면을 면밀하게 검토하여, 활용률을 극대화 할 수 있는 형태로 빅 데이터 시스템을 설계하는 것이 필요하다. 둘째, 기업이 빅 데이터를 도입하는 측면에서 시스템 도입 비용의 부담, 시스템 활용상의 어려움, 공급 기업에 대한 신뢰성이 부족을 제시하고 있다는 점이다. 세계적인 IT 기업이 빅 데이터 시장을 선점하고 있는 상황에서 국내 기업의 빅 데이터 도입은 외국기업에 의존할 수밖에 없다. 세계적인 IT 강국임에도 불구하고 글로벌 IT 기업이 없는 우리나라의 IT 산업의 현실을 감안할 때, 빅 데이터는 세계적인 기업을 육성할 수 있는 기회라 생각한다. 따라서 정부는 적극적인 정책적 지원을 통하여 Star 기업을 육성할 필요가 있다. 셋째, 빅 데이터 도입 및 운영을 위한 기업 내부 및 외부 전문 인력이 부족하다는 측면이다. 빅 데이터는 시스템 구축보다 데이터를 활용하여 얼마나 가치 있는 결과를 도출할 수 있느냐가 중요한 시스템이다. 이를 위해서는 IT, 통계, 전략, 경영 등 다양한 분야의 학문적 지식과 경험이 갖추어진 인재가 필요하며 이들을 대상으로 체계적인 교육을 통한 인력양성이 이루어져야 한다.&amp;#xD; 본 연구는 빅 데이터 도입의도에 영향을 주는 주요 변수를 파악하고, 이를 검증함으로써 빅 데이터 관련분야를 실증연구하는데 이론적 토대를 마련하였으며, 이를 실증분석함으로써 빅 데이터 도입을 고려하고 있는 기업과 정책개발자에게 유용한 가이드라인을 제시할 수 있을 것으로 기대된다."
        },
        {
          "rank": 28,
          "score": 0.6678053140640259,
          "doc_id": "NART98451950",
          "title": "Big Data Processing Technologies in Distributed Information Systems",
          "abstract": "<P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART98451950&target=NART&cn=NART98451950",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems Big Data Processing Technologies in Distributed Information Systems <P><B>Abstract</B></P>  <P>The analysis of Big data technologies was provided. An example of MapReduce paradigm application, uploading of big volumes of data, processing and analyzing of unstructured information and its distribution into the clustered database was provided. The article summarizes the concept of 'big data'. Examples of methods for working with arrays of unstructured data are given. The parallel system Resilient Distributed Datasets (RDD) is organized. The class of basic database operations was realized: database con-nection, table creation, getting in line id, returning all elements of the database, update, delete and create the line.</P>"
        },
        {
          "rank": 29,
          "score": 0.6676981449127197,
          "doc_id": "JAKO202213042291194",
          "title": "Cloud Computing Platforms for Big Data Adoption and Analytics",
          "abstract": "Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS).",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202213042291194&target=NART&cn=JAKO202213042291194",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Cloud Computing Platforms for Big Data Adoption and Analytics Big Data is a data analysis technology empowered by late advances in innovations and engineering. In any case, big data involves a colossal responsibility of equipment and handling assets, making reception expenses of big data innovation restrictive to little and medium estimated organizations. Cloud computing offers the guarantee of big data execution to little and medium measured organizations. Big Data preparing is performed through a programming worldview known as MapReduce. Normally, execution of the MapReduce worldview requires organized joined stockpiling and equal preparing. The computing needs of MapReduce writing computer programs are frequently past what little and medium measured business can submit. Cloud computing is on-request network admittance to computing assets, given by an external element. Normal arrangement models for cloud computing incorporate platform as a service (PaaS), software as a service (SaaS), framework as a service (IaaS), and equipment as a service (HaaS)."
        },
        {
          "rank": 30,
          "score": 0.6664366126060486,
          "doc_id": "NART102773225",
          "title": "Big data prioritization in SCM decision-making: Its role and performance implications",
          "abstract": "<P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART102773225&target=NART&cn=NART102773225",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications Big data prioritization in SCM decision-making: Its role and performance implications <P><B>Abstract</B></P>  <P>Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.</P>   <P><B>Highlights</B></P>  <P> <UL> <LI>  A survey of 84 managers in a supply chain management context </LI> <LI>  Positive association between Big Data Availability and use in SCM decision-making </LI> <LI>  Big Data Availability positively influences Big Data Prioritization. </LI> <LI>  Big Data Prioritization positively impacts use of big data in SCM decision-making. </LI> <LI>  The use of big data in SCM decision-making positively impacts SCM performance. </LI> </UL> </P>"
        },
        {
          "rank": 31,
          "score": 0.6653543710708618,
          "doc_id": "JAKO201033359738092",
          "title": "공급망 품질향상을 위한 6시그마 적용방법",
          "abstract": "For the success of total six sigma innovation, it is necessary to improve the suppliers' quality in the supply chain. This paper presents the deployment and support system of six sigma innovation for supply chain quality improvement, with the application to an aerospace production company. The process of project selection, project implementation, financial effect verification, benefit sharing is presented. This paper will benefit the companies which are going to enhance all the companies in the supply chain via six sigma activities.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201033359738092&target=NART&cn=JAKO201033359738092",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "공급망 품질향상을 위한 6시그마 적용방법 공급망 품질향상을 위한 6시그마 적용방법 공급망 품질향상을 위한 6시그마 적용방법 For the success of total six sigma innovation, it is necessary to improve the suppliers' quality in the supply chain. This paper presents the deployment and support system of six sigma innovation for supply chain quality improvement, with the application to an aerospace production company. The process of project selection, project implementation, financial effect verification, benefit sharing is presented. This paper will benefit the companies which are going to enhance all the companies in the supply chain via six sigma activities."
        },
        {
          "rank": 32,
          "score": 0.6649181842803955,
          "doc_id": "JAKO202032362242352",
          "title": "빅데이터 분석을 위한 파티션 기반 시각화 알고리즘",
          "abstract": "오늘날 빅데이터로부터 유의미한 결과를 도출하는 연구가 활발히 진행되고 있다. 본 논문에선 빅데이터의 데이터의 영역들을 파티션(partition)으로 설정하고 각 파티션들의 대표 값을 계산하여 변수들 사이의 상관관계를 분석 할 수 있는 파티션 기반 빅데이터 분석 알고리즘을 제안한다. 본 논문에선 파티션의 크기조절이 가능한 파티션 기반 빅데이터 분석 알고리즘의 파티션 크기 변화에 따른 시각화 결과를 비교분석하였다. 제안한 파티션 기반 빅데이터 분석 알고리즘을 검증하기 위해 의류 회사 'A'의 빅데이터를 분석하여 온도와 판매 가격 변화에 따른 상품의 판매량 변화를 분석하고 시각화하여 유의미한 결과를 얻을 수 있었다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242352&target=NART&cn=JAKO202032362242352",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 빅데이터 분석을 위한 파티션 기반 시각화 알고리즘 오늘날 빅데이터로부터 유의미한 결과를 도출하는 연구가 활발히 진행되고 있다. 본 논문에선 빅데이터의 데이터의 영역들을 파티션(partition)으로 설정하고 각 파티션들의 대표 값을 계산하여 변수들 사이의 상관관계를 분석 할 수 있는 파티션 기반 빅데이터 분석 알고리즘을 제안한다. 본 논문에선 파티션의 크기조절이 가능한 파티션 기반 빅데이터 분석 알고리즘의 파티션 크기 변화에 따른 시각화 결과를 비교분석하였다. 제안한 파티션 기반 빅데이터 분석 알고리즘을 검증하기 위해 의류 회사 'A'의 빅데이터를 분석하여 온도와 판매 가격 변화에 따른 상품의 판매량 변화를 분석하고 시각화하여 유의미한 결과를 얻을 수 있었다."
        },
        {
          "rank": 33,
          "score": 0.6636834144592285,
          "doc_id": "JAKO202125761334616",
          "title": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구",
          "abstract": "4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202125761334616&target=NART&cn=JAKO202125761334616",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 빅데이터 품질이 기업의 경영성과에 미치는 영향에 관한 연구 4차산업혁명시대에 정보통신기술의 비약적인 발전, 고객구매 성향의 다양함, 복잡함은 산업 전체적으로 데이터의 양적 중가를 가져와 '빅데이터' 시대를 맞이하게 되었다. 빅데이터 시대는 데이터를 분석, 활용하여 기업의 전략적 의사결정에 활용하는 것이 기업의 핵심 역량으로 자리 잡게 되었다. 하지만 현재 빅데이터 연구들은 기술적 이슈와 미래 잠재 가치 중심이었다. 반면 기업이 보유한 내.외부 고객 빅데이터의 품질 및 활용 수준관리에 대한 연구와 논의는 부족하였다. 본 연구에서는 기업의 내.외부 빅데이터 품질관리 정보시스템 측면와 품질경영 측면으로 인식하여 영향요인을 도출하였다. 또한 빅데이터 품질관리, 빅데이터 활용 및 수준관리가 기업의 업무 효율화와 기업 경영성과에 유의한 영향을 미치는지 204명의 임직원 설문을 통해 조사하였고, 가설을 설정하여 검증하였다. 연구결과 경영층의 지원, 개인 혁신성, 경영환경변화, 빅데이터 품질활용 지표관리, 빅데이터 거버넌스 체계 마련이 기업 경영성과에 유의한 영향을 미쳤다."
        },
        {
          "rank": 34,
          "score": 0.6614242196083069,
          "doc_id": "JAKO201723954939431",
          "title": "빅데이터 품질 확장을 위한 서비스 품질 연구",
          "abstract": "데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201723954939431&target=NART&cn=JAKO201723954939431",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 빅데이터 품질 확장을 위한 서비스 품질 연구 데이터 품질에 대한 연구는 오랜 기간 동안 수행되어 왔다. 하지만 이러한 데이터 품질관리 연구는 구조적 데이터를 대상으로 하였다. 최근에 디지털혁명 또는 4차산업혁명이 일어나면서 빅데이터에 대한 품질관리가 중요해 지고 있다. 본 논문에서는 기존 논문을 분석하여 빅데이터 품질 유형을 분류하고 비교 분석하였다. 요약하면, 빅데이터 품질 유형은 빅데이터 값, 빅데이터 구조, 빅데이터 품질 프로세스, 빅데이터 가치사슬 단계, 빅데이터 모형 성숙도 등으로 분류할 수 있다. 이러한 비교 연구를 바탕으로 본 논문에서는 새로운 기준을 제시하고자 한다."
        },
        {
          "rank": 35,
          "score": 0.6612679958343506,
          "doc_id": "JAKO201617338764393",
          "title": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구",
          "abstract": "본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201617338764393&target=NART&cn=JAKO201617338764393",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발에 관한 연구 본 연구는 빅데이터 유통 생태계에 기반한 단계별 빅데이터 유통 모델 개발 방안을 제안한다. 제안하는 빅데이터 유통모델의 개발은 데이터 중개 및 거래 플랫폼 구축, 거래지원 시스템 구축, 데이터 유통 포털 및 빅데이터 거래소 연결망 구축과 같이 3단계로 구성된다. 데이터 중개 및 거래 플랫폼 구축 단계에서는 데이터 유통 및 거래 플랫폼이 구축되며, 총괄시스템과 등록 및 거래관리 시스템으로 구성되며, 거래지원 시스템 구축 단계에서는 원활한 데이터 거래를 위한 거래지원 시스템이 추가적으로 구축된다. 마지막 데이터 유통 포털 및 빅데이터 거래소 연결망 구축 단계에서는 여러 거래소들의 통합에 필요한 유통 관리 시스템이 구축된다. 새로운 기술, 프로세스, 데이터 과학 등을 이용하여 과거의 데이터 관리 시스템을 빠르게 대체해 나가고 있는 현대의 데이터 시장에서 데이터 유통시장 모델은 계속 진화하고 있으며, 비즈니스 업계에서 수용되고 있다. 따라서 제안하는 빅데이터 유통 모델은 멀지 않은 장래에 데이터를 관리하고 접근하기 위한 산업표준 확립 시 고려될 수 있다고 사료된다."
        },
        {
          "rank": 36,
          "score": 0.6610150337219238,
          "doc_id": "JAKO201813649332298",
          "title": "스마트 물관리를 위한 빅데이터 거버넌스 모델",
          "abstract": "스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201813649332298&target=NART&cn=JAKO201813649332298",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리를 위한 빅데이터 거버넌스 모델 스마트 물관리 분야에서도 빅데이터 분석을 통해 경쟁력을 강화하려는 요구가 급증하면서 빅데이터에 대한 체계적인 관리(거버넌스)가 중요한 이슈로 부각되고 있다. 빅데이터 거버넌스는 데이터의 품질보장, 프라이버시 보호, 데이터 수명관리, 데이터 전담조직을 통한 데이터 소유 및 관리권의 명확화 등의 데이터 관리를 평가하고(Evaluation), 지시하며(Direction), 모니터링(Monitoring) 하는 체계적인 관리활동을 의미한다. 빅데이터 거버넌스가 확립되지 못하면 중요한 의사결정에 품질이 낮은 데이터를 사용함으로써 심각한 문제를 야기할 수 있으며, 개인 프라이버시 관련 데이터로 인해 빅브라더의 우려가 현실화될 수 있고, 폭증하는 데이터의 수명관리 소홀로 인해 IT 비용이 급증하기도 한다. 이러한 기술적인 문제가 완비되더라도 데이터 관련 문제를 전담하고 책임지는 조직과 인력이 없다면 빅데이터 효과는 지속되지 못할 것이다. 본 연구에서는 빅데이터 기반의 스마트 물관리를 위한 데이터 거버넌스 구축모델을 제시하고, 실제 물관리 업무에 적용한 사례를 소개한다."
        },
        {
          "rank": 37,
          "score": 0.6589568853378296,
          "doc_id": "ART002127072",
          "title": "Development of a Big Data Capability Assessment Model",
          "abstract": "Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ART002127072&target=NART&cn=ART002127072",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Development of a Big Data Capability Assessment Model Numerous organizations are turning to big data intelligence, expecting to elicit huge benefitsfrom big data. A large number of them, however, are experiencing failures and struggling, not knowingwhere to start and where to continue. This study aims to develop a big data capability assessment modelto provide these organizations with a practical guide and an evolutionary strategy for big data adoption.Significant big data capability factors were derived based on relevant capability and maturity modelsas well as interviews with big data experts. We devised a framework for assessing capability level,identifying weak capability types, and suggesting adequate guidelines according to evolutionary stage.Our model has been applied to five organizations in different business sectors for validation andrefinement based on feedback."
        },
        {
          "rank": 38,
          "score": 0.6588573455810547,
          "doc_id": "ATN0048509631",
          "title": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안",
          "abstract": "빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0048509631&target=NART&cn=ATN0048509631",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 소비자분야 공공 빅데이터 활용 현황과 고도화 방안 빅데이터 활용 능력이 국가경쟁력을 높이기 위한 중요 항목으로 대두되고 있다. 소비자 빅데이터 분석을 기반으로 정부·민간에서 소비자 관련 개선된 서비스 창출이 가능하나 현재 소비자 공공 빅데이터는 행정자료로서의 의미가 크며, 데이터가 가지고 있는 실질적인 가치를 극대화하지는 못하고 있는 실정이다. 이에 본 연구는 소비자분야 공공 빅데이터의 활용 현황을 파악하고, 정책, 행정의 효율성과 성과 개선을 위해 빅데이터 활용도를 높이는 고도화 방안을 제안하는 것을 목적으로 한다. 소비자 공공 빅데이터의 유형과 공정거래위원회와 한국소비자원에서 보유 및 관리하는 데이터 현황을 조사하는 것을 통해 빅데이터 활용 실태를 파악하였고, 문헌고찰, 실무자 심층면접, 브레인스토밍, 전문가 자문을 통해 빅데이터 활용 고도화를 위한 제안점을 도출하고 그 타당성과 실효성을 검토하였다.소비자분야 공공 빅데이터를 보다 체계적으로 축적하고 활용함으로써 소비자 관련 정책을 고도화하기 위해서는 공정거래위원회 내부에 존재하는 데이터들을 통합하고 분석 가능한 형태로 데이터베이스화하는 작업과 한국소비자원에서 관리하는 데이터를 체계화하고 품질을 개선하여 활용도를 높이는 노력이 이루어져야 한다. 두 기관의 DB를 상호 연계하기 위한 법적 근거 확립 및 표준화 가이드라인 마련도 필요하다. 또한, 공정거래위원회와 한국소비자원은 소비자 빅데이터에 관한 총체적인 이해를 기반으로, 소비자분야 데이터 생산자와 수요자 등 협력 가능한 이해관계자를 명확하게 정의하고, 소비자 빅데이터의 헤게모니를 가지고 실질적인 컨트롤타워로서의 역할을 확고히 하는 것이 중요하다. 이를 기반으로 소비자분야 맞춤형 데이터 어젠다를 구축하는 하향식 접근과 소비자 빅데이터 활용 협의체를 구축하는 상향식 접근을 병행하고, 데이터 기반 문화에 대한 리더십과 지원, 데이터 자산에 대한 가치 인정 및 기술 투자 등 데이터 활용 조직문화를 확산하는 것이 필요하다."
        },
        {
          "rank": 39,
          "score": 0.6574709415435791,
          "doc_id": "DIKO0017154536",
          "title": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템",
          "abstract": "IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0017154536&target=NART&cn=DIKO0017154536",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 빅데이터를 활용한 개인 맞춤형 상품 추천 시스템 IT 기술의 발전으로 대용량 데이터베이스와 데이터웨어하우스 구축이 가능해 지면서 기업에서 축적하고 활용할 수 있는 데이터의 양과 종류는 기하급수적으 로 증가하고 있다. 이를 통해 기업과 조직은 시장 동향을 분석하고, 고객의 행 동을 예측하며, 운영 효율성을 극대화하고 있다. 사용자들이 접하는 정보의 양 이 많아짐에 따라 개인의 취향과 선호를 고려한 개인 맞춤형 추천 서비스의 중 요성이 커지고 있다. 로그 데이터는 방대한 양과 복잡성으로 인해 수집과 분석이 어려워 활용도 가 떨어지고, 사용자가 입력하는 데이터는 제한적이다. 또한, 신규 사용자와 신 규 상품에 대한 데이터가 부족하면 추천이 어렵고, 실시간으로 데이터를 모니 터링하고 대응하는데 한계가 있다. 본 논문에서는 위와 같은 문제를 해결하기 위해 Apache 웹 서버에서 생성된 로그 데이터를 수집하고 전처리하여 데이터베이스에 삽입하였다. 로그, 사용자 정보, 서비스 신청 내역 데이터를 병합하여 사용자가 어떤 브라우저와 운영체 제를 통해 서비스를 신청했는지, 어떤 서비스에 가장 관심을 가지는지 등의 패 턴을 분석하고 데이터베이스에 삽입하였다. 사용자에게 개인화된 서비스를 추 천하기 위해 오토인코더 기반의 추천 알고리즘을 구현하였다. 오토인코더 모델 을 설계 및 컴파일하고, 사용자-아이템 행렬을 사용하여 학습하였다. 학습된 모 델에서 추출된 사용자 잠재 표현을 기반으로 코사인 유사도를 계산하여 유사도 가 높은 사용자가 선호한 서비스를 추천하고 서비스 이용 데이터가 부족한 사 용자에게는 전체 데이터를 기반으로 선호도가 높은 서비스를 기본 추천으로 제 공하였다. 또한, 실시간 데이터 모니터링을 위해 관리자 대시보드를 구현하였 다. 사용자의 행동 패턴을 기반으로 맞춤형 서비스를 제공함으로써, 사용자 경험 이 향상될 것으로 기대된다. 이러한 맞춤형 서비스는 고객 충성도를 높이고, 반 복 구매율을 향상하는데 기여할 수 있다. 또한, 기업의 마케팅 전략을 보다 효 율적으로 개선할 수 있다. 이를 통해 제품 판매율을 증대시키고, 경쟁 우위를 확보할 것으로 기대된다."
        },
        {
          "rank": 40,
          "score": 0.6571858525276184,
          "doc_id": "JAKO201914439302359",
          "title": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구",
          "abstract": "IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201914439302359&target=NART&cn=JAKO201914439302359",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법 연구 IT기술의 발달로 인해 생성되는 데이터의 양은 매년 기하급수적으로 증가하고 있으며, 이에 대한 대안으로 분산시스템과 인-메모리 기반 빅데이터 처리 기법의 연구가 활발히 이루어지고 있다. 기존 빅데이터 처리 기법들의 처리 성능은 노드의 수와 메모리 용량이 증가될수록 보다 빠르게 빅데이터 처리한다. 그러나 노드의 수의 증가는 빅데이터 인프라 환경에서 장애발생 빈도가 높아지며, 인프라 관리 포인트 및 인프라 운영비용도 증가된다. 또한 메모리 용량의 증가는 노드 구성에 대한 인프라 비용이 증가된다. 이에 본 논문에서는 빅데이터 처리율 향상을 위한 인-메모리 기반 하이브리드 빅데이터 처리 기법을 제안한다. 제안하는 기법은 분산시스템 처리기법에 Combiner 단계를 추가하고, 그 단계에서 인-메모리 기반 처리 기술을 적용하여 기존 분산시스템 기반 빅데이터 처리기법에 비해 빅데이터 처리시간을 약 22% 감소시켰다. 향후, 제안하는 기법의 실질적인 검증을 위해 더 많은 노드로 구성된 빅데이터 인프라 환경에서의 현실적 성능평가가 필요하다."
        },
        {
          "rank": 41,
          "score": 0.6571165323257446,
          "doc_id": "JAKO202317861205261",
          "title": "준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안",
          "abstract": "국립해양조사원(KHOA, Korea Hydrographic and Oceanographic Agency)은 국가해양관측망의 안정적인 운영과 해양관측자료의 품질 향상을 위하여 관측시설물 유지관리와 해양관측자료의 품질처리(실시간 및 비실시간)를 수행하고 있다. 실시간 품질처리는 다양한 물리적 알고리즘 및 기준을 이용하여 자동 품질처리를 수행하는 것으로, 실시간 품질처리가 완료된 관측자료는 '국립해양조사원 홈페이지 누리집'을 통해 제공 중이다. 비실시간 품질처리는 매월 초순에 전월의 관측자료를 대상으로 품질관리 담당자가 수동 품질처리를 수행하는 것이며, 비실시간 품질처리가 완료된 자료는 가공 및 분석을 통해 통계 자료, 1시간 조위 등을 산출하여 해당 정보들을 간행물에서 제공하고 있다. 본 연구는 국내 해양관측자료의 품질처리 방법 개선을 위하여 기존 실시간, 비실시간 품질처리 기법 외 적용이 가능한 준실시간 품질처리 기법을 조사하고, 해당 기법을 해수위 관측자료에 적용 및 실험하여 활용 가능성을 검토하였다. 해양관측자료 준실시간 품질처리 기법의 조사 결과, 다양한 해양과 관련된 국제적인 유관기관(IOC, GLOSS 등)에서는 해수위(조위) 관측자료의 품질개선을 위해 SELENE(SEa LEvel NEar-real time quality control processing) 알고리즘의 적용을 적극 권장하고 있다. 이에 국립해양조사원의 조위관측소에서 수집한 조위 자료에 대해 품질처리 최적화 실험을 통해 적합한 매개변수를 산출하였으며, 해당 기법을 적용하여 품질처리 정확도를 분석하였다. 분석 결과, 특이상황을 제외한 조위 관측자료의 준실시간 품질처리 정확도는 평균 90% 이상으로 매우 양호하게 나타났다. 따라서 실시간 및 비실시간 품질검사 외 해당 준실시간 품질처리 기법을 품질검사 현업에 도입&#x00B7;적용한다면, 조위 관측자료의 품질개선과 더불어 신속한 품질처리 자료 생산으로 해양정보 서비스 활용도 향상에 큰 도움이 될 것으로 생각된다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202317861205261&target=NART&cn=JAKO202317861205261",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 준실시간 품질처리 기법을 활용한 해수위 관측자료의 품질개선 방안 국립해양조사원(KHOA, Korea Hydrographic and Oceanographic Agency)은 국가해양관측망의 안정적인 운영과 해양관측자료의 품질 향상을 위하여 관측시설물 유지관리와 해양관측자료의 품질처리(실시간 및 비실시간)를 수행하고 있다. 실시간 품질처리는 다양한 물리적 알고리즘 및 기준을 이용하여 자동 품질처리를 수행하는 것으로, 실시간 품질처리가 완료된 관측자료는 '국립해양조사원 홈페이지 누리집'을 통해 제공 중이다. 비실시간 품질처리는 매월 초순에 전월의 관측자료를 대상으로 품질관리 담당자가 수동 품질처리를 수행하는 것이며, 비실시간 품질처리가 완료된 자료는 가공 및 분석을 통해 통계 자료, 1시간 조위 등을 산출하여 해당 정보들을 간행물에서 제공하고 있다. 본 연구는 국내 해양관측자료의 품질처리 방법 개선을 위하여 기존 실시간, 비실시간 품질처리 기법 외 적용이 가능한 준실시간 품질처리 기법을 조사하고, 해당 기법을 해수위 관측자료에 적용 및 실험하여 활용 가능성을 검토하였다. 해양관측자료 준실시간 품질처리 기법의 조사 결과, 다양한 해양과 관련된 국제적인 유관기관(IOC, GLOSS 등)에서는 해수위(조위) 관측자료의 품질개선을 위해 SELENE(SEa LEvel NEar-real time quality control processing) 알고리즘의 적용을 적극 권장하고 있다. 이에 국립해양조사원의 조위관측소에서 수집한 조위 자료에 대해 품질처리 최적화 실험을 통해 적합한 매개변수를 산출하였으며, 해당 기법을 적용하여 품질처리 정확도를 분석하였다. 분석 결과, 특이상황을 제외한 조위 관측자료의 준실시간 품질처리 정확도는 평균 90% 이상으로 매우 양호하게 나타났다. 따라서 실시간 및 비실시간 품질검사 외 해당 준실시간 품질처리 기법을 품질검사 현업에 도입&#x00B7;적용한다면, 조위 관측자료의 품질개선과 더불어 신속한 품질처리 자료 생산으로 해양정보 서비스 활용도 향상에 큰 도움이 될 것으로 생각된다."
        },
        {
          "rank": 42,
          "score": 0.656856894493103,
          "doc_id": "JAKO201835146902109",
          "title": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법",
          "abstract": "인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201835146902109&target=NART&cn=JAKO201835146902109",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 로그 분석 처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법 인터넷과 스마트기기의 발달로 인해 소셜미디어 등 다양한 미디어의 접근의 용이해짐에 따라 많은 양의 빅데이터들이 생성되고 있다. 특히 다양한 인터넷 서비스를 제공하는 기업들은 고객 성향 및 패턴, 보안성 강화를 위해 맵리듀스 기반 빅데이터 분석 기법들을 활용하여 빅데이터 분석하고 있다. 그러나 맵리듀스는 리듀스 단계에서 생성되는 리듀서 객체의 수를 한 개로 정의하고 있어, 빅데이터 분석할 때 처리될 많은 데이터들이 하나의 리듀서 객체에 집중된다. 이로 인해 리듀서 객체는 병목현상이 발생으로 빅데이터 분석 처리율이 감소한다. 이에 본 논문에서는 로그 분석처리율 향상을 위한 맵리듀스 기반 분할 빅데이터 분석 기법을 제안한다. 제안한 기법은 리듀서 분할 단계와 분석 결과병합 단계로 구분하며 리듀서 객체의 수를 유동적으로 생성하여 병목현상을 감소시켜 빅데이터 처리율을 향상시킨다."
        },
        {
          "rank": 43,
          "score": 0.6558279991149902,
          "doc_id": "JAKO202408557619302",
          "title": "빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현",
          "abstract": "본 논문은 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현을 제안한다. 제안하는 시스템은 빅데이터로 구성된 미세먼지 및 기상 정보를 통해 미세먼지 대기환경지수를 분류하는 시스템이다. 이 시스템은 머신러닝 기반의 대기환경지수 분류 카테고리별 이상치에 따른 이상치 탐지 알고리즘 설계를 통해 미세먼지를 분류한다. 카메라에서 수집된 영상의 심도 데이터는 미세먼지 농도에 따른 영상을 수집한 후 미세먼지 가시마스크를 생성합니다. 그리고 모노 심도 추정 알고리즘을 통한 학습 기반 핑거프린팅 기법으로 모노스코프 카메라에서 수집된 미세먼지의 가시거리를 추론하여 미세먼지 농도를 도출합니다. 본 방법의 실험 및 분석을 위해 미세먼지 농도 데이터와 지역별, 시간별 CCTV 영상 데이터를 매칭하여 학습 데이터를 생성한 후 모델을 생성하여 실제 환경에서 테스트한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202408557619302&target=NART&cn=JAKO202408557619302",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현 본 논문은 빅데이터 기반 미세먼지 이상 탐지 머신러닝 시스템 설계 및 구현을 제안한다. 제안하는 시스템은 빅데이터로 구성된 미세먼지 및 기상 정보를 통해 미세먼지 대기환경지수를 분류하는 시스템이다. 이 시스템은 머신러닝 기반의 대기환경지수 분류 카테고리별 이상치에 따른 이상치 탐지 알고리즘 설계를 통해 미세먼지를 분류한다. 카메라에서 수집된 영상의 심도 데이터는 미세먼지 농도에 따른 영상을 수집한 후 미세먼지 가시마스크를 생성합니다. 그리고 모노 심도 추정 알고리즘을 통한 학습 기반 핑거프린팅 기법으로 모노스코프 카메라에서 수집된 미세먼지의 가시거리를 추론하여 미세먼지 농도를 도출합니다. 본 방법의 실험 및 분석을 위해 미세먼지 농도 데이터와 지역별, 시간별 CCTV 영상 데이터를 매칭하여 학습 데이터를 생성한 후 모델을 생성하여 실제 환경에서 테스트한다."
        },
        {
          "rank": 44,
          "score": 0.6551364660263062,
          "doc_id": "DIKO0016958889",
          "title": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화",
          "abstract": "이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0016958889&target=NART&cn=DIKO0016958889",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 빅데이터 및 머신러닝을 통한 분산 시스템 기반 비즈니스 프로세스 최적화 이 논문은 현대 기업의 비즈니스 프로세스 최적화를 위한 기술적 변화를 심도 있게 분석한다. 디지털 변환, 클라우드 컴퓨팅, 빅데이터, 인공지능 등의 기술 도입이 기존 방식의 한계를 드러내고, 새로운 접근법을 제시한다. &amp;#xD; 특히, 클라우드 기반 분산 시스템의 중요성을 강조하며, 이 시스템이 프로세스 자동화, 표준화, 최적화를 지원하는 방법을 설명한다.&amp;#xD; &amp;#xD; 또한, 분산 클라우드 환경에서 워크로드 관리와 분석을 위한 방법론을 제시한다. 주로 실시간 데이터 스트림 처리와 예측 분석에 초점을 맞추며, 빅데이터와 머신러닝 기술을 통합한다. 실시간 처리는 지속적인 데이터 &amp;#xD; 흐름을 즉각적으로 분석하며, 예측 분석은 머신러닝을 이용해 미래 트렌드를 예측한다. 특히 산업 자동화 분야에서 중요하며, 숨겨진 패턴 인식과 예측 모델 구축을 통해 설비 고장 예측, 수요 예측 등에 활용된다. 이 방법론은 &amp;#xD; 복잡한 데이터 환경에서 기업의 효율성과 전략적 의사결정을 지원한다.&amp;#xD; 결론적으로, 논문은 분산 클라우드 환경에서 비즈니스 프로세스를 통합하고, 빅데이터와 머신러닝을 활용해 실시간 의사결정을 최적화하는 새로운 시스템을 제시한다. 이는 클라우드 컴퓨팅, 빅데이터, 머신러닝의 &amp;#xD; 발전에 중요한 영향을 미치며, 기술 통합과 디지털 변환에 기여한다. 이 연구는 기술이 비즈니스 환경에서 어떻게 활용될 수 있는지 중요한 통찰을 제공한다."
        },
        {
          "rank": 45,
          "score": 0.6534549593925476,
          "doc_id": "JAKO202032362242335",
          "title": "국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론",
          "abstract": "국내 전력산업이 스마트 그리드화 되면서 이로 인해 발생하는 빅데이터를 활용하여 수요관리, 시설물관리, 대고객서비스 등을 위한 빅데이터 플랫폼들이 도입되고 있는 추세이다. 그러나 빅데이터 프로젝트의 속성상 실제로 빅데이터 플랫폼의 활용이 업무 프로세스 상에서 정착되기 위해서는 많은 시간과 업데이트가 필요하다. 따라서 기존에 알려져 있거나 이론적인 평가 방법으로는 초기 빅데이터 플랫폼의 성과를 평가하기는 적절하지 않다. 본 논문에서는 빅데이터의 규모, 다양성, 속도에 따른 정보의 완전성/충분성, 정보의 신뢰성/정확성, 정보의 적합성/관련성, 정보의 상세성/구체성, 정보의 비교가능성, 정보의 불편성, 정보의 적시성 등 특정 정보의 7 가지 품질 측면에서 전력산업에서 초기 빅데이터 플랫폼의 성과를 평가하는 방법론을 제시한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202032362242335&target=NART&cn=JAKO202032362242335",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업에서의 빅데이터 플랫폼 성과 평가 방법론 국내 전력산업이 스마트 그리드화 되면서 이로 인해 발생하는 빅데이터를 활용하여 수요관리, 시설물관리, 대고객서비스 등을 위한 빅데이터 플랫폼들이 도입되고 있는 추세이다. 그러나 빅데이터 프로젝트의 속성상 실제로 빅데이터 플랫폼의 활용이 업무 프로세스 상에서 정착되기 위해서는 많은 시간과 업데이트가 필요하다. 따라서 기존에 알려져 있거나 이론적인 평가 방법으로는 초기 빅데이터 플랫폼의 성과를 평가하기는 적절하지 않다. 본 논문에서는 빅데이터의 규모, 다양성, 속도에 따른 정보의 완전성/충분성, 정보의 신뢰성/정확성, 정보의 적합성/관련성, 정보의 상세성/구체성, 정보의 비교가능성, 정보의 불편성, 정보의 적시성 등 특정 정보의 7 가지 품질 측면에서 전력산업에서 초기 빅데이터 플랫폼의 성과를 평가하는 방법론을 제시한다."
        },
        {
          "rank": 46,
          "score": 0.6526627540588379,
          "doc_id": "ATN0025420792",
          "title": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델",
          "abstract": "With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420792&target=NART&cn=ATN0025420792",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 효과적인 사이버공간 작전수행을 위한 빅데이터 거버넌스 모델 With the advent of the fourth industrial revolution characterized by hyperconnectivity and superintelligence and the emerging cyber physical systems, enormous volumes of data are being generated in the cyberspace every day ranging from the records about human life and activities to the communication records of computers, information and communication devices, and the Internet of things. Big data represented by 3Vs (volume, velocity, and variety) are actively used in the defence field as well. This paper proposes a big data governance model to support effective military operations in the cyberspace. Cyberspace operation missions and big data types that can be collected in the cyberspace are classified and integrated with big data governance issues to build a big data governance framework model. Then the effectiveness of the constructed model is verified through examples. The result of this study will be able to assist big data utilization planning in the defence sector."
        },
        {
          "rank": 47,
          "score": 0.6521248817443848,
          "doc_id": "ATN0038877162",
          "title": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구",
          "abstract": "Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0038877162&target=NART&cn=ATN0038877162",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 인공지능과 빅데이터를 활용한 예지 정비 적용 방안에 관한 연구 Artificial intelligence and big data are the core technologies of the Fourth Industrial Revolution and are changing the landscape in many fields, including national defense. This study specifically describes the concept of predictive maintenance that can directly utilize artificial intelligence and bigdata, and uses the turbofan engine dataset and the bearing dataset among NASA data as its application methods. For predictive maintenance, sound predictive management is essential, and when artificial intelligence is properly used, it is possible to analyze vast amounts of data and make accurate predictions. In addition, future research directions for applying artificial intelligence and big data to the defense field in the future were presented."
        },
        {
          "rank": 48,
          "score": 0.6521072387695312,
          "doc_id": "JAKO201833469089907",
          "title": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현",
          "abstract": "맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO201833469089907&target=NART&cn=JAKO201833469089907",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 빅데이터 처리시간 감소와 저장 효율성이 향상을 위한 맵리듀스 기반 빅데이터 처리 기법 구현 맵리듀스는 하둡의 필수 핵심 기술로 하둡 분산 파일 시스템을 기반으로 빅데이터를 처리하는 가장 보편화되어 사용되고 있다. 그러나 기존 맵리듀스 기반 빅데이터 처리 기법은 하둡 분산 파일 시스템에 정해진 블록의 크기대로 파일 나눠 저장되는 특징으로 인해 인프라 자원의 낭비가 극심하다. 이에 본 논문에서는 효율적인 맵리듀스 기반 빅데이터 처리기법을 제안한다. 제안하는 기법은 처리할 데이터를 사전에 맵리듀스에서 처리하기 적합한 데이터 형태로 변환 및 압축하여 빅데이터 인프라 환경의 저장 효율성을 증가시킨다. 또한 제안하는 기법은 저장 효율성을 중점으로 구현했을 때 발생할 수 있는 데이터 처리 시간의 지연 문제를 해결한다."
        },
        {
          "rank": 49,
          "score": 0.6506145000457764,
          "doc_id": "ATN0025420762",
          "title": "의료기관 빅데이터 품질관리의 필요성과 사례 분석",
          "abstract": "The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=ATN0025420762&target=NART&cn=ATN0025420762",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 의료기관 빅데이터 품질관리의 필요성과 사례 분석 The use of Bigdata plays an important role in all areas of society. Especially in the health care field, the role of Bigdata is very considerable because it deals with people’s life and health. However, the interest and awareness of quality control of medical data is markedly low. Because the low-quality medical Bigdata leads to national loss and public health impairment, quality control of medical Bigdata is needed. The purpose of this research is to present the direction of medical Bigdata quality management by examining literature and cases of domestic and foreign medical Bigdata quality management practices. In addition, as a case of medical Bigdata quality control in the Y medical institution in Korea, activities of a Bigdata quality management TFT and results of a survey conducted for major data users in the hospital were presented."
        },
        {
          "rank": 50,
          "score": 0.6496791839599609,
          "doc_id": "JAKO202413350409295",
          "title": "빅데이터 기반의 화물운송 효율성 분석 방법론 개발",
          "abstract": "본 연구는 화물차 적재 여부를 추정하는 인공지능 모델을 개발을 통해 화물차 적재율을 분석하고 물류 운송 효율성을 측정할 수 있는 지표를 개발하는 것을 목표로 한다. 이를 위해, 데이터 파이프라인 개념을 도입하여 다양한 데이터를 융합하고, 화물차의 출&#x00B7;도착지, 운행경로, 방문 시설 등을 추출하였다. 이를 기반으로 XGBoost를 활용하여 화물차의 적재 여부 추정 모델을 개발하였으며, 최종적으로 화물 운송의 효율성을 측정할 수 있는 주요 지표들을 도출하였다.",
          "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO202413350409295&target=NART&cn=JAKO202413350409295",
          "author": "nan",
          "embedding_mode": "3*title+abstract",
          "embedding_text": "빅데이터 기반의 화물운송 효율성 분석 방법론 개발 빅데이터 기반의 화물운송 효율성 분석 방법론 개발 빅데이터 기반의 화물운송 효율성 분석 방법론 개발 본 연구는 화물차 적재 여부를 추정하는 인공지능 모델을 개발을 통해 화물차 적재율을 분석하고 물류 운송 효율성을 측정할 수 있는 지표를 개발하는 것을 목표로 한다. 이를 위해, 데이터 파이프라인 개념을 도입하여 다양한 데이터를 융합하고, 화물차의 출&#x00B7;도착지, 운행경로, 방문 시설 등을 추출하였다. 이를 기반으로 XGBoost를 활용하여 화물차의 적재 여부 추정 모델을 개발하였으며, 최종적으로 화물 운송의 효율성을 측정할 수 있는 주요 지표들을 도출하였다."
        }
      ]
    }
  ],
  "meta": {
    "model": "gemini-2.5-flash",
    "temperature": 0.2
  }
}