{
    "id": "row_000044",
    "result": {
        "title": "Audiovisual Speech Recognition: Integration of Hidden Markov Models and Neural Networks for Robustness in Noisy Environments",
        "introduction": "Audiovisual speech recognition aims to overcome the limitations of traditional speech recognition systems in noisy environments by combining auditory and visual information. This approach leverages the complementary strengths of Hidden Markov Models (HMMs) and Neural Networks (NNs) to enhance recognition performance and achieve robustness when faced with various types and levels of noise.",
        "main_body": "The integration of Hidden Markov Models (HMMs) and Neural Networks (NNs) in audiovisual speech recognition for robustness in noisy environments occurs through several mechanisms. First, to improve the performance of visual information recognition, a probabilistic optimization algorithm for HMMs is proposed. This algorithm, which combines simulated annealing with local search operators, performs a global search to enhance HMM recognition performance, unlike traditional expectation-maximization algorithms that only perform local optimization. This makes the visual component more robust. Second, to make acoustic information recognition more robust, a technique is developed to model inter-frame correlations within HMMs. This addresses the dynamic characteristics of speech, which are often not fully considered in conventional HMM-based acoustic modeling. By modeling the joint probability distribution of different frames using Gaussian mixture models, the conditional dependencies between frames are handled, leading to more robust performance in noisy acoustic environments. Third, neural networks are utilized in the information integration stage to effectively combine the complementary visual and auditory information. After separately recognizing results from visual and auditory data, a trained neural network outputs appropriate weights for the given audiovisual data, even when the type and level of noise are unknown. This process aims to achieve optimal recognition results and maximize the synergistic effect of both information streams, ensuring that the integrated recognition performance is at least equal to or better than using either visual or auditory information alone. Furthermore, some approaches propose a hybrid network called \"neural network predictive HMMs.\" These systems define a predictive neural network for each HMM state, using it to generate dynamic prediction values based on past feature vectors, rather than relying on fixed average vectors. This imbues HMMs with dynamic characteristics, addressing their traditional weakness in handling temporal correlation in speech patterns. Additionally, neural networks can be used to adapt phone HMMs to noisy speech by mapping clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios as inputs. This adaptation makes the HMMs effective in recognizing new speakers under various noise and SNR conditions.",
        "conclusion": "By employing probabilistic optimization and inter-frame correlation modeling within HMMs for visual and acoustic information respectively, and by using neural networks for intelligent information integration and HMM adaptation, audiovisual speech recognition systems achieve enhanced robustness in noisy environments. This integrated approach leverages the strengths of both models to process dynamic speech patterns, compensate for noise-induced information loss, and optimally combine multimodal data, leading to significantly improved recognition rates under challenging conditions."
    },
    "prompt": "You will be given a JSON object as a string which contains a series of related search queries and their retrieved documents ('hits'). Do not make answer from external knowledge. You must make answer inside of Context.\nYour main task is to answer the specific 'Question' provided below. Use the entire JSON data as context to formulate your answer, paying close attention to the 'text' fields within the 'hits' lists.\n\nThe JSON data has a list of queries. The 'original' query is the one you need to answer. The other queries are supplementary and provide additional context.\nDo not use \"*\", \"-\" symbols. Please don't use \"**\" to emphasize words. Don't answer in markdown format just write it simple.\n\nIf the 'Question' is in Korean, format your answer in Korean as follows:\n##제목##\n\n##서론##\n\n##본론##\n\n##결론##\n\nIf the 'Question' is in English, format your answer in English as follows, If English then Just write title inside of ##{Title}##:\n##{Title}##\n\n##Introduction##\n\n##Main Body##\n\n##Conclusion##\n\n--- Context ---\n{\n  \"id\": \"row_000044\",\n  \"model_name\": \"Alibaba-NLP/gte-multilingual-base\",\n  \"timestamp_kst\": \"2025-09-08T23:55:38.353340+09:00\",\n  \"trial_id\": \"76513040\",\n  \"queries\": [\n    {\n      \"query\": \"How does the audiovisual speech recognition approach integrate hidden Markov models and neural networks to achieve robustness in noisy environments?\",\n      \"query_meta\": {\n        \"type\": \"original\"\n      },\n      \"top_k\": 50,\n      \"hits\": [\n        {\n          \"rank\": 1,\n          \"score\": 0.8063604235649109,\n          \"doc_id\": \"DIKO0011019580\",\n          \"title\": \"시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합\",\n          \"abstract\": \"음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.\",\n          \"source\": \"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580\",\n          \"author\": \"nan\",\n          \"embedding_mode\": \"3*title+abstract\",\n          \"embedding_text\": \"시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.\"\n        }\n      ]\n    },\n    {\n      \"query\": \"What is the function of Hidden Markov Models (HMMs) in audiovisual speech recognition?\",\n      \"query_meta\": {\n        \"type\": \"single_hop\",\n        \"index\": 0\n      },\n      \"top_k\": 50,\n      \"hits\": [\n        {\n          \"rank\": 1,\n          \"score\": 0.7824913859367371,\n          \"doc_id\": \"NART70632792\",\n          \"title\": \"Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis\",\n          \"abstract\": \"<P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>\",\n          \"source\": \"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70632792&target=NART&cn=NART70632792\",\n          \"author\": \"nan\",\n          \"embedding_mode\": \"3*title+abstract\",\n          \"embedding_text\": \"Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis <P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>\"\n        }\n      ]\n    },\n    {\n      \"query\": \"What is the function of neural networks (NNs) in audiovisual speech recognition?\",\n      \"query_meta\": {\n        \"type\": \"single_hop\",\n        \"index\": 1\n      },\n      \"top_k\": 50,\n      \"hits\": [\n        {\n          \"rank\": 1,\n          \"score\": 0.7729944586753845,\n          \"doc_id\": \"JAKO200411922338894\",\n          \"title\": \"신경망 기반 음성, 영상 및 문맥 통합 음성인식\",\n          \"abstract\": \"최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.\",\n          \"source\": \"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894\",\n          \"author\": \"nan\",\n          \"embedding_mode\": \"3*title+abstract\",\n          \"embedding_text\": \"신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.\"\n        }\n      ]\n    },\n    {\n      \"query\": \"How are Hidden Markov Models (HMMs) and neural networks (NNs) integrated within the audiovisual speech recognition approach?\",\n      \"query_meta\": {\n        \"type\": \"single_hop\",\n        \"index\": 2\n      },\n      \"top_k\": 50,\n      \"hits\": [\n        {\n          \"rank\": 1,\n          \"score\": 0.8010904788970947,\n          \"doc_id\": \"DIKO0007842188\",\n          \"title\": \"신경망 예측 HMM을 이용한 음성인식에 관한 연구\",\n          \"abstract\": \"음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.\",\n          \"source\": \"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188\",\n          \"author\": \"nan\",\n          \"embedding_mode\": \"3*title+abstract\",\n          \"embedding_text\": \"신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.\"\n        }\n      ]\n    },\n    {\n      \"query\": \"How does the integration of HMMs and NNs enhance robustness in noisy environments for audiovisual speech recognition?\",\n      \"query_meta\": {\n        \"type\": \"single_hop\",\n        \"index\": 3\n      },\n      \"top_k\": 50,\n      \"hits\": [\n        {\n          \"rank\": 1,\n          \"score\": 0.8070221543312073,\n          \"doc_id\": \"NART16453920\",\n          \"title\": \"Neural-network-based HMM adaptation for noisy speech recognition.\",\n          \"abstract\": \"<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>\",\n          \"source\": \"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920\",\n          \"author\": \"nan\",\n          \"embedding_mode\": \"3*title+abstract\",\n          \"embedding_text\": \"Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>\"\n        }\n      ]\n    }\n  ],\n  \"meta\": {\n    \"model\": \"gemini-2.5-flash\",\n    \"temperature\": 0.2\n  }\n}\n\n--- Question ---\nHow does the audiovisual speech recognition approach integrate hidden Markov models and neural networks to achieve robustness in noisy environments?\n\n",
    "model": "models/gemini-2.5-flash",
    "retrival": {
        "id": "row_000044",
        "model_name": "Alibaba-NLP/gte-multilingual-base",
        "timestamp_kst": "2025-09-08T23:55:38.353340+09:00",
        "trial_id": "76513040",
        "queries": [
            {
                "query": "How does the audiovisual speech recognition approach integrate hidden Markov models and neural networks to achieve robustness in noisy environments?",
                "query_meta": {
                    "type": "original"
                },
                "top_k": 50,
                "hits": [
                    {
                        "rank": 1,
                        "score": 0.8063604235649109,
                        "doc_id": "DIKO0011019580",
                        "title": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",
                        "abstract": "음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다.",
                        "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0011019580&target=NART&cn=DIKO0011019580",
                        "author": "nan",
                        "embedding_mode": "3*title+abstract",
                        "embedding_text": "시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합 음성인식은 인간과 기계의 인터페이스 서비스를 위한 중요한 기술이다. 현재까지 개발된 많은 음성인식 시스템은 제어된 환경에서는 높은 인식율을 보이지만, 잡음 환경에서는 성능이 크게 저하되는 한계가 있다. 이러한 한계를 극복하기 위한 방법의 하나인 시청각 음성인식은 잡음이 존재하는 환경에서 강인한 인식을 위해 마이크로 녹음한 음성신호 (목소리)와 카메라로 기록한 영상신호(입술의 움직임)를 모두 이용하여 음성을 인식하는 기술이다. 영상신호를 이용한 인식은 잡음이 적은 상황에서는 기존의 음성인식에 비해 낮은 인식 성능을 보이지만 소리잡음에 영향을 받지 않기 때문에 잡음 환경에서 음성인식을 보완하는 유용한 방법이 된다. 본 논문에서는 시청각 음성인식 시스템을 구성하는 청각신호를 이용한 인식, 시각정보를 이용한 인식, 그리고 두 정보의 통합 등의 세 부분을 고려하여 각 부분의 성능을 향상시킴으로써 잡음환경에서의 강인함을 향상시키고자 한다. 첫째, 시각정보를 이용한 인식의 성능을 향상시키기 위해 인식기인 은닉 마르코프 모델(hidden Markov model)의 확률적인 최적화 알고리즘을 제안한다. 알고리즘의 성능과 수렴속도를 개선하기 위해 확률적인 최적화 알고리즘의 하나인 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질 기법을 개발한다. 기존의 은닉 마르코프 모델의 학습 알고리즘인 기대-최대(expectation-maximization) 알고리즘은 가능도 (likelihood) 함수에 대해 지역 최적화만을 수행하는 반면, 제안하는 알고리즘은 전 영역에서 탐색을 수행하며 결과적으로 은닉 마르코프 모델의 인식 성능을 높인다. 제안하는 알고리즘이 전역최적해에 확률로써 수렴하는 것을 수학적으로 증명한다. 둘째, 청각정보를 이용한 인식을 강인하게 하기 위해 은닉 마르코프 모델에서 관측 프레임간의 상관관계를 모델링하는 기법을 개발한다. 음성의 동적 특성은 사람이 잡음환경에서 강인한 인식 성능을 보이는데 도움을 주는 것으로 알려져 있으나 기존의 은닉 마르코프 모델을 이용한 음성 모델링에서는 충분히 고려되지 않고 있다. 본 논문에서는 가우시안 혼합 모델(Gaussian mixture model)로 서로 다른 프레임의 결합 확률분포를 모델링하여 프레임간의 조건부 의존관계를 다루는 기법을 제안한다. 또한, 기대-최대 알고리즘에 기반하여 제안하는 모델의 학습 알고리즘을 개발한다. 제안하는 모델을 이용함으로써 청각 정보를 이용한 인식에서 잡음에 더욱 강인한 성능을 얻도록 한다. 셋째, 시각정보와 청각정보의 상호보완성을 효과적으로 이용하여 잡음에 강인한 최종 인식결과를 얻기 위해 정보 통합 단계에서 신경회로망을 이용하는 기법을 제안한다. 정보 통합 단계에서는 시각정보와 청각정보를 각각 따로 인식한 결과를 가중치 기법을 통해 최종 결과를 얻는데, 학습된 신경회로망은 잡음의 종류와 수준을 알 수 없는 주어진 시청각 데이터에 대해 적절한 가중치를 출력함으로써 최적의 인식결과를 얻도록 한다. 이를 통해 통합 인식 결과가 시각 또는 청각정보만을 이용한 인식결과보다 최소한 같거나 좋을 뿐 아니라 두 정보에 의한 시너지 효과를 최대화하도록 한다. 제안하는 시스템을 화자독립 고립단어 인식문제에 적용하여 그 성능을 보인다. 실험 결과 제안하는 시스템이 기존의 시스템에 비해 다양한 잡음 환경에서 더욱 강인한 성능을 보이는 것을 확인한다."
                    }
                ]
            },
            {
                "query": "What is the function of Hidden Markov Models (HMMs) in audiovisual speech recognition?",
                "query_meta": {
                    "type": "single_hop",
                    "index": 0
                },
                "top_k": 50,
                "hits": [
                    {
                        "rank": 1,
                        "score": 0.7824913859367371,
                        "doc_id": "NART70632792",
                        "title": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis",
                        "abstract": "<P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>",
                        "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART70632792&target=NART&cn=NART70632792",
                        "author": "nan",
                        "embedding_mode": "3*title+abstract",
                        "embedding_text": "Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis Joint Audiovisual Hidden Semi-Markov Model-Based Speech Synthesis <P>This paper investigates joint speaker-dependent audiovisual Hidden Semi-Markov Models (HSMM) where the visual models produce a sequence of 3D motion tracking data that is used to animate a talking head and the acoustic models are used for speech synthesis. Different acoustic, visual, and joint audiovisual models for four different Austrian German speakers were trained and we show that the joint models perform better compared to other approaches in terms of synchronization quality of the synthesized visual speech. In addition, a detailed analysis of the acoustic and visual alignment is provided for the different models. Importantly, the joint audiovisual modeling does not decrease the acoustic synthetic speech quality compared to acoustic-only modeling so that there is a clear advantage in the common duration model of the joint audiovisual modeling approach that is used for synchronizing acoustic and visual parameter sequences. Finally, it provides a model that integrates the visual and acoustic speech dynamics.</P>"
                    }
                ]
            },
            {
                "query": "What is the function of neural networks (NNs) in audiovisual speech recognition?",
                "query_meta": {
                    "type": "single_hop",
                    "index": 1
                },
                "top_k": 50,
                "hits": [
                    {
                        "rank": 1,
                        "score": 0.7729944586753845,
                        "doc_id": "JAKO200411922338894",
                        "title": "신경망 기반 음성, 영상 및 문맥 통합 음성인식",
                        "abstract": "최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다.",
                        "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=JAKO200411922338894&target=NART&cn=JAKO200411922338894",
                        "author": "nan",
                        "embedding_mode": "3*title+abstract",
                        "embedding_text": "신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 신경망 기반 음성, 영상 및 문맥 통합 음성인식 최근 잡음환경에서 신뢰도 높은 음성인식을 위해 음성정보와 영상정보를 융합하는 방법이 활발히 연구되고 있다. 본 논문에서는 이절적인 정보의 융합에 적합한 신경망 모델을 기반으로 음성, 영상 및 문맥 정보 등 다양한 정보를 융합하여 잡음 환경에서 고려단어를 인식하는 음성인식 기법에 대하여 기술한다. 음성과 영상 특징을 이용한 이중 모드 신경망 BMNN(BiModal Neural Network)을 제안한다. BMM은 4개 층으로 이루어진 다층퍼셉트론의 구조를 가지며 각 층은 입력 특징의 추상화 기능을 수행한다. BMNN에서는 제 3층이 잡음에 의한 음성 정보의 손실을 보상하기 위하여 음성과 영상 특징을 통합하는 기능을 수행한다. 또한, 잡음환경에서 음성 인식률을 향상시키기 위해 사용자가 말한 단어들의 순차 패턴을 나타내는 문맥정보를 이용한 후처리 방법을 제안한다. 잡음환경에서 BMNN은 단순히 음성만을 사용한 것 보다 높은 성능을 보임으로써 그 타당성을 확인할 수 있을 뿐 아니라, 특히 문맥을 이용한 후처리를 하였을 경우 잡음 환경에서 90%이상의 인식률을 달성하였다 본 연구는 잡음환경에서 강인한 음성인식을 위해 다양한 추가 정보를 사용함으로써 성능을 향상시킬 수 있음을 제시한다."
                    }
                ]
            },
            {
                "query": "How are Hidden Markov Models (HMMs) and neural networks (NNs) integrated within the audiovisual speech recognition approach?",
                "query_meta": {
                    "type": "single_hop",
                    "index": 2
                },
                "top_k": 50,
                "hits": [
                    {
                        "rank": 1,
                        "score": 0.8010904788970947,
                        "doc_id": "DIKO0007842188",
                        "title": "신경망 예측 HMM을 이용한 음성인식에 관한 연구",
                        "abstract": "음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다.",
                        "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=DIKO0007842188&target=NART&cn=DIKO0007842188",
                        "author": "nan",
                        "embedding_mode": "3*title+abstract",
                        "embedding_text": "신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 신경망 예측 HMM을 이용한 음성인식에 관한 연구 음성은 인간의 가장 자연스러운 의사소통의 수단이며 이러한 음성에 의한 인간-기계 인터페이스는 속도가 빠르고 특별한 훈련이 없어도 이루어진다. 또한 컴퓨터 및 정보통신 기술의 급속한 발전으로 음성인식 기술은 중요한 연구 과제가 되고 있다. 이러한 음성인식에 관한 연구는 HMM과 신경망에 의한 방법들이 활발히 진행되고 있다. 그러나 HMM은 모델구조의 결정에 어려움이 있으며, 음성의 과도적 정보를 경시하는 경향이 있기 때문에 시간적 상관 표현력이 부족한 결점이 있다. 따라서 이러한 단점을 극복하기 위하여 음성의 동적특성을 표현할 수 있는 회귀계수와 지속시간 확률등을 파라메터로 추가하거나, 언어학적 제약을 가하여 최적의 단어별을 탐색하는 언어적 모델을 결합한 음성이해 시스템으로 발전하고 있다. 또한 신경망의 경우 그 구조나 가중치에 시간적인 것이 고려되지 않으므로 패턴이 정적인 경우 인식률이 높으나 음성과 같은 시계열 패턴의 비선형 신축을 취급하기 어렵다. 따라서 이러한 단점을 보완하기 위하여 회귀신경망, 예측형 신경망등이 제안되었다. 본 논문에서는 이러한 점들을 고려하여 HMM의 패턴에 대한 시간적 상관표현력을 개선시킬 수 있는 신경망 예측 HMM을 제안한다. 신경망 예측 HMM은 HMM과 신경망의 장점을 함께 사용할 수 있는 하이브리드형 네트워크로 예측형 신경망을 HMM의 각 상태마다 예측기로 정의하여 일정치인 평균벡터 대신에 과거의 특징벡터의 영향을 받아 동적으로 변화하는 신경망에 의한 예측치를 이용하는 것이다. 따라서 예측형 신경망은 학습패턴 설정자체가 시변성을 반영하는 동적 네트워크의 특성을 가지므로 HMM에 동적 특성을 부여할 수 있다. 실험에서는 단독 숫자음과 100음절 데이터를 이용하여 HMM과 신경망 그리고 본 논문에서 제안한 신경망 예측 HMM의 인식성능을 비교·검토하였다. 신경망 예측 HMM은 MLP 예측 HMM, Elman망 예측 HMM, Jordan망 예측 HMM의 3가지이다. 실험결과 평가용 데이터를 기준으로 단독 숫자음에 대해서는 MLP 예측 HMM이 99.5%로 가장 우수한 결과를, 100음절 데이터에 대해서는 HMM이 87.7%로 가장 우수한 결과를 보였다. Elman망 예측 HMM과 Jordan망 예측 HMM의 경우 회귀구조임에도 불구하고 MLP 예측 HMM의 인식성능을 상회하지는 못하였다. 따라서 신경망 예측 HMM의 인식성능을 향상시키기 위해서는 데이터에 따른 효과의 검토와 음성패턴의 시간적 상관관계를 보다 더 잘 표현 할 수 있는 신경망의 구조에 대한 연구가 요구되며, 신경망과 HMM의 학습알고리즘에 대한 연구가 필요하다고 판단된다. 본 논문에서 제안한 신경망 예측 HMM은 HMM과 신경망의 결합이라고 하는 향후 가장 유효한 방법의 하나로 사료되며 연속음성 인식시스템으로 확장할 수 있을 것으로 기대된다."
                    }
                ]
            },
            {
                "query": "How does the integration of HMMs and NNs enhance robustness in noisy environments for audiovisual speech recognition?",
                "query_meta": {
                    "type": "single_hop",
                    "index": 3
                },
                "top_k": 50,
                "hits": [
                    {
                        "rank": 1,
                        "score": 0.8070221543312073,
                        "doc_id": "NART16453920",
                        "title": "Neural-network-based HMM adaptation for noisy speech recognition.",
                        "abstract": "<P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>",
                        "source": "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=NART16453920&target=NART&cn=NART16453920",
                        "author": "nan",
                        "embedding_mode": "3*title+abstract",
                        "embedding_text": "Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. Neural-network-based HMM adaptation for noisy speech recognition. <P>This paper proposes a new method, using neural networks, of adapting phone HMMs to noisy speech. The neural networks are designed to map clean speech HMMs to noise-adapted HMMs, using noise HMMs and signal-to-noise ratios (SNRs) as inputs. The neural network is trained by minimizing the mean square error between the output HMMs and the target noise-adapted HMMs. In an evaluation, the proposed method was used to recognize noisy broadcast-news speech in speaker-dependent and speaker-independent modes. The trained networks were found to be effective in recognizing new speakers under new noise and various SNR conditions.</P>"
                    }
                ]
            }
        ],
        "meta": {
            "model": "gemini-2.5-flash",
            "temperature": 0.2
        }
    }
}