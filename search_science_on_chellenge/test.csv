Question,SAI_Answer,translated_question,translated_SAI_answer,retrieved_article_name_1,retrieved_article_name_2,retrieved_article_name_3,retrieved_article_name_4,retrieved_article_name_5,retrieved_article_name_6,retrieved_article_name_7,retrieved_article_name_8,retrieved_article_name_9,retrieved_article_name_10,retrieved_article_name_11,retrieved_article_name_12,retrieved_article_name_13,retrieved_article_name_14,retrieved_article_name_15,retrieved_article_name_16,retrieved_article_name_17,retrieved_article_name_18,retrieved_article_name_19,retrieved_article_name_20,retrieved_article_name_21,retrieved_article_name_22,retrieved_article_name_23,retrieved_article_name_24,retrieved_article_name_25,retrieved_article_name_26,retrieved_article_name_27,retrieved_article_name_28,retrieved_article_name_29,retrieved_article_name_30,retrieved_article_name_31,retrieved_article_name_32,retrieved_article_name_33,retrieved_article_name_34,retrieved_article_name_35,retrieved_article_name_36,retrieved_article_name_37,retrieved_article_name_38,retrieved_article_name_39,retrieved_article_name_40,retrieved_article_name_41,retrieved_article_name_42,retrieved_article_name_43,retrieved_article_name_44,retrieved_article_name_45,retrieved_article_name_46,retrieved_article_name_47,retrieved_article_name_48,retrieved_article_name_49,retrieved_article_name_50,id,elapsed_times
How can the rationale and structure of the free electronic textbook outlining the essential mathematics for understanding AI in a one- or two-semester undergraduate course be summarized?,"##Free Electronic Textbook on Essential Mathematics for AI## ##Introduction## As artificial intelligence permeates modern industries—from healthcare and robotics to smart homes and IoT—understanding its underlying mathematical principles has become indispensable for undergraduate students. To address this need, a research team developed a free electronic textbook titled “Fundamental Mathematics for AI,” designed to cover all core math concepts required for AI and machine learning within one or two semesters. ##Main Body## The textbook is organized into modular chapters that build progressively: it begins with vector and matrix operations fundamental to neural networks, then introduces probability theory and statistical inference for data modeling, followed by calculus and optimization techniques that underpin learning algorithms. Each module includes context-relevant examples, problem-solving exercises, and visualizations tailored to the local curriculum, ensuring practical comprehension. Accompanying online resources and interactive lectures support students from diverse majors, reinforcing theoretical material with hands-on applications in Python and MATLAB. The entire course framework—from learning objectives to assessment items—has been openly shared and successfully implemented at the undergraduate and graduate levels. ##Conclusion## By structuring essential topics into a cohesive, semester-based sequence and providing free, adaptable materials, this electronic textbook equips learners with the rigorous mathematical toolkit required for AI and facilitates broader access to high-quality instruction in rapidly evolving technological fields.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",0,1.1859924140007934
How do artificial neural networks employ weight matrices and vector mappings to relate inputs and outputs in applied linguistics?,"##Artificial Neural Networks and Their Mathematical Mapping## ##Introduction## Artificial neural networks (ANNs) use mathematical structures to transform linguistic inputs into meaningful outputs. By representing each layer’s activations as vectors and interconnecting them with weight matrices, ANNs provide a framework for modeling complex relationships in language data. ##Main Body## An input vector encodes linguistic features (e.g., word embeddings or syntactic cues). This vector is multiplied by a weight matrix to yield a new vector, which passes through a non-linear activation function to introduce flexibility. In multilayer networks, each subsequent hidden layer repeats this vector-matrix multiplication, enabling the system to capture increasingly abstract linguistic patterns. During training, the network adjusts its weight matrices via optimization algorithms (such as gradient descent) to minimize the difference between predicted output vectors and target outputs, thereby learning the proper mapping from inputs to outputs. ##Conclusion## Through iterative matrix multiplications and nonlinear activations, ANNs learn to map input representations of language into desired outputs, underpinning tasks like translation, parsing, and semantic interpretation in applied linguistics.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",1,1.1859924140007934
What approach and results characterize the system that learns TurKontrol’s POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks?,"##Learning TurKontrol’s POMDP Parameters from Mechanical Turk Data for Dynamic Crowdsourced Task Optimization## ##Introduction## Iterative crowdsourcing workflows often suffer from unpredictable worker reliability and costly redundancies. TurKontrol addresses this by framing quality control as a Partially Observable Markov Decision Process (POMDP), yet its practical deployment requires accurate model parameters. A novel system was developed to infer these POMDP parameters directly from large-scale Mechanical Turk data and then use them to guide live task execution. ##Main Body## First, the system aggregates task outcomes and worker responses to estimate key POMDP variables—worker accuracy distributions, transition probabilities for item quality, and voting behavior parameters—through statistical learning techniques. With these learned parameters, it dynamically selects whether to assign new workers, request additional votes, or accept the current result, balancing cost against expected quality improvements. This adaptive control strategy was tested on a successive-improvement editing workflow, continuously observing and updating the POMDP policy as new data accrued. Compared to a fixed-strategy (nonadaptive) workflow using the same budget, the learned POMDP yielded higher-quality final artifacts, demonstrating both effective parameter estimation and cost-efficient decision making. ##Conclusion## By end-to-end learning of TurKontrol’s POMDP parameters from real Mechanical Turk interactions and applying the model in an adaptive control loop, the system significantly enhances the quality of iterative crowdsourced tasks without increasing expenditure.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",2,1.1859924140007934
What are the key features of a sustainability-oriented corporate culture that shape the development and management of sustainable artificial intelligence?,"##Sustainability-Oriented Corporate Culture for Sustainable AI## ##Introduction## As organizations increasingly deploy artificial intelligence to address societal and environmental challenges, the underlying corporate culture plays a decisive role in ensuring that AI applications contribute to sustainable development. A sustainability-oriented culture embeds norms, values, and structures that guide the design, deployment, and governance of AI toward long-term ecological health, social equity, and economic resilience. ##Main Body## 1. Shared Sustainability Values: Organizations with a sustainability-oriented culture articulate clear environmental and social objectives, aligning AI teams around common purpose beyond short-term profit. These values become part of mission statements, performance metrics, and internal communications, steering AI initiatives toward reducing waste, emissions, or inequalities. 2. Leadership Commitment and Incentives: Senior executives visibly champion sustainable AI by tying leadership performance reviews and incentive schemes to sustainability indicators—such as carbon reduction goals or fairness metrics—ensuring that resource allocation and strategic priorities reflect sustainable development aims. 3. Cross-Functional Collaboration: Such cultures foster strong interfaces among data scientists, engineers, ethical specialists, and external stakeholders (e.g., community representatives, NGOs), enabling AI development processes that integrate technical feasibility with environmental impact assessments and social risk evaluations. 4. Transparency and Accountability: Transparency mechanisms—public reporting on AI’s resource consumption, decision-making criteria, and environmental footprints—combined with internal accountability structures (audit committees, ethics boards) help organizations monitor and correct unsustainable AI practices. 5. Continuous Learning and Adaptation: A learning-oriented culture promotes regular training on sustainable AI methods, post-deployment reviews of environmental and social outcomes, and iterative improvements based on feedback loops, thereby institutionalizing best practices like energy-efficient algorithms or bias mitigation techniques. 6. Inclusive Stakeholder Engagement: By proactively involving suppliers, customers, regulators, and affected communities in AI project governance, firms ensure that diverse perspectives shape sustainable AI solutions, anticipate unintended consequences, and build broader support for long-term initiatives. ##Conclusion## A corporate culture that embeds sustainability at every level—from leadership incentives and shared values to transparent practices and continuous learning—provides the essential environment in which sustainable artificial intelligence can flourish. Consequently, companies with such cultural features are better equipped to harness AI’s potential for reducing environmental impact, promoting social equity, and creating resilient economic value over the long term.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",3,1.1859924140007934
How can the main applications of machine learning methods for early diagnosis of maternal-fetal conditions and their ethical considerations be summarized?,"##Machine Learning Applications for Early Maternal-Fetal Diagnosis and Ethical Aspects## ##Introduction## Advances in machine learning have enabled earlier and more accurate detection of maternal-fetal complications—such as preterm birth and abnormal fetal growth—by mining complex biomedical datasets. These predictive tools promise to guide timely clinical interventions, but their deployment raises important ethical questions around patient privacy, data governance, and fairness. ##Main Body## Contemporary methods employ supervised learning algorithms (e.g., support vector machines, random forests, neural networks) to analyze multi-modal inputs: ultrasound images, biochemical markers, electronic health records, and wearable sensor signals. In preterm birth prediction, models integrate demographic factors, cervical measurements, contraction patterns, and inflammatory profiles to achieve high sensitivity in identifying at-risk pregnancies. For fetal growth assessment, algorithms process placental perfusion metrics and biometric parameters to flag intrauterine growth restriction or macrosomia. Rigorous validation—using cross-validation, external cohorts, and ROC analysis—has demonstrated robust performance, though algorithm generalizability can be limited by cohort heterogeneity. Ethical considerations include safeguarding maternal and fetal data privacy, obtaining informed consent for data collection and model use, ensuring transparency and interpretability of model outputs for clinicians and patients, and actively addressing bias stemming from underrepresented subpopulations in training datasets. ##Conclusion## Machine learning holds significant promise for early diagnosis of maternal-fetal conditions by leveraging diverse data sources and advanced predictive models. To realize clinical benefits responsibly, it is crucial to implement ethical safeguards—ensuring privacy protection, transparent decision-making, and equitable performance across all patient groups.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",4,1.1859924140007934
초등학교 수준에서 설명 가능한 인공지능 교육의 핵심 요소와 활용 방안을 어떻게 요약할 수 있나요?,"##제목## 초등학교 수준에서 설명 가능한 인공지능 교육의 핵심 요소 및 구성주의적 활용 방안 ##서론## 인공지능(AI)이 빠르게 일상에 스며들며 AI 원리를 단순히 소비하는 단계를 넘어 스스로 이해하고 설명할 수 있는 능력이 중요해졌다. 특히 초등학생은 문제 해결과 비판적 사고의 기초를 형성하는 시기이므로, AI 개념을 쉬운 언어와 실생활 예제로 설명하고 학습자가 직접 개념을 구성해 보는 경험을 제공하는 것이 핵심이다. ##본론## 1. 설명 가능한 AI 교육의 핵심 요소 - 인간 중심의 문제 해결 학습: AI가 실제 삶의 문제를 어떻게 도울 수 있는지 사례를 통해 깨닫게 함 - 알고리즘 원리의 직관적 이해: 블록 코드나 그림, 역할 놀이 등을 활용해 입력·처리·출력 과정을 체험 - 해석력 강화: 학습자가 AI 모델의 결과를 인간의 관점에서 설명하도록 유도해 ‘왜’라는 질문을 강조 - 다양한 교수·학습 도구 활용: 시각화 도구, 마이크로비트·스마트 로봇 등 눈에 보이는 매체로 알고리즘 동작 원리를 학습 2. 구성주의 관점의 보완적 활용 - 학습자 주도 탐구: 학급 내 소그룹 프로젝트로 AI 활용 과제를 스스로 설계·실행하며 개념을 구성 - 경험 중심 통합: 진화생물학·뇌과학·시스템 이론 등 다양한 배경 지식을 놀이·토론 활동에 녹여 융합적 이해 촉진 - 협력적 피드백: 동료 간 설명·시연 과정을 통해 서로 다른 관점을 공유하며 개념을 수정·발전 ##결론## 초등학생 대상 설명 가능한 AI 교육은 실생활 사례와 직관적 알고리즘 체험을 통해 해석력과 문제 해결 능력을 동시에 키우며, 구성주의적 수업 설계로 학습자 스스로 지식을 구성하는 과정을 지원할 때 더욱 효과적이다. 이러한 접근은 학생들이 AI 원리를 바탕으로 비판적·창의적 사고를 확장하도록 돕는다.",How can I summarize the core elements and ways of using AI education that can be explained at elementary school level?,"##title## The core elements of artificial intelligence education, which can be explained at the elementary school level, ##introduction## The ability to understand and explain themselves beyond the stage of artificial intelligence (AI) quickly penetrates into everyday life and simply consumes AI principles. In particular, elementary school students are the time to form the basis of problem solving and critical thinking, so it is important to explain the AI concept as an easy language and real life example, and provide learners the experience of forming a concept. ## Main ## 1. The core element of the explanatory AI education -Learning of human -centered problem solving: AI realizes how to help real life problems. -Intuitive understanding of the principle of algorithm: Experience the input, processing, and output process using block codes, pictures, and role play -Interpretation: Interpretation: Emphasizing the question of 'why' by encouraging learners to explain the results of the AI model from a human perspective. -Using a variety of teaching and learning tools: visualization tools, microbit and smart robots, etc. 2. Complementary use of constructivist perspective -Learner -led exploration: Design and executing AI tasks by themselves and organizing concepts as a small group project in the class. -Experience -based integration: Various background knowledge such as evolutionary biology, brain science, and system theory is dissolved in play and discussion activities to promote fusion understanding -Feedback of collaborative feedback: Modify and develop concepts by sharing different perspectives through descriptions and demonstrations between colleagues ##conclusion## AI education, which can be explained to elementary school students, is more effective in supporting the process of constructing knowledge by learners by simultaneously developing interpretation and problem solving skills through real life cases and intuitive algorithm experiences. This approach helps students expand critical and creative thinking based on AI principles.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",5,1.1859924140007934
생성형 AI 콘텐츠의 가치 유형별 소비자 인식과 AI 사용 공개에 대한 인식 특성을 어떻게 요약할 수 있나요?,"##제목## 생성형 AI 콘텐츠 가치·형식별 소비자 인식과 AI 사용 공개 태도 분석 ##서론## 생성형 인공지능(AIGC)은 다양한 미디어 형식으로 자율 생성 능력을 가지지만, 진정성 문제로 규제와 투명성 요구가 커지고 있다. 이에 소비자가 AIGC를 어떻게 인지하고 AI 사용 공개를 어떤 원칙으로 받아들이는지 이해하는 것이 중요하다. 본 연구는 콘텐츠 가치 유형(실용적·쾌락적)과 미디어 형식(글·사진·영상)을 결합한 여섯 가지 시나리오에서 소비자 인식을 분석했다. ##본론## 카노 모형을 활용해 각 시나리오의 만족도와 불만족 요인을 측정하고, 인지된 진정성과 기만 여부에 따라 그룹을 구분했다. 실용적 콘텐츠(특히 뉴스)에서는 AI 사용에 대해 부정적 인식이 우세했고, 영상 뉴스에서 그 강도가 가장 컸다. 반면 쾌락적 콘텐츠(영화·드라마)에서는 AI 사용에 대한 관심이 낮거나 오히려 긍정적인 태도가 관찰되었다. AI 사용 공개는 콘텐츠 가치에 관계없이 ‘지켜야 할 원칙’으로 여겨졌으나, 실용적 콘텐츠에서 그 중요성이 더 크게 드러났다. ##결론## 소비자는 콘텐츠의 가치 유형과 형식에 따라 AIGC와 AI 사용 공개에 상이한 태도를 보인다. 뉴스 같은 정보성 콘텐츠에서는 투명성과 진정성 확보 노력이 필수적하며, 쾌락적 영역에서는 경험 개선을 위한 활용이 가능하다. 향후 AI 활용의 신뢰도를 높이기 위해 진정성 강화 및 투명성 제고 방안을 지속적으로 모색해야 한다.",How can you summarize the recognition characteristics of consumer awareness and AI disclosure by value type?,"##title## Producted AI Content Value and Family -specific Consumer Recognition and AI Public Attitude Analysis ##introduction## Productive artificial intelligence (AIGC) has the ability to generate autonomous generations in various media formats, but due to authenticity, regulations and transparency demands are increasing. It is important to understand how consumers recognize AIGC and how they accept AI disclosure. This study analyzed consumer perception in six scenarios that combine content value types (practical and pleasure) and media formats (text, photographs, and videos). ## Main ## Using the cano model, the group was measured by measuring the satisfaction and dissatisfaction of each scenario, and the group was distinguished according to the recognized authenticity and deceit. In practical contents (especially news), negative perceptions of AI use were prevailed, and the intensity in video news was the largest. On the other hand, in pleasure contents (movies and dramas), interest in using AI was low or rather positive. The disclosure of the use of AI was regarded as a ""principle to be kept,"" regardless of the value of the content, but its importance was even greater in practical contents. ##conclusion## Consumers show different attitudes in the release of AIGC and AI according to the value types and forms of the content. Efforts to secure transparency and authenticity are essential for information content such as news, and in pleasure areas, it is possible to improve experience. In order to increase the reliability of AI utilization in the future, it is necessary to continue to seek ways to strengthen authenticity and improve transparency.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",6,1.1859924140007934
"항공 분야에 적용된 인공지능의 기본 개념과 산업적 의미, 직면 과제를 간략하게 정리할 수 있나요?","##제목## 항공 분야에 적용된 인공지능 ##서론## 인공지능은 1956년 개념이 정립된 이래 컴퓨터 기반으로 최소한의 인간 개입 하에 지능적 의사결정을 수행하도록 발전해왔다. 항공 산업은 복잡한 환경에서 실시간 의사결정과 방대한 데이터를 요구하므로, AI 기술 도입을 통해 운영 효율화와 안전성 강화를 동시에 추구하게 되었다. ##본론## 1. 기본 개념 • 자율비행·항로 최적화: 기체 센서 데이터를 토대로 최적 경로를 자동으로 탐색·수정 • 예측정비(Predictive Maintenance): 기체의 상태 데이터를 분석해 고장 발생 시점을 사전 예측 • 안전 모니터링: 조종실·객실·지상 설비 전반의 이상 징후를 실시간 탐지 2. 산업적 의미 • 운항 효율성 제고: 최적 경로 산출과 정비 간격 단축으로 연료비 및 운영비 절감 • 안전성 향상: 조종사 경로 지원 및 위험 상황 조기 경고를 통해 사고 위험 감소 • 서비스 품질 강화: 승객 탑승 경험 개선 및 정시 운항률 상승에 따른 고객 만족도 제고 3. 직면 과제 • 윤리·법적 이슈: 자율결정 과정의 책임 주체 규명 및 국제 규제 체계 정립 • 전문인력 역할 변화: 조종사·정비사 등 기존 전문가와 AI 간 협업 모델 설계 • 기술 신뢰성 확보: AI 알고리즘의 설명 가능성과 검증된 안전성 입증 • 데이터 관리·보안: 항공기·탑승객 정보의 프라이버시 보호와 사이버 공격 대비 ##결론## 인공지능은 항공 산업의 운항 효율, 안전성, 서비스 품질을 획기적으로 개선할 잠재력을 지닌다. 다만 윤리·법적 규제 정비, 전문가 협업 체계 구축, 기술 검증 및 보안 확보 등의 과제를 해결해야만 보다 광범위한 상용화와 지속 가능한 발전이 가능하다.","Can I briefly summarize the basic concepts, industrial meanings, and face tasks of artificial intelligence applied to the aviation field?","##title## Artificial intelligence applied to aviation ##introduction## Since the establishment of the concept in 1956, artificial intelligence has been developing to carry out intelligent decisions with minimal human intervention based on computers. Since the aviation industry requires real -time decision -making and vast data in a complex environment, the introduction of AI technology has been pursued at the same time. ## Main ## 1. Basic concept • Autonomous flight and route optimization: automatically exploring and modifying the optimal path based on gas sensor data • Predictive Maintenance: Analyze the state data of the gas and predict the failure time. • Safety monitoring: real -time detection of abnormal signs of control room, room, and ground facilities 2. Industrial meaning • Enhancement of operating efficiency: Reduction of fuel and operating costs by calculating optimal routes and shortening maintenance intervals • Improved safety: Reduced accident risks through pilot path support and early warning of dangerous situations • Strengthening service quality: Enhancement of customer satisfaction due to improving passenger boarding experience and increasing on -time operating rate 3. Facial task • Ethics and legal issues: identifying responsibility for autonomous decision -making process and establishing international regulatory system • Changes in professional manpower role: Designed for collaborative models between existing experts such as pilots and mechanics and AI • Securing technology reliability: The possibility of explanation of AI algorithms and proven proven safety • Data management and security: Privacy protection and cyber attacks of aircraft and passenger information ##conclusion## Artificial intelligence has the potential to dramatically improve the efficiency, safety and service quality of the aviation industry. However, it is necessary to solve the tasks such as ethics and legal regulatory maintenance, establishment of expert collaboration system, technical verification and security secure.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",7,1.1859924140007934
구성주의 관점에서 인공지능 연구가 확장한 지능 이해의 지평과 주요 기술 동향을 어떻게 요약할 수 있나요?,"##제목## 구성주의 관점의 인공지능 지능 이해 지평 확장과 주요 기술 동향 ##서론## 구성주의는 데카르트적 이성주의를 넘어 진화생물학·진화심리학·뇌과학·시스템 이론·복잡계 이론 등 여러 학문적 성과를 통합하여 지능을 환경과 상호작용하며 능동적으로 형성되는 현상으로 이해한다. 이러한 관점은 전통적 상징처리 모델과 달리 경험적이고 맥락적이며 다층적인 학습 과정을 강조한다. ##본론## 첫째, 구성주의적 접근은 에이전트가 자신의 지식 구조를 환경과의 지속적 상호작용을 통해 스스로 재구성하도록 설계된 인공생명(Artificial Life)과 군집지능(Swarm Intelligence) 연구를 활성화시켰다. 둘째, 심층강화학습과 예측부호화(Predictive Coding) 같은 기술은 에이전트 기반 프레임워크로 전환되어, 맥락 인식과 적응 능력을 강화하며 구성주의 이론을 실현하고 있다. 셋째, 구성주의는 인지적·정서적 요소를 함께 다루는 설명 가능한 AI 및 인간-기계 협업 시스템 설계에도 적용되어, 신뢰형 AI와 교육·심리치료 등 다양한 분야에서 혁신적 접근을 가능하게 한다. ##결론## 구성주의 관점은 지능을 단순 정보 처리 능력 이상으로 보고, 분산 에이전트와 상호작용 기반 학습을 핵심 원리로 제시함으로써 AI 연구의 지평을 넓힌다. 이는 범용지능 실현과 인간 수준의 협업형 AI 개발을 위한 중요한 이론적 토대를 제공한다.",How can we summarize the horizon and major technical trends that have expanded by artificial intelligence research from the perspective of components?,"##title## The extension of the horizon of artificial intelligence understanding in terms of constructivist and major technology trends ##introduction## Configurationism is understood as a phenomenon in which intelligence interacts with the environment by integrating various academic achievements such as evolutionary biology, evolutionary psychology, brain science, system theory, and complexity theory beyond Descartic rationalism. This perspective emphasizes emphasis on empirical, contextual, and multilayer, unlike traditional symbolism models. ## Main ## First, the constructive approach activated the study of artificial life and swarm intelligence designed to reconstruct their knowledge structure through continuous interaction with the environment. Second, technologies such as in -depth enhancement learning and predictive coding are converted into agent -based frameworks, enhancing context recognition and adaptation ability and realizing constructivism theory. Third, constructivism is also applied to the designable AI and human-machine collaboration system design that deals with cognitive and emotional elements, enabling innovative approaches in various fields such as trust AI and education and psychological therapy. ##conclusion## Configuration's perspective seeks the horizon of AI research by viewing intelligence beyond simple information processing ability and presenting interaction -based learning with distributed agents as a key principle. This provides an important theoretical foundation for the realization of general intelligence and the development of human -level collaborative AI.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",8,1.1859924140007934
"컴퓨터과학자들이 제안한 인공지능 정의에 내재된 지능, 뇌, 그리고 컴퓨터 모의 사이의 논쟁적 쟁점을 어떻게 요약할 수 있나요?","##제목## 인공지능 정의에 담긴 지능·뇌·컴퓨터 모의의 핵심 논쟁 ##서론## 인공지능 연구에서 지능, 뇌, 그리고 컴퓨터 모의 사이의 관계를 어떻게 설정하느냐는 정의 자체의 방향을 가르는 중요한 쟁점이다. AI 연구자들은 인간 지능의 본질을 과학적으로 분석하면서 동시에 이를 컴퓨터 시스템으로 구현·복제하려는 목표를 공유한다. 이 과정에서 드러나는 주요 논쟁은 경험적 기술 발전의 문제를 넘어 논리적·개념적 선험성에 관한 것이다. ##본론## 1. 지능의 개념화: - 일부 정의는 지능을 문제 해결 능력이나 정보처리 효율로 환원하지만, 다른 입장에서는 창의성·맥락 이해 등 비계산적 요소를 강조한다. - 이처럼 지능의 범위를 어떻게 설정하느냐에 따라 AI 목표와 평가 기준이 달라진다. 2. 지능과 뇌의 관계: - 기계적 모의가 가능한가라는 물음은 뇌의 기능을 얼마나 정밀하게 수학·논리 모델로 환원할 수 있는지와 직결된다. - 신경망, 복잡계 이론 등 뇌과학 성과를 차용한 접근이 존재하지만, 생물학적 뇌가 지니는 비선형·동적 특성을 모두 모방하기에는 한계가 명확하다. 3. 컴퓨터 모의의 논리 구조: - 컴퓨터 시뮬레이션은 기호 처리(symbolic processing)와 계산 모델에 기반하지만, 이론적 비판론자들은 의미 부여·상향식 학습 등을 처리하지 못한다고 지적한다. - 따라서 AI 정의는 기술적 능력과 더불어 개념적 명료성, 즉 어떤 ‘지능’을 왜·어떻게 모의하는지에 대한 논리적 근거 확보가 필수적이다. 4. 경험적 진보 vs 선험적 분석: - 하드웨어·알고리즘 발전이 보여주는 성과에도 불구하고, AI 탐구의 핵심은 개념·논리적 쟁점에 대한 선험적 고찰에서 비롯된다. - 지능과 뇌, 그리고 컴퓨터 모의 간의 논의를 명확히 구축해야만 지속 가능한 이론적 토대를 마련할 수 있다. ##결론## 인공지능의 정의를 둘러싼 논쟁은 기술적 성취를 넘어 지능의 본질과 뇌 모사의 논리적 근거를 엄밀히 따지는 개념적 과제를 요구한다. 이를 통해 AI 연구는 단순 시뮬레이션 수준을 넘어, 인간 지능의 다양한 특성을 정교하게 반영하고 설명할 수 있는 방향으로 진화할 수 있다.","How can you summarize the controversial issue between intelligence, brain, and computer simulation inherent in the definition of artificial intelligence proposed by computer scientists?","##title## Intelligence, brain, and computer mock core arguments contained in artificial intelligence definition ##introduction## How to set up the relationship between intelligence, brain, and computer mock in AI research is an important issue that divides the direction of the definition itself. AI researchers scientifically analyze the essence of human intelligence and at the same time share their goals to implement and replicate them with their computer systems. The main debate revealed in this process is to go beyond the problem of empirical technology and relate to logical and conceptual priorities. ## Main ## 1. Conceptualization of Intelligence: Some definitions reduce intelligence with problem -solving ability or information processing efficiency, but other perspectives emphasize non -calculated factors such as creativity and context. -The AI goal and evaluation criteria depend on how to set the scope of intelligence. 2. The relationship between intelligence and brain: The question of whether mechanical simulation is possible is directly related to how precisely the brain's function can be reduced to mathematics and logical models. Although there are approaches to brain science, such as neural networks and complex theory, there is a clear limit to imitating all nonlinear and dynamic characteristics of biological brain. 3. Computer mock logic structure: Computer simulations are based on symbolic processing and calculation models, but theoretical criticisms point out that they do not process meaning and bottom -up learning. Therefore, AI definition is essential to secure a logical basis for the technical ability, the conceptual clarity, that is, what kind of intelligence, and how to simulate what intelligence. 4. Empirical Progress vs priority analysis: Despite the achievements of the development of hardware and algorithms, the core of the AI exploration comes from a priori consideration of concept and logical issues. -The discussion between intelligence, brain, and computer mocks can be clearly established to lay the foundation for sustainable theoretical theoretical theoretical theoretical. ##conclusion## The debate over the definition of artificial intelligence goes beyond technical achievements and requires a conceptual task that strictly determines the essence of intelligence and the logical basis of brain simulation. Through this, AI research can go beyond simple simulation levels, and evolve in a way that can be delicately reflected and explained the various characteristics of human intelligence.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",9,1.1859924140007934
"How would you summarize the proposed enabling framework for achieving the second Sustainable Development Goal, emphasizing the role of data sharing and near real-time analytics?","##Enabling Data-Driven Framework for SDG2## ##Introduction## This framework addresses the urgent goal of eradicating hunger and securing safe, nutritious food for all by outlining a connected platform that spans the entire food network. It builds on the Sustainable Development Solutions Network’s recommendation for a generic enabling mechanism adaptable to any country’s development status. ##Main Body## At its core, the framework establishes clear information flows and feedback loops among farmers, suppliers, policymakers, researchers, and consumers to coordinate interventions across production, distribution, and consumption. Free exchange of data—ranging from crop yields and market prices to nutritional indicators—is coupled with near real-time analytics to detect emerging risks, optimize resource allocation, and guide policy decisions. The incorporation of IoT sensors and Big Data technologies ensures continuous monitoring of environmental conditions, supply chain performance, and food safety metrics. Case studies illustrate how rapid data sharing and analytics have enhanced responsiveness in both developing and western economies, improving resilience against climate shocks, price volatility, and supply disruptions. ##Conclusion## By leveraging open data and instantaneous analytics, this enabling framework creates a dynamic, knowledge-driven environment essential for achieving SDG2’s vision of a hunger-free, sustainable, and equitable global food system.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",10,1.1859924140007934
Can you outline the main advances and challenges in applying artificial intelligence and Big Data to medical imaging in neurology?,"##Artificial Intelligence and Big Data in Neurology## ##Introduction## Recent technological developments have enabled the collection and analysis of vast amounts of clinical and imaging data in neurology. These resources—including electronic health records, population registries, and advanced neuroimaging databases—offer unprecedented opportunities to enhance diagnosis and treatment of neurological disorders. ##Main Body## Key advances include the deployment of machine learning models that automate lesion detection and segmentation on MRI and CT scans, improving both speed and consistency compared to manual interpretation. Deep learning frameworks have demonstrated high accuracy in classifying complex patterns associated with stroke, multiple sclerosis, Alzheimer’s disease, and other conditions, leveraging convolutional neural networks trained on large annotated datasets. Integration of real-world data (RWD) and multi-modal analytics has supported the development of predictive models for disease progression and treatment response, while large-scale collaborative initiatives are standardizing data formats and promoting federated learning to protect patient privacy. Despite these successes, challenges persist: variability in image acquisition protocols compromises model generalizability, data heterogeneity and missing labels hamper robust training, and ensuring data quality and provenance remains difficult. Ethical concerns around informed consent, algorithmic bias, and data security further complicate deployment in clinical settings, and regulatory frameworks are still evolving to address accountability and transparency of AI‐driven decisions. ##Conclusion## Artificial intelligence and Big Data analytics are transforming medical imaging in neurology by enabling more accurate, efficient, and personalized care, yet overcoming data quality issues, ethical considerations, and implementation barriers is essential to fully realize their clinical potential.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",11,1.1859924140007934
What is the primary argument regarding the environmental impact of Big Data initiatives and the ethical considerations tied to data’s material presence?,"## Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives ## ## Introduction## Big Data projects often emphasize analytical capabilities while neglecting the environmental and ethical consequences of the physical infrastructures they require. Recognizing data’s materiality—servers, storage facilities, and energy consumption—is crucial to understanding the full impact of digital expansion. ## Main Body## The argument centers on three ethical concerns: first, the terminology used in data governance can obscure the environmental costs of data storage and processing; second, there is a growing tension between the rapid deployment of data centers and the goals of environmental policy aimed at reducing carbon footprints; third, unequal distribution of the ecological burdens—such as land use, energy demand, and electronic waste—raises questions of fairness and social justice. By drawing on perspectives from environmental studies and Science and Technology Studies, the authors show how the “immaterial” rhetoric of Big Data masks its concrete resource demands and spatial footprint. They advocate for a shift in governance vocabulary, alignment of data initiatives with sustainability regulations, and equitable sharing of environmental responsibilities. ## Conclusion## Acknowledging data’s physical presence and its environmental ramifications is essential for developing more sustainable, ethically informed practices in data storage, production, and governance.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",12,1.1859924140007934
How does the content describe the combination of phenomenological and mechanistic approaches through Big Data analytics to support personalized healthcare?,"##Integrating Empirical Insights and Mechanistic Models for Personalized Healthcare## ##Introduction## Personalized healthcare aims to tailor diagnosis and treatment to individual patients by combining two complementary modeling philosophies. Phenomenological approaches extract patterns directly from large-scale patient data, while mechanistic models build detailed, causal representations of physiological processes. Integrating these through Big Data analytics and Virtual Physiological Human (VPH) technologies offers a unified path toward in silico medicine. ##Main Body## Big Data analytics supplies the phenomenological component by uncovering correlations and trends across diverse, high-volume datasets. Mechanistic VPH models contribute causal understanding of tissue, organ, and whole-body dynamics. Neither approach stands alone; their fusion hinges on domain-specific technological advances. First, systems must securely manage and analyze sensitive, heterogeneous data—including nontextual formats—across distributed environments. Second, specialized analytics are needed to merge bioinformatics and systems biology insights with clinical observations at multiple scales. Finally, continuous data streams from daily life must be processed to delineate each patient’s “physiological envelope,” capturing normal variability and early signs of deviation. ##Conclusion## By addressing the challenges of data security, heterogeneity, distributed management, and multi-scale integration, Big Data technologies can bridge phenomenological and mechanistic paradigms. This synergy promises robust, patient-specific in silico medicine, marking a strategic priority for targeted research and funding in personalized healthcare.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",13,1.1859924140007934
What are the key findings of the socio-technical evaluation on Big Data developmental processes and the factors influencing user adoption?,"##Socio-Technical Evaluation and User Adoption in Big Data Development## ##Introduction## This study examines how Big Data practices emerge, become routinized, and integrate into organizations by applying a socio-technical lens. Using Normalization Process Theory, it analyzes the interplay between technology, organizational context, and human actors in South Korea’s Big Data ecosystem. It also investigates what drives or hinders individual users from embracing Big Data tools and insights. ##Main Body## • Developmental Processes: The evaluation identifies three core mechanisms—coherence (making sense of Big Data), cognitive participation (buy-in from stakeholders), and collective action (operational work to embed new practices). It reveals that successful integration depends on clear role definitions, shared understanding of expected benefits, and alignment with existing workflows. • Implementation Challenges: Technical complexity, insufficient training, and fragmented data governance emerged as obstacles to embedding Big Data solutions. Organizational support structures, such as cross-functional collaboration and continuous feedback channels, proved critical for sustaining adoption. • User Adoption Factors: Empirical user modeling highlights two primary drivers: cognitive motivations (perceived usefulness, ease of interpretation) and individual values (trust, data privacy concerns, alignment with personal goals). Users are more likely to adopt Big Data when interfaces communicate actionable insights and respect ethical considerations. • Design Implications: The findings underscore the need for user-centered development, where end-users participate in requirement setting, iterative prototyping, and evaluation. Tailoring data visualization and analytics to users’ domain expertise significantly enhances perceived value and motivation to engage. ##Conclusion## Achieving widespread adoption of Big Data depends on attending to both socio-technical dynamics and human factors. By embedding user-centered principles throughout the developmental lifecycle—clarifying objectives, fostering stakeholder engagement, and aligning technical functionality with cognitive and ethical user needs—organizations can ensure new Big Data practices become normalized, scalable, and impactful.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",14,1.1859924140007934
Big Data를 이용한 Warehouse Management System 모델에서 제시된 핵심 개념과 방향을 요약해 주시겠습니까?,"##제목## Big Data를 활용한 창고관리 시스템 모델 연구: SAP S/4 HANA 중심 ##서론## 디지털 전환(Digital Transformation)은 단순히 기존 데이터를 전자화하는 단계를 넘어 실시간 데이터 처리·분석 역량을 확보하는 것을 의미한다. 특히 산업 창고관리 분야에서는 재고·입출고·물류 흐름 등 방대한 운영 데이터를 효과적으로 활용할 수 있는 모델이 필요하다. 본 연구는 SAP S/4 HANA를 기반으로 대용량 데이터를 수집·처리하는 Warehouse Management System(WMS) 모델의 핵심 개념과 향후 방향을 제안하는 데 목적이 있다. ##본론## 1. Big Data 중심 아키텍처 - 센서와 ERP로부터 생성되는 다양한 물류 데이터를 실시간 스트리밍 및 배치 처리로 통합 - Hadoop, Spark 등 분산컴퓨팅 프레임워크를 활용해 대규모 트랜잭션과 로그를 고속 처리 2. SAP S/4 HANA 플랫폼 활용 - 인메모리(in-memory) 데이터베이스로 재고 현황·입출고 기록을 즉시 조회·분석 - 표준화된 모듈을 통해 창고 레이아웃 관리, 물류 작업 지시, 자동화 설비 연동 기능 제공 3. 지능형 분석 및 예측 - 수요·재고 변동 패턴을 기계학습으로 예측해 적정 재고 수준 자동 조정 - 실시간 KPI 대시보드를 구축해 운영 현황을 시각화하고 이상 징후를 조기 감지 ##결론## Big Data 기반 WMS 모델은 실시간 의사결정과 프로세스 자동화를 가능케 하며, SAP S/4 HANA의 인메모리 처리 기술을 통해 운영 효율을 극대화한다. 향후 IoT 센서, AI 알고리즘, 로봇 물류 설비와의 연계 강화를 통해 스마트 물류 환경으로의 진화를 기대할 수 있다.",없음,"##title## Warehouse Management System Model Study using Big Data: SAP S/4 HANA Center ##introduction## Digital transformation means securing real -time data processing and analysis capabilities beyond simply electronically electronic steps. In particular, in the field of industrial warehouse management, a model is needed to effectively utilize vast operation data such as inventory, deposit, and logistics flow. This study aims to propose the core concepts and future directions of the Warehouse Management System (WMS) model, which collects and processes large data based on SAP S/4 hana. ## Main ## 1. Big Data -centric architecture -Integrate various logistics data generated from sensors and ERPs into real -time streaming and batch processing -Fall processing large -scale transactions and logs using distributed computing frameworks such as HADOOP and SPARK 2. Use SAP S/4 HANA platform -Interview and analysis of inventory status and deposit records with in-memory database -Provide warehouse layout management, logistics work instructions, automation facility interworking function through standardized modules 3. Intelligent analysis and prediction -Ex adjusting the appropriate inventory level by predicting demand and inventory change patterns with machine learning -Real -time KPI dashboards to visualize the operation status and detect abnormal signs early. ##conclusion## The Big Data -based WMS model enables real -time decision -making and process automation, and maximizes operational efficiency through the In -Memo -Memory processing technology of SAP S/4 HANA. In the future, we can expect the evolution to the smart logistics environment by strengthening the connection with IoT sensors, AI algorithms, and robot logistics facilities.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",15,1.1859924140007934
DTG 실 주행데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM의 핵심 구성 요소를 요약해 주세요.,"##제목## DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 SBiFEM ##서론## DTG 운행기록계와 GPS 공간데이터의 대규모 축적으로 연료소모량 예측을 위한 빅데이터 분석의 필요성이 커졌다. 기존 모델은 제한된 환경에서 검증되어 실제 상용차 운행 시 정확도가 낮은 문제가 있었다. 이를 해결하기 위해 운전자 특성 및 도로 환경정보를 반영한 SBiFEM을 제안한다. ##본론## - 전처리 기술: 통계기법과 운행 패턴 분석을 결합한 필터링으로 센싱 및 GPS 데이터의 이상치(Outlier)를 제거해 신뢰성 확보 - 빅데이터 맵매칭: 대량의 GPS 궤적을 전자지도에 매칭하여 도로 유형, 경사도, 제한속도 등 공간 빅데이터 변수 추출 - 운행 패턴 생성: 속도·가속도·유휴시간 등 운전자 운행특성을 운행 패턴 변수로 정의하여 연료소모 영향 요인으로 활용 - 연료소모량 추정 모델: 공간빅데이터와 운행 패턴 변수를 회귀 기반 모델에 통합해 실제 운행 환경을 반영한 정밀 추정식 구축 - 시스템 구현 및 검증: Hadoop, HBase, MapReduce 기반 5대 분산 서버에서 분석 프로세스를 수행하고 SIDRA, VSP, VT-Micro 모델 대비 Correlation 0.9169, MAPE 0.1846을 달성해 성능 우수성 입증 ##결론## SBiFEM은 DTG 실 주행데이터와 공간 정보를 결합해 실제 운행 환경을 반영한 변수로 연료소모를 정밀하게 추정하며, 대규모 분산 처리와 비교 실험을 통해 기존 모델 대비 월등히 높은 정확도를 검증했다.","Please summarize the core components of SBIFEM, an estimated fuel cluster estimation model using DTG actual driving data and spatial information.","##title## Big Data -based fuel consumption estimation model using DTG real data and spatial information SBIFEM ##introduction## The large -scale accumulation of DTG operating records and GPS spatial data has increased the need for big data analysis to predict fuel and volume. Existing models have been verified in a limited environment and have a problem with low accuracy during actual commercial vehicles. To solve this problem, SBIFEM is proposed to reflect driver characteristics and road environment information. ## Main ## -Preating technology: Census and removing Outlier of GPS data with filtering that combines statistical techniques and operating pattern analysis to secure reliability -Big data map matching: A large amount of GPS trajectory on the electronic map to extract spatial big data variable such as road type, inclination, and limit speed -Incremental operation pattern: Using the driver's driving characteristics such as speed, acceleration, and idle time as an operation pattern variable and used as a fuel consumption impact factor -Puisotor Motor Estimation Model: Space big data and operating pattern variables are integrated into regression -based models to establish precise estimates that reflect the actual operating environment System Implementation and Verification: Hadoop, HBase, and MapREDUCE-based 5 Distributed Server performs analysis processes and achieved 0.9169, MAPE 0.1846 compared to SIDRA, VSP, VT-MICRO model to demonstrate performance excellence by achieving 0.1846 ##conclusion## SBIFEM combines DTG actual driving data and spatial information to precisely estimate fuel consumption as a variable that reflects the actual operating environment, and has verified a much higher accuracy compared to the existing model through large -scale distributed processing and comparison experiments.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",16,1.1859924140007934
빅데이터 처리 과정별 위험요인 유형과 우선순위를 간략하게 요약해 주시겠습니까?,"##제목## 빅데이터 처리 단계별 위험요인 유형과 우선순위 ##서론## 빅데이터 도입이 활발해지면서 데이터 수집부터 활용까지 전 과정에서 발생할 수 있는 다양한 위험요인을 체계적으로 분석하고, 전문가 설문을 통해 그 심각도에 따른 우선순위를 파악할 필요가 대두되었다. ##본론## 1. 수집 단계: 데이터 품질 저하와 불완전한 수집 프로세스로 인한 오류 발생 위험 2. 저장 단계: 보안 취약점과 데이터 유실·손상 위험 3. 분석 단계: 알고리즘 편향, 해석 오류 및 모델 신뢰성 저하 위험 4. 시각화 단계: 과장·왜곡된 정보 전달로 인한 오판 위험 5. 적용 단계: 잘못된 의사결정, 윤리·법적 문제 발생 위험 – 전문가 설문 결과, 먼저 해결해야 할 최우선 위험으로는 수집 단계의 품질 오류와 저장 단계의 보안 문제가 꼽혔으며, 그 다음으로 분석·시각화 과정의 해석 오류가 중요한 것으로 나타났다. ##결론## 단계별 위험요인을 명확히 파악하고 우선순위에 따라 대응 방안을 마련함으로써 빅데이터 처리 전 과정의 안정성을 높이고 효과적인 활용이 가능해진다.",Can you briefly summarize the types and priorities of risk factors for each big data processing process?,"##title## Big data processing stage type and priority ##introduction## As the introduction of big data became more active, it was necessary to systematically analyze various risk factors that can occur throughout the process from data collection to utilization, and to identify priority due to the severity through expert surveys. ## Main ## 1. Collection Stage: Data Quality Risk of Error due to Incomant Collection Processes 2. Storage Stage: Risk of security vulnerabilities and data loss and damage 3. Analysis Step: Risk of algorithm bias, analysis error and model reliability decrease 4. Visualization Stage: Odan Risk due to exaggeration and distorted information delivery 5. Application Stage: Risk of incorrect decision, ethics and legal problems - According to the expert survey, the first priority to be solved was the quality error of the collection stage and the security problem in the storage stage, followed by the analysis and visualization process. ##conclusion## By clearly identifying the risk factors of each stage and preparing a countermeasure according to priority, it enables increasing the stability of the entire big data processing process and effective utilization.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",17,1.1859924140007934
패키징 분야에서의 빅데이터 분석 기법과 소비자 인식 분석 방안을 요약해 주세요.,"##제목## 빅데이터 기반 스마트 패키징 분석 및 소비자 인식 평가 방안 ##서론## 스마트 패키징은 4차 산업혁명 시대에 IoT, 빅데이터, 클라우드 기술을 융합해 제품의 부가가치를 높이는 전략 도구입니다. 특히 소비자의 구매 결정 과정에서 패키징이 미치는 영향이 크기 때문에, 이를 정밀하게 파악하고 적용하기 위한 빅데이터 분석 기법이 요구됩니다. 본 연구는 패키징 분야에 활용 가능한 데이터 수집·저장·분석 방법을 정리하고, 소비자 인식 분석 방안을 제안합니다. ##본론## 1. 데이터 원천 및 관리 - 사유 데이터(private data)와 커뮤니티 데이터(community data)를 활용해 소비자 행동 및 반응 정보를 수집·저장합니다. 2. 패키징 요소별 영향력 도출 - 의미연결망 분석과 텍스트마이닝으로 패키징 관련 키워드와 연관성을 파악하고, 빈도 분석을 통해 주요 속성의 영향도를 계량화합니다. 3. 감정 및 선호도 심층 분석 - 저관여 제품을 대상으로 텍스트 마이닝, 오피니언 마이닝, 소셜 네트워크 분석을 결합해 소비자 감정과 선호 패키징 유형을 도출합니다. ##결론## 제안된 빅데이터 분석 기법을 통해 패키징 요소가 소비자 인식 및 감정에 미치는 영향을 객관적으로 평가할 수 있습니다. 이를 바탕으로 기업은 차별화된 디자인 전략과 제품 개선 방향을 수립해 마케팅 효율을 높일 수 있습니다. 궁극적으로 스마트 패키징 구현을 통해 소비자 만족도를 증대시키고 시장 경쟁력을 강화할 수 있습니다.",Please summarize big data analysis techniques and consumer recognition analysis in the field of packaging.,"##title## Big data -based smart packaging analysis and consumer recognition evaluation plan ##introduction## Smart packaging is a strategic tool that increases the added value of the product by combining IoT, big data, and cloud technologies in the era of the Fourth Industrial Revolution. In particular, since the impact of packaging on the purchase decision of consumers, big data analysis techniques are required to identify and apply it precisely. This study summarizes data collection, storage, and analysis methods that can be used in the field of packaging, and proposes consumer recognition analysis. ## Main ## 1. Data Source and Management -The use private data and community data to collect and store consumer behavior and reaction information. 2. Doting influence by packaging element -The significant connection network analysis and text mining understand the connection with the keywords related to packaging, and the frequency analysis weigh the effects of major attributes. 3. In -depth analysis of emotion and preference -Combine text mining, opinion mining, and social network analysis for low -corruption products to derive consumer sentiment and preferred packaging type. ##conclusion## The proposed big data analysis technique allows you to objectively evaluate the impact of packaging elements on consumer awareness and emotions. Based on this, companies can increase marketing efficiency by establishing differentiated design strategies and product improvement directions. Ultimately, smart packaging can be implemented to increase consumer satisfaction and strengthen market competitiveness.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",18,1.1859924140007934
제조 품질 개선을 위해 제안된 식스 시그마 기반 Big Data 활용 방법의 주요 절차를 요약해 주시겠습니까?,"##제목## 빅데이터를 활용한 식스 시그마 기반 제조 품질 개선 절차 요약 ##서론## 제조 기업은 전통적인 식스 시그마 프로젝트를 통해 체계적인 품질 개선을 추진해 왔으나, 최근 빅데이터 기술을 접목함으로써 문제점 탐색과 개선 효과 검증을 더욱 신속·정밀하게 수행할 수 있는 가능성이 커졌다. 본 연구에서는 식스 시그마의 DMAIC(Define-Measure-Analyze-Improve-Control) 단계별로 빅데이터 활용 방안을 제안한다. ##본론## 1. Define(정의) - 개선 목표 및 핵심 품질 이슈를 명확히 설정 - 빅데이터 플랫폼에 연계 가능한 공정·장비·검사 데이터 범위 지정 2. Measure(측정) - 센서, 생산관리시스템, 검사 장비 등에서 대량의 실시간 데이터를 수집·통합 - 데이터 정합성·이상치 검출을 위한 전처리 적용 3. Analyze(분석) - 통계적 기법 및 머신러닝 모델을 활용해 주요 결함 원인과 공정 변수 상관관계 파악 - 멀티변량 분석을 통해 숨겨진 패턴 및 잠재적 리스크 식별 4. Improve(개선) - 분석 결과를 바탕으로 공정 조건·검사 기준을 최적화 - 시뮬레이션 및 파일럿 실험을 통해 개선안의 실효성 검증 5. Control(관리) - 실시간 모니터링 대시보드와 이상 알림 시스템을 구축해 개선 결과 지속 관찰 - 제어 차트·경고 임계치 설정으로 재발 방지 및 표준화 유지 ##결론## 식스 시그마의 DMAIC 절차에 빅데이터 수집·분석·시각화 역량을 결합함으로써 품질 문제를 더욱 빠르고 정확하게 해결할 수 있으며, 지속적인 모니터링을 통해 제조 공정의 안정성과 경쟁력을 동시에 확보할 수 있다.",Can you summarize the main procedures of the Six Sigma -based BIG DAG DAG Data?,"##title## Six Six Sigma -based manufacturing quality improvement procedures using big data ##introduction## Manufacturing companies have been pursuing systematic quality improvement through traditional Six Sigma projects, but recently, by combining big data technology, the possibility of further and precisely conducting problems search and improved effects is increased. In this study, Six Sigma's DMAIC (Define-Measure-Analyze-IMPROVE-Control) will be proposed. ## Main ## 1. Define (definition) -It clearly set improvement goals and core quality issues -Designation of process, equipment, and inspection data that can be linked to the big data platform 2. Measure (measurement) -Collect and integrate large amounts of real -time data from sensors, production management systems, inspection equipment, etc. -Condrocation for detection of data consistency and overtake value 3. Analyze (analysis) -Incrighten statistical techniques and machine learning models to identify the causes of major defects and fair variables. -It identifies hidden patterns and potential risks through multi -variable analysis 4. IMPROVE (improvement) -Intimature of process conditions and inspection standards based on analysis results. -Efficiency of improvement plan through simulation and pilot experiments 5. Control (management) -Real -time monitoring dashboard and abnormal notification system have been established to continue to observe improvement results -It prevents recurrence and standardization by setting control charts and warning thresholds ##conclusion## By combining big data collection, analysis, and visualization capabilities with Six Sigma's DMAIC procedure, quality problems can be solved faster and more accurately, and continuous monitoring can secure the stability and competitiveness of the manufacturing process at the same time.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",19,1.1859924140007934
Could you summarize how deep learning techniques are envisioned to enhance radar imaging and the main challenges and proposed network architecture discussed?,"##Deep Learning for Radar## ##Introduction## Advances in deep learning offer new opportunities to improve radar imaging beyond traditional automatic target recognition. By integrating neural network models with established radar signal processing, researchers aim to capture complex non-linearities and adaptively compensate for system imperfections. ##Main Body## Deep learning is envisioned to play a central role across a wide range of radar imaging challenges, including synthetic aperture radar (SAR) image formation and autofocus. Key hurdles include the scarcity of labeled radar data, the need to respect the physics of the SAR forward model, and the requirement to mitigate phase errors caused by platform motion. To address these, a hybrid network architecture is proposed that embeds traditional SAR modeling blocks within a deep learning framework: the network learns to approximate the non-linear inversion of the SAR forward operator while leveraging analytic layers for known propagation effects. Additionally, the model is trained to predict and correct trajectory-based phase distortions, improving autofocus performance without relying solely on handcrafted algorithms. ##Conclusion## By combining deep learning’s data-driven learning with established SAR theory, the proposed approach promises enhanced image clarity and robustness to motion errors. Overcoming data limitations and ensuring model fidelity to radar physics are critical for realizing these gains in practical radar systems.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",20,1.1859924140007934
"Can you provide a concise overview of the comparison between deep learning and deep reinforcement learning for complex image analysis, highlighting their strengths and weaknesses?","##Comparison of Deep Reinforcement Learning and Deep Learning for Complex Image Analysis## ##Introduction## Complex image analysis tasks—such as histopathological slide interpretation—require powerful feature extraction to support accurate diagnosis. Convolutional neural networks (CNNs) have driven major advances in segmentation, detection, and tumor classification, but they depend on large, well‐annotated datasets and often lose spatial context when applied patchwise. Deep reinforcement learning (DRL) has emerged as an alternative that learns policies to navigate and analyze images without exhaustive annotations, potentially preserving contextual information. ##Main Body## Deep learning excels at hierarchical feature learning and benefits from mature frameworks and GPU acceleration; however, it struggles with gigabyte‐scale images, adversarial input variations, and the patch‐based multi‐instance learning (MIL) approach’s tendency to fragment context. DRL formulates image analysis as a sequential decision problem, enabling models to selectively attend to informative regions and learn from limited data while maintaining spatial coherence. This reinforcement approach reduces reliance on localized labels and mitigates data scarcity, though it demands careful reward function design and often incurs greater computational cost during training. ##Conclusion## While deep learning remains the primary choice for segmentation and classification when plentiful annotated data exist, deep reinforcement learning offers a promising complement in scenarios with limited labels and extremely large images, preserving contextual integrity and enabling more adaptive feature extraction.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",21,1.1859924140007934
"Could you briefly summarize the methodology and results of using CNN, LSTM, and SVM combinations for noninvasive diabetes detection based on HRV signals?","##Diabetes detection using deep learning algorithms## ##Introduction## Heart rate variability (HRV) extracted from ECG signals provides a noninvasive window into autonomic function and has shown promise for early diabetes screening. Leveraging advances in deep learning, this study explores how convolutional and recurrent neural networks can capture complex temporal dynamics in HRV data to distinguish diabetic from healthy subjects. ##Main Body## The methodology combines convolutional neural networks (CNNs) and long short-term memory (LSTM) networks—either standalone or in tandem—to learn spatial and temporal features from RR-interval sequences. These learned representations are then fed into a support vector machine (SVM) classifier, which refines decision boundaries between normal and diabetic patterns. Incorporating SVM on top of CNN and CNN-LSTM models yields incremental performance gains of 0.03% and 0.06%, respectively, over architectures without SVM. Overall, the hybrid framework achieves a classification accuracy of 95.7%, demonstrating robustness in noninvasive diabetes detection. ##Conclusion## By fusing CNN- and LSTM-based feature extraction with SVM classification, the proposed approach attains high diagnostic accuracy on HRV data, offering a practical and precise tool for early, noninvasive diabetes detection.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",22,1.1859924140007934
Can you outline the key deep learning and machine learning models evaluated for electricity demand prediction and their comparative performance in terms of MSE and MAPE?,"##Effective Electricity Demand Prediction via Deep Learning## ##Introduction## Accurate short-term forecasting of household electricity demand is critical for reducing waste and improving energy management in smart grids. Time-series prediction remains a challenge, prompting comparison between traditional statistical methods and modern deep learning architectures. ##Main Body## Three models were tested on German home appliance power-consumption data: - An error-corrected multilayer perceptron (eMLP), which combines a standard MLP with an error-correction mechanism. - An autoregressive integrated moving average (ARIMA) model, representing a classical statistical approach. - A hybrid convolutional neural network–long short-term memory (CNN-LSTM) network, designed to extract spatial patterns via convolution layers and capture temporal dependencies through LSTM units. Performance was evaluated using mean square error (MSE) and mean absolute percentage error (MAPE). The CNN-LSTM achieved the lowest MSE and MAPE, significantly outperforming eMLP, which in turn outperformed ARIMA. ##Conclusion## The CNN-LSTM architecture demonstrated superior accuracy in electricity demand forecasting, highlighting the benefit of combining convolutional feature extraction with recurrent temporal modeling over both pure neural networks and traditional time-series methods.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",23,1.1859924140007934
"Can you summarize the main findings from the topic modeling analysis of deep learning research trends over the past ten years, including country-specific differences?","##Deep Learning Research Trend Analysis## ##Introduction## A systematic review employing Latent Dirichlet Allocation (LDA) distilled the evolution of deep learning research over the past decade, mapping both thematic shifts and national emphases. ##Main Body## – Data Collection and Topic Extraction: Over ten years of deep learning publications were gathered and preprocessed; LDA identified core topics including network architectures (e.g. CNNs, RNNs), computer vision, natural language processing, reinforcement learning, and generative models. – Temporal Trends: Early work concentrated on foundational model design and training algorithms, while later years saw growing interest in application-driven studies and multimodal or interdisciplinary approaches. – Country-Specific Differences: • United States: Led in algorithmic innovations and theoretical advances. • China: Rapidly expanded research on large-scale and industry-oriented applications. • South Korea: Focused strongly on cloud-based frameworks, performance benchmarking, and hardware optimization. • United Kingdom: Maintained a balanced portfolio spanning foundational methods and applied domains. ##Conclusion## Topic modeling reveals a clear progression from core model development to diverse real-world applications, with each major research country exhibiting distinct strategic priorities that shape the global deep learning landscape.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",24,1.1859924140007934
클라우드 컴퓨팅 환경에서 오픈소스 기반 딥 러닝 프레임워크들 간의 성능 비교 결과와 그 의의를 간결하게 정리해 주실 수 있나요?,"##제목## 클라우드 컴퓨팅 환경에서 오픈소스 기반 Deep Learning 프레임워크 성능 비교 ##서론## 통신·스토리지 기술 발전과 데이터 저장 비용 절감에 힘입어 대규모 데이터를 신속·효율적으로 처리할 수 있는 Cloud Computing이 각광받고 있으며, 이를 위해 TensorFlow, PyTorch, Caffe 등 다양한 오픈소스 Deep Learning 프레임워크가 개발되었습니다. 그러나 실제 클라우드 환경에서 어떤 프레임워크가 최적의 성능을 발휘하는지에 대한 체계적 비교 연구는 부족한 실정입니다. ##본론## 대표적 클라우드 오픈소스 플랫폼인 OpenStack 위에 주요 프레임워크를 설치하여 동일 모델과 하이퍼파라미터로 실험을 수행했습니다. 학습 시간, GPU 및 메모리 활용률, 분산 학습 확장성 세 가지 기준으로 벤치마킹한 결과, 일부 프레임워크는 대용량 데이터 병렬 처리 시 우수한 학습 속도와 안정적인 자원 관리를 보였고, 다른 프레임워크는 소규모 또는 메모리 제약이 있는 환경에서 더 낮은 메모리 소모로 효율을 발휘했습니다. ##결론## 이번 비교 연구는 클라우드 환경에서 비용과 성능을 종합적으로 고려해 프레임워크를 선택하고 최적화 전략을 수립하는 데 실질적 가이드를 제공합니다.",Can you briefly summarize the performance comparison results and its significance between open source -based deep learning frameworks in the cloud computing environment?,"##title## Open source -based Deep Learning framework performance comparison in cloud computing environment ##introduction## Thanks to the development of communication and storage technology and the reduction of data storage costs, Cloud Computing, which can quickly and efficiently process large data, has been in the spotlight, and various open source Deep Learning frameworks such as Tensorflow, PyTorch, and Caffe have been developed. However, systematic comparison studies on which frameworks are optimal in the actual cloud environment are insufficient. ## Main ## The main framework was installed on top of OPENSTACK, a representative cloud open source platform, and experimented with the same model and hyper parameter. As a result of benchmarking on three criteria: learning time, GPU and memory utilization rate, and distributed learning scalability, some frameworks showed excellent learning speed and stable resource management in parallel with large amounts of data, and other frameworks were efficient with lower memory consumption in an environment with small or memory constraints. ##conclusion## This comparison study provides practical guides in selecting frameworks and establishing optimization strategies in consideration of cost and performance in the cloud environment.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",25,1.1859924140007934
DC 모터 제어 시스템에 딥 러닝 기반 제어기를 적용한 방법과 PID 제어기와의 성능 비교 결과를 요약해 주실 수 있나요?,"##제목## 딥 러닝 기반 제어기 설계 및 PID 제어기와의 성능 비교 ##서론## 딥 러닝은 기존 인공신경망보다 은닉층과 뉴런 수를 확장해 복잡한 문제를 해결하도록 고안된 심층 인공신경망 알고리즘이다. 산업 현장에서는 여전히 PID 제어기가 널리 사용되고 있으나, 제어문제에 딥 러닝을 적용한 연구는 부족하다. 본 연구는 DC 모터 제어 시스템에 딥 러닝 제어기를 도입해 PID 제어기 성능을 모방·개선할 수 있는지를 검증하고자 한다. ##본론## 1. 제어기 구조 설계 - 깊은 신경망 중 하나인 Deep Belief Network(DBN)를 사용해 딥 러닝 제어기를 구현 - PID 제어기에 입력되는 참조 신호와 PID 출력값을 학습 데이터로 활용 2. 데이터 수집 및 전처리 - DC 모터 시스템에 다양한 제어 입력을 주어 PID 제어기의 출력 토크 및 속도 응답을 기록 - 입력·출력 쌍을 정규화해 DBN 학습용으로 구성 3. 학습 및 시뮬레이션 - DBN의 가중치를 역전파(backpropagation) 방식으로 최적화하여 PID 동작 특성을 모방 - MATLAB/Simulink 기반 시뮬레이션 환경에서 제안 제어기와 기존 PID 제어기의 응답 비교 4. 성능 비교 결과 - 과도응답 특성(오버슈트, 상승 시간)과 정상상태 오차에서 DBN 제어기가 PID와 유사한 제어 성능 달성 - 일부 실험 조건에서 노이즈 내성 및 비선형 구간 처리 능력이 DBN 제어기에서 더 우수한 경향 관찰 ##결론## 딥 러닝 제어기는 학습된 PID 동작을 효과적으로 모방하면서도 비선형 및 노이즈 환경에서 안정적인 제어 성능을 보였다. 향후 실험 환경 다양화와 하드웨어 구현을 통해 상용 제어기 대체 가능성을 더욱 검증할 필요가 있다.",Can you summarize the performance comparison results with a deep learning -based controller and PID controller?,"##title## Comparison of performance with deep learning -based controller design and PID controller ##introduction## Deep learning is an in -depth artificial neural network algorithm designed to expand the hidden and neurons rather than the existing artificial neural network to solve complex problems. In the industrial field, PID controllers are still widely used, but there is a lack of research with deep learning to control problems. This study aims to verify whether the PID controller performance can be imitated and improved by introducing a deep learning controller into the DC motor control system. ## Main ## 1. Design of controller structure -Dep Belief Network (DBN), one of the deep neural networks, is used to implement a deep learning controller -Use the reference signal and PID output value entered into the PID controller as a learning data 2. Data collection and pretreatment -DC motor system gives a variety of control inputs to record the output torque and speed response of the PID controller. -Normalization of input and output pairs and organized for DBN learning 3. Learning and simulation -It is optimized by the BackPropagation method of the DBN to imitate PID operation characteristics. -Comparing the response between the proposal controller and the existing PID controller in the MATLAB/SIMULINK -based simulation environment 4. Comparison of performance comparisons -DBN controller is similar to PID in transitional response characteristics (overstity, up time) and normal state error. -In some experimental conditions, noise resistance and nonlinear inter -handling capacity observes superior tendency in DBN controllers. ##conclusion## Deep learning controllers effectively imitated the learned PID behavior, while showing stable control performance in nonlinear and noise environments. In the future, it is necessary to further verify the possibility of replacement of commercial controllers by diversifying the experimental environment and implementing hardware.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",26,1.1859924140007934
"DBN 기반 딥 러닝을 이용한 기업부도 예측과 기존 SVM 방법 간의 성능 차이, 특히 부도기업 예측 민감도 향상 결과를 간단히 정리해 주실 수 있나요?","##제목## DBN 기반 딥러닝과 SVM을 활용한 기업부도 예측 성능 비교 ##서론## 기업부도는 국가경제와 이해관계자들에게 심각한 손실을 초래하므로, 이를 정확히 예측하는 연구가 중요하다. 최근 이미지·음성·자연어 처리 분야에서 우수한 성능을 보인 Deep Belief Network(DBN)를 기업부도 예측에 도입하여 기존의 Support Vector Machine(SVM)과 비교 분석을 수행하였다. ##본론## - 연구 데이터 및 변수: 1999~2015년 코스닥·코스피 비금융업종 2,164개 기업(정상 1,669개, 부도 495개)과 한국은행 기업경영분석의 재무비율 변수 활용 - 모델 비교: DBN과 전통적 SVM을 동일 데이터로 학습·검증 - 주요 결과: 전반적 평가척도에서 DBN이 SVM보다 우수한 예측력을 보였으며, 특히 부도기업을 정확히 식별하는 민감도(sensitivity)가 시험 데이터 기준으로 5% 이상 높게 향상됨 ##결론## DBN 기반 딥러닝은 SVM 대비 부도기업 탐지 능력을 크게 개선하여, 기업부도 예측 분야에서 딥러닝 기법의 유용성을 확인시켜 주었다.","Can you briefly summarize the difference in performance differences between predictions and existing SVM methods, especially bankruptcy company prediction sensitivity improvement?","##title## DBN -based deep learning and business departments using SVM are also comparing predictive performance ##introduction## Since corporate bankruptcy causes serious losses to the national economy and stakeholders, research to predict it is important. Recently, the company introduced the Deep Belief Network (DBN), which showed excellent performance in the field of image, voice, and natural language processing, was also introduced to predict the existing Support Vector Machine (SVM). ## Main ## -Data and variable: 1999 ~ 2015 KOSDAQ and KOSDAPS non -financial sectors 2,164 companies (1,669 normal, 495 bankruptcy) -Model Comparison: Learning and verifying DBN and traditional SVM with the same data -Main results: In the overall evaluation scale, DBN showed better predictions than SVM, and in particular, sensitivity that accurately identifies bankruptcy companies is more than 5% higher based on test data. ##conclusion## DBN -based deep learning has greatly improved the detection of bankruptcy companies compared to SVM, and confirmed the usefulness of deep learning techniques in the field of predictions.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",27,1.1859924140007934
비정형 리뷰 데이터를 활용해 고객 평점을 예측하기 위해 설계된 딥 러닝 모델 구조와 주요 실험 결과(정확도·출력 카테고리)를 요약해 주실 수 있나요?,"##제목## 딥러닝 기반 고객평점 예측 모델 요약 ##서론## 온라인 쇼핑몰에서는 사용자가 남긴 비정형 텍스트 리뷰가 구매 결정에 큰 영향을 미치지만, 개인정보 제약으로 일반적인 고객 특성 데이터를 활용하기 어렵다. 본 연구는 리뷰 자체에서 고객 특징을 자동으로 추출해 평점을 예측하는 딥러닝 모델을 제안한다. ##본론## 모델 구조는 텍스트 마이닝 기법을 통해 전처리된 리뷰 텍스트로부터 특성을 추출하고, 다층 퍼셉트론 구조에 입력하도록 설계되었다. 은닉층에는 과적합을 완화하기 위한 Drop-Out을 적용하고, 활성화 함수로는 연산 효율이 높은 ReLU를 사용했다. 출력층은 고객 평점을 ‘좋음’, ‘보통’, ‘나쁨’의 세 가지 카테고리로 분류하도록 구성되었다. 실험 대상은 11번가에서 수집한 화장품 리뷰 데이터이며, 학습된 모델은 실제 입력 평점과 비교해 90%의 분류 정확도를 기록했다. ##결론## 제안된 딥러닝 모델은 비정형 리뷰만으로 고객 평점을 세 단계로 높은 정확도로 예측할 수 있음을 보였으며, 개인정보 없이도 사용자 만족도 분석 및 추천 시스템 등에 활용 가능함을 입증했다.",Can you summarize the deep learning model structure and major experiments designed to predict the customer ratings by utilizing atypical review data?,"##title## Summary of deep learning -based customer rating prediction model ##introduction## In the online shopping mall, the user's unstructured text review has a big impact on the purchase decision, but it is difficult to use general customer characteristics data as a constraint of personal information. This study suggests a deep learning model that automatically extracts customer features and predicts the rating. ## Main ## The model structure is designed to extract the characteristics from the pre -processed review text through the text mining technique and to input it into the multilayer perceptron structure. The hidden layer applied a Drop-out to relieve overpacking, and the activation function used a high computational efficiency. The output layer is composed of three categories: 'good', 'normal' and 'bad'. The experiment target is cosmetics review data collected at 11th Street, and the learned model recorded 90%classification accuracy compared to the actual input rating. ##conclusion## The proposed deep learning model shows that the customer rating can be predicted at three stages with only an atypical review, and proved to be used for user satisfaction analysis and recommendation system without personal information.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",28,1.1859924140007934
"Go 게임에 적용된 심층 학습 기술의 핵심 아이디어와 제안된 CNN 레이어 구성, 실험 비교 결과를 간결하게 정리해 주실 수 있나요?","##제목## 바둑에 적용된 심층 학습 기술 설계 및 성능 비교 ##서론## - Go 게임은 규칙은 단순하지만 조합 수가 방대하여 전통적 알고리즘만으로 최적 수를 탐색하기 어려움 - 딥 러닝, 특히 CNN을 활용해 수읽기와 다음 수 예측 정확도를 높이고자 하는 연구가 주목받고 있음 ##본론## - 핵심 아이디어: 오픈소스 Go 엔진(HuuDucGo, Orego, Fuego)에 심층 학습을 접목하여 다음 착점을 계산 - 제안된 CNN 구조: 5개의 은닉층 중 3개를 컨볼루션 레이어로 구성하고, 나머지 2개는 완전연결층으로 수 평가 수행 - 학습 방법: 대규모 기보 데이터를 이용해 각 네트워크가 정책망(policy network)으로 작동하도록 지도학습 - 실험 결과: HuuDucGo 모델은 Orego 및 Fuego와 비교 시 수렴 속도와 착점 예측 정확도에서 유사한 성능을 보이며, 제안 구조의 실용성 입증 ##결론## - 3개의 CNN 레이어를 포함한 5층 네트워크는 기존 엔진과 동등한 수준의 수읽기 성능을 달성 - Go 게임에 대한 딥 러닝 적용 가능성을 확인했으며, 향후 대용량 연산 및 강화학습 도입으로 추가 성능 향상 여지 존재","Can you briefly summarize the core ideas of in -depth learning technology applied to Go games, the proposed CNN layer configuration and experimental comparison results?","##title## In -depth learning technology design and performance comparison applied to Go ##introduction## -GO game has a simple rules, but the number of combinations is huge, so it is difficult to explore the optimal number with traditional algorithms. -The research to increase the number of reads and the next water prediction accuracy using deep learning, especially CNN, is attracting attention. ## Main ## -Core Ideas: Calculate the next worship by incorporating in -depth learning with open source Go engine (Huuducgo, Orego, Fuego) -CNN structure proposed: 3 out of five hidden layers consists of a confection layer, and the other two are completely connected to the number of numbers. -Learning method: Learning to operate each network with a policy network using large -scale notification data. -The HuuducGo model shows similar performance in convergence speed and accuracy of accuracy when comparing with OREGO and FUEGO. ##conclusion## -The 5th floor network, including three CNN layers, achieves the same level of reading performance as the existing engine. -I have confirmed the possibility of applying deep learning for GO games, and the introduction of large -capacity computing and reinforcement learning in the future","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",29,1.1859924140007934
How would you concisely summarize the strategic landscape and major industry examples that characterize IT convergence developments in Korea?,"##Strategic Landscape and Key Industry Cases of IT Convergence in Korea## ##Introduction## IT convergence in Korea has emerged as a core driver of national growth, combining information technology with traditional industries to foster new markets and enhance competitiveness. Government initiatives launched since 2008 have provided policy frameworks, R&D support and specialized convergence centers to accelerate cross–sector collaboration and standardization efforts. ##Main Body## Strategically, Korea benchmarks international convergence best practices while selectively focusing resources on promising fields such as u-IT, IT/OT and IT/BT fusion. In consumer electronics, LG and Samsung integrate sensors, network connectivity and multimedia platforms to deliver intelligent home appliances and smart displays. Heavy industry player POSCO employs IT to optimize steel production processes and develop smart factory solutions. The power sector’s Advanced Distribution Management System illustrates IT/OT convergence by merging SCADA, automation and global information-sharing functions for real-time grid control. Defense convergence models leverage commercial IT to improve weapon acquisition, command-and-control and logistics through dedicated defense IT convergence centers and new business-model frameworks. In agriculture and environment, smart-farm projects combine IoT sensors with climate control systems to promote low-carbon green growth, while healthcare and sports services use wearable u-IT devices and big-data analytics to enhance rehabilitation and performance monitoring. ##Conclusion## Korea’s IT convergence landscape is characterized by targeted government support, cross-industry standardization and leading examples in electronics, manufacturing, energy, defense and green industries. Sustained success will depend on ecosystem development, talent cultivation and continuous alignment of policy with emerging technological synergies.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",30,1.1859924140007934
Can you provide a brief synthesis of the performance evaluation criteria and standardization framework proposed for u-IT convergence devices?,"##Assessment and Standardization of Performance Criteria for u-IT Convergence Devices## ##Introduction## The rapid evolution of ubiquitous IT technologies has driven the development of convergence devices across communication, broadcasting, portals, content, equipment, and solution domains. To support reliable deployment and market adoption, a structured framework for assessing device performance and ensuring interoperability is essential. ##Main Body## The study first defines u-IT convergence devices and identifies common sensing elements—temperature, pressure, magnetic, optical, gas, and humidity sensors—that underpin their functionality. It then establishes three core evaluation dimensions: technical feasibility (performance and accuracy), economic feasibility (cost and resource efficiency), and management feasibility (maintainability and operational support). Building on these criteria, the research proposes a standardization framework for network-integrated devices, detailing guidelines for certification, interoperability testing, and quality assurance. ##Conclusion## By integrating rigorous performance metrics with a unified standardization approach, this framework fosters consistent certification, enhances device safety and reliability, and lays the groundwork for broader adoption of u-IT convergence systems in a ubiquitous information society.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",31,1.1859924140007934
How would you distill the key design elements and convergence concepts of an IT/OT-based advanced distribution management system?,"##Title## Design Elements and Convergence Principles of an IT/OT-Based Advanced Distribution Management System ##Introduction## Power distribution networks have evolved beyond basic SCADA and automation to embrace Advanced Distribution Management Systems (ADMS) that fuse operational technology (OT) with information technology (IT). This convergence blurs traditional boundaries, promoting interoperability, real-time data exchange and enhanced decision-making across the grid. ##Main Body## Key design elements center on a multi-layered architecture that integrates distribution SCADA for remote monitoring, distribution automation for service restoration and a suite of management applications to optimize performance. Interoperability standards and a data-centric middleware layer ensure seamless communication among sensors, actuators, control centers and enterprise systems. The IT/OT convergence concept drives the joint deployment of ICT capabilities—such as data analytics, enterprise integration and cybersecurity—with OT functions like fault detection, remote control and load management. System configurations typically include distributed field devices connected through resilient, secure communication channels, scalable computing resources for analytics, and modular applications for network modeling, outage management and voltage optimization. ##Conclusion## By tightly integrating IT and OT layers, a converged ADMS delivers real-time visibility, operational agility and higher distribution efficiency. This holistic design approach lays the foundation for smarter, more resilient and adaptive power grids.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",32,1.1859924140007934
Could you outline the principal concerns IT companies face in defense-related IT convergence and the proposed solutions for cost estimation and governance?,"##Key Challenges and Solutions in Defense IT Convergence## ##Introduction## Defense-related IT convergence involves integrating commercial information technologies into military acquisition and operations. While this integration promises enhanced capability and efficiency, IT firms encounter unique hurdles when entering defense projects due to stringent requirements and complex procurement structures. ##Main Body## 1. Role Clarification: IT companies often face ambiguity over their responsibilities in defense programs, stemming from traditional procurement models that favor established defense contractors. Clear definition of tasks, deliverables, and accountability is proposed via standardized role descriptions and contractual frameworks tailored to IT services. 2. Governance and Control Tower: The absence of a centralized oversight entity leads to fragmented decision-making and delayed approvals. Establishing a dedicated defense IT convergence “control tower” can unify stakeholders, streamline processes, and monitor progress through joint military–industry governance boards. 3. Software Cost Estimation: Conventional cost models are ill-suited for software-intensive projects, resulting in budget overruns and disputes. Adopting recognized estimation methodologies—such as COCOMO II or function-point analysis—alongside modular development contracts can yield more realistic forecasts and cost transparency. ##Conclusion## Addressing these concerns through explicit role definitions, a centralized governance structure, and robust software cost-estimation practices enables smoother collaboration between IT firms and defense organizations, ultimately reducing risk and improving project outcomes.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",33,1.1859924140007934
How can you succinctly capture the factors that shape consumer purchase attitudes toward IT-based convergence products and their implications for competitiveness?,"##Title## Factors Influencing Consumer Attitudes toward IT‐Based Convergence Products and Their Competitive Implications ##Introduction## This study examines how consumers’ perceived attitudes toward IT‐based convergence products shape their purchase decisions and explores the strategic implications for firms seeking to strengthen competitiveness in this emerging market. ##Main Body## Grounded in established decision‐making theories, the research formulates and empirically tests hypotheses about key attitude drivers. Perceived usefulness stands out as the dominant factor: when consumers believe that a convergence product offers clear functional benefits and enhances their tasks, they are far more likely to adopt it. Other elements—such as ease of use, technological novelty, and alignment with lifestyle needs—also contribute but to a lesser extent. By measuring these perceptions through surveys and statistical analyses, the study identifies which product attributes most influence consumer attitudes. Armed with these insights, companies can prioritize feature development, tailor communication strategies, and refine pricing models to highlight utility and differentiate offerings. ##Conclusion## Focusing on the utility dimension of convergence products enables firms to cultivate favorable consumer attitudes, paving the way for successful market entry and sustained competitive advantage.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",34,1.1859924140007934
한국 IT융합 신산업 역량강화요인과 이를 도출하기 위한 연구 결과를 간결하게 요약해 주시겠습니까?,"##제목## IT융합 신산업 역량 강화 요인 도출 연구 개요 ##서론## IT는 한국 경제성장과 사회 전반의 혁신을 이끌며 생산성·효율성·편의성을 크게 향상시켜 왔고, 타 산업과의 융합을 통해 새로운 성장 동력으로 부상하였다. 이러한 맥락에서 IT융합 신산업의 경쟁력 강화를 위해 핵심 역량 요인을 과학적으로 도출하는 것이 중요하다. ##본론## 이 연구는 2011년 정책연구에서 학계 및 공공기관 전문가를 대상으로 델파이 기법을 활용하여 IT융합 역량 요소를 도출하고, 이를 기존 선행연구 결과와 비교·분석하여 역량 수준 변화를 평가하였다. 분석 과정에서 전략적 자원 집중, 산·학·연 협력 확대, 표준화 추진, 전문 인력 양성, 정책 지원 체계 구축 등이 핵심 강화 요인으로 식별되었다. 각 요인은 신산업 창출과 지속적 성장에 필요한 기반으로 평가되었으며, 국내외 주요국의 융합 전략과 비교해 볼 때 한국의 강·약점을 객관적으로 파악할 수 있었다. ##결론## 본 연구는 델파이 결과와 비교 분석을 통해 IT융합 신산업 역량 강화의 구체적 방향을 제시하며, 향후 정책 수립과 산업 전략 마련 시 실질적 가이드라인으로 활용될 수 있다.",Can you concernly summarize the factors of strengthening the new IT convergence and the results of the research to derive it?,"##title## IT convergence new industrial capacity strengthening factor derivation research ##introduction## IT has greatly improved productivity, efficiency, and convenience by leading Korea's economic growth and innovation throughout society, and has emerged as a new growth engine through fusion with other industries. In this context, it is important to scientifically derive core competency factors to strengthen the competitiveness of IT convergence new industries. ## Main ## In the 2011 policy study, IT convergence capacity elements were used to use Delphi techniques for academic and public institution experts, and compared with the results of the previous studies. In the analysis process, strategic resources focused, expansion of industry, academia and research cooperation, standardization promotion, fostering professional manpower, and establishing a policy support system were identified as core factors. Each factor was evaluated as the basis for the creation of new industries and continuous growth, and compared to the convergence strategy of major domestic and foreign countries, Korea's strong and weaknesses were objectively identified. ##conclusion## This study suggests a specific direction of strengthening IT convergence new industries by comparative analysis and comparative analysis, and can be used as a practical guideline for future policy establishment and industrial strategy.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",35,1.1859924140007934
IT와 BT 융합 기술의 특성과 특허 분석 결과를 바탕으로 융합 강도와 협력 네트워크를 요약해 주세요.,"##제목## IT와 BT 융합 기술의 특성과 특허 분석 ##서론## 정보기술(IT)과 생명공학(BT)의 융합은 신시장 창출과 기술 혁신을 이끄는 핵심 동력으로 떠오르고 있습니다. 그러나 정량적 데이터에 기반한 IT-BT 융합 정도와 협력 양상에 대한 연구가 부족한 상황입니다. 이에 특허 인용·공동분류 분석을 통해 융합 강도와 관련 조직 간 네트워크를 파악하고자 합니다. ##본론## 1. 분석 방법 - 특허 인용(citation)과 공동분류(co-classification) 정보를 활용해 기술 간 융합 강도를 계량화 - 두 가지 포트폴리오 매트릭스를 개발해 융합 범위와 심도를 시각화 2. 융합 강도 측정 - IT-BT 교차 특허 수와 인용 빈도가 꾸준히 증가, 특히 최근 몇 년간 융합 특허 비중이 크게 확대 - 공동분류 분석 결과, 정보처리 기술과 유전자·단백질 분석 기술 간 상호참조가 빈번 3. 협력 네트워크 - 기업·연구기관·대학 간 특허 공동 출원·인용 네트워크가 형성되어 있으며, 노드 중심성 분석에서 몇몇 주도 기업이 핵심 허브 역할 - BT 분야의 연구집단이 상대적으로 강한 내부 협력망을 구축한 반면, IT 분야는 외부 기관과의 연계가 활발 ##결론## 특허 기반 분석을 통해 IT-BT 융합 기술의 강도가 지속 상승 중임을 확인했으며, 기업·학계·연구소 간 협력 네트워크가 융합 확산의 핵심 축으로 자리매김함을 보여줍니다. 이러한 정량적 증거는 각 조직이 융합 전략 수립과 협업 파트너 발굴 시 유용한 참고자료가 될 것입니다.",Summary the convergence strength and cooperative network based on the characteristics of IT and BT convergence technology and patent analysis results.,"##title## Characteristics and patent analysis of IT and BT convergence technology ##introduction## The convergence of information technology (IT) and biotechnology (BT) is emerging as a core engine for creating new markets and technology innovation. However, there is a lack of research on IT-BT convergence and cooperation patterns based on quantitative data. Therefore, through patented citation and joint classification analysis, we would like to identify the network between related organizations. ## Main ## 1. Analysis method -The use of patent citation and co-classification information by quantifying convergence strength between technologies by utilizing information -Investigating the convergence range and depth by developing two portfolio matrix 2. Fusion strength measurement -The number of IT-BT cross-patents and the frequency of citation steadily increases, especially in recent years, the proportion of convergence patents has increased significantly in recent years -As a result of the joint classification analysis, the mutual reference between the information processing technology and the genetic and protein analysis technology is frequent. 3. Cooperation network -Patent joint application and citation networks between companies, research institutes, and universities are formed, and some leading companies play a core hub role in node -centric analysis. -However, the research group in the BT field has established a relatively strong internal cooperation grid, while the IT field is active in connection with external institutions. ##conclusion## The patent-based analysis confirmed that the intensity of IT-BT convergence technology is continuously rising, and it shows that the cooperative network between corporations, academia and research institutes has become a core axis of convergence proliferation. This quantitative evidence will be a useful reference for each organization when establishing a convergence strategy and finding a collaborative partner.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",36,1.1859924140007934
스마트 농업 분야에서 저탄소 녹색산업 정책을 지원하는 IT 융합 기술 적용 사례와 효과를 요약해 주시겠습니까?,"##제목## 저탄소 녹색산업 정책 지원을 위한 스마트 농업 IT 융합기술 적용 사례와 효과 ##서론## 최근 발리 로드맵 채택으로 개발도상국 역시 온실가스 감축 의무를 지게 되면서 산업 전 분야에서 저탄소 전략이 요구되고 있다. 농업 분야는 기후 변화 대응과 식량 안보를 동시에 해결할 수 있는 핵심 산업으로 주목받고 있으며, 이에 스마트 농업에 IT 융합 기술을 도입하여 저탄소 녹색산업을 육성하려는 정책적 노력이 진행되고 있다. ##본론## 1. 스마트팜 환경제어 시스템: 온·습도, 가스, 광도 센서와 네트워크 기능을 활용해 실시간으로 작물 재배 환경을 모니터링하고 자동으로 관개·환기·조명을 조절함으로써 에너지 소비와 온실가스 배출을 줄인다. 2. 데이터 기반 의사결정: 빅데이터와 시뮬레이터를 결합해 다양한 작물·지역별 생육 조건을 분석하고, 정책 수립 시 과학적 근거를 제공하여 효율적인 자원 배분이 가능하다. 3. 에너지 효율화 및 비용 절감: 네트워크 제어 기술을 적용한 농업용 설비가 전력 사용량을 최적화하고, ICT 기반 원격 관리로 인건비를 절감하여 경제성과 지속가능성을 동시에 높인다. 4. 일자리 창출과 산업 연계: 스마트 농업 시스템 구축을 위한 소프트웨어 개발, 장비 유지보수, 데이터 분석 분야 등 신성장 일자리를 창출하고, 지역 시뮬레이터 기관과 정책 부처의 협업 모델을 제시한다. ##결론## 스마트 농업에 IT 융합 기술을 적용하면 생산성 향상과 온실가스 감축을 동시에 달성할 수 있으며, 데이터 기반의 정책 결정과 신기술 일자리 창출에도 기여한다. 향후 시스템 시뮬레이션 조직과의 연계 강화, 인력 양성, 인프라 확충을 통해 저탄소 녹색산업 정책을 더욱 효과적으로 지원할 수 있다.",Can you summarize the cases and effects of IT convergence technology that supports low -carbon green industry policy in smart agriculture?,"##title## Cases and effects of smart agricultural IT convergence technology for low -carbon green industry policy support ##introduction## With the adoption of Bali Roadmap, developing countries have also been obliged to reduce greenhouse gas emissions, requiring low -carbon strategies in all industries. The agricultural sector is attracting attention as a core industry that can solve both climate change and food security at the same time. Therefore, policy efforts to foster the low -carbon green industry by introducing IT convergence technology to smart agriculture. ## Main ## 1. Smart Farm Environmental Control System: Use the on -humidity, gas, light sensor and network functions to monitor the crop cultivation environment in real time and automatically adjust irrigation, ventilation, and lighting to reduce energy consumption and greenhouse gas emissions. 2. Data -based decision: combining big data and simulators to analyze various crops and regional growth conditions for each crop and region, and provide scientific basis when establishing policies to efficiently distribute resources. 3. Energy efficiency and cost savings: Agricultural facilities using network control technology optimize power consumption and reduce labor costs by ICT -based remote management to increase economic feasibility and sustainability at the same time. 4. Creation of jobs and industrial linkage: Create new growth jobs such as software development, equipment maintenance, and data analysis to build smart agricultural systems, and present collaboration models of local simulator institutions and policy departments. ##conclusion## Applying IT convergence technology to smart agriculture can achieve productivity improvement and greenhouse gas reduction at the same time, and contributes to data -based policy decisions and new technology jobs. In the future, it is possible to more effectively support low -carbon green industry policy by strengthening linkage with system simulation organizations, fostering manpower, and expanding infrastructure.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",37,1.1859924140007934
국방 IT융합 비즈니스 모델 유형과 핵심 프로세스를 간략히 정리해 주세요.,"##제목## 국방 IT융합 비즈니스 모델 유형 및 핵심 프로세스 ##서론## 국방 IT융합은 민간의 첨단 정보기술을 군사 분야에 적용하여 전투력과 운영 효율을 극대화하기 위한 국가 전략이다. 2008년 관련 정책 수립 이후 국방IT융합센터를 중심으로 과제 발굴·기획·실행이 이뤄지면서 다양한 비즈니스 모델이 제시되었다. 본 요약에서는 주요 모델 유형과 이를 추진하기 위한 핵심 프로세스를 정리한다. ##본론## 1. 비즈니스 모델 유형 가. 무기체계 획득·관리: 자산의 설계 단계부터 폐기 단계까지 전 주기를 IT로 통합 관리 나. 군사정보 수집·분석: 빅데이터·AI 기반 정보 통합·분석 플랫폼 구축 다. 군사력 건설(훈련·운영): 가상·증강현실을 활용한 전술훈련 및 원격 지휘통제 체계 라. 자원관리 및 지원: 물류·병참·정비 업무의 실시간 모니터링 및 자동화 2. 핵심 프로세스 1) 요구분석 및 개념정의: 군 전문인력과 협력해 임무별 요구사항 수립 2) 상용기술 탐색·검증: 민간 IT 제품의 적합성 평가 및 시범적용 절차 3) 조달·배치 절차: 국방획득 프로세스에 신속 도입을 위한 시험·인증·조달 경로 확보 4) 통제·조정(컨트롤타워): 융합센터 주관으로 산·학·연 협력과 의사결정 조율 5) 비용 예측 및 성과평가: 소프트웨어 개발비용 합리화와 KPI 기반 결과 측정 ##결론## 국방 IT융합 비즈니스 모델은 임무 영역별 특화된 네 가지 유형으로 구분되며, 이를 실현하기 위해 요구분석에서 성과평가에 이르는 순환적 프로세스를 체계화해야 한다. 이러한 모델과 과정을 일관되게 운영하면 스마트 국방 구현과 함께 국방 산업의 혁신적 성장 동력을 확보할 수 있다.",Please briefly summarize the type of defense IT convergence business model and the core process.,"##title## Defense IT convergence business model type and core process ##introduction## Defense IT convergence is a national strategy to maximize combat and operational efficiency by applying private advanced information technology to the military sector. Since the establishment of relevant policies in 2008, various business models have been proposed with the discovery, planning, and implementation of the Defense IT Convergence Center. This summary summarizes major model types and key processes to promote it. ## Main ## 1. Business model type go. Acquisition and management of the weapon system: Integrated management of the entire period from IT from the design stage of the asset to the disposal stage me. Collection / Analysis of Military Information: Integration and Analysis Platform based on Big Data and AI -based information all. Military power construction (training and operation): Tactical training and remote command control system using virtual and augmented reality la. Resource management and support: real -time monitoring and automation of logistics, logistics, and maintenance work 2. Core process 1) Requirements and Conceptual Affection: In cooperation with military experts, establish requirements for each mission 2) Commercial Technology Search and Verification: Procedure for Evaluation and Pilot Application of Private IT Products 3) Procurement / Placement Procedure: Secure test, certification, and procurement route for rapid introduction to the defense acquisition process 4) Control and adjustment (control tower): Coordination of industrial, academia, research cooperation and decision -making with the organizer of the convergence center 5) Cost prediction and performance evaluation: Rationalization of software development costs and measurement of KPI -based results ##conclusion## Defense IT Convergence Business Models are divided into four types of specialized mission areas, and to realize this, the circular process from requirements analysis to performance evaluation must be systematic. Consistently operating these models and processes can secure innovative growth engines in the defense industry along with the implementation of smart defense.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",38,1.1859924140007934
AHP 방법론을 이용한 에너지-IT 융합기술 도출 과정과 연구 성과를 압축적으로 알려주실 수 있나요?,"##제목## AHP 방법론을 활용한 에너지-IT 융합기술 도출 및 성과 요약 ##서론## 지속적인 에너지 소비 비효율과 환경문제 해결을 위해 에너지-IT(EIT) 융합이 효과적인 대안으로 주목받고 있으나, 국내에서는 스마트그리드 외에 체계적인 기술 선별과 정책적 투자가 미흡한 실정이다. 이에 본 연구는 AHP(Analytic Hierarchy Process) 기법을 통해 융합 기술의 효용성을 정량적으로 분석하고 우선순위를 도출하고자 하였다. ##본론## 1. 평가 체계 구성 - 에너지 저감 분야와 기술별 평가 기준(기술성, 경제성, 경영성 등)을 계층화하여 AHP 모델을 설계하였다. 2. 전문가 설문 및 가중치 산출 - 산업·학계 전문가를 대상으로 설문을 실시해 각 평가 기준의 상대적 중요도를 도출하였다. 3. 융합 분야 우선순위 - 에너지 절감 분야 중 ‘에너지절약형 건물(그린 빌딩)’이 가장 높은 효용성을 보였으며, - 그린 빌딩 내에서는 ‘네트워크 기능을 활용한 건물 내 에너지 소비 장치 제어·모니터링 기술’이 기술성·경제성 부문에서 최고 점수를 획득했다. 4. 정책적 시사점 - 정량적 우선순위는 정부의 에너지 효율화 정책 및 R&D 투자 방향 설정에 기초 자료로 활용될 수 있다. ##결론## AHP 분석 결과, 그린 빌딩 분야의 네트워크 기반 에너지 소비 장치 관리 기술이 국내 EIT 융합의 핵심 과제로 선정되었으며, 이를 바탕으로 국가 에너지 문제 해결과 경쟁력 강화를 위한 정책 결정에 실질적 기여가 가능하다.",Can you inform the energy-IT convergence technology and research results using AHP methodology?,"##title## Energy-IT convergence technology using AHP methodology and summary ##introduction## Energy-IT (EIT) convergence is attracting attention as an effective alternative to solve continuous energy consumption and environmental problems. Therefore, this study was intended to quantitatively analyze the utility of fusion technology and derive priority through the Analytic Hierarchy Process (AHP) technique. ## Main ## 1. Composition of evaluation system -The AHP model was designed by laying the energy reduction field and the evaluation criteria (technical, economic feasibility, management, etc.) by technical reduction. 2. Calculation of expert surveys and weights -The survey was conducted to industrial and academia experts to derive relative importance of each evaluation criteria. 3. Priority in convergence field -In the energy saving field, the 'energy -saving building (green building)' showed the most effective. In the green building, the “Energy Consumption Device Control and Monitoring Technology in Building using Network Functions” scored the highest score in the technical and economic feasibility. 4. Policy implications Quantitative priorities can be used as basic data for the government's energy efficiency policy and R & D investment direction. ##conclusion## As a result of the AHP analysis, the network -based energy consumption management technology in the green building sector was selected as a key task of domestic EIT convergence, and based on this, it is possible to contribute to the policy decision to solve national energy problems and strengthen competitiveness.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",39,1.1859924140007934
How would you concisely summarize the key findings on using machine learning classifiers combined with molecular docking to predict cytochrome P450 ligand interactions?,"##Title## Integrative Machine Learning and Docking Approach for Predicting Cytochrome P450 Ligand Binding ##Introduction## Cytochrome P450 (CYP) enzymes play a central role in the first-phase metabolism of drugs and xenobiotics, making accurate prediction of ligand–CYP interactions critical in early drug development. Traditional experimental screening of potential CYP substrates and inhibitors is time-consuming and resource-intensive. Combining fast, data-driven classification models with molecular docking offers a promising in silico strategy to forecast which compounds are likely to bind specific CYP isoforms. ##Main Body## Four machine learning classifiers—Laplacian-modified naïve Bayesian, random forest, recursive partitioning, and support vector machine—were trained on known ligands of the five major CYP isoenzymes responsible for over 80% of drug metabolism. All models achieved over 80% accuracy, sensitivity, and specificity, alongside statistically significant AUC and Matthews correlation coefficient values, confirming their robust discriminative power. Complementary docking studies then evaluated how representative substrates orient and interact within each CYP active site, predicting plausible binding modes and key contact residues. This dual workflow—classification to flag likely binders followed by docking to characterize their interaction geometries—provides both rapid screening and mechanistic insight. ##Conclusion## By integrating high-performing machine learning classifiers with molecular docking, this approach enables reliable prediction of CYP–ligand interactions and detailed hypotheses on binding mechanisms, streamlining early evaluation of drug candidates and helping prioritize compounds for experimental validation.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",40,1.1859924140007934
Could you outline the main points about the role of large-scale machine learning in bridging database systems and commercial applications?,"##Large-Scale Machine Learning and Commercial Applications## ##Introduction## The integration of machine learning with database technologies has shifted from a purely academic endeavor to a cornerstone of modern commercial and scientific systems. As data volumes grow into the tera-scale range, quality modeling increasingly depends on the ability to process and learn from massive datasets. Bridging database systems and real-world applications therefore requires not only new algorithms but also scalable infrastructures and standardized workflows. ##Main Body## Large-scale machine learning applications today rely on distributed storage and parallel computing frameworks tightly coupled with database engines to handle high-velocity, high-volume data. Typical workflows start with data ingestion and cleaning within a database environment, proceed to feature extraction and model training across compute clusters, and culminate in model deployment back into operational systems for real-time prediction or batch scoring. Current systems support—such as MapReduce, distributed SQL engines, and specialized ML libraries—address many scaling challenges, but critical gaps remain. In particular, there is no universally accepted life-cycle process for productionizing models (akin to CRISP-DM in data mining), leading to ad hoc integration, limited reuse, and operational bottlenecks. Moreover, emerging advances in ML research (e.g., streaming models, adaptive learning) demand new database primitives for incremental updates, low-latency inference, and co-optimization of storage and computation. ##Conclusion## To fully bridge database systems and commercial applications, future work must deliver unified platforms that support both established ML use cases and cutting-edge research. Standardized life-cycle processes, tighter DB-ML integration, and extensible infrastructures will be key to operationalizing large-scale learning at enterprise scale.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",41,1.1859924140007934
What are the core contributions of spatial and temporal adaptation techniques in machine learning–based scheduling knowledge acquisition?,"##Machine Learning–Based Scheduling Knowledge Acquisition with Spatial and Temporal Adaptation## ##Introduction## Effective scheduling in manufacturing relies on dispatching rules that adapt to changing system states over time. Traditional machine learning approaches have focused primarily on temporal adaptation, selecting optimal rules based solely on system state dynamics. Introducing spatial adaptation—where each machine tailors its rule choice by considering neighboring machines—promises further productivity gains. ##Main Body## This study formalizes two adaptation concepts: temporal adaptation (choosing rules as system states evolve) and spatial adaptation (each machine accounts for its own and adjacent machines’ rule effects). To capture these adaptations, the authors propose (1) a Taguchi-based systematic experiment design that incrementally uncovers robust dispatching rule combinations and (2) a coevolutionary genetic algorithm (GA) that evolves flexible rule sets across machine populations. In a stable semiconductor reentrant flow, the Taguchi method identified rule combinations that outperformed heuristics and maintained robustness under noise. For more dynamic fuel-transfer manufacturing, extending Taguchi to spatial–temporal adaptation yielded improved strategies but at considerable computational cost. The coevolutionary GA addresses this by encoding rule options per machine population and introducing a fitness evaluation combining zero-order (baseline performance) and first-order (performance sensitivity) measures; this innovation mitigates interpopulation ripples and speeds convergence. Comparative experiments show the GA delivers high-quality solutions rapidly, while the Taguchi procedure offers valuable insights into decision processes. ##Conclusion## Integrating spatial and temporal adaptations enhances scheduling rule learning by accounting for both dynamic changes and intermachine interactions. The Taguchi approach provides robust, noise-resilient rule combinations and educates experts on decision logic, whereas the coevolutionary GA dramatically reduces learning time and yields flexible, high-performance strategies. Together, these contributions advance automated knowledge acquisition for complex scheduling environments.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",42,1.1859924140007934
How does the audiovisual speech recognition approach integrate hidden Markov models and neural networks to achieve robustness in noisy environments?,"##Audiovisual Speech Recognition Approach## ##Introduction## Audiovisual speech recognition leverages both acoustic signals and visual cues from lip movements to overcome the severe performance drop of conventional audio‐only systems in noisy environments. By treating visual information as a noise‐immune complement to audio, the approach is partitioned into three core components—visual recognition, auditory modeling, and multimodal fusion—to enhance overall robustness. ##Main Body## First, the visual subsystem refines hidden Markov models (HMMs) through a hybrid probabilistic optimization algorithm. It integrates simulated annealing with local search operators to escape local maxima of the likelihood function, ensuring a more global exploration of HMM parameters and faster convergence for modeling lip‐movement sequences. Second, the auditory subsystem extends standard HMMs by explicitly modeling inter‐frame correlations within the speech signal. Instead of treating frames independently, a Gaussian mixture framework captures joint distributions of consecutive feature vectors, and a tailored expectation–maximization procedure estimates parameters that better reflect temporal dependencies, thereby improving noise resilience. Third, the fusion stage employs a neural network that learns to weight the outputs of audio‐only and visual‐only recognizers. Trained on mixed‐noise data without prior noise‐level knowledge, this network dynamically adjusts modality weights to maximize recognition accuracy, producing results that consistently match or exceed the best single‐modality output and exploit cross‐modal synergy. ##Conclusion## By combining globally optimized HMMs for visual processing, inter‐frame‐aware acoustic models, and adaptive neural‐network–based fusion, the audiovisual system achieves robust speech recognition under diverse and unknown noise conditions. This tri-part integration harnesses the complementary strengths of auditory and visual modalities, resulting in significant and reliable performance gains in noisy environments.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",43,1.1859924140007934
What is the essence of applying various machine and deep learning approaches to pharmacogenomics research for antidepressant treatment prediction?,"##Harnessing Machine and Deep Learning in Pharmacogenomics for Antidepressant Response## ##Introduction## Personalizing antidepressant therapy in major depressive disorder relies on identifying genetic and biological markers that predict treatment success. The convergence of machine learning (ML), deep learning (DL), neuroimaging, and multi-omics data has emerged as a transformative approach to uncover the complex patterns driving individual drug response. ##Main Body## Researchers apply a variety of ML algorithms—such as random forests, support vector machines, and neural networks—alongside DL architectures to integrate genomic variants, transcriptomic profiles, and imaging-derived features. These models have successfully predicted patient outcomes, highlighted potential biomarkers, and enhanced patient stratification for specific antidepressants. Neuroimaging pharmacogenomics extends this work by correlating brain activity signatures with genetic data, boosting prediction performance and shedding light on underlying biological mechanisms. However, standardizing heterogeneous datasets, ensuring model interpretability, and overcoming limited sample sizes remain key challenges for broad clinical adoption. ##Conclusion## By melding ML and DL techniques with comprehensive multi-omics and neuroimaging datasets, researchers are forging a path toward more accurate antidepressant response predictions and biomarker discovery. Ongoing improvements in data harmonization and algorithm transparency will further enable truly personalized treatment strategies for patients with depression.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",44,1.1859924140007934
"Laplacian 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신을 활용한 A₃ 아데노신 수용체 조절제 연구의 핵심 성과를 간결하게 정리해 주실 수 있나요?","##제목## A₃ 아데노신 수용체 조절제 연구의 기계학습 및 3D-QSAR 모델 ##서론## A₃ 아데노신 수용체(A₃ AR)는 다양한 질환 치료 타깃으로 부상한 GPCR 계열이며, 효능제와 길항제의 발굴을 위해 초기 단계에서 후보 물질의 활성을 정확히 예측하는 기법이 필요하다. ##본론## - 라플라시안 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신 세 가지 기계학습 기법을 적용해 분류 모델을 구축하였고, 정확도·민감도·특이도가 모두 90% 이상, AUC와 MCC 역시 0.9 이상으로 우수한 성능을 확인했다. - 효능제(agonist)와 길항제(antagonist) 각각에 대해 CoMFA와 CoMSIA 기반 3차원 정량적 구조-활성관계(3D-QSAR) 모델을 개발하여, 교차검증 q²는 효능제에서 0.594(CoMFA)·0.560(CoMSIA), 길항제에서 0.726·0.665, 결정계수 r²는 효능제에서 0.937·0.907, 길항제에서 0.913·0.915로 높은 예측력을 달성했으며 테스트 세트에서도 모두 0.73 이상을 기록했다. - 두 모델 분석을 통해 A₃ AR 작용제·길항제 분류에서 5′-아마이드 위치 수소 결합 공여자 유무가 핵심적인 활성 결정 인자로 작용함을 규명했다. ##결론## 제안된 기계학습 기반 분류기 및 3D-QSAR 모델은 A₃ 아데노신 수용체 조절제의 후보 물질 선별과 신약개발 연구에 실질적인 가이드를 제공할 수 있을 것으로 기대된다.","Can you briefly summarize the core achievements of A₃ adenosine receptor regulator studies using LAPLACIAN deformed Nive Bayes, decision -making trees, and support vector machines?","##title## Machine learning and 3D-QSAAR model of A₃ adenosine receptor regulator study ##introduction## A₃ adenosine receptor (A₃ AR) is a GPCR series that has emerged as a target for treating various diseases, and requires an technique to accurately predict the activity of the candidate material at the initial stage for the discovery of efficacy and antagonists. ## Main ## -The classification model was established by applying three machine learning techniques: La Plazian deformation, nive, and support vector machines, and more than 90% of accuracy, sensitivity, and specificity, and AUC and MCC also confirmed excellent performance of 0.9 or more. -The developed a comfa and comsia-based three-dimensional quantitative structure-active relationship (3D-QSAAR) for each efficacy agonist and antagonist, and the cross-verification Q² is 0.594 (Comfa), 0.560 (COMSIA), and Gil antagonism. 0.726 · 0.665, the crystal coefficient R² achieved high predictions with 0.937 · 0.907 in the efficacy, 0.913 · 0.915 in the antagonist, and more than 0.73 in the test set. -The analysis of the two models identified the A₃ AR agonist and antagonist classification that the 5'-amide position hydrogen bond donor acts as a key activity determinant. ##conclusion## The proposed machine learning-based classifiers and 3D-QSAR models are expected to provide practical guides in selecting candidate materials and researching new drug development of A₃ adenosine receptor regulator.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",45,1.1859924140007934
지식 기반 스케줄링에서 공간적·시간적 적응을 구현하는 기계학습 방법들의 주요 특징을 요약해 주실 수 있나요?,"##제목## 지식 기반 스케줄링에서 공간적·시간적 적응 기계학습 방법의 주요 특징 ##서론## 지식 기반 스케줄링 시스템은 생산 시스템의 동적 상태에 맞춰 작업배정 규칙을 선정하기 위해 기계학습 기법을 활용한다. 기존 연구가 주로 시간적응(temporal adaptation)에 집중해 온 반면, 본 연구는 기계 간 상호작용을 고려하는 공간적용(spatial adaptation)과 이를 시간적응과 융합한 공간-시간적응(spatial-temporal adaptation)을 구현하는 두 가지 방법을 제안한다. ##본론## 첫 번째 방법은 다구치(Taguchi) 실험계획법을 통해 단계별로 각 기계의 최적 작업배정 규칙을 체계적으로 획득하는 방식이다. 반도체 일관가공공정과 연료전송장치 제조시스템에 적용해 휴리스틱 규칙 대비 높은 수행도와 강건성을 확인하였으며, 공간-시간적용으로 확장 시 시스템 상태 변동에 적응한 더욱 향상된 전략을 도출했다. 두 번째 방법은 공진화 유전자 알고리듬(coevolutionary genetic algorithm)을 이용해 각 기계의 규칙 후보 집단을 동시 진화시키며 학습 시간을 단축하고 유연한 전략을 생성하는 기법이다. 개체 적합도 평가는 0계 성능(기존 수행도)과 1계 성능(첫 번째 변화에 대한 기여도)의 함수로 정의하여 심한 변동과 파동효과를 완화하였고, 태그치 방법 대비 빠른 수렴과 양질의 해를 도출함을 실험적으로 입증했다. ##결론## 다구치 실험계획법은 안정적이고 해석 가능한 규칙 조합을 제공하여 전문가 교육에 유리하며, 공진화 유전자 알고리듬은 학습 속도와 유연성 면에서 우수한 성능을 보인다. 두 접근 방식 모두 공간적·시간적응을 통해 생산성 향상에 기여할 수 있는 효과적인 기계학습 기반 지식획득 방안임을 확인하였다.",Can you summarize the main features of machine learning methods that realize spatial and time adaptation in knowledge -based scheduling?,"##title## Main features of spatial and time adaptive machine learning methods in knowledge -based scheduling ##introduction## The knowledge -based scheduling system utilizes machine learning techniques to select a task assignment rules according to the dynamic status of the production system. While existing studies have mainly focused on temporal adaptation, this study suggests two methods that implement spatial adaptation and space-time adaptation and time adaptation that considers the interaction between machines. ## Main ## The first method is to systematically obtain the optimal work assignment rules of each machine in step through the Taguchi Experimental Planning Act. The semiconductor consistency was applied to public and fuel transmission system manufacturing systems to confirm higher performance and strength compared to the Hurricial rules. The second method is a technique for simultaneous evolution of the rules candidate groups of each machine using the CoEVOLUTIONARY Genetic Algorithm, shortening the learning time and creating a flexible strategy. The individual suitability evaluation was defined as a function of 0 -based performance (existing performance) and one -stage performance (contribution to the first change) to alleviate severe fluctuations and wave effects, and demonstrated experimental harm compared to tagging methods. ##conclusion## The Taguchi Experimental Planning Act is advantageous for professional education by providing a stable and interpretable rules combination, and the resonating genetic algorithm is excellent in terms of learning speed and flexibility. Both approaches were confirmed that it was an effective way to acquire knowledge -based knowledge -based knowledge that can contribute to productivity improvement through spatial and time adaptation.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",46,1.1859924140007934
잡음 환경에서 시청각 음성인식의 인식률을 높이기 위해 은닉 마르코프 모델과 신경망 통합 전략이 어떻게 구성되었는지 간략히 설명해 주실 수 있나요?,"##제목## 시청각 음성인식 시스템의 은닉 마르코프 모델 최적화 및 신경망 기반 통합 전략 ##서론## 소음이 심한 환경에서는 음성신호만으로는 인식 성능이 크게 저하되기 때문에, 입술 움직임 등의 시각정보를 함께 활용하는 시청각 음성인식이 주목받고 있다. 본 시스템은 청각·시각 정보를 각각 개선하고, 최종 단계에서 두 정보를 효과적으로 융합하여 잡음 환경에서의 강인한 인식률을 달성하고자 설계되었다. ##본론## 1. 시각 정보 인식을 위한 HMM 확률적 최적화 - 기존 EM(기대-최대) 학습 알고리즘이 지역 최적화에 머무르는 한계를 극복하기 위해, 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질을 도입하였다. - 전역 탐색을 수행함으로써 은닉 마르코프 모델의 파라미터를 확률적으로 최적화하여 수렴 속도와 인식 성능을 동시에 향상시키며, 이 방법의 전역 최적해 수렴 특성을 수학적으로 증명하였다. 2. 청각 정보 인식을 위한 프레임 간 상관관계 모델링 - 음성 신호의 동적 특성을 반영하기 위해, 서로 다른 관측 프레임 간의 결합 확률 분포를 가우시안 혼합 모델로 모델링하였다. - 새로운 EM 기반 학습 알고리즘을 개발하여 프레임 간 조건부 의존성을 효과적으로 학습하고, 잡음 환경에서도 강인한 인식 성능을 확보하였다. 3. 신경회로망을 이용한 시청각 정보 통합 - 시각·청각 정보로부터 독립적으로 얻은 인식 결과를 통합하기 위해, 잡음 종류와 수준에 따라 최적 가중치를 출력할 수 있는 신경망 기반 가중치 학습 방식을 제안하였다. - 이 통합 단계에서 학습된 신경회로망은 단일 정보만을 사용할 때보다 동일하거나 우수한 인식률을 보이며, 두 정보 간 시너지 효과를 극대화한다. - 화자 독립 고립 단어 인식 실험 결과, 다양한 소음 환경에서 기존 시스템 대비 통합 인식 성능이 유의미하게 향상됨을 확인하였다. ##결론## 은닉 마르코프 모델의 확률적 전역 최적화, 프레임 간 상관관계 모델링, 그리고 신경망 기반 정보 융합의 세 가지 전략을 결합함으로써, 잡음이 심한 환경에서도 시청각 음성인식의 인식률을 크게 향상시킬 수 있음을 입증하였다.",Can you briefly explain how the hidden Marov model and the neural network integration strategy were organized to increase the recognition rate of audiovisual voice recognition in the noise environment?,"##title## Optimization of hidden Marcov model and neural network -based integration strategy ##introduction## In an environment where the noise is severe, the voice signal alone decreases the recognition performance, so the audio -voice recognition that utilizes visual information such as lips movements is attracting attention. This system is designed to improve the hearing and visual information, and to effectively combine the two information at the final stage to achieve strong recognition rate in the noise environment. ## Main ## 1. HMM probability optimization for visual information recognition -In order to overcome the limitations of the existing EM (expected-maximum) learning algorithm, we introduced hybrid mock quenching that combines mock quenching annealing and local search operators. -Increasing the parameters of the hidden Marcov model by performing global search, the convergence speed and recognition performance were improved at the same time, and the global optimal resolution convergence characteristics of this method were mathematically proved. 2. Modeling between frames for hearing information recognition -In order to reflect the dynamic characteristics of the voice signal, the combination probability distribution between different observation frames was modeled as a Gaussian mixed model. -The new EM -based learning algorithm has been developed to effectively learn conditional dependence between frames and secure strong recognition performance in noise. 3. Integrate audiovisual information using the neuropathy network -In order to integrate the results obtained independently from visual and hearing information, we proposed a neural network -based weight learning method that can output optimal weight according to the type and level of noise. -The neuropathy network learned in this integration stage shows the same or superior recognition rate than only a single information, and maximizes the synergy effect between the two information. As a result of the speaker independent isolation word recognition experiment, it was confirmed that the integrated recognition performance was significantly improved compared to the existing system in various noise environments. ##conclusion## By combining the three strategies of the probabilistic global optimization of the hidden Marcof model, the correlation between the frame, and the neural network -based information convergence, it proved to greatly improve the recognition rate of audiovisual voice recognition even in a noise environment.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",47,1.1859924140007934
Particle Swarm Optimization을 이용해 퍼지 Extreme Learning Machine의 활성화 함수 파라미터를 최적화하는 기법의 핵심 원리를 요약해 주실 수 있나요?,"##제목## PSO 기반 퍼지 Extreme Learning Machine 활성화 함수 파라미터 최적화 기법 ##서론## Extreme Learning Machine(ELM)은 전형적인 신경망 대비 학습 속도가 매우 빠르지만, 활성화 함수 파라미터를 일괄 선정할 경우 성능이 제한될 수 있다. 여기에 전문가 언어 정보 표현에 유리한 퍼지 이론을 결합한 퍼지 ELM은 활성화 함수 설계의 자유도를 높이지만, 적절한 파라미터 탐색이 필요하다. 따라서 본 기법은 Particle Swarm Optimization(PSO)을 통해 퍼지 ELM의 활성화 함수 파라미터를 자동으로 최적화하고자 한다. ##본론## 먼저, 기존 시그모이드 함수 대신 퍼지 C-평균(Fuzzy C-Means) 클러스터링 알고리즘에서 도출한 활성화 레벨 함수를 사용하여 퍼지 ELM의 은닉층 출력을 정의한다. 다음으로, PSO 알고리즘을 적용하여 클러스터 중심과 퍼지 지수 등 활성화 함수의 핵심 파라미터를 탐색한다. PSO는 개체(입자)들의 군집 행동을 모방하여 전역 최적해로 빠르게 수렴하며, 반복 평가를 통해 최적의 파라미터 조합을 찾는다. 마지막으로, 다양한 머신러닝 데이터셋을 활용해 최적화 전후의 분류 성능 변화를 비교·검증한다. ##결론## PSO를 통한 활성화 함수 파라미터 자동 최적화는 퍼지 ELM의 분류 정확도와 일반화 성능을 모두 개선시키며, 반복적인 휴리스틱 설정 과정을 줄여 실용적인 모델 설계를 가능하게 한다.",없음,"##title## PSO -based fuzzy extreme learning machine activation function parameter optimization technique ##introduction## EXTREME Learning Machine (ELM) has a very fast learning speed compared to typical neural networks, but performance can be limited by selecting activation function parameters. In addition, Fuzzy ELM, which combines fuzzy theory advantageous for expert language information, increases the freedom of activation function design, but requires appropriate parameter search. Therefore, this technique intends to automatically optimize the activation function parameters of Fuzzy ELM through Particle Swarm Optimization (PSO). ## Main ## First, it defines the hinting layer of the fuzzy ELM using the activation level function derived from the Fuzzy C-MeanS clustering algorithm instead of the existing sigmoid function. Next, the PSO algorithm is applied to explore the core parameters of the activation function such as the cluster center and the fuzzy index. The PSO imitates the clustering behavior of the individuals (particles) and converges quickly to the global optimal year, and finds an optimal parameter combination through repeated evaluation. Finally, it uses various machine learning datasets to compare and verify the classification performance change before and after optimization. ##conclusion## Automatic optimization of activation function parameters through PSO improves both the classification accuracy and generalization of the purge ELM, and reduces the repetitive heuristic setting process to enable practical model design.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",48,1.1859924140007934
Lifelong Machine Learning 앙상블 방식으로 스팸 메시지 필터링 성능을 개선한 방법의 주요 아이디어와 장점을 간결하게 제시해 주실 수 있나요?,"##제목## Lifelong Machine Learning과 나이브 베이즈 앙상블을 이용한 스팸 메시지 필터링 ##서론## 스팸 문자는 끊임없이 새로운 단어와 패턴을 적용해 기존 필터를 우회하므로, 고정된 학습 모델만으로는 적절히 대응하기 어렵다. 이러한 한계를 극복하기 위해 과거 지식을 누적·활용하며 지속 학습하는 Lifelong Machine Learning(LLML) 개념이 도입되었다. ##본론## 제안 기법은 문서 분류에 널리 사용되는 나이브 베이즈 분류기와 LLML의 ELLA 모델을 앙상블로 결합한다. LLML은 이전 학습에서 획득한 특성·패턴 정보를 새로운 데이터에 전이해 빠르게 적응하고, 나이브 베이즈는 낮은 계산 복잡도로 실시간 필터링에 적합하다. 앙상블 구조를 통해 두 모델의 장점을 동시에 활용함으로써, 신규 스팸 단어·패턴에도 높은 민감도와 정확도를 유지할 수 있다. ##결론## 과거 학습 경험을 지속적으로 보존·활용하는 LLML 기반 앙상블은 스팸 필터링의 적응성을 대폭 향상시키며, 변화하는 스팸 유형에 효과적으로 대응할 수 있다.","Lifelong Machine Learning ensemble, can you provide a concise of the main ideas and advantages of the method that improves spam message filtering performance?","##title## Lifelong Machine Learning and Spam Message Filtering using Nive Bayes Ensemble ##introduction## Spam characters are constantly bypassing existing filters by applying new words and patterns, so it is difficult to respond properly with a fixed learning model alone. In order to overcome these limitations, the concept of LIFELONG MACHINE Learning (LLML), which cumulates and utilizes past knowledge, has been introduced. ## Main ## The proposal technique combines the Nive Bayes classifier and the ELLA model of LLML, which are widely used in document classification, with ensemble. LLML is quickly adapted to the new data by transferring the characteristics and pattern information obtained from previous learning, and Nive Bayes is suitable for real -time filtering with low computation complexity. By using the advantages of the two models at the same time through the ensemble structure, it is possible to maintain high sensitivity and accuracy in new spam words and patterns. ##conclusion## LLML -based ensemble, which continuously preserves and utilizes past learning experiences, greatly improves the adaptability of spam filtering and can effectively respond to changing spam types.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",49,1.1859924140007934
